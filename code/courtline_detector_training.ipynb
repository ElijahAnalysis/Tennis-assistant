{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7ef7f25-563e-4bed-8ed0-e912e96f7185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from scipy import stats\n",
    "from scipy.stats import randint, uniform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bcde2a5a-721f-4d5a-a33f-a5569412dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1af8e9ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitems\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'items'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import cv2\n",
    "import items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4c8a6e-f85e-4879-b63e-59170d32f3ef",
   "metadata": {},
   "source": [
    "## IMPORT & EXPLORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57aa93f9-e3ec-4385-a9d7-55b930ddeb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeypointsDataset(Dataset):\n",
    "    def __init__(self, img_dir, data_file):\n",
    "        self.img_dir = img_dir\n",
    "        with open(data_file, \"r\") as f:\n",
    "            self.data = json.load(f)\n",
    "        \n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        img = cv2.imread(f\"{self.img_dir}/{item['id']}.png\")\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = self.transforms(img)\n",
    "\n",
    "        kps = np.array(item['kps']).flatten()\n",
    "        kps = kps.astype(np.float32)\n",
    "\n",
    "        kps[::2] *= 224.0 / w  # Adjust x coordinates\n",
    "        kps[1::2] *= 224.0 / h  # Adjust y coordinates\n",
    "\n",
    "        return img, kps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72736b07-5386-4eb8-b083-5899ed22af59",
   "metadata": {},
   "outputs": [],
   "source": [
    "cour_keypoints_dataset_train = KeypointsDataset(img_dir = r\"C:\\Users\\User\\Downloads\\tennis_court_det_dataset\\data\\images\",\n",
    "                                                data_file = r\"C:\\Users\\User\\Downloads\\tennis_court_det_dataset\\data\\data_train.json\" )\n",
    "\n",
    "cour_keypoints_dataset_val = KeypointsDataset(img_dir = r\"C:\\Users\\User\\Downloads\\tennis_court_det_dataset\\data\\images\",\n",
    "                                              data_file = r\"C:\\Users\\User\\Downloads\\tennis_court_det_dataset\\data\\data_val.json\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a3c80c12-b8f5-45a8-88fe-c23ae9e2ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cour_keypoints_train_dataloader = DataLoader( cour_keypoints_dataset_train, batch_size = 32, drop_last = True )\n",
    "cour_keypoints_val_dataloader = DataLoader( cour_keypoints_dataset_val, batch_size = 32, drop_last = True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3490988-ed9a-4201-bac9-89fd8784c184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.6898, -1.3473, -1.6384,  ..., -1.3644, -1.4158, -1.5870],\n",
       "          [-1.3473, -1.2103, -0.9534,  ..., -1.0048, -1.1418, -1.2959],\n",
       "          [-1.0219, -1.0733, -1.1760,  ..., -1.3302, -1.3130, -1.4500],\n",
       "          ...,\n",
       "          [-1.3302, -0.9363, -0.9192,  ..., -1.1418, -1.1247, -1.2103],\n",
       "          [-1.0733, -0.6452, -0.8678,  ..., -1.1247, -1.1247, -1.2103],\n",
       "          [-1.3987, -0.9877, -0.7137,  ..., -1.1418, -1.1418, -1.2274]],\n",
       " \n",
       "         [[-1.5105, -1.1604, -1.5105,  ..., -1.3004, -1.3179, -1.4930],\n",
       "          [-1.1779, -1.0378, -0.8102,  ..., -0.9153, -1.0378, -1.1954],\n",
       "          [-0.9328, -0.9853, -1.0903,  ..., -1.2304, -1.1779, -1.3179],\n",
       "          ...,\n",
       "          [-1.4930, -0.6527, -0.0399,  ..., -0.1099, -0.1450, -0.3025],\n",
       "          [-1.2479, -0.6001, -0.1275,  ..., -0.1099, -0.1450, -0.3200],\n",
       "          [-1.4230, -0.9503, -0.0924,  ..., -0.1275, -0.1450, -0.3200]],\n",
       " \n",
       "         [[-1.2990, -0.9504, -1.2816,  ..., -1.1421, -1.1770, -1.3513],\n",
       "          [-0.9504, -0.7936, -0.5670,  ..., -0.7587, -0.8807, -1.0376],\n",
       "          [-0.6193, -0.6715, -0.7936,  ..., -1.0376, -1.0027, -1.1421],\n",
       "          ...,\n",
       "          [-1.1596, -0.5844,  0.2696,  ...,  0.2522,  0.2522,  0.1128],\n",
       "          [-0.3927, -0.2010,  0.2522,  ...,  0.2696,  0.2696,  0.1302],\n",
       "          [-0.1312, -0.0441,  0.4265,  ...,  0.2871,  0.2696,  0.1128]]]),\n",
       " array([ 80.325   ,  65.64445 , 144.55    ,  65.64445 ,  54.774998,\n",
       "        169.86667 , 167.3     , 169.86667 ,  88.375   ,  65.64445 ,\n",
       "         68.95    , 169.86667 , 136.5     ,  65.64445 , 153.3     ,\n",
       "        169.86667 ,  85.575   ,  80.88889 , 138.95    ,  80.88889 ,\n",
       "         75.6     , 134.0889  , 147.525   , 133.77779 , 112.174995,\n",
       "         80.88889 , 111.475   , 133.77779 ], dtype=float32))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cour_keypoints_dataset_train.__getitem__(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f077d1",
   "metadata": {},
   "source": [
    "## MODEL BUILD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bbe9d6",
   "metadata": {},
   "source": [
    "#### ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e421fdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8d3e977a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_CudaDeviceProperties(name='NVIDIA GeForce RTX 3050 Laptop GPU', major=8, minor=6, total_memory=4095MB, multi_processor_count=16, uuid=15678e8c-abb7-821b-a8bf-1798d0455d2e, L2_cache_size=1MB)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_properties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ed000605-1800-4380-bcd1-3e11526f0c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "efficientnetb0 = models.efficientnet_b0(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6705ef55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (8): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=True)\n",
       "    (1): Linear(in_features=1280, out_features=28, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnetb0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7fbbef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "in_features = efficientnetb0.classifier[1].in_features\n",
    "efficientnetb0.classifier[1] = torch.nn.Linear(in_features, 14 * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c4459521",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnetb0 = efficientnetb0.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8a687aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]             864\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
      "              SiLU-3         [-1, 32, 112, 112]               0\n",
      "            Conv2d-4         [-1, 32, 112, 112]             288\n",
      "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
      "              SiLU-6         [-1, 32, 112, 112]               0\n",
      " AdaptiveAvgPool2d-7             [-1, 32, 1, 1]               0\n",
      "            Conv2d-8              [-1, 8, 1, 1]             264\n",
      "              SiLU-9              [-1, 8, 1, 1]               0\n",
      "           Conv2d-10             [-1, 32, 1, 1]             288\n",
      "          Sigmoid-11             [-1, 32, 1, 1]               0\n",
      "SqueezeExcitation-12         [-1, 32, 112, 112]               0\n",
      "           Conv2d-13         [-1, 16, 112, 112]             512\n",
      "      BatchNorm2d-14         [-1, 16, 112, 112]              32\n",
      "           MBConv-15         [-1, 16, 112, 112]               0\n",
      "           Conv2d-16         [-1, 96, 112, 112]           1,536\n",
      "      BatchNorm2d-17         [-1, 96, 112, 112]             192\n",
      "             SiLU-18         [-1, 96, 112, 112]               0\n",
      "           Conv2d-19           [-1, 96, 56, 56]             864\n",
      "      BatchNorm2d-20           [-1, 96, 56, 56]             192\n",
      "             SiLU-21           [-1, 96, 56, 56]               0\n",
      "AdaptiveAvgPool2d-22             [-1, 96, 1, 1]               0\n",
      "           Conv2d-23              [-1, 4, 1, 1]             388\n",
      "             SiLU-24              [-1, 4, 1, 1]               0\n",
      "           Conv2d-25             [-1, 96, 1, 1]             480\n",
      "          Sigmoid-26             [-1, 96, 1, 1]               0\n",
      "SqueezeExcitation-27           [-1, 96, 56, 56]               0\n",
      "           Conv2d-28           [-1, 24, 56, 56]           2,304\n",
      "      BatchNorm2d-29           [-1, 24, 56, 56]              48\n",
      "           MBConv-30           [-1, 24, 56, 56]               0\n",
      "           Conv2d-31          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-32          [-1, 144, 56, 56]             288\n",
      "             SiLU-33          [-1, 144, 56, 56]               0\n",
      "           Conv2d-34          [-1, 144, 56, 56]           1,296\n",
      "      BatchNorm2d-35          [-1, 144, 56, 56]             288\n",
      "             SiLU-36          [-1, 144, 56, 56]               0\n",
      "AdaptiveAvgPool2d-37            [-1, 144, 1, 1]               0\n",
      "           Conv2d-38              [-1, 6, 1, 1]             870\n",
      "             SiLU-39              [-1, 6, 1, 1]               0\n",
      "           Conv2d-40            [-1, 144, 1, 1]           1,008\n",
      "          Sigmoid-41            [-1, 144, 1, 1]               0\n",
      "SqueezeExcitation-42          [-1, 144, 56, 56]               0\n",
      "           Conv2d-43           [-1, 24, 56, 56]           3,456\n",
      "      BatchNorm2d-44           [-1, 24, 56, 56]              48\n",
      "  StochasticDepth-45           [-1, 24, 56, 56]               0\n",
      "           MBConv-46           [-1, 24, 56, 56]               0\n",
      "           Conv2d-47          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-48          [-1, 144, 56, 56]             288\n",
      "             SiLU-49          [-1, 144, 56, 56]               0\n",
      "           Conv2d-50          [-1, 144, 28, 28]           3,600\n",
      "      BatchNorm2d-51          [-1, 144, 28, 28]             288\n",
      "             SiLU-52          [-1, 144, 28, 28]               0\n",
      "AdaptiveAvgPool2d-53            [-1, 144, 1, 1]               0\n",
      "           Conv2d-54              [-1, 6, 1, 1]             870\n",
      "             SiLU-55              [-1, 6, 1, 1]               0\n",
      "           Conv2d-56            [-1, 144, 1, 1]           1,008\n",
      "          Sigmoid-57            [-1, 144, 1, 1]               0\n",
      "SqueezeExcitation-58          [-1, 144, 28, 28]               0\n",
      "           Conv2d-59           [-1, 40, 28, 28]           5,760\n",
      "      BatchNorm2d-60           [-1, 40, 28, 28]              80\n",
      "           MBConv-61           [-1, 40, 28, 28]               0\n",
      "           Conv2d-62          [-1, 240, 28, 28]           9,600\n",
      "      BatchNorm2d-63          [-1, 240, 28, 28]             480\n",
      "             SiLU-64          [-1, 240, 28, 28]               0\n",
      "           Conv2d-65          [-1, 240, 28, 28]           6,000\n",
      "      BatchNorm2d-66          [-1, 240, 28, 28]             480\n",
      "             SiLU-67          [-1, 240, 28, 28]               0\n",
      "AdaptiveAvgPool2d-68            [-1, 240, 1, 1]               0\n",
      "           Conv2d-69             [-1, 10, 1, 1]           2,410\n",
      "             SiLU-70             [-1, 10, 1, 1]               0\n",
      "           Conv2d-71            [-1, 240, 1, 1]           2,640\n",
      "          Sigmoid-72            [-1, 240, 1, 1]               0\n",
      "SqueezeExcitation-73          [-1, 240, 28, 28]               0\n",
      "           Conv2d-74           [-1, 40, 28, 28]           9,600\n",
      "      BatchNorm2d-75           [-1, 40, 28, 28]              80\n",
      "  StochasticDepth-76           [-1, 40, 28, 28]               0\n",
      "           MBConv-77           [-1, 40, 28, 28]               0\n",
      "           Conv2d-78          [-1, 240, 28, 28]           9,600\n",
      "      BatchNorm2d-79          [-1, 240, 28, 28]             480\n",
      "             SiLU-80          [-1, 240, 28, 28]               0\n",
      "           Conv2d-81          [-1, 240, 14, 14]           2,160\n",
      "      BatchNorm2d-82          [-1, 240, 14, 14]             480\n",
      "             SiLU-83          [-1, 240, 14, 14]               0\n",
      "AdaptiveAvgPool2d-84            [-1, 240, 1, 1]               0\n",
      "           Conv2d-85             [-1, 10, 1, 1]           2,410\n",
      "             SiLU-86             [-1, 10, 1, 1]               0\n",
      "           Conv2d-87            [-1, 240, 1, 1]           2,640\n",
      "          Sigmoid-88            [-1, 240, 1, 1]               0\n",
      "SqueezeExcitation-89          [-1, 240, 14, 14]               0\n",
      "           Conv2d-90           [-1, 80, 14, 14]          19,200\n",
      "      BatchNorm2d-91           [-1, 80, 14, 14]             160\n",
      "           MBConv-92           [-1, 80, 14, 14]               0\n",
      "           Conv2d-93          [-1, 480, 14, 14]          38,400\n",
      "      BatchNorm2d-94          [-1, 480, 14, 14]             960\n",
      "             SiLU-95          [-1, 480, 14, 14]               0\n",
      "           Conv2d-96          [-1, 480, 14, 14]           4,320\n",
      "      BatchNorm2d-97          [-1, 480, 14, 14]             960\n",
      "             SiLU-98          [-1, 480, 14, 14]               0\n",
      "AdaptiveAvgPool2d-99            [-1, 480, 1, 1]               0\n",
      "          Conv2d-100             [-1, 20, 1, 1]           9,620\n",
      "            SiLU-101             [-1, 20, 1, 1]               0\n",
      "          Conv2d-102            [-1, 480, 1, 1]          10,080\n",
      "         Sigmoid-103            [-1, 480, 1, 1]               0\n",
      "SqueezeExcitation-104          [-1, 480, 14, 14]               0\n",
      "          Conv2d-105           [-1, 80, 14, 14]          38,400\n",
      "     BatchNorm2d-106           [-1, 80, 14, 14]             160\n",
      " StochasticDepth-107           [-1, 80, 14, 14]               0\n",
      "          MBConv-108           [-1, 80, 14, 14]               0\n",
      "          Conv2d-109          [-1, 480, 14, 14]          38,400\n",
      "     BatchNorm2d-110          [-1, 480, 14, 14]             960\n",
      "            SiLU-111          [-1, 480, 14, 14]               0\n",
      "          Conv2d-112          [-1, 480, 14, 14]           4,320\n",
      "     BatchNorm2d-113          [-1, 480, 14, 14]             960\n",
      "            SiLU-114          [-1, 480, 14, 14]               0\n",
      "AdaptiveAvgPool2d-115            [-1, 480, 1, 1]               0\n",
      "          Conv2d-116             [-1, 20, 1, 1]           9,620\n",
      "            SiLU-117             [-1, 20, 1, 1]               0\n",
      "          Conv2d-118            [-1, 480, 1, 1]          10,080\n",
      "         Sigmoid-119            [-1, 480, 1, 1]               0\n",
      "SqueezeExcitation-120          [-1, 480, 14, 14]               0\n",
      "          Conv2d-121           [-1, 80, 14, 14]          38,400\n",
      "     BatchNorm2d-122           [-1, 80, 14, 14]             160\n",
      " StochasticDepth-123           [-1, 80, 14, 14]               0\n",
      "          MBConv-124           [-1, 80, 14, 14]               0\n",
      "          Conv2d-125          [-1, 480, 14, 14]          38,400\n",
      "     BatchNorm2d-126          [-1, 480, 14, 14]             960\n",
      "            SiLU-127          [-1, 480, 14, 14]               0\n",
      "          Conv2d-128          [-1, 480, 14, 14]          12,000\n",
      "     BatchNorm2d-129          [-1, 480, 14, 14]             960\n",
      "            SiLU-130          [-1, 480, 14, 14]               0\n",
      "AdaptiveAvgPool2d-131            [-1, 480, 1, 1]               0\n",
      "          Conv2d-132             [-1, 20, 1, 1]           9,620\n",
      "            SiLU-133             [-1, 20, 1, 1]               0\n",
      "          Conv2d-134            [-1, 480, 1, 1]          10,080\n",
      "         Sigmoid-135            [-1, 480, 1, 1]               0\n",
      "SqueezeExcitation-136          [-1, 480, 14, 14]               0\n",
      "          Conv2d-137          [-1, 112, 14, 14]          53,760\n",
      "     BatchNorm2d-138          [-1, 112, 14, 14]             224\n",
      "          MBConv-139          [-1, 112, 14, 14]               0\n",
      "          Conv2d-140          [-1, 672, 14, 14]          75,264\n",
      "     BatchNorm2d-141          [-1, 672, 14, 14]           1,344\n",
      "            SiLU-142          [-1, 672, 14, 14]               0\n",
      "          Conv2d-143          [-1, 672, 14, 14]          16,800\n",
      "     BatchNorm2d-144          [-1, 672, 14, 14]           1,344\n",
      "            SiLU-145          [-1, 672, 14, 14]               0\n",
      "AdaptiveAvgPool2d-146            [-1, 672, 1, 1]               0\n",
      "          Conv2d-147             [-1, 28, 1, 1]          18,844\n",
      "            SiLU-148             [-1, 28, 1, 1]               0\n",
      "          Conv2d-149            [-1, 672, 1, 1]          19,488\n",
      "         Sigmoid-150            [-1, 672, 1, 1]               0\n",
      "SqueezeExcitation-151          [-1, 672, 14, 14]               0\n",
      "          Conv2d-152          [-1, 112, 14, 14]          75,264\n",
      "     BatchNorm2d-153          [-1, 112, 14, 14]             224\n",
      " StochasticDepth-154          [-1, 112, 14, 14]               0\n",
      "          MBConv-155          [-1, 112, 14, 14]               0\n",
      "          Conv2d-156          [-1, 672, 14, 14]          75,264\n",
      "     BatchNorm2d-157          [-1, 672, 14, 14]           1,344\n",
      "            SiLU-158          [-1, 672, 14, 14]               0\n",
      "          Conv2d-159          [-1, 672, 14, 14]          16,800\n",
      "     BatchNorm2d-160          [-1, 672, 14, 14]           1,344\n",
      "            SiLU-161          [-1, 672, 14, 14]               0\n",
      "AdaptiveAvgPool2d-162            [-1, 672, 1, 1]               0\n",
      "          Conv2d-163             [-1, 28, 1, 1]          18,844\n",
      "            SiLU-164             [-1, 28, 1, 1]               0\n",
      "          Conv2d-165            [-1, 672, 1, 1]          19,488\n",
      "         Sigmoid-166            [-1, 672, 1, 1]               0\n",
      "SqueezeExcitation-167          [-1, 672, 14, 14]               0\n",
      "          Conv2d-168          [-1, 112, 14, 14]          75,264\n",
      "     BatchNorm2d-169          [-1, 112, 14, 14]             224\n",
      " StochasticDepth-170          [-1, 112, 14, 14]               0\n",
      "          MBConv-171          [-1, 112, 14, 14]               0\n",
      "          Conv2d-172          [-1, 672, 14, 14]          75,264\n",
      "     BatchNorm2d-173          [-1, 672, 14, 14]           1,344\n",
      "            SiLU-174          [-1, 672, 14, 14]               0\n",
      "          Conv2d-175            [-1, 672, 7, 7]          16,800\n",
      "     BatchNorm2d-176            [-1, 672, 7, 7]           1,344\n",
      "            SiLU-177            [-1, 672, 7, 7]               0\n",
      "AdaptiveAvgPool2d-178            [-1, 672, 1, 1]               0\n",
      "          Conv2d-179             [-1, 28, 1, 1]          18,844\n",
      "            SiLU-180             [-1, 28, 1, 1]               0\n",
      "          Conv2d-181            [-1, 672, 1, 1]          19,488\n",
      "         Sigmoid-182            [-1, 672, 1, 1]               0\n",
      "SqueezeExcitation-183            [-1, 672, 7, 7]               0\n",
      "          Conv2d-184            [-1, 192, 7, 7]         129,024\n",
      "     BatchNorm2d-185            [-1, 192, 7, 7]             384\n",
      "          MBConv-186            [-1, 192, 7, 7]               0\n",
      "          Conv2d-187           [-1, 1152, 7, 7]         221,184\n",
      "     BatchNorm2d-188           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-189           [-1, 1152, 7, 7]               0\n",
      "          Conv2d-190           [-1, 1152, 7, 7]          28,800\n",
      "     BatchNorm2d-191           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-192           [-1, 1152, 7, 7]               0\n",
      "AdaptiveAvgPool2d-193           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-194             [-1, 48, 1, 1]          55,344\n",
      "            SiLU-195             [-1, 48, 1, 1]               0\n",
      "          Conv2d-196           [-1, 1152, 1, 1]          56,448\n",
      "         Sigmoid-197           [-1, 1152, 1, 1]               0\n",
      "SqueezeExcitation-198           [-1, 1152, 7, 7]               0\n",
      "          Conv2d-199            [-1, 192, 7, 7]         221,184\n",
      "     BatchNorm2d-200            [-1, 192, 7, 7]             384\n",
      " StochasticDepth-201            [-1, 192, 7, 7]               0\n",
      "          MBConv-202            [-1, 192, 7, 7]               0\n",
      "          Conv2d-203           [-1, 1152, 7, 7]         221,184\n",
      "     BatchNorm2d-204           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-205           [-1, 1152, 7, 7]               0\n",
      "          Conv2d-206           [-1, 1152, 7, 7]          28,800\n",
      "     BatchNorm2d-207           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-208           [-1, 1152, 7, 7]               0\n",
      "AdaptiveAvgPool2d-209           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-210             [-1, 48, 1, 1]          55,344\n",
      "            SiLU-211             [-1, 48, 1, 1]               0\n",
      "          Conv2d-212           [-1, 1152, 1, 1]          56,448\n",
      "         Sigmoid-213           [-1, 1152, 1, 1]               0\n",
      "SqueezeExcitation-214           [-1, 1152, 7, 7]               0\n",
      "          Conv2d-215            [-1, 192, 7, 7]         221,184\n",
      "     BatchNorm2d-216            [-1, 192, 7, 7]             384\n",
      " StochasticDepth-217            [-1, 192, 7, 7]               0\n",
      "          MBConv-218            [-1, 192, 7, 7]               0\n",
      "          Conv2d-219           [-1, 1152, 7, 7]         221,184\n",
      "     BatchNorm2d-220           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-221           [-1, 1152, 7, 7]               0\n",
      "          Conv2d-222           [-1, 1152, 7, 7]          28,800\n",
      "     BatchNorm2d-223           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-224           [-1, 1152, 7, 7]               0\n",
      "AdaptiveAvgPool2d-225           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-226             [-1, 48, 1, 1]          55,344\n",
      "            SiLU-227             [-1, 48, 1, 1]               0\n",
      "          Conv2d-228           [-1, 1152, 1, 1]          56,448\n",
      "         Sigmoid-229           [-1, 1152, 1, 1]               0\n",
      "SqueezeExcitation-230           [-1, 1152, 7, 7]               0\n",
      "          Conv2d-231            [-1, 192, 7, 7]         221,184\n",
      "     BatchNorm2d-232            [-1, 192, 7, 7]             384\n",
      " StochasticDepth-233            [-1, 192, 7, 7]               0\n",
      "          MBConv-234            [-1, 192, 7, 7]               0\n",
      "          Conv2d-235           [-1, 1152, 7, 7]         221,184\n",
      "     BatchNorm2d-236           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-237           [-1, 1152, 7, 7]               0\n",
      "          Conv2d-238           [-1, 1152, 7, 7]          10,368\n",
      "     BatchNorm2d-239           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-240           [-1, 1152, 7, 7]               0\n",
      "AdaptiveAvgPool2d-241           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-242             [-1, 48, 1, 1]          55,344\n",
      "            SiLU-243             [-1, 48, 1, 1]               0\n",
      "          Conv2d-244           [-1, 1152, 1, 1]          56,448\n",
      "         Sigmoid-245           [-1, 1152, 1, 1]               0\n",
      "SqueezeExcitation-246           [-1, 1152, 7, 7]               0\n",
      "          Conv2d-247            [-1, 320, 7, 7]         368,640\n",
      "     BatchNorm2d-248            [-1, 320, 7, 7]             640\n",
      "          MBConv-249            [-1, 320, 7, 7]               0\n",
      "          Conv2d-250           [-1, 1280, 7, 7]         409,600\n",
      "     BatchNorm2d-251           [-1, 1280, 7, 7]           2,560\n",
      "            SiLU-252           [-1, 1280, 7, 7]               0\n",
      "AdaptiveAvgPool2d-253           [-1, 1280, 1, 1]               0\n",
      "         Dropout-254                 [-1, 1280]               0\n",
      "          Linear-255                   [-1, 28]          35,868\n",
      "================================================================\n",
      "Total params: 4,043,416\n",
      "Trainable params: 4,043,416\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 173.64\n",
      "Params size (MB): 15.42\n",
      "Estimated Total Size (MB): 189.64\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(efficientnetb0, (3,224,224), device = 'cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70959ac2",
   "metadata": {},
   "source": [
    "#### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "19cdff10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 0, Training Loss: 14539.4229\n",
      "Epoch 0, Step 1, Training Loss: 14697.1963\n",
      "Epoch 0, Step 2, Training Loss: 14865.8057\n",
      "Epoch 0, Step 3, Training Loss: 14782.2168\n",
      "Epoch 0, Step 4, Training Loss: 14964.3613\n",
      "Epoch 0, Step 5, Training Loss: 14315.5166\n",
      "Epoch 0, Step 6, Training Loss: 14451.6211\n",
      "Epoch 0, Step 7, Training Loss: 15263.0830\n",
      "Epoch 0, Step 8, Training Loss: 14649.1250\n",
      "Epoch 0, Step 9, Training Loss: 14425.1602\n",
      "Epoch 0, Step 10, Training Loss: 14535.4629\n",
      "Epoch 0, Step 11, Training Loss: 14626.4434\n",
      "Epoch 0, Step 12, Training Loss: 14969.0215\n",
      "Epoch 0, Step 13, Training Loss: 15063.8760\n",
      "Epoch 0, Step 14, Training Loss: 14574.3652\n",
      "Epoch 0, Step 15, Training Loss: 14747.5186\n",
      "Epoch 0, Step 16, Training Loss: 14473.8535\n",
      "Epoch 0, Step 17, Training Loss: 14578.4316\n",
      "Epoch 0, Step 18, Training Loss: 14609.2363\n",
      "Epoch 0, Step 19, Training Loss: 14688.2051\n",
      "Epoch 0, Step 20, Training Loss: 14740.4824\n",
      "Epoch 0, Step 21, Training Loss: 15045.3730\n",
      "Epoch 0, Step 22, Training Loss: 14478.1768\n",
      "Epoch 0, Step 23, Training Loss: 14947.4297\n",
      "Epoch 0, Step 24, Training Loss: 14143.2734\n",
      "Epoch 0, Step 25, Training Loss: 14707.2471\n",
      "Epoch 0, Step 26, Training Loss: 13981.5791\n",
      "Epoch 0, Step 27, Training Loss: 14755.6416\n",
      "Epoch 0, Step 28, Training Loss: 14212.5332\n",
      "Epoch 0, Step 29, Training Loss: 14396.8330\n",
      "Epoch 0, Step 30, Training Loss: 14496.3994\n",
      "Epoch 0, Step 31, Training Loss: 14547.6094\n",
      "Epoch 0, Step 32, Training Loss: 14550.6152\n",
      "Epoch 0, Step 33, Training Loss: 14109.9951\n",
      "Epoch 0, Step 34, Training Loss: 14545.3848\n",
      "Epoch 0, Step 35, Training Loss: 14290.7305\n",
      "Epoch 0, Step 36, Training Loss: 14472.9932\n",
      "Epoch 0, Step 37, Training Loss: 14481.5430\n",
      "Epoch 0, Step 38, Training Loss: 14626.0762\n",
      "Epoch 0, Step 39, Training Loss: 14581.5918\n",
      "Epoch 0, Step 40, Training Loss: 14254.5879\n",
      "Epoch 0, Step 41, Training Loss: 14555.9023\n",
      "Epoch 0, Step 42, Training Loss: 14466.5234\n",
      "Epoch 0, Step 43, Training Loss: 14102.0586\n",
      "Epoch 0, Step 44, Training Loss: 14576.0586\n",
      "Epoch 0, Step 45, Training Loss: 14205.6748\n",
      "Epoch 0, Step 46, Training Loss: 14016.3018\n",
      "Epoch 0, Step 47, Training Loss: 14024.5537\n",
      "Epoch 0, Step 48, Training Loss: 14114.6904\n",
      "Epoch 0, Step 49, Training Loss: 14578.1377\n",
      "Epoch 0, Step 50, Training Loss: 14146.4482\n",
      "Epoch 0, Step 51, Training Loss: 13999.2979\n",
      "Epoch 0, Step 52, Training Loss: 13727.4492\n",
      "Epoch 0, Step 53, Training Loss: 14033.1455\n",
      "Epoch 0, Step 54, Training Loss: 14092.9893\n",
      "Epoch 0, Step 55, Training Loss: 14374.5049\n",
      "Epoch 0, Step 56, Training Loss: 14428.4629\n",
      "Epoch 0, Step 57, Training Loss: 14058.7842\n",
      "Epoch 0, Step 58, Training Loss: 14331.1953\n",
      "Epoch 0, Step 59, Training Loss: 14157.6650\n",
      "Epoch 0, Step 60, Training Loss: 14429.8867\n",
      "Epoch 0, Step 61, Training Loss: 13661.4697\n",
      "Epoch 0, Step 62, Training Loss: 13665.7529\n",
      "Epoch 0, Step 63, Training Loss: 13858.6074\n",
      "Epoch 0, Step 64, Training Loss: 14027.4043\n",
      "Epoch 0, Step 65, Training Loss: 13702.7148\n",
      "Epoch 0, Step 66, Training Loss: 13687.6738\n",
      "Epoch 0, Step 67, Training Loss: 14433.7002\n",
      "Epoch 0, Step 68, Training Loss: 13874.8223\n",
      "Epoch 0, Step 69, Training Loss: 14250.3672\n",
      "Epoch 0, Step 70, Training Loss: 13885.3779\n",
      "Epoch 0, Step 71, Training Loss: 13733.6807\n",
      "Epoch 0, Step 72, Training Loss: 13624.0830\n",
      "Epoch 0, Step 73, Training Loss: 13897.4434\n",
      "Epoch 0, Step 74, Training Loss: 13677.4414\n",
      "Epoch 0, Step 75, Training Loss: 13754.7881\n",
      "Epoch 0, Step 76, Training Loss: 14070.3008\n",
      "Epoch 0, Step 77, Training Loss: 13696.8398\n",
      "Epoch 0, Step 78, Training Loss: 13621.9756\n",
      "Epoch 0, Step 79, Training Loss: 13393.7148\n",
      "Epoch 0, Step 80, Training Loss: 13233.3604\n",
      "Epoch 0, Step 81, Training Loss: 13884.3779\n",
      "Epoch 0, Step 82, Training Loss: 13497.7217\n",
      "Epoch 0, Step 83, Training Loss: 13797.2461\n",
      "Epoch 0, Step 84, Training Loss: 13502.8623\n",
      "Epoch 0, Step 85, Training Loss: 13602.0342\n",
      "Epoch 0, Step 86, Training Loss: 13413.8213\n",
      "Epoch 0, Step 87, Training Loss: 13249.3506\n",
      "Epoch 0, Step 88, Training Loss: 14076.3486\n",
      "Epoch 0, Step 89, Training Loss: 13168.6299\n",
      "Epoch 0, Step 90, Training Loss: 13266.9473\n",
      "Epoch 0, Step 91, Training Loss: 13659.0068\n",
      "Epoch 0, Step 92, Training Loss: 13347.6660\n",
      "Epoch 0, Step 93, Training Loss: 13531.4600\n",
      "Epoch 0, Step 94, Training Loss: 13254.8945\n",
      "Epoch 0, Step 95, Training Loss: 13219.0381\n",
      "Epoch 0, Step 96, Training Loss: 13186.8262\n",
      "Epoch 0, Step 97, Training Loss: 13318.6943\n",
      "Epoch 0, Step 98, Training Loss: 13506.6572\n",
      "Epoch 0, Step 99, Training Loss: 13574.8691\n",
      "Epoch 0, Step 100, Training Loss: 13260.2129\n",
      "Epoch 0, Step 101, Training Loss: 13235.4883\n",
      "Epoch 0, Step 102, Training Loss: 13677.4932\n",
      "Epoch 0, Step 103, Training Loss: 13212.4092\n",
      "Epoch 0, Step 104, Training Loss: 13161.0029\n",
      "Epoch 0, Step 105, Training Loss: 13002.4229\n",
      "Epoch 0, Step 106, Training Loss: 13234.4102\n",
      "Epoch 0, Step 107, Training Loss: 13431.4004\n",
      "Epoch 0, Step 108, Training Loss: 13050.0537\n",
      "Epoch 0, Step 109, Training Loss: 13124.6143\n",
      "Epoch 0, Step 110, Training Loss: 13371.3076\n",
      "Epoch 0, Step 111, Training Loss: 13019.6025\n",
      "Epoch 0, Step 112, Training Loss: 13090.9521\n",
      "Epoch 0, Step 113, Training Loss: 13078.5840\n",
      "Epoch 0, Step 114, Training Loss: 12818.8027\n",
      "Epoch 0, Step 115, Training Loss: 13089.5254\n",
      "Epoch 0, Step 116, Training Loss: 12863.2998\n",
      "Epoch 0, Step 117, Training Loss: 13114.0850\n",
      "Epoch 0, Step 118, Training Loss: 12977.8066\n",
      "Epoch 0, Step 119, Training Loss: 12754.1768\n",
      "Epoch 0, Step 120, Training Loss: 13152.3662\n",
      "Epoch 0, Step 121, Training Loss: 12999.4189\n",
      "Epoch 0, Step 122, Training Loss: 12627.6699\n",
      "Epoch 0, Step 123, Training Loss: 13096.6455\n",
      "Epoch 0, Step 124, Training Loss: 13158.0664\n",
      "Epoch 0, Step 125, Training Loss: 12919.1855\n",
      "Epoch 0, Step 126, Training Loss: 12551.8809\n",
      "Epoch 0, Step 127, Training Loss: 12485.0137\n",
      "Epoch 0, Step 128, Training Loss: 12612.3975\n",
      "Epoch 0, Step 129, Training Loss: 12729.5186\n",
      "Epoch 0, Step 130, Training Loss: 12780.2842\n",
      "Epoch 0, Step 131, Training Loss: 12616.4902\n",
      "Epoch 0, Step 132, Training Loss: 12824.0586\n",
      "Epoch 0, Step 133, Training Loss: 12589.3760\n",
      "Epoch 0, Step 134, Training Loss: 12942.8447\n",
      "Epoch 0, Step 135, Training Loss: 12670.3135\n",
      "Epoch 0, Step 136, Training Loss: 12566.7529\n",
      "Epoch 0, Step 137, Training Loss: 12671.4746\n",
      "Epoch 0, Step 138, Training Loss: 12591.7588\n",
      "Epoch 0, Step 139, Training Loss: 12358.3174\n",
      "Epoch 0, Step 140, Training Loss: 12354.3135\n",
      "Epoch 0, Step 141, Training Loss: 12554.9336\n",
      "Epoch 0, Step 142, Training Loss: 12409.0010\n",
      "Epoch 0, Step 143, Training Loss: 12662.0674\n",
      "Epoch 0, Step 144, Training Loss: 12368.0361\n",
      "Epoch 0, Step 145, Training Loss: 12506.9316\n",
      "Epoch 0, Step 146, Training Loss: 12249.0664\n",
      "Epoch 0, Step 147, Training Loss: 12408.9648\n",
      "Epoch 0, Step 148, Training Loss: 12332.6992\n",
      "Epoch 0, Step 149, Training Loss: 12557.8467\n",
      "Epoch 0, Step 150, Training Loss: 12163.7637\n",
      "Epoch 0, Step 151, Training Loss: 12154.5986\n",
      "Epoch 0, Step 152, Training Loss: 12444.6592\n",
      "Epoch 0, Step 153, Training Loss: 12258.8975\n",
      "Epoch 0, Step 154, Training Loss: 12349.1338\n",
      "Epoch 0, Step 155, Training Loss: 12154.0811\n",
      "Epoch 0, Step 156, Training Loss: 12439.0205\n",
      "Epoch 0, Step 157, Training Loss: 12665.5361\n",
      "Epoch 0, Step 158, Training Loss: 12380.0068\n",
      "Epoch 0, Step 159, Training Loss: 12136.5342\n",
      "Epoch 0, Step 160, Training Loss: 12475.0020\n",
      "Epoch 0, Step 161, Training Loss: 12005.1504\n",
      "Epoch 0, Step 162, Training Loss: 12365.0479\n",
      "Epoch 0, Step 163, Training Loss: 12285.1299\n",
      "Epoch 0, Step 164, Training Loss: 12141.5381\n",
      "Epoch 0, Step 165, Training Loss: 11949.7666\n",
      "Epoch 0, Step 166, Training Loss: 12087.9307\n",
      "Epoch 0, Step 167, Training Loss: 12139.3955\n",
      "Epoch 0, Step 168, Training Loss: 11859.8398\n",
      "Epoch 0, Step 169, Training Loss: 12292.7412\n",
      "Epoch 0, Step 170, Training Loss: 12197.5732\n",
      "Epoch 0, Step 171, Training Loss: 12083.4941\n",
      "Epoch 0, Step 172, Training Loss: 11997.0303\n",
      "Epoch 0, Step 173, Training Loss: 12145.9648\n",
      "Epoch 0, Step 174, Training Loss: 11848.3398\n",
      "Epoch 0, Step 175, Training Loss: 12423.2305\n",
      "Epoch 0, Step 176, Training Loss: 12000.0449\n",
      "Epoch 0, Step 177, Training Loss: 12406.6650\n",
      "Epoch 0, Step 178, Training Loss: 12354.4980\n",
      "Epoch 0, Step 179, Training Loss: 11967.5654\n",
      "Epoch 0, Step 180, Training Loss: 11587.2402\n",
      "Epoch 0, Step 181, Training Loss: 12133.2002\n",
      "Epoch 0, Step 182, Training Loss: 12263.2666\n",
      "Epoch 0, Step 183, Training Loss: 11652.5361\n",
      "Epoch 0, Step 184, Training Loss: 11956.0898\n",
      "Epoch 0, Step 185, Training Loss: 11480.8936\n",
      "Epoch 0, Step 186, Training Loss: 11985.6260\n",
      "Epoch 0, Step 187, Training Loss: 11835.0488\n",
      "Epoch 0, Step 188, Training Loss: 11608.1299\n",
      "Epoch 0, Step 189, Training Loss: 11706.2754\n",
      "Epoch 0, Step 190, Training Loss: 12304.6230\n",
      "Epoch 0, Step 191, Training Loss: 11844.9541\n",
      "Epoch 0, Step 192, Training Loss: 12058.9561\n",
      "Epoch 0, Step 193, Training Loss: 12118.0264\n",
      "Epoch 0, Step 194, Training Loss: 12080.0225\n",
      "Epoch 0, Step 195, Training Loss: 11975.9668\n",
      "Epoch 0, Step 196, Training Loss: 12015.6084\n",
      "Epoch 0, Step 197, Training Loss: 11611.9473\n",
      "Epoch 0, Step 198, Training Loss: 11708.6299\n",
      "Epoch 0, Step 199, Training Loss: 11885.5996\n",
      "Epoch 0, Step 200, Training Loss: 11431.5088\n",
      "Epoch 0, Step 201, Training Loss: 11517.1738\n",
      "Epoch 0, Step 202, Training Loss: 11472.7100\n",
      "Epoch 0, Step 203, Training Loss: 11797.7705\n",
      "Epoch 0, Step 204, Training Loss: 12103.3584\n",
      "Epoch 0, Step 205, Training Loss: 11866.7393\n",
      "Epoch 0, Step 206, Training Loss: 11551.6729\n",
      "--- Epoch 0, Validation Loss: 11609.7385 ---\n",
      "Epoch 1, Step 0, Training Loss: 11445.5723\n",
      "Epoch 1, Step 1, Training Loss: 11564.7168\n",
      "Epoch 1, Step 2, Training Loss: 11711.0723\n",
      "Epoch 1, Step 3, Training Loss: 11656.7354\n",
      "Epoch 1, Step 4, Training Loss: 11774.5029\n",
      "Epoch 1, Step 5, Training Loss: 11207.3262\n",
      "Epoch 1, Step 6, Training Loss: 11316.1455\n",
      "Epoch 1, Step 7, Training Loss: 12061.2598\n",
      "Epoch 1, Step 8, Training Loss: 11474.2295\n",
      "Epoch 1, Step 9, Training Loss: 11258.1055\n",
      "Epoch 1, Step 10, Training Loss: 11350.3379\n",
      "Epoch 1, Step 11, Training Loss: 11429.4346\n",
      "Epoch 1, Step 12, Training Loss: 11741.6758\n",
      "Epoch 1, Step 13, Training Loss: 11821.1787\n",
      "Epoch 1, Step 14, Training Loss: 11384.2764\n",
      "Epoch 1, Step 15, Training Loss: 11511.2568\n",
      "Epoch 1, Step 16, Training Loss: 11252.8838\n",
      "Epoch 1, Step 17, Training Loss: 11350.9180\n",
      "Epoch 1, Step 18, Training Loss: 11373.4668\n",
      "Epoch 1, Step 19, Training Loss: 11450.3389\n",
      "Epoch 1, Step 20, Training Loss: 11503.7529\n",
      "Epoch 1, Step 21, Training Loss: 11751.6904\n",
      "Epoch 1, Step 22, Training Loss: 11242.7295\n",
      "Epoch 1, Step 23, Training Loss: 11641.6338\n",
      "Epoch 1, Step 24, Training Loss: 10964.9893\n",
      "Epoch 1, Step 25, Training Loss: 11425.4600\n",
      "Epoch 1, Step 26, Training Loss: 10801.4473\n",
      "Epoch 1, Step 27, Training Loss: 11476.0850\n",
      "Epoch 1, Step 28, Training Loss: 10977.9268\n",
      "Epoch 1, Step 29, Training Loss: 11138.4033\n",
      "Epoch 1, Step 30, Training Loss: 11232.7080\n",
      "Epoch 1, Step 31, Training Loss: 11277.3379\n",
      "Epoch 1, Step 32, Training Loss: 11288.8330\n",
      "Epoch 1, Step 33, Training Loss: 10907.2002\n",
      "Epoch 1, Step 34, Training Loss: 11293.4600\n",
      "Epoch 1, Step 35, Training Loss: 11061.3467\n",
      "Epoch 1, Step 36, Training Loss: 11210.8955\n",
      "Epoch 1, Step 37, Training Loss: 11246.5049\n",
      "Epoch 1, Step 38, Training Loss: 11359.1982\n",
      "Epoch 1, Step 39, Training Loss: 11312.2998\n",
      "Epoch 1, Step 40, Training Loss: 11030.7539\n",
      "Epoch 1, Step 41, Training Loss: 11293.1758\n",
      "Epoch 1, Step 42, Training Loss: 11204.8242\n",
      "Epoch 1, Step 43, Training Loss: 10891.8623\n",
      "Epoch 1, Step 44, Training Loss: 11312.8838\n",
      "Epoch 1, Step 45, Training Loss: 11003.6973\n",
      "Epoch 1, Step 46, Training Loss: 10806.5381\n",
      "Epoch 1, Step 47, Training Loss: 10870.8662\n",
      "Epoch 1, Step 48, Training Loss: 10914.6318\n",
      "Epoch 1, Step 49, Training Loss: 11337.3779\n",
      "Epoch 1, Step 50, Training Loss: 10958.3066\n",
      "Epoch 1, Step 51, Training Loss: 10842.6719\n",
      "Epoch 1, Step 52, Training Loss: 10604.9053\n",
      "Epoch 1, Step 53, Training Loss: 10856.7314\n",
      "Epoch 1, Step 54, Training Loss: 10923.9580\n",
      "Epoch 1, Step 55, Training Loss: 11191.0430\n",
      "Epoch 1, Step 56, Training Loss: 11253.0264\n",
      "Epoch 1, Step 57, Training Loss: 10927.8506\n",
      "Epoch 1, Step 58, Training Loss: 11155.2744\n",
      "Epoch 1, Step 59, Training Loss: 11006.0811\n",
      "Epoch 1, Step 60, Training Loss: 11259.3555\n",
      "Epoch 1, Step 61, Training Loss: 10587.7412\n",
      "Epoch 1, Step 62, Training Loss: 10597.9990\n",
      "Epoch 1, Step 63, Training Loss: 10784.8652\n",
      "Epoch 1, Step 64, Training Loss: 10907.2686\n",
      "Epoch 1, Step 65, Training Loss: 10654.9375\n",
      "Epoch 1, Step 66, Training Loss: 10643.2148\n",
      "Epoch 1, Step 67, Training Loss: 11298.8447\n",
      "Epoch 1, Step 68, Training Loss: 10826.1250\n",
      "Epoch 1, Step 69, Training Loss: 11151.6914\n",
      "Epoch 1, Step 70, Training Loss: 10839.3076\n",
      "Epoch 1, Step 71, Training Loss: 10719.7441\n",
      "Epoch 1, Step 72, Training Loss: 10619.0625\n",
      "Epoch 1, Step 73, Training Loss: 10863.1035\n",
      "Epoch 1, Step 74, Training Loss: 10667.2305\n",
      "Epoch 1, Step 75, Training Loss: 10738.6123\n",
      "Epoch 1, Step 76, Training Loss: 11048.8369\n",
      "Epoch 1, Step 77, Training Loss: 10729.3906\n",
      "Epoch 1, Step 78, Training Loss: 10650.9199\n",
      "Epoch 1, Step 79, Training Loss: 10456.2480\n",
      "Epoch 1, Step 80, Training Loss: 10322.1348\n",
      "Epoch 1, Step 81, Training Loss: 10925.7705\n",
      "Epoch 1, Step 82, Training Loss: 10562.5342\n",
      "Epoch 1, Step 83, Training Loss: 10811.8506\n",
      "Epoch 1, Step 84, Training Loss: 10592.3496\n",
      "Epoch 1, Step 85, Training Loss: 10669.9160\n",
      "Epoch 1, Step 86, Training Loss: 10500.1094\n",
      "Epoch 1, Step 87, Training Loss: 10352.0830\n",
      "Epoch 1, Step 88, Training Loss: 11107.1113\n",
      "Epoch 1, Step 89, Training Loss: 10318.8193\n",
      "Epoch 1, Step 90, Training Loss: 10372.9053\n",
      "Epoch 1, Step 91, Training Loss: 10735.7568\n",
      "Epoch 1, Step 92, Training Loss: 10475.1787\n",
      "Epoch 1, Step 93, Training Loss: 10634.7061\n",
      "Epoch 1, Step 94, Training Loss: 10414.0205\n",
      "Epoch 1, Step 95, Training Loss: 10378.5625\n",
      "Epoch 1, Step 96, Training Loss: 10368.3145\n",
      "Epoch 1, Step 97, Training Loss: 10462.9062\n",
      "Epoch 1, Step 98, Training Loss: 10658.8174\n",
      "Epoch 1, Step 99, Training Loss: 10713.1875\n",
      "Epoch 1, Step 100, Training Loss: 10418.2920\n",
      "Epoch 1, Step 101, Training Loss: 10409.9502\n",
      "Epoch 1, Step 102, Training Loss: 10812.9248\n",
      "Epoch 1, Step 103, Training Loss: 10412.6162\n",
      "Epoch 1, Step 104, Training Loss: 10359.0723\n",
      "Epoch 1, Step 105, Training Loss: 10217.6377\n",
      "Epoch 1, Step 106, Training Loss: 10444.7812\n",
      "Epoch 1, Step 107, Training Loss: 10602.0898\n",
      "Epoch 1, Step 108, Training Loss: 10267.5586\n",
      "Epoch 1, Step 109, Training Loss: 10318.3086\n",
      "Epoch 1, Step 110, Training Loss: 10561.9668\n",
      "Epoch 1, Step 111, Training Loss: 10266.7939\n",
      "Epoch 1, Step 112, Training Loss: 10336.4111\n",
      "Epoch 1, Step 113, Training Loss: 10313.8154\n",
      "Epoch 1, Step 114, Training Loss: 10078.4111\n",
      "Epoch 1, Step 115, Training Loss: 10335.8574\n",
      "Epoch 1, Step 116, Training Loss: 10118.6387\n",
      "Epoch 1, Step 117, Training Loss: 10357.8955\n",
      "Epoch 1, Step 118, Training Loss: 10230.8486\n",
      "Epoch 1, Step 119, Training Loss: 10043.7305\n",
      "Epoch 1, Step 120, Training Loss: 10366.0928\n",
      "Epoch 1, Step 121, Training Loss: 10286.0527\n",
      "Epoch 1, Step 122, Training Loss: 9950.7656\n",
      "Epoch 1, Step 123, Training Loss: 10375.2109\n",
      "Epoch 1, Step 124, Training Loss: 10439.0850\n",
      "Epoch 1, Step 125, Training Loss: 10206.9590\n",
      "Epoch 1, Step 126, Training Loss: 9894.1484\n",
      "Epoch 1, Step 127, Training Loss: 9853.2842\n",
      "Epoch 1, Step 128, Training Loss: 9929.8428\n",
      "Epoch 1, Step 129, Training Loss: 10058.2402\n",
      "Epoch 1, Step 130, Training Loss: 10112.6387\n",
      "Epoch 1, Step 131, Training Loss: 9952.3047\n",
      "Epoch 1, Step 132, Training Loss: 10111.3848\n",
      "Epoch 1, Step 133, Training Loss: 9969.3232\n",
      "Epoch 1, Step 134, Training Loss: 10256.4736\n",
      "Epoch 1, Step 135, Training Loss: 10014.7852\n",
      "Epoch 1, Step 136, Training Loss: 9917.4863\n",
      "Epoch 1, Step 137, Training Loss: 10046.1484\n",
      "Epoch 1, Step 138, Training Loss: 9962.4561\n",
      "Epoch 1, Step 139, Training Loss: 9741.1455\n",
      "Epoch 1, Step 140, Training Loss: 9741.0469\n",
      "Epoch 1, Step 141, Training Loss: 9944.8750\n",
      "Epoch 1, Step 142, Training Loss: 9787.3555\n",
      "Epoch 1, Step 143, Training Loss: 10006.7285\n",
      "Epoch 1, Step 144, Training Loss: 9767.3555\n",
      "Epoch 1, Step 145, Training Loss: 9867.5957\n",
      "Epoch 1, Step 146, Training Loss: 9645.6816\n",
      "Epoch 1, Step 147, Training Loss: 9791.7705\n",
      "Epoch 1, Step 148, Training Loss: 9768.9570\n",
      "Epoch 1, Step 149, Training Loss: 9944.2324\n",
      "Epoch 1, Step 150, Training Loss: 9593.6631\n",
      "Epoch 1, Step 151, Training Loss: 9562.7344\n",
      "Epoch 1, Step 152, Training Loss: 9857.2246\n",
      "Epoch 1, Step 153, Training Loss: 9675.4600\n",
      "Epoch 1, Step 154, Training Loss: 9757.8477\n",
      "Epoch 1, Step 155, Training Loss: 9588.4844\n",
      "Epoch 1, Step 156, Training Loss: 9815.4570\n",
      "Epoch 1, Step 157, Training Loss: 10035.9375\n",
      "Epoch 1, Step 158, Training Loss: 9793.4443\n",
      "Epoch 1, Step 159, Training Loss: 9606.1904\n",
      "Epoch 1, Step 160, Training Loss: 9893.7363\n",
      "Epoch 1, Step 161, Training Loss: 9467.5117\n",
      "Epoch 1, Step 162, Training Loss: 9796.8311\n",
      "Epoch 1, Step 163, Training Loss: 9701.1162\n",
      "Epoch 1, Step 164, Training Loss: 9591.8281\n",
      "Epoch 1, Step 165, Training Loss: 9415.1299\n",
      "Epoch 1, Step 166, Training Loss: 9543.6787\n",
      "Epoch 1, Step 167, Training Loss: 9590.2754\n",
      "Epoch 1, Step 168, Training Loss: 9373.8936\n",
      "Epoch 1, Step 169, Training Loss: 9726.1924\n",
      "Epoch 1, Step 170, Training Loss: 9656.2637\n",
      "Epoch 1, Step 171, Training Loss: 9555.0586\n",
      "Epoch 1, Step 172, Training Loss: 9482.5059\n",
      "Epoch 1, Step 173, Training Loss: 9616.8154\n",
      "Epoch 1, Step 174, Training Loss: 9348.4521\n",
      "Epoch 1, Step 175, Training Loss: 9862.4033\n",
      "Epoch 1, Step 176, Training Loss: 9472.8330\n",
      "Epoch 1, Step 177, Training Loss: 9860.7549\n",
      "Epoch 1, Step 178, Training Loss: 9814.9971\n",
      "Epoch 1, Step 179, Training Loss: 9440.7344\n",
      "Epoch 1, Step 180, Training Loss: 9126.0615\n",
      "Epoch 1, Step 181, Training Loss: 9597.5469\n",
      "Epoch 1, Step 182, Training Loss: 9696.8398\n",
      "Epoch 1, Step 183, Training Loss: 9190.6455\n",
      "Epoch 1, Step 184, Training Loss: 9460.2607\n",
      "Epoch 1, Step 185, Training Loss: 9034.0537\n",
      "Epoch 1, Step 186, Training Loss: 9498.5000\n",
      "Epoch 1, Step 187, Training Loss: 9341.4521\n",
      "Epoch 1, Step 188, Training Loss: 9154.8193\n",
      "Epoch 1, Step 189, Training Loss: 9240.9580\n",
      "Epoch 1, Step 190, Training Loss: 9827.5312\n",
      "Epoch 1, Step 191, Training Loss: 9354.1201\n",
      "Epoch 1, Step 192, Training Loss: 9561.0000\n",
      "Epoch 1, Step 193, Training Loss: 9598.3506\n",
      "Epoch 1, Step 194, Training Loss: 9570.7793\n",
      "Epoch 1, Step 195, Training Loss: 9472.7441\n",
      "Epoch 1, Step 196, Training Loss: 9526.8281\n",
      "Epoch 1, Step 197, Training Loss: 9151.9316\n",
      "Epoch 1, Step 198, Training Loss: 9242.5000\n",
      "Epoch 1, Step 199, Training Loss: 9412.1699\n",
      "Epoch 1, Step 200, Training Loss: 8999.2441\n",
      "Epoch 1, Step 201, Training Loss: 9092.4473\n",
      "Epoch 1, Step 202, Training Loss: 9053.9648\n",
      "Epoch 1, Step 203, Training Loss: 9329.3486\n",
      "Epoch 1, Step 204, Training Loss: 9598.0049\n",
      "Epoch 1, Step 205, Training Loss: 9392.5107\n",
      "Epoch 1, Step 206, Training Loss: 9125.0596\n",
      "--- Epoch 1, Validation Loss: 9168.8316 ---\n",
      "Epoch 2, Step 0, Training Loss: 9028.0908\n",
      "Epoch 2, Step 1, Training Loss: 9137.0107\n",
      "Epoch 2, Step 2, Training Loss: 9276.9209\n",
      "Epoch 2, Step 3, Training Loss: 9198.2168\n",
      "Epoch 2, Step 4, Training Loss: 9310.1904\n",
      "Epoch 2, Step 5, Training Loss: 8843.0938\n",
      "Epoch 2, Step 6, Training Loss: 8919.6133\n",
      "Epoch 2, Step 7, Training Loss: 9512.4678\n",
      "Epoch 2, Step 8, Training Loss: 9066.4023\n",
      "Epoch 2, Step 9, Training Loss: 8856.9238\n",
      "Epoch 2, Step 10, Training Loss: 8939.3818\n",
      "Epoch 2, Step 11, Training Loss: 9056.2539\n",
      "Epoch 2, Step 12, Training Loss: 9311.3203\n",
      "Epoch 2, Step 13, Training Loss: 9358.9570\n",
      "Epoch 2, Step 14, Training Loss: 8963.5918\n",
      "Epoch 2, Step 15, Training Loss: 9123.5732\n",
      "Epoch 2, Step 16, Training Loss: 8874.2500\n",
      "Epoch 2, Step 17, Training Loss: 8976.5225\n",
      "Epoch 2, Step 18, Training Loss: 8993.9434\n",
      "Epoch 2, Step 19, Training Loss: 9079.3584\n",
      "Epoch 2, Step 20, Training Loss: 9066.7178\n",
      "Epoch 2, Step 21, Training Loss: 9314.8076\n",
      "Epoch 2, Step 22, Training Loss: 8886.5596\n",
      "Epoch 2, Step 23, Training Loss: 9239.3965\n",
      "Epoch 2, Step 24, Training Loss: 8625.5098\n",
      "Epoch 2, Step 25, Training Loss: 9031.6504\n",
      "Epoch 2, Step 26, Training Loss: 8473.1387\n",
      "Epoch 2, Step 27, Training Loss: 9064.7646\n",
      "Epoch 2, Step 28, Training Loss: 8662.8340\n",
      "Epoch 2, Step 29, Training Loss: 8808.3389\n",
      "Epoch 2, Step 30, Training Loss: 8867.5752\n",
      "Epoch 2, Step 31, Training Loss: 8913.8037\n",
      "Epoch 2, Step 32, Training Loss: 8917.7910\n",
      "Epoch 2, Step 33, Training Loss: 8594.1123\n",
      "Epoch 2, Step 34, Training Loss: 8918.1602\n",
      "Epoch 2, Step 35, Training Loss: 8707.4473\n",
      "Epoch 2, Step 36, Training Loss: 8861.5605\n",
      "Epoch 2, Step 37, Training Loss: 8881.3779\n",
      "Epoch 2, Step 38, Training Loss: 8984.3018\n",
      "Epoch 2, Step 39, Training Loss: 8943.1348\n",
      "Epoch 2, Step 40, Training Loss: 8692.4971\n",
      "Epoch 2, Step 41, Training Loss: 8931.9473\n",
      "Epoch 2, Step 42, Training Loss: 8860.6621\n",
      "Epoch 2, Step 43, Training Loss: 8572.0605\n",
      "Epoch 2, Step 44, Training Loss: 8926.9521\n",
      "Epoch 2, Step 45, Training Loss: 8661.4600\n",
      "Epoch 2, Step 46, Training Loss: 8508.6973\n",
      "Epoch 2, Step 47, Training Loss: 8545.2988\n",
      "Epoch 2, Step 48, Training Loss: 8589.5156\n",
      "Epoch 2, Step 49, Training Loss: 8976.7959\n",
      "Epoch 2, Step 50, Training Loss: 8638.0801\n",
      "Epoch 2, Step 51, Training Loss: 8534.1172\n",
      "Epoch 2, Step 52, Training Loss: 8339.1348\n",
      "Epoch 2, Step 53, Training Loss: 8542.0078\n",
      "Epoch 2, Step 54, Training Loss: 8602.5107\n",
      "Epoch 2, Step 55, Training Loss: 8853.2559\n",
      "Epoch 2, Step 56, Training Loss: 8921.7529\n",
      "Epoch 2, Step 57, Training Loss: 8591.3379\n",
      "Epoch 2, Step 58, Training Loss: 8846.2422\n",
      "Epoch 2, Step 59, Training Loss: 8683.4209\n",
      "Epoch 2, Step 60, Training Loss: 8935.2148\n",
      "Epoch 2, Step 61, Training Loss: 8331.6621\n",
      "Epoch 2, Step 62, Training Loss: 8349.3516\n",
      "Epoch 2, Step 63, Training Loss: 8491.3232\n",
      "Epoch 2, Step 64, Training Loss: 8616.2168\n",
      "Epoch 2, Step 65, Training Loss: 8401.0645\n",
      "Epoch 2, Step 66, Training Loss: 8382.9844\n",
      "Epoch 2, Step 67, Training Loss: 8976.4473\n",
      "Epoch 2, Step 68, Training Loss: 8551.2520\n",
      "Epoch 2, Step 69, Training Loss: 8844.4512\n",
      "Epoch 2, Step 70, Training Loss: 8555.8965\n",
      "Epoch 2, Step 71, Training Loss: 8480.9717\n",
      "Epoch 2, Step 72, Training Loss: 8328.7754\n",
      "Epoch 2, Step 73, Training Loss: 8570.7393\n",
      "Epoch 2, Step 74, Training Loss: 8395.3340\n",
      "Epoch 2, Step 75, Training Loss: 8455.6709\n",
      "Epoch 2, Step 76, Training Loss: 8755.8105\n",
      "Epoch 2, Step 77, Training Loss: 8454.8389\n",
      "Epoch 2, Step 78, Training Loss: 8379.9043\n",
      "Epoch 2, Step 79, Training Loss: 8197.7129\n",
      "Epoch 2, Step 80, Training Loss: 8129.8599\n",
      "Epoch 2, Step 81, Training Loss: 8646.8398\n",
      "Epoch 2, Step 82, Training Loss: 8328.6191\n",
      "Epoch 2, Step 83, Training Loss: 8533.2061\n",
      "Epoch 2, Step 84, Training Loss: 8349.0137\n",
      "Epoch 2, Step 85, Training Loss: 8422.5508\n",
      "Epoch 2, Step 86, Training Loss: 8223.4648\n",
      "Epoch 2, Step 87, Training Loss: 8155.7212\n",
      "Epoch 2, Step 88, Training Loss: 8808.7461\n",
      "Epoch 2, Step 89, Training Loss: 8115.6846\n",
      "Epoch 2, Step 90, Training Loss: 8154.6670\n",
      "Epoch 2, Step 91, Training Loss: 8467.6982\n",
      "Epoch 2, Step 92, Training Loss: 8255.7129\n",
      "Epoch 2, Step 93, Training Loss: 8378.3262\n",
      "Epoch 2, Step 94, Training Loss: 8203.3330\n",
      "Epoch 2, Step 95, Training Loss: 8151.8306\n",
      "Epoch 2, Step 96, Training Loss: 8154.6235\n",
      "Epoch 2, Step 97, Training Loss: 8242.3965\n",
      "Epoch 2, Step 98, Training Loss: 8369.1289\n",
      "Epoch 2, Step 99, Training Loss: 8436.1445\n",
      "Epoch 2, Step 100, Training Loss: 8189.2983\n",
      "Epoch 2, Step 101, Training Loss: 8211.2305\n",
      "Epoch 2, Step 102, Training Loss: 8554.8350\n",
      "Epoch 2, Step 103, Training Loss: 8191.9341\n",
      "Epoch 2, Step 104, Training Loss: 8170.9883\n",
      "Epoch 2, Step 105, Training Loss: 8020.5366\n",
      "Epoch 2, Step 106, Training Loss: 8240.3320\n",
      "Epoch 2, Step 107, Training Loss: 8396.8887\n",
      "Epoch 2, Step 108, Training Loss: 8089.0684\n",
      "Epoch 2, Step 109, Training Loss: 8141.0234\n",
      "Epoch 2, Step 110, Training Loss: 8327.2842\n",
      "Epoch 2, Step 111, Training Loss: 8069.3535\n",
      "Epoch 2, Step 112, Training Loss: 8147.1611\n",
      "Epoch 2, Step 113, Training Loss: 8116.2817\n",
      "Epoch 2, Step 114, Training Loss: 7916.8018\n",
      "Epoch 2, Step 115, Training Loss: 8129.8755\n",
      "Epoch 2, Step 116, Training Loss: 7957.2158\n",
      "Epoch 2, Step 117, Training Loss: 8158.0684\n",
      "Epoch 2, Step 118, Training Loss: 8034.0068\n",
      "Epoch 2, Step 119, Training Loss: 7912.1812\n",
      "Epoch 2, Step 120, Training Loss: 8164.7700\n",
      "Epoch 2, Step 121, Training Loss: 8147.2354\n",
      "Epoch 2, Step 122, Training Loss: 7790.9189\n",
      "Epoch 2, Step 123, Training Loss: 8158.4106\n",
      "Epoch 2, Step 124, Training Loss: 8230.7148\n",
      "Epoch 2, Step 125, Training Loss: 8031.4395\n",
      "Epoch 2, Step 126, Training Loss: 7790.7881\n",
      "Epoch 2, Step 127, Training Loss: 7709.4434\n",
      "Epoch 2, Step 128, Training Loss: 7793.6704\n",
      "Epoch 2, Step 129, Training Loss: 7898.3374\n",
      "Epoch 2, Step 130, Training Loss: 7951.0537\n",
      "Epoch 2, Step 131, Training Loss: 7813.1899\n",
      "Epoch 2, Step 132, Training Loss: 7975.6255\n",
      "Epoch 2, Step 133, Training Loss: 7794.5986\n",
      "Epoch 2, Step 134, Training Loss: 8057.4946\n",
      "Epoch 2, Step 135, Training Loss: 7875.3530\n",
      "Epoch 2, Step 136, Training Loss: 7785.7212\n",
      "Epoch 2, Step 137, Training Loss: 7927.7866\n",
      "Epoch 2, Step 138, Training Loss: 7804.1426\n",
      "Epoch 2, Step 139, Training Loss: 7621.3086\n",
      "Epoch 2, Step 140, Training Loss: 7651.8252\n",
      "Epoch 2, Step 141, Training Loss: 7788.7114\n",
      "Epoch 2, Step 142, Training Loss: 7645.1924\n",
      "Epoch 2, Step 143, Training Loss: 7865.5508\n",
      "Epoch 2, Step 144, Training Loss: 7650.3027\n",
      "Epoch 2, Step 145, Training Loss: 7777.3696\n",
      "Epoch 2, Step 146, Training Loss: 7556.0664\n",
      "Epoch 2, Step 147, Training Loss: 7683.4287\n",
      "Epoch 2, Step 148, Training Loss: 7693.6436\n",
      "Epoch 2, Step 149, Training Loss: 7802.0684\n",
      "Epoch 2, Step 150, Training Loss: 7511.6802\n",
      "Epoch 2, Step 151, Training Loss: 7486.8320\n",
      "Epoch 2, Step 152, Training Loss: 7719.8643\n",
      "Epoch 2, Step 153, Training Loss: 7601.1055\n",
      "Epoch 2, Step 154, Training Loss: 7639.8213\n",
      "Epoch 2, Step 155, Training Loss: 7523.5215\n",
      "Epoch 2, Step 156, Training Loss: 7672.5396\n",
      "Epoch 2, Step 157, Training Loss: 7870.9009\n",
      "Epoch 2, Step 158, Training Loss: 7691.9434\n",
      "Epoch 2, Step 159, Training Loss: 7487.3086\n",
      "Epoch 2, Step 160, Training Loss: 7790.9204\n",
      "Epoch 2, Step 161, Training Loss: 7418.0508\n",
      "Epoch 2, Step 162, Training Loss: 7681.2891\n",
      "Epoch 2, Step 163, Training Loss: 7619.4814\n",
      "Epoch 2, Step 164, Training Loss: 7517.2056\n",
      "Epoch 2, Step 165, Training Loss: 7361.1724\n",
      "Epoch 2, Step 166, Training Loss: 7447.7603\n",
      "Epoch 2, Step 167, Training Loss: 7519.9966\n",
      "Epoch 2, Step 168, Training Loss: 7323.4673\n",
      "Epoch 2, Step 169, Training Loss: 7634.9971\n",
      "Epoch 2, Step 170, Training Loss: 7573.2603\n",
      "Epoch 2, Step 171, Training Loss: 7461.3975\n",
      "Epoch 2, Step 172, Training Loss: 7413.2705\n",
      "Epoch 2, Step 173, Training Loss: 7521.7471\n",
      "Epoch 2, Step 174, Training Loss: 7299.7627\n",
      "Epoch 2, Step 175, Training Loss: 7726.4512\n",
      "Epoch 2, Step 176, Training Loss: 7407.6846\n",
      "Epoch 2, Step 177, Training Loss: 7735.7388\n",
      "Epoch 2, Step 178, Training Loss: 7692.9497\n",
      "Epoch 2, Step 179, Training Loss: 7409.4570\n",
      "Epoch 2, Step 180, Training Loss: 7148.0327\n",
      "Epoch 2, Step 181, Training Loss: 7534.0918\n",
      "Epoch 2, Step 182, Training Loss: 7607.4736\n",
      "Epoch 2, Step 183, Training Loss: 7144.5161\n",
      "Epoch 2, Step 184, Training Loss: 7415.1104\n",
      "Epoch 2, Step 185, Training Loss: 7036.7324\n",
      "Epoch 2, Step 186, Training Loss: 7466.2158\n",
      "Epoch 2, Step 187, Training Loss: 7305.0942\n",
      "Epoch 2, Step 188, Training Loss: 7116.1099\n",
      "Epoch 2, Step 189, Training Loss: 7197.9468\n",
      "Epoch 2, Step 190, Training Loss: 7765.8096\n",
      "Epoch 2, Step 191, Training Loss: 7288.6797\n",
      "Epoch 2, Step 192, Training Loss: 7482.5239\n",
      "Epoch 2, Step 193, Training Loss: 7505.0093\n",
      "Epoch 2, Step 194, Training Loss: 7482.0806\n",
      "Epoch 2, Step 195, Training Loss: 7447.5278\n",
      "Epoch 2, Step 196, Training Loss: 7454.1436\n",
      "Epoch 2, Step 197, Training Loss: 7187.0728\n",
      "Epoch 2, Step 198, Training Loss: 7210.8428\n",
      "Epoch 2, Step 199, Training Loss: 7405.5454\n",
      "Epoch 2, Step 200, Training Loss: 6989.6924\n",
      "Epoch 2, Step 201, Training Loss: 7085.1680\n",
      "Epoch 2, Step 202, Training Loss: 7008.5068\n",
      "Epoch 2, Step 203, Training Loss: 7299.0918\n",
      "Epoch 2, Step 204, Training Loss: 7559.5508\n",
      "Epoch 2, Step 205, Training Loss: 7382.1304\n",
      "Epoch 2, Step 206, Training Loss: 7118.9731\n",
      "--- Epoch 2, Validation Loss: 7256.7494 ---\n",
      "Epoch 3, Step 0, Training Loss: 7015.8262\n",
      "Epoch 3, Step 1, Training Loss: 7142.3760\n",
      "Epoch 3, Step 2, Training Loss: 7257.5547\n",
      "Epoch 3, Step 3, Training Loss: 7165.9814\n",
      "Epoch 3, Step 4, Training Loss: 7272.2329\n",
      "Epoch 3, Step 5, Training Loss: 6849.6738\n",
      "Epoch 3, Step 6, Training Loss: 6947.3115\n",
      "Epoch 3, Step 7, Training Loss: 7464.7271\n",
      "Epoch 3, Step 8, Training Loss: 7090.3169\n",
      "Epoch 3, Step 9, Training Loss: 6883.7759\n",
      "Epoch 3, Step 10, Training Loss: 6951.9834\n",
      "Epoch 3, Step 11, Training Loss: 7067.5742\n",
      "Epoch 3, Step 12, Training Loss: 7268.8965\n",
      "Epoch 3, Step 13, Training Loss: 7334.5186\n",
      "Epoch 3, Step 14, Training Loss: 6998.9634\n",
      "Epoch 3, Step 15, Training Loss: 7093.5908\n",
      "Epoch 3, Step 16, Training Loss: 6912.6665\n",
      "Epoch 3, Step 17, Training Loss: 6999.1880\n",
      "Epoch 3, Step 18, Training Loss: 7012.9546\n",
      "Epoch 3, Step 19, Training Loss: 7081.1626\n",
      "Epoch 3, Step 20, Training Loss: 7109.5342\n",
      "Epoch 3, Step 21, Training Loss: 7299.7837\n",
      "Epoch 3, Step 22, Training Loss: 6909.2358\n",
      "Epoch 3, Step 23, Training Loss: 7217.5864\n",
      "Epoch 3, Step 24, Training Loss: 6688.4863\n",
      "Epoch 3, Step 25, Training Loss: 7038.5273\n",
      "Epoch 3, Step 26, Training Loss: 6551.5493\n",
      "Epoch 3, Step 27, Training Loss: 7122.8364\n",
      "Epoch 3, Step 28, Training Loss: 6722.9902\n",
      "Epoch 3, Step 29, Training Loss: 6820.3599\n",
      "Epoch 3, Step 30, Training Loss: 6874.8330\n",
      "Epoch 3, Step 31, Training Loss: 6925.6318\n",
      "Epoch 3, Step 32, Training Loss: 6955.8584\n",
      "Epoch 3, Step 33, Training Loss: 6672.9253\n",
      "Epoch 3, Step 34, Training Loss: 6941.2485\n",
      "Epoch 3, Step 35, Training Loss: 6767.1489\n",
      "Epoch 3, Step 36, Training Loss: 6913.1543\n",
      "Epoch 3, Step 37, Training Loss: 6951.3843\n",
      "Epoch 3, Step 38, Training Loss: 7021.7383\n",
      "Epoch 3, Step 39, Training Loss: 6972.1777\n",
      "Epoch 3, Step 40, Training Loss: 6761.2778\n",
      "Epoch 3, Step 41, Training Loss: 6953.1787\n",
      "Epoch 3, Step 42, Training Loss: 6890.0850\n",
      "Epoch 3, Step 43, Training Loss: 6681.1206\n",
      "Epoch 3, Step 44, Training Loss: 6976.2358\n",
      "Epoch 3, Step 45, Training Loss: 6784.3755\n",
      "Epoch 3, Step 46, Training Loss: 6605.7559\n",
      "Epoch 3, Step 47, Training Loss: 6659.1831\n",
      "Epoch 3, Step 48, Training Loss: 6694.8003\n",
      "Epoch 3, Step 49, Training Loss: 6997.5415\n",
      "Epoch 3, Step 50, Training Loss: 6713.1606\n",
      "Epoch 3, Step 51, Training Loss: 6630.4390\n",
      "Epoch 3, Step 52, Training Loss: 6469.6411\n",
      "Epoch 3, Step 53, Training Loss: 6648.6533\n",
      "Epoch 3, Step 54, Training Loss: 6686.0640\n",
      "Epoch 3, Step 55, Training Loss: 6941.9819\n",
      "Epoch 3, Step 56, Training Loss: 6953.3833\n",
      "Epoch 3, Step 57, Training Loss: 6700.5918\n",
      "Epoch 3, Step 58, Training Loss: 6901.6846\n",
      "Epoch 3, Step 59, Training Loss: 6730.2119\n",
      "Epoch 3, Step 60, Training Loss: 6972.8223\n",
      "Epoch 3, Step 61, Training Loss: 6466.5933\n",
      "Epoch 3, Step 62, Training Loss: 6474.9146\n",
      "Epoch 3, Step 63, Training Loss: 6618.1855\n",
      "Epoch 3, Step 64, Training Loss: 6697.7222\n",
      "Epoch 3, Step 65, Training Loss: 6503.7412\n",
      "Epoch 3, Step 66, Training Loss: 6503.8882\n",
      "Epoch 3, Step 67, Training Loss: 7006.7583\n",
      "Epoch 3, Step 68, Training Loss: 6614.9565\n",
      "Epoch 3, Step 69, Training Loss: 6921.2012\n",
      "Epoch 3, Step 70, Training Loss: 6679.3765\n",
      "Epoch 3, Step 71, Training Loss: 6598.6064\n",
      "Epoch 3, Step 72, Training Loss: 6514.8989\n",
      "Epoch 3, Step 73, Training Loss: 6668.9312\n",
      "Epoch 3, Step 74, Training Loss: 6543.1606\n",
      "Epoch 3, Step 75, Training Loss: 6554.9878\n",
      "Epoch 3, Step 76, Training Loss: 6856.2925\n",
      "Epoch 3, Step 77, Training Loss: 6588.3950\n",
      "Epoch 3, Step 78, Training Loss: 6482.7720\n",
      "Epoch 3, Step 79, Training Loss: 6356.3066\n",
      "Epoch 3, Step 80, Training Loss: 6327.5132\n",
      "Epoch 3, Step 81, Training Loss: 6761.7803\n",
      "Epoch 3, Step 82, Training Loss: 6466.1631\n",
      "Epoch 3, Step 83, Training Loss: 6659.9468\n",
      "Epoch 3, Step 84, Training Loss: 6514.4468\n",
      "Epoch 3, Step 85, Training Loss: 6527.5776\n",
      "Epoch 3, Step 86, Training Loss: 6407.7041\n",
      "Epoch 3, Step 87, Training Loss: 6274.9644\n",
      "Epoch 3, Step 88, Training Loss: 6890.8931\n",
      "Epoch 3, Step 89, Training Loss: 6292.7051\n",
      "Epoch 3, Step 90, Training Loss: 6317.5449\n",
      "Epoch 3, Step 91, Training Loss: 6588.3374\n",
      "Epoch 3, Step 92, Training Loss: 6418.5239\n",
      "Epoch 3, Step 93, Training Loss: 6527.9121\n",
      "Epoch 3, Step 94, Training Loss: 6382.6533\n",
      "Epoch 3, Step 95, Training Loss: 6313.2402\n",
      "Epoch 3, Step 96, Training Loss: 6315.3057\n",
      "Epoch 3, Step 97, Training Loss: 6423.3940\n",
      "Epoch 3, Step 98, Training Loss: 6506.2715\n",
      "Epoch 3, Step 99, Training Loss: 6602.4053\n",
      "Epoch 3, Step 100, Training Loss: 6356.8740\n",
      "Epoch 3, Step 101, Training Loss: 6359.7446\n",
      "Epoch 3, Step 102, Training Loss: 6635.1958\n",
      "Epoch 3, Step 103, Training Loss: 6355.1392\n",
      "Epoch 3, Step 104, Training Loss: 6331.1357\n",
      "Epoch 3, Step 105, Training Loss: 6199.7090\n",
      "Epoch 3, Step 106, Training Loss: 6427.3540\n",
      "Epoch 3, Step 107, Training Loss: 6544.6899\n",
      "Epoch 3, Step 108, Training Loss: 6291.8452\n",
      "Epoch 3, Step 109, Training Loss: 6293.8145\n",
      "Epoch 3, Step 110, Training Loss: 6444.6436\n",
      "Epoch 3, Step 111, Training Loss: 6274.5923\n",
      "Epoch 3, Step 112, Training Loss: 6302.5737\n",
      "Epoch 3, Step 113, Training Loss: 6261.1592\n",
      "Epoch 3, Step 114, Training Loss: 6152.9521\n",
      "Epoch 3, Step 115, Training Loss: 6308.0146\n",
      "Epoch 3, Step 116, Training Loss: 6175.3921\n",
      "Epoch 3, Step 117, Training Loss: 6339.0811\n",
      "Epoch 3, Step 118, Training Loss: 6255.9434\n",
      "Epoch 3, Step 119, Training Loss: 6092.9009\n",
      "Epoch 3, Step 120, Training Loss: 6280.5571\n",
      "Epoch 3, Step 121, Training Loss: 6326.2100\n",
      "Epoch 3, Step 122, Training Loss: 6027.4312\n",
      "Epoch 3, Step 123, Training Loss: 6339.5435\n",
      "Epoch 3, Step 124, Training Loss: 6450.2559\n",
      "Epoch 3, Step 125, Training Loss: 6233.2715\n",
      "Epoch 3, Step 126, Training Loss: 5972.7627\n",
      "Epoch 3, Step 127, Training Loss: 5924.3613\n",
      "Epoch 3, Step 128, Training Loss: 6027.6943\n",
      "Epoch 3, Step 129, Training Loss: 6133.7739\n",
      "Epoch 3, Step 130, Training Loss: 6179.2095\n",
      "Epoch 3, Step 131, Training Loss: 6039.5386\n",
      "Epoch 3, Step 132, Training Loss: 6150.0796\n",
      "Epoch 3, Step 133, Training Loss: 6023.3350\n",
      "Epoch 3, Step 134, Training Loss: 6273.2979\n",
      "Epoch 3, Step 135, Training Loss: 6091.7549\n",
      "Epoch 3, Step 136, Training Loss: 6009.4775\n",
      "Epoch 3, Step 137, Training Loss: 6136.5981\n",
      "Epoch 3, Step 138, Training Loss: 6038.9351\n",
      "Epoch 3, Step 139, Training Loss: 5866.8716\n",
      "Epoch 3, Step 140, Training Loss: 5911.7324\n",
      "Epoch 3, Step 141, Training Loss: 6044.4893\n",
      "Epoch 3, Step 142, Training Loss: 5925.1733\n",
      "Epoch 3, Step 143, Training Loss: 6134.4917\n",
      "Epoch 3, Step 144, Training Loss: 5885.1890\n",
      "Epoch 3, Step 145, Training Loss: 5991.6943\n",
      "Epoch 3, Step 146, Training Loss: 5795.8584\n",
      "Epoch 3, Step 147, Training Loss: 5943.5718\n",
      "Epoch 3, Step 148, Training Loss: 5952.9346\n",
      "Epoch 3, Step 149, Training Loss: 6022.5630\n",
      "Epoch 3, Step 150, Training Loss: 5758.6880\n",
      "Epoch 3, Step 151, Training Loss: 5740.5239\n",
      "Epoch 3, Step 152, Training Loss: 5914.6475\n",
      "Epoch 3, Step 153, Training Loss: 5836.1899\n",
      "Epoch 3, Step 154, Training Loss: 5892.9087\n",
      "Epoch 3, Step 155, Training Loss: 5804.5337\n",
      "Epoch 3, Step 156, Training Loss: 5936.8564\n",
      "Epoch 3, Step 157, Training Loss: 6110.3149\n",
      "Epoch 3, Step 158, Training Loss: 5901.4331\n",
      "Epoch 3, Step 159, Training Loss: 5808.7412\n",
      "Epoch 3, Step 160, Training Loss: 6018.8550\n",
      "Epoch 3, Step 161, Training Loss: 5722.2881\n",
      "Epoch 3, Step 162, Training Loss: 5963.2808\n",
      "Epoch 3, Step 163, Training Loss: 5919.3696\n",
      "Epoch 3, Step 164, Training Loss: 5788.6787\n",
      "Epoch 3, Step 165, Training Loss: 5658.0762\n",
      "Epoch 3, Step 166, Training Loss: 5737.7271\n",
      "Epoch 3, Step 167, Training Loss: 5803.9307\n",
      "Epoch 3, Step 168, Training Loss: 5603.1660\n",
      "Epoch 3, Step 169, Training Loss: 5863.0918\n",
      "Epoch 3, Step 170, Training Loss: 5828.1567\n",
      "Epoch 3, Step 171, Training Loss: 5764.0718\n",
      "Epoch 3, Step 172, Training Loss: 5755.8911\n",
      "Epoch 3, Step 173, Training Loss: 5774.7202\n",
      "Epoch 3, Step 174, Training Loss: 5643.8916\n",
      "Epoch 3, Step 175, Training Loss: 5961.4189\n",
      "Epoch 3, Step 176, Training Loss: 5717.5322\n",
      "Epoch 3, Step 177, Training Loss: 6011.6533\n",
      "Epoch 3, Step 178, Training Loss: 5961.4478\n",
      "Epoch 3, Step 179, Training Loss: 5702.3472\n",
      "Epoch 3, Step 180, Training Loss: 5450.5659\n",
      "Epoch 3, Step 181, Training Loss: 5828.4526\n",
      "Epoch 3, Step 182, Training Loss: 5900.8394\n",
      "Epoch 3, Step 183, Training Loss: 5500.0728\n",
      "Epoch 3, Step 184, Training Loss: 5705.4780\n",
      "Epoch 3, Step 185, Training Loss: 5368.0181\n",
      "Epoch 3, Step 186, Training Loss: 5779.8071\n",
      "Epoch 3, Step 187, Training Loss: 5601.9434\n",
      "Epoch 3, Step 188, Training Loss: 5452.1787\n",
      "Epoch 3, Step 189, Training Loss: 5579.9912\n",
      "Epoch 3, Step 190, Training Loss: 6065.7837\n",
      "Epoch 3, Step 191, Training Loss: 5654.9878\n",
      "Epoch 3, Step 192, Training Loss: 5777.4800\n",
      "Epoch 3, Step 193, Training Loss: 5789.2861\n",
      "Epoch 3, Step 194, Training Loss: 5802.6143\n",
      "Epoch 3, Step 195, Training Loss: 5742.7036\n",
      "Epoch 3, Step 196, Training Loss: 5749.1675\n",
      "Epoch 3, Step 197, Training Loss: 5505.0449\n",
      "Epoch 3, Step 198, Training Loss: 5545.7178\n",
      "Epoch 3, Step 199, Training Loss: 5719.3760\n",
      "Epoch 3, Step 200, Training Loss: 5388.3828\n",
      "Epoch 3, Step 201, Training Loss: 5420.4756\n",
      "Epoch 3, Step 202, Training Loss: 5419.9312\n",
      "Epoch 3, Step 203, Training Loss: 5569.3643\n",
      "Epoch 3, Step 204, Training Loss: 5822.4014\n",
      "Epoch 3, Step 205, Training Loss: 5702.0190\n",
      "Epoch 3, Step 206, Training Loss: 5450.6675\n",
      "--- Epoch 3, Validation Loss: 5582.5602 ---\n",
      "Epoch 4, Step 0, Training Loss: 5368.3428\n",
      "Epoch 4, Step 1, Training Loss: 5479.7710\n",
      "Epoch 4, Step 2, Training Loss: 5587.6206\n",
      "Epoch 4, Step 3, Training Loss: 5521.1221\n",
      "Epoch 4, Step 4, Training Loss: 5599.3325\n",
      "Epoch 4, Step 5, Training Loss: 5229.4424\n",
      "Epoch 4, Step 6, Training Loss: 5292.5151\n",
      "Epoch 4, Step 7, Training Loss: 5766.8691\n",
      "Epoch 4, Step 8, Training Loss: 5457.9121\n",
      "Epoch 4, Step 9, Training Loss: 5277.4595\n",
      "Epoch 4, Step 10, Training Loss: 5342.9370\n",
      "Epoch 4, Step 11, Training Loss: 5409.8306\n",
      "Epoch 4, Step 12, Training Loss: 5647.1567\n",
      "Epoch 4, Step 13, Training Loss: 5666.6108\n",
      "Epoch 4, Step 14, Training Loss: 5372.7324\n",
      "Epoch 4, Step 15, Training Loss: 5461.0972\n",
      "Epoch 4, Step 16, Training Loss: 5267.6729\n",
      "Epoch 4, Step 17, Training Loss: 5355.5620\n",
      "Epoch 4, Step 18, Training Loss: 5342.4478\n",
      "Epoch 4, Step 19, Training Loss: 5476.7065\n",
      "Epoch 4, Step 20, Training Loss: 5488.5708\n",
      "Epoch 4, Step 21, Training Loss: 5619.7915\n",
      "Epoch 4, Step 22, Training Loss: 5315.5884\n",
      "Epoch 4, Step 23, Training Loss: 5572.5303\n",
      "Epoch 4, Step 24, Training Loss: 5093.4717\n",
      "Epoch 4, Step 25, Training Loss: 5392.3262\n",
      "Epoch 4, Step 26, Training Loss: 5007.1709\n",
      "Epoch 4, Step 27, Training Loss: 5463.9556\n",
      "Epoch 4, Step 28, Training Loss: 5169.2539\n",
      "Epoch 4, Step 29, Training Loss: 5266.7100\n",
      "Epoch 4, Step 30, Training Loss: 5291.4238\n",
      "Epoch 4, Step 31, Training Loss: 5335.4443\n",
      "Epoch 4, Step 32, Training Loss: 5365.3203\n",
      "Epoch 4, Step 33, Training Loss: 5072.7671\n",
      "Epoch 4, Step 34, Training Loss: 5327.5415\n",
      "Epoch 4, Step 35, Training Loss: 5205.1196\n",
      "Epoch 4, Step 36, Training Loss: 5284.4893\n",
      "Epoch 4, Step 37, Training Loss: 5382.5527\n",
      "Epoch 4, Step 38, Training Loss: 5404.3164\n",
      "Epoch 4, Step 39, Training Loss: 5337.7646\n",
      "Epoch 4, Step 40, Training Loss: 5168.6719\n",
      "Epoch 4, Step 41, Training Loss: 5344.3394\n",
      "Epoch 4, Step 42, Training Loss: 5288.3335\n",
      "Epoch 4, Step 43, Training Loss: 5055.7881\n",
      "Epoch 4, Step 44, Training Loss: 5338.2559\n",
      "Epoch 4, Step 45, Training Loss: 5183.1284\n",
      "Epoch 4, Step 46, Training Loss: 5017.1831\n",
      "Epoch 4, Step 47, Training Loss: 5080.3662\n",
      "Epoch 4, Step 48, Training Loss: 5102.4131\n",
      "Epoch 4, Step 49, Training Loss: 5396.0337\n",
      "Epoch 4, Step 50, Training Loss: 5123.8613\n",
      "Epoch 4, Step 51, Training Loss: 5062.1157\n",
      "Epoch 4, Step 52, Training Loss: 4938.7690\n",
      "Epoch 4, Step 53, Training Loss: 5093.5000\n",
      "Epoch 4, Step 54, Training Loss: 5156.2690\n",
      "Epoch 4, Step 55, Training Loss: 5300.3345\n",
      "Epoch 4, Step 56, Training Loss: 5354.2012\n",
      "Epoch 4, Step 57, Training Loss: 5130.9087\n",
      "Epoch 4, Step 58, Training Loss: 5318.8965\n",
      "Epoch 4, Step 59, Training Loss: 5172.7993\n",
      "Epoch 4, Step 60, Training Loss: 5383.3281\n",
      "Epoch 4, Step 61, Training Loss: 4921.5884\n",
      "Epoch 4, Step 62, Training Loss: 4925.4878\n",
      "Epoch 4, Step 63, Training Loss: 5039.7305\n",
      "Epoch 4, Step 64, Training Loss: 5104.4531\n",
      "Epoch 4, Step 65, Training Loss: 4966.3496\n",
      "Epoch 4, Step 66, Training Loss: 4974.2178\n",
      "Epoch 4, Step 67, Training Loss: 5405.5386\n",
      "Epoch 4, Step 68, Training Loss: 5114.9351\n",
      "Epoch 4, Step 69, Training Loss: 5331.9756\n",
      "Epoch 4, Step 70, Training Loss: 5115.7500\n",
      "Epoch 4, Step 71, Training Loss: 5036.6089\n",
      "Epoch 4, Step 72, Training Loss: 4962.0674\n",
      "Epoch 4, Step 73, Training Loss: 5095.1797\n",
      "Epoch 4, Step 74, Training Loss: 4995.5928\n",
      "Epoch 4, Step 75, Training Loss: 5028.8730\n",
      "Epoch 4, Step 76, Training Loss: 5298.4512\n",
      "Epoch 4, Step 77, Training Loss: 5041.9116\n",
      "Epoch 4, Step 78, Training Loss: 4991.6812\n",
      "Epoch 4, Step 79, Training Loss: 4855.8555\n",
      "Epoch 4, Step 80, Training Loss: 4804.6519\n",
      "Epoch 4, Step 81, Training Loss: 5179.0068\n",
      "Epoch 4, Step 82, Training Loss: 4935.6377\n",
      "Epoch 4, Step 83, Training Loss: 5087.0781\n",
      "Epoch 4, Step 84, Training Loss: 5008.1069\n",
      "Epoch 4, Step 85, Training Loss: 4996.4829\n",
      "Epoch 4, Step 86, Training Loss: 4872.8066\n",
      "Epoch 4, Step 87, Training Loss: 4777.6040\n",
      "Epoch 4, Step 88, Training Loss: 5270.9590\n",
      "Epoch 4, Step 89, Training Loss: 4773.2939\n",
      "Epoch 4, Step 90, Training Loss: 4757.9976\n",
      "Epoch 4, Step 91, Training Loss: 5043.4629\n",
      "Epoch 4, Step 92, Training Loss: 4911.2866\n",
      "Epoch 4, Step 93, Training Loss: 5012.1128\n",
      "Epoch 4, Step 94, Training Loss: 4853.6455\n",
      "Epoch 4, Step 95, Training Loss: 4839.5718\n",
      "Epoch 4, Step 96, Training Loss: 4794.9390\n",
      "Epoch 4, Step 97, Training Loss: 4904.5908\n",
      "Epoch 4, Step 98, Training Loss: 4972.6899\n",
      "Epoch 4, Step 99, Training Loss: 5041.8608\n",
      "Epoch 4, Step 100, Training Loss: 4835.5649\n",
      "Epoch 4, Step 101, Training Loss: 4878.4155\n",
      "Epoch 4, Step 102, Training Loss: 5099.1675\n",
      "Epoch 4, Step 103, Training Loss: 4867.8252\n",
      "Epoch 4, Step 104, Training Loss: 4833.6992\n",
      "Epoch 4, Step 105, Training Loss: 4713.8633\n",
      "Epoch 4, Step 106, Training Loss: 4909.5889\n",
      "Epoch 4, Step 107, Training Loss: 5006.4268\n",
      "Epoch 4, Step 108, Training Loss: 4757.3945\n",
      "Epoch 4, Step 109, Training Loss: 4757.4155\n",
      "Epoch 4, Step 110, Training Loss: 4952.1709\n",
      "Epoch 4, Step 111, Training Loss: 4808.0449\n",
      "Epoch 4, Step 112, Training Loss: 4819.2012\n",
      "Epoch 4, Step 113, Training Loss: 4795.6968\n",
      "Epoch 4, Step 114, Training Loss: 4628.0322\n",
      "Epoch 4, Step 115, Training Loss: 4834.7256\n",
      "Epoch 4, Step 116, Training Loss: 4719.7021\n",
      "Epoch 4, Step 117, Training Loss: 4843.9746\n",
      "Epoch 4, Step 118, Training Loss: 4758.3926\n",
      "Epoch 4, Step 119, Training Loss: 4646.4248\n",
      "Epoch 4, Step 120, Training Loss: 4834.6343\n",
      "Epoch 4, Step 121, Training Loss: 4858.0400\n",
      "Epoch 4, Step 122, Training Loss: 4577.5757\n",
      "Epoch 4, Step 123, Training Loss: 4824.6938\n",
      "Epoch 4, Step 124, Training Loss: 4909.0674\n",
      "Epoch 4, Step 125, Training Loss: 4731.9180\n",
      "Epoch 4, Step 126, Training Loss: 4551.9424\n",
      "Epoch 4, Step 127, Training Loss: 4543.0586\n",
      "Epoch 4, Step 128, Training Loss: 4568.8125\n",
      "Epoch 4, Step 129, Training Loss: 4677.0010\n",
      "Epoch 4, Step 130, Training Loss: 4686.2769\n",
      "Epoch 4, Step 131, Training Loss: 4603.9751\n",
      "Epoch 4, Step 132, Training Loss: 4705.1631\n",
      "Epoch 4, Step 133, Training Loss: 4532.1445\n",
      "Epoch 4, Step 134, Training Loss: 4757.8672\n",
      "Epoch 4, Step 135, Training Loss: 4653.3135\n",
      "Epoch 4, Step 136, Training Loss: 4570.5352\n",
      "Epoch 4, Step 137, Training Loss: 4684.7524\n",
      "Epoch 4, Step 138, Training Loss: 4563.5913\n",
      "Epoch 4, Step 139, Training Loss: 4467.4126\n",
      "Epoch 4, Step 140, Training Loss: 4442.5229\n",
      "Epoch 4, Step 141, Training Loss: 4607.1846\n",
      "Epoch 4, Step 142, Training Loss: 4424.9092\n",
      "Epoch 4, Step 143, Training Loss: 4635.4873\n",
      "Epoch 4, Step 144, Training Loss: 4461.0820\n",
      "Epoch 4, Step 145, Training Loss: 4547.1211\n",
      "Epoch 4, Step 146, Training Loss: 4403.6387\n",
      "Epoch 4, Step 147, Training Loss: 4502.2876\n",
      "Epoch 4, Step 148, Training Loss: 4540.5674\n",
      "Epoch 4, Step 149, Training Loss: 4591.6479\n",
      "Epoch 4, Step 150, Training Loss: 4356.7090\n",
      "Epoch 4, Step 151, Training Loss: 4307.1035\n",
      "Epoch 4, Step 152, Training Loss: 4555.4492\n",
      "Epoch 4, Step 153, Training Loss: 4419.2261\n",
      "Epoch 4, Step 154, Training Loss: 4456.7866\n",
      "Epoch 4, Step 155, Training Loss: 4392.5879\n",
      "Epoch 4, Step 156, Training Loss: 4505.2373\n",
      "Epoch 4, Step 157, Training Loss: 4632.3398\n",
      "Epoch 4, Step 158, Training Loss: 4491.3594\n",
      "Epoch 4, Step 159, Training Loss: 4388.1504\n",
      "Epoch 4, Step 160, Training Loss: 4618.1914\n",
      "Epoch 4, Step 161, Training Loss: 4306.9673\n",
      "Epoch 4, Step 162, Training Loss: 4508.6362\n",
      "Epoch 4, Step 163, Training Loss: 4475.4316\n",
      "Epoch 4, Step 164, Training Loss: 4379.3110\n",
      "Epoch 4, Step 165, Training Loss: 4287.8101\n",
      "Epoch 4, Step 166, Training Loss: 4344.4434\n",
      "Epoch 4, Step 167, Training Loss: 4422.9873\n",
      "Epoch 4, Step 168, Training Loss: 4243.7705\n",
      "Epoch 4, Step 169, Training Loss: 4451.8135\n",
      "Epoch 4, Step 170, Training Loss: 4462.2720\n",
      "Epoch 4, Step 171, Training Loss: 4366.5352\n",
      "Epoch 4, Step 172, Training Loss: 4370.5977\n",
      "Epoch 4, Step 173, Training Loss: 4360.7632\n",
      "Epoch 4, Step 174, Training Loss: 4216.9878\n",
      "Epoch 4, Step 175, Training Loss: 4570.6636\n",
      "Epoch 4, Step 176, Training Loss: 4341.4316\n",
      "Epoch 4, Step 177, Training Loss: 4572.7954\n",
      "Epoch 4, Step 178, Training Loss: 4545.3662\n",
      "Epoch 4, Step 179, Training Loss: 4332.2197\n",
      "Epoch 4, Step 180, Training Loss: 4077.9377\n",
      "Epoch 4, Step 181, Training Loss: 4436.9355\n",
      "Epoch 4, Step 182, Training Loss: 4495.5918\n",
      "Epoch 4, Step 183, Training Loss: 4123.0771\n",
      "Epoch 4, Step 184, Training Loss: 4298.7842\n",
      "Epoch 4, Step 185, Training Loss: 3996.1201\n",
      "Epoch 4, Step 186, Training Loss: 4395.8276\n",
      "Epoch 4, Step 187, Training Loss: 4268.2930\n",
      "Epoch 4, Step 188, Training Loss: 4131.8691\n",
      "Epoch 4, Step 189, Training Loss: 4205.3735\n",
      "Epoch 4, Step 190, Training Loss: 4645.2842\n",
      "Epoch 4, Step 191, Training Loss: 4252.2407\n",
      "Epoch 4, Step 192, Training Loss: 4370.2310\n",
      "Epoch 4, Step 193, Training Loss: 4387.8887\n",
      "Epoch 4, Step 194, Training Loss: 4374.7520\n",
      "Epoch 4, Step 195, Training Loss: 4385.9790\n",
      "Epoch 4, Step 196, Training Loss: 4381.1392\n",
      "Epoch 4, Step 197, Training Loss: 4146.5518\n",
      "Epoch 4, Step 198, Training Loss: 4192.2173\n",
      "Epoch 4, Step 199, Training Loss: 4344.3276\n",
      "Epoch 4, Step 200, Training Loss: 4007.9382\n",
      "Epoch 4, Step 201, Training Loss: 4097.2334\n",
      "Epoch 4, Step 202, Training Loss: 4037.2507\n",
      "Epoch 4, Step 203, Training Loss: 4248.6348\n",
      "Epoch 4, Step 204, Training Loss: 4431.9927\n",
      "Epoch 4, Step 205, Training Loss: 4303.1909\n",
      "Epoch 4, Step 206, Training Loss: 4104.8979\n",
      "--- Epoch 4, Validation Loss: 4397.6029 ---\n",
      "Epoch 5, Step 0, Training Loss: 4036.0532\n",
      "Epoch 5, Step 1, Training Loss: 4130.4155\n",
      "Epoch 5, Step 2, Training Loss: 4235.8486\n",
      "Epoch 5, Step 3, Training Loss: 4191.1934\n",
      "Epoch 5, Step 4, Training Loss: 4233.6646\n",
      "Epoch 5, Step 5, Training Loss: 3962.9365\n",
      "Epoch 5, Step 6, Training Loss: 3975.8645\n",
      "Epoch 5, Step 7, Training Loss: 4389.6475\n",
      "Epoch 5, Step 8, Training Loss: 4117.4028\n",
      "Epoch 5, Step 9, Training Loss: 3939.1392\n",
      "Epoch 5, Step 10, Training Loss: 3998.1631\n",
      "Epoch 5, Step 11, Training Loss: 4111.6182\n",
      "Epoch 5, Step 12, Training Loss: 4284.6733\n",
      "Epoch 5, Step 13, Training Loss: 4300.1050\n",
      "Epoch 5, Step 14, Training Loss: 4058.2021\n",
      "Epoch 5, Step 15, Training Loss: 4147.0757\n",
      "Epoch 5, Step 16, Training Loss: 3948.0549\n",
      "Epoch 5, Step 17, Training Loss: 4059.6470\n",
      "Epoch 5, Step 18, Training Loss: 3999.0366\n",
      "Epoch 5, Step 19, Training Loss: 4152.4922\n",
      "Epoch 5, Step 20, Training Loss: 4127.4438\n",
      "Epoch 5, Step 21, Training Loss: 4266.1250\n",
      "Epoch 5, Step 22, Training Loss: 3990.2236\n",
      "Epoch 5, Step 23, Training Loss: 4191.1558\n",
      "Epoch 5, Step 24, Training Loss: 3855.3503\n",
      "Epoch 5, Step 25, Training Loss: 4051.2808\n",
      "Epoch 5, Step 26, Training Loss: 3712.0142\n",
      "Epoch 5, Step 27, Training Loss: 4146.0566\n",
      "Epoch 5, Step 28, Training Loss: 3877.5300\n",
      "Epoch 5, Step 29, Training Loss: 3945.5034\n",
      "Epoch 5, Step 30, Training Loss: 3985.8484\n",
      "Epoch 5, Step 31, Training Loss: 4000.9048\n",
      "Epoch 5, Step 32, Training Loss: 4047.1296\n",
      "Epoch 5, Step 33, Training Loss: 3815.6372\n",
      "Epoch 5, Step 34, Training Loss: 4027.1304\n",
      "Epoch 5, Step 35, Training Loss: 3885.0024\n",
      "Epoch 5, Step 36, Training Loss: 4007.2668\n",
      "Epoch 5, Step 37, Training Loss: 4059.8738\n",
      "Epoch 5, Step 38, Training Loss: 4080.4336\n",
      "Epoch 5, Step 39, Training Loss: 4006.6206\n",
      "Epoch 5, Step 40, Training Loss: 3852.1057\n",
      "Epoch 5, Step 41, Training Loss: 4027.7769\n",
      "Epoch 5, Step 42, Training Loss: 3968.2493\n",
      "Epoch 5, Step 43, Training Loss: 3806.3145\n",
      "Epoch 5, Step 44, Training Loss: 4027.8401\n",
      "Epoch 5, Step 45, Training Loss: 3884.8860\n",
      "Epoch 5, Step 46, Training Loss: 3755.8574\n",
      "Epoch 5, Step 47, Training Loss: 3792.7622\n",
      "Epoch 5, Step 48, Training Loss: 3794.2117\n",
      "Epoch 5, Step 49, Training Loss: 4071.6416\n",
      "Epoch 5, Step 50, Training Loss: 3854.8655\n",
      "Epoch 5, Step 51, Training Loss: 3823.4270\n",
      "Epoch 5, Step 52, Training Loss: 3698.1553\n",
      "Epoch 5, Step 53, Training Loss: 3778.5073\n",
      "Epoch 5, Step 54, Training Loss: 3844.4573\n",
      "Epoch 5, Step 55, Training Loss: 4000.4907\n",
      "Epoch 5, Step 56, Training Loss: 4087.3691\n",
      "Epoch 5, Step 57, Training Loss: 3860.9009\n",
      "Epoch 5, Step 58, Training Loss: 4014.5068\n",
      "Epoch 5, Step 59, Training Loss: 3896.8484\n",
      "Epoch 5, Step 60, Training Loss: 4110.3354\n",
      "Epoch 5, Step 61, Training Loss: 3676.3909\n",
      "Epoch 5, Step 62, Training Loss: 3696.0688\n",
      "Epoch 5, Step 63, Training Loss: 3820.6704\n",
      "Epoch 5, Step 64, Training Loss: 3839.8147\n",
      "Epoch 5, Step 65, Training Loss: 3745.1995\n",
      "Epoch 5, Step 66, Training Loss: 3723.1887\n",
      "Epoch 5, Step 67, Training Loss: 4108.2920\n",
      "Epoch 5, Step 68, Training Loss: 3807.1304\n",
      "Epoch 5, Step 69, Training Loss: 4068.7937\n",
      "Epoch 5, Step 70, Training Loss: 3828.3245\n",
      "Epoch 5, Step 71, Training Loss: 3803.1973\n",
      "Epoch 5, Step 72, Training Loss: 3689.2090\n",
      "Epoch 5, Step 73, Training Loss: 3871.7329\n",
      "Epoch 5, Step 74, Training Loss: 3754.4526\n",
      "Epoch 5, Step 75, Training Loss: 3727.0295\n",
      "Epoch 5, Step 76, Training Loss: 3978.7808\n",
      "Epoch 5, Step 77, Training Loss: 3815.5715\n",
      "Epoch 5, Step 78, Training Loss: 3707.7754\n",
      "Epoch 5, Step 79, Training Loss: 3583.8645\n",
      "Epoch 5, Step 80, Training Loss: 3568.0962\n",
      "Epoch 5, Step 81, Training Loss: 3954.7373\n",
      "Epoch 5, Step 82, Training Loss: 3707.8311\n",
      "Epoch 5, Step 83, Training Loss: 3834.8491\n",
      "Epoch 5, Step 84, Training Loss: 3756.3638\n",
      "Epoch 5, Step 85, Training Loss: 3755.9751\n",
      "Epoch 5, Step 86, Training Loss: 3616.3811\n",
      "Epoch 5, Step 87, Training Loss: 3551.8489\n",
      "Epoch 5, Step 88, Training Loss: 3990.3257\n",
      "Epoch 5, Step 89, Training Loss: 3577.6370\n",
      "Epoch 5, Step 90, Training Loss: 3580.9946\n",
      "Epoch 5, Step 91, Training Loss: 3782.5444\n",
      "Epoch 5, Step 92, Training Loss: 3638.3928\n",
      "Epoch 5, Step 93, Training Loss: 3737.7925\n",
      "Epoch 5, Step 94, Training Loss: 3622.9905\n",
      "Epoch 5, Step 95, Training Loss: 3613.5718\n",
      "Epoch 5, Step 96, Training Loss: 3567.1626\n",
      "Epoch 5, Step 97, Training Loss: 3635.1895\n",
      "Epoch 5, Step 98, Training Loss: 3768.3809\n",
      "Epoch 5, Step 99, Training Loss: 3784.5928\n",
      "Epoch 5, Step 100, Training Loss: 3601.1934\n",
      "Epoch 5, Step 101, Training Loss: 3653.8528\n",
      "Epoch 5, Step 102, Training Loss: 3863.4604\n",
      "Epoch 5, Step 103, Training Loss: 3617.2290\n",
      "Epoch 5, Step 104, Training Loss: 3623.0020\n",
      "Epoch 5, Step 105, Training Loss: 3524.9875\n",
      "Epoch 5, Step 106, Training Loss: 3670.5957\n",
      "Epoch 5, Step 107, Training Loss: 3782.1772\n",
      "Epoch 5, Step 108, Training Loss: 3551.5242\n",
      "Epoch 5, Step 109, Training Loss: 3549.5562\n",
      "Epoch 5, Step 110, Training Loss: 3709.1079\n",
      "Epoch 5, Step 111, Training Loss: 3589.7981\n",
      "Epoch 5, Step 112, Training Loss: 3624.2737\n",
      "Epoch 5, Step 113, Training Loss: 3586.4524\n",
      "Epoch 5, Step 114, Training Loss: 3480.7830\n",
      "Epoch 5, Step 115, Training Loss: 3660.5479\n",
      "Epoch 5, Step 116, Training Loss: 3495.5969\n",
      "Epoch 5, Step 117, Training Loss: 3611.5488\n",
      "Epoch 5, Step 118, Training Loss: 3547.6301\n",
      "Epoch 5, Step 119, Training Loss: 3463.1821\n",
      "Epoch 5, Step 120, Training Loss: 3582.1545\n",
      "Epoch 5, Step 121, Training Loss: 3672.0168\n",
      "Epoch 5, Step 122, Training Loss: 3423.7815\n",
      "Epoch 5, Step 123, Training Loss: 3606.8406\n",
      "Epoch 5, Step 124, Training Loss: 3695.3049\n",
      "Epoch 5, Step 125, Training Loss: 3521.4304\n",
      "Epoch 5, Step 126, Training Loss: 3399.7998\n",
      "Epoch 5, Step 127, Training Loss: 3357.7131\n",
      "Epoch 5, Step 128, Training Loss: 3421.2112\n",
      "Epoch 5, Step 129, Training Loss: 3497.7976\n",
      "Epoch 5, Step 130, Training Loss: 3511.0557\n",
      "Epoch 5, Step 131, Training Loss: 3370.0608\n",
      "Epoch 5, Step 132, Training Loss: 3484.1531\n",
      "Epoch 5, Step 133, Training Loss: 3387.6682\n",
      "Epoch 5, Step 134, Training Loss: 3611.5281\n",
      "Epoch 5, Step 135, Training Loss: 3495.8572\n",
      "Epoch 5, Step 136, Training Loss: 3400.8110\n",
      "Epoch 5, Step 137, Training Loss: 3475.0198\n",
      "Epoch 5, Step 138, Training Loss: 3396.8562\n",
      "Epoch 5, Step 139, Training Loss: 3291.3484\n",
      "Epoch 5, Step 140, Training Loss: 3323.5166\n",
      "Epoch 5, Step 141, Training Loss: 3425.6548\n",
      "Epoch 5, Step 142, Training Loss: 3324.7888\n",
      "Epoch 5, Step 143, Training Loss: 3456.0793\n",
      "Epoch 5, Step 144, Training Loss: 3321.3813\n",
      "Epoch 5, Step 145, Training Loss: 3373.8372\n",
      "Epoch 5, Step 146, Training Loss: 3259.5356\n",
      "Epoch 5, Step 147, Training Loss: 3303.6167\n",
      "Epoch 5, Step 148, Training Loss: 3430.7385\n",
      "Epoch 5, Step 149, Training Loss: 3433.3933\n",
      "Epoch 5, Step 150, Training Loss: 3234.3606\n",
      "Epoch 5, Step 151, Training Loss: 3214.3645\n",
      "Epoch 5, Step 152, Training Loss: 3371.5400\n",
      "Epoch 5, Step 153, Training Loss: 3276.9241\n",
      "Epoch 5, Step 154, Training Loss: 3335.8518\n",
      "Epoch 5, Step 155, Training Loss: 3250.1018\n",
      "Epoch 5, Step 156, Training Loss: 3304.9080\n",
      "Epoch 5, Step 157, Training Loss: 3454.5776\n",
      "Epoch 5, Step 158, Training Loss: 3354.5486\n",
      "Epoch 5, Step 159, Training Loss: 3237.1917\n",
      "Epoch 5, Step 160, Training Loss: 3418.5513\n",
      "Epoch 5, Step 161, Training Loss: 3214.9187\n",
      "Epoch 5, Step 162, Training Loss: 3357.0435\n",
      "Epoch 5, Step 163, Training Loss: 3329.9158\n",
      "Epoch 5, Step 164, Training Loss: 3233.4509\n",
      "Epoch 5, Step 165, Training Loss: 3161.6436\n",
      "Epoch 5, Step 166, Training Loss: 3190.5603\n",
      "Epoch 5, Step 167, Training Loss: 3282.2380\n",
      "Epoch 5, Step 168, Training Loss: 3128.3762\n",
      "Epoch 5, Step 169, Training Loss: 3304.1233\n",
      "Epoch 5, Step 170, Training Loss: 3305.0107\n",
      "Epoch 5, Step 171, Training Loss: 3219.7607\n",
      "Epoch 5, Step 172, Training Loss: 3236.6514\n",
      "Epoch 5, Step 173, Training Loss: 3222.4087\n",
      "Epoch 5, Step 174, Training Loss: 3160.6213\n",
      "Epoch 5, Step 175, Training Loss: 3378.8584\n",
      "Epoch 5, Step 176, Training Loss: 3165.9946\n",
      "Epoch 5, Step 177, Training Loss: 3437.6189\n",
      "Epoch 5, Step 178, Training Loss: 3385.2776\n",
      "Epoch 5, Step 179, Training Loss: 3204.9456\n",
      "Epoch 5, Step 180, Training Loss: 3056.0142\n",
      "Epoch 5, Step 181, Training Loss: 3273.1257\n",
      "Epoch 5, Step 182, Training Loss: 3357.3088\n",
      "Epoch 5, Step 183, Training Loss: 3032.3123\n",
      "Epoch 5, Step 184, Training Loss: 3158.9500\n",
      "Epoch 5, Step 185, Training Loss: 2970.1121\n",
      "Epoch 5, Step 186, Training Loss: 3267.3093\n",
      "Epoch 5, Step 187, Training Loss: 3115.2632\n",
      "Epoch 5, Step 188, Training Loss: 3067.2649\n",
      "Epoch 5, Step 189, Training Loss: 3077.2925\n",
      "Epoch 5, Step 190, Training Loss: 3507.8367\n",
      "Epoch 5, Step 191, Training Loss: 3133.1917\n",
      "Epoch 5, Step 192, Training Loss: 3256.1067\n",
      "Epoch 5, Step 193, Training Loss: 3251.6089\n",
      "Epoch 5, Step 194, Training Loss: 3282.4812\n",
      "Epoch 5, Step 195, Training Loss: 3240.8899\n",
      "Epoch 5, Step 196, Training Loss: 3245.7339\n",
      "Epoch 5, Step 197, Training Loss: 3076.0681\n",
      "Epoch 5, Step 198, Training Loss: 3118.5798\n",
      "Epoch 5, Step 199, Training Loss: 3260.4094\n",
      "Epoch 5, Step 200, Training Loss: 2963.9011\n",
      "Epoch 5, Step 201, Training Loss: 3016.3928\n",
      "Epoch 5, Step 202, Training Loss: 2988.2803\n",
      "Epoch 5, Step 203, Training Loss: 3137.5994\n",
      "Epoch 5, Step 204, Training Loss: 3353.5464\n",
      "Epoch 5, Step 205, Training Loss: 3217.6526\n",
      "Epoch 5, Step 206, Training Loss: 3028.9417\n",
      "--- Epoch 5, Validation Loss: 3029.2509 ---\n",
      "Epoch 6, Step 0, Training Loss: 2962.2139\n",
      "Epoch 6, Step 1, Training Loss: 3052.9431\n",
      "Epoch 6, Step 2, Training Loss: 3145.6865\n",
      "Epoch 6, Step 3, Training Loss: 3121.6135\n",
      "Epoch 6, Step 4, Training Loss: 3143.5364\n",
      "Epoch 6, Step 5, Training Loss: 2892.5266\n",
      "Epoch 6, Step 6, Training Loss: 2935.8940\n",
      "Epoch 6, Step 7, Training Loss: 3269.0798\n",
      "Epoch 6, Step 8, Training Loss: 3041.7800\n",
      "Epoch 6, Step 9, Training Loss: 2905.2708\n",
      "Epoch 6, Step 10, Training Loss: 2926.7083\n",
      "Epoch 6, Step 11, Training Loss: 3025.7898\n",
      "Epoch 6, Step 12, Training Loss: 3169.7961\n",
      "Epoch 6, Step 13, Training Loss: 3211.4177\n",
      "Epoch 6, Step 14, Training Loss: 2990.6257\n",
      "Epoch 6, Step 15, Training Loss: 3036.9634\n",
      "Epoch 6, Step 16, Training Loss: 2888.2039\n",
      "Epoch 6, Step 17, Training Loss: 2947.1912\n",
      "Epoch 6, Step 18, Training Loss: 2936.8284\n",
      "Epoch 6, Step 19, Training Loss: 3045.0049\n",
      "Epoch 6, Step 20, Training Loss: 3074.0747\n",
      "Epoch 6, Step 21, Training Loss: 3157.7283\n",
      "Epoch 6, Step 22, Training Loss: 2925.2100\n",
      "Epoch 6, Step 23, Training Loss: 3117.4526\n",
      "Epoch 6, Step 24, Training Loss: 2800.3774\n",
      "Epoch 6, Step 25, Training Loss: 3030.3870\n",
      "Epoch 6, Step 26, Training Loss: 2725.9204\n",
      "Epoch 6, Step 27, Training Loss: 3035.0920\n",
      "Epoch 6, Step 28, Training Loss: 2838.8767\n",
      "Epoch 6, Step 29, Training Loss: 2891.6497\n",
      "Epoch 6, Step 30, Training Loss: 2928.0647\n",
      "Epoch 6, Step 31, Training Loss: 2989.2310\n",
      "Epoch 6, Step 32, Training Loss: 2974.4683\n",
      "Epoch 6, Step 33, Training Loss: 2768.7664\n",
      "Epoch 6, Step 34, Training Loss: 2977.6335\n",
      "Epoch 6, Step 35, Training Loss: 2872.0979\n",
      "Epoch 6, Step 36, Training Loss: 2935.1389\n",
      "Epoch 6, Step 37, Training Loss: 3006.4561\n",
      "Epoch 6, Step 38, Training Loss: 3039.9678\n",
      "Epoch 6, Step 39, Training Loss: 2992.9138\n",
      "Epoch 6, Step 40, Training Loss: 2864.6279\n",
      "Epoch 6, Step 41, Training Loss: 2961.9294\n",
      "Epoch 6, Step 42, Training Loss: 2963.2490\n",
      "Epoch 6, Step 43, Training Loss: 2769.0315\n",
      "Epoch 6, Step 44, Training Loss: 2995.8826\n",
      "Epoch 6, Step 45, Training Loss: 2846.0588\n",
      "Epoch 6, Step 46, Training Loss: 2734.1262\n",
      "Epoch 6, Step 47, Training Loss: 2787.1042\n",
      "Epoch 6, Step 48, Training Loss: 2778.9119\n",
      "Epoch 6, Step 49, Training Loss: 3021.0081\n",
      "Epoch 6, Step 50, Training Loss: 2825.2209\n",
      "Epoch 6, Step 51, Training Loss: 2751.8098\n",
      "Epoch 6, Step 52, Training Loss: 2673.4575\n",
      "Epoch 6, Step 53, Training Loss: 2794.7498\n",
      "Epoch 6, Step 54, Training Loss: 2814.9185\n",
      "Epoch 6, Step 55, Training Loss: 2986.1370\n",
      "Epoch 6, Step 56, Training Loss: 3009.3333\n",
      "Epoch 6, Step 57, Training Loss: 2831.9292\n",
      "Epoch 6, Step 58, Training Loss: 2954.3206\n",
      "Epoch 6, Step 59, Training Loss: 2856.2087\n",
      "Epoch 6, Step 60, Training Loss: 3047.0693\n",
      "Epoch 6, Step 61, Training Loss: 2674.7065\n",
      "Epoch 6, Step 62, Training Loss: 2718.8445\n",
      "Epoch 6, Step 63, Training Loss: 2738.6799\n",
      "Epoch 6, Step 64, Training Loss: 2843.6838\n",
      "Epoch 6, Step 65, Training Loss: 2714.1692\n",
      "Epoch 6, Step 66, Training Loss: 2733.8679\n",
      "Epoch 6, Step 67, Training Loss: 3046.0256\n",
      "Epoch 6, Step 68, Training Loss: 2783.0671\n",
      "Epoch 6, Step 69, Training Loss: 3002.0002\n",
      "Epoch 6, Step 70, Training Loss: 2812.5281\n",
      "Epoch 6, Step 71, Training Loss: 2793.4265\n",
      "Epoch 6, Step 72, Training Loss: 2713.1375\n",
      "Epoch 6, Step 73, Training Loss: 2843.2585\n",
      "Epoch 6, Step 74, Training Loss: 2739.8533\n",
      "Epoch 6, Step 75, Training Loss: 2718.6306\n",
      "Epoch 6, Step 76, Training Loss: 2999.3899\n",
      "Epoch 6, Step 77, Training Loss: 2773.8171\n",
      "Epoch 6, Step 78, Training Loss: 2708.0969\n",
      "Epoch 6, Step 79, Training Loss: 2650.0461\n",
      "Epoch 6, Step 80, Training Loss: 2607.0955\n",
      "Epoch 6, Step 81, Training Loss: 2907.0090\n",
      "Epoch 6, Step 82, Training Loss: 2687.0891\n",
      "Epoch 6, Step 83, Training Loss: 2832.1018\n",
      "Epoch 6, Step 84, Training Loss: 2777.9836\n",
      "Epoch 6, Step 85, Training Loss: 2808.0298\n",
      "Epoch 6, Step 86, Training Loss: 2658.9053\n",
      "Epoch 6, Step 87, Training Loss: 2545.5039\n",
      "Epoch 6, Step 88, Training Loss: 2937.5012\n",
      "Epoch 6, Step 89, Training Loss: 2623.4502\n",
      "Epoch 6, Step 90, Training Loss: 2576.2681\n",
      "Epoch 6, Step 91, Training Loss: 2764.0032\n",
      "Epoch 6, Step 92, Training Loss: 2684.5640\n",
      "Epoch 6, Step 93, Training Loss: 2732.4368\n",
      "Epoch 6, Step 94, Training Loss: 2662.8875\n",
      "Epoch 6, Step 95, Training Loss: 2628.9800\n",
      "Epoch 6, Step 96, Training Loss: 2635.5422\n",
      "Epoch 6, Step 97, Training Loss: 2663.6123\n",
      "Epoch 6, Step 98, Training Loss: 2755.1755\n",
      "Epoch 6, Step 99, Training Loss: 2791.1199\n",
      "Epoch 6, Step 100, Training Loss: 2642.5320\n",
      "Epoch 6, Step 101, Training Loss: 2681.2446\n",
      "Epoch 6, Step 102, Training Loss: 2839.0237\n",
      "Epoch 6, Step 103, Training Loss: 2674.1257\n",
      "Epoch 6, Step 104, Training Loss: 2684.5359\n",
      "Epoch 6, Step 105, Training Loss: 2559.5898\n",
      "Epoch 6, Step 106, Training Loss: 2723.3862\n",
      "Epoch 6, Step 107, Training Loss: 2780.6370\n",
      "Epoch 6, Step 108, Training Loss: 2609.6484\n",
      "Epoch 6, Step 109, Training Loss: 2558.0798\n",
      "Epoch 6, Step 110, Training Loss: 2720.4990\n",
      "Epoch 6, Step 111, Training Loss: 2616.0403\n",
      "Epoch 6, Step 112, Training Loss: 2640.8894\n",
      "Epoch 6, Step 113, Training Loss: 2619.8728\n",
      "Epoch 6, Step 114, Training Loss: 2507.1033\n",
      "Epoch 6, Step 115, Training Loss: 2663.6719\n",
      "Epoch 6, Step 116, Training Loss: 2521.8633\n",
      "Epoch 6, Step 117, Training Loss: 2651.4648\n",
      "Epoch 6, Step 118, Training Loss: 2604.0681\n",
      "Epoch 6, Step 119, Training Loss: 2527.2712\n",
      "Epoch 6, Step 120, Training Loss: 2635.8098\n",
      "Epoch 6, Step 121, Training Loss: 2670.5898\n",
      "Epoch 6, Step 122, Training Loss: 2469.3032\n",
      "Epoch 6, Step 123, Training Loss: 2617.9099\n",
      "Epoch 6, Step 124, Training Loss: 2725.7417\n",
      "Epoch 6, Step 125, Training Loss: 2579.0859\n",
      "Epoch 6, Step 126, Training Loss: 2478.6829\n",
      "Epoch 6, Step 127, Training Loss: 2483.9644\n",
      "Epoch 6, Step 128, Training Loss: 2447.3115\n",
      "Epoch 6, Step 129, Training Loss: 2533.6494\n",
      "Epoch 6, Step 130, Training Loss: 2548.7642\n",
      "Epoch 6, Step 131, Training Loss: 2479.5942\n",
      "Epoch 6, Step 132, Training Loss: 2563.6362\n",
      "Epoch 6, Step 133, Training Loss: 2429.2625\n",
      "Epoch 6, Step 134, Training Loss: 2634.0769\n",
      "Epoch 6, Step 135, Training Loss: 2517.9463\n",
      "Epoch 6, Step 136, Training Loss: 2500.0076\n",
      "Epoch 6, Step 137, Training Loss: 2568.1733\n",
      "Epoch 6, Step 138, Training Loss: 2473.6594\n",
      "Epoch 6, Step 139, Training Loss: 2388.3936\n",
      "Epoch 6, Step 140, Training Loss: 2412.9355\n",
      "Epoch 6, Step 141, Training Loss: 2509.5364\n",
      "Epoch 6, Step 142, Training Loss: 2392.8618\n",
      "Epoch 6, Step 143, Training Loss: 2552.3474\n",
      "Epoch 6, Step 144, Training Loss: 2396.1470\n",
      "Epoch 6, Step 145, Training Loss: 2487.5532\n",
      "Epoch 6, Step 146, Training Loss: 2342.1729\n",
      "Epoch 6, Step 147, Training Loss: 2438.3884\n",
      "Epoch 6, Step 148, Training Loss: 2514.2070\n",
      "Epoch 6, Step 149, Training Loss: 2514.8745\n",
      "Epoch 6, Step 150, Training Loss: 2341.6489\n",
      "Epoch 6, Step 151, Training Loss: 2324.3738\n",
      "Epoch 6, Step 152, Training Loss: 2480.8682\n",
      "Epoch 6, Step 153, Training Loss: 2372.3203\n",
      "Epoch 6, Step 154, Training Loss: 2417.7461\n",
      "Epoch 6, Step 155, Training Loss: 2357.2354\n",
      "Epoch 6, Step 156, Training Loss: 2445.5239\n",
      "Epoch 6, Step 157, Training Loss: 2498.5007\n",
      "Epoch 6, Step 158, Training Loss: 2434.2078\n",
      "Epoch 6, Step 159, Training Loss: 2372.1223\n",
      "Epoch 6, Step 160, Training Loss: 2538.0339\n",
      "Epoch 6, Step 161, Training Loss: 2293.9590\n",
      "Epoch 6, Step 162, Training Loss: 2464.5867\n",
      "Epoch 6, Step 163, Training Loss: 2405.3149\n",
      "Epoch 6, Step 164, Training Loss: 2341.3787\n",
      "Epoch 6, Step 165, Training Loss: 2293.6697\n",
      "Epoch 6, Step 166, Training Loss: 2346.7183\n",
      "Epoch 6, Step 167, Training Loss: 2360.4309\n",
      "Epoch 6, Step 168, Training Loss: 2260.6465\n",
      "Epoch 6, Step 169, Training Loss: 2442.4114\n",
      "Epoch 6, Step 170, Training Loss: 2384.4805\n",
      "Epoch 6, Step 171, Training Loss: 2330.5735\n",
      "Epoch 6, Step 172, Training Loss: 2315.5747\n",
      "Epoch 6, Step 173, Training Loss: 2356.0020\n",
      "Epoch 6, Step 174, Training Loss: 2259.1487\n",
      "Epoch 6, Step 175, Training Loss: 2466.7651\n",
      "Epoch 6, Step 176, Training Loss: 2334.7168\n",
      "Epoch 6, Step 177, Training Loss: 2533.7334\n",
      "Epoch 6, Step 178, Training Loss: 2478.2539\n",
      "Epoch 6, Step 179, Training Loss: 2296.5776\n",
      "Epoch 6, Step 180, Training Loss: 2190.3721\n",
      "Epoch 6, Step 181, Training Loss: 2390.2368\n",
      "Epoch 6, Step 182, Training Loss: 2434.0933\n",
      "Epoch 6, Step 183, Training Loss: 2192.8884\n",
      "Epoch 6, Step 184, Training Loss: 2311.4177\n",
      "Epoch 6, Step 185, Training Loss: 2121.7695\n",
      "Epoch 6, Step 186, Training Loss: 2397.5303\n",
      "Epoch 6, Step 187, Training Loss: 2248.1870\n",
      "Epoch 6, Step 188, Training Loss: 2203.8320\n",
      "Epoch 6, Step 189, Training Loss: 2253.0342\n",
      "Epoch 6, Step 190, Training Loss: 2622.1436\n",
      "Epoch 6, Step 191, Training Loss: 2229.5935\n",
      "Epoch 6, Step 192, Training Loss: 2378.0151\n",
      "Epoch 6, Step 193, Training Loss: 2366.8350\n",
      "Epoch 6, Step 194, Training Loss: 2387.0693\n",
      "Epoch 6, Step 195, Training Loss: 2364.8503\n",
      "Epoch 6, Step 196, Training Loss: 2350.8611\n",
      "Epoch 6, Step 197, Training Loss: 2239.5046\n",
      "Epoch 6, Step 198, Training Loss: 2238.9766\n",
      "Epoch 6, Step 199, Training Loss: 2352.0837\n",
      "Epoch 6, Step 200, Training Loss: 2137.6731\n",
      "Epoch 6, Step 201, Training Loss: 2193.0386\n",
      "Epoch 6, Step 202, Training Loss: 2153.0122\n",
      "Epoch 6, Step 203, Training Loss: 2259.0156\n",
      "Epoch 6, Step 204, Training Loss: 2432.1714\n",
      "Epoch 6, Step 205, Training Loss: 2309.3721\n",
      "Epoch 6, Step 206, Training Loss: 2195.5601\n",
      "--- Epoch 6, Validation Loss: 2307.5523 ---\n",
      "Epoch 7, Step 0, Training Loss: 2101.4661\n",
      "Epoch 7, Step 1, Training Loss: 2232.6636\n",
      "Epoch 7, Step 2, Training Loss: 2236.1672\n",
      "Epoch 7, Step 3, Training Loss: 2257.9050\n",
      "Epoch 7, Step 4, Training Loss: 2269.1541\n",
      "Epoch 7, Step 5, Training Loss: 2059.5425\n",
      "Epoch 7, Step 6, Training Loss: 2095.2251\n",
      "Epoch 7, Step 7, Training Loss: 2361.2212\n",
      "Epoch 7, Step 8, Training Loss: 2164.2585\n",
      "Epoch 7, Step 9, Training Loss: 2063.3384\n",
      "Epoch 7, Step 10, Training Loss: 2086.3201\n",
      "Epoch 7, Step 11, Training Loss: 2161.3054\n",
      "Epoch 7, Step 12, Training Loss: 2325.6846\n",
      "Epoch 7, Step 13, Training Loss: 2337.0481\n",
      "Epoch 7, Step 14, Training Loss: 2163.2683\n",
      "Epoch 7, Step 15, Training Loss: 2198.4539\n",
      "Epoch 7, Step 16, Training Loss: 2080.9758\n",
      "Epoch 7, Step 17, Training Loss: 2140.3279\n",
      "Epoch 7, Step 18, Training Loss: 2120.7493\n",
      "Epoch 7, Step 19, Training Loss: 2182.1230\n",
      "Epoch 7, Step 20, Training Loss: 2212.7446\n",
      "Epoch 7, Step 21, Training Loss: 2282.1106\n",
      "Epoch 7, Step 22, Training Loss: 2125.9922\n",
      "Epoch 7, Step 23, Training Loss: 2277.1765\n",
      "Epoch 7, Step 24, Training Loss: 1994.1205\n",
      "Epoch 7, Step 25, Training Loss: 2176.5129\n",
      "Epoch 7, Step 26, Training Loss: 1928.1582\n",
      "Epoch 7, Step 27, Training Loss: 2243.0496\n",
      "Epoch 7, Step 28, Training Loss: 2009.7808\n",
      "Epoch 7, Step 29, Training Loss: 2099.0793\n",
      "Epoch 7, Step 30, Training Loss: 2084.4695\n",
      "Epoch 7, Step 31, Training Loss: 2114.7830\n",
      "Epoch 7, Step 32, Training Loss: 2141.5044\n",
      "Epoch 7, Step 33, Training Loss: 2001.2317\n",
      "Epoch 7, Step 34, Training Loss: 2140.1416\n",
      "Epoch 7, Step 35, Training Loss: 2051.4600\n",
      "Epoch 7, Step 36, Training Loss: 2121.8306\n",
      "Epoch 7, Step 37, Training Loss: 2161.4165\n",
      "Epoch 7, Step 38, Training Loss: 2191.9565\n",
      "Epoch 7, Step 39, Training Loss: 2143.4248\n",
      "Epoch 7, Step 40, Training Loss: 2055.1145\n",
      "Epoch 7, Step 41, Training Loss: 2158.1675\n",
      "Epoch 7, Step 42, Training Loss: 2137.5537\n",
      "Epoch 7, Step 43, Training Loss: 1962.9298\n",
      "Epoch 7, Step 44, Training Loss: 2156.6440\n",
      "Epoch 7, Step 45, Training Loss: 2043.3547\n",
      "Epoch 7, Step 46, Training Loss: 1930.9294\n",
      "Epoch 7, Step 47, Training Loss: 2000.4318\n",
      "Epoch 7, Step 48, Training Loss: 1984.6123\n",
      "Epoch 7, Step 49, Training Loss: 2182.2539\n",
      "Epoch 7, Step 50, Training Loss: 2014.9630\n",
      "Epoch 7, Step 51, Training Loss: 1993.1642\n",
      "Epoch 7, Step 52, Training Loss: 1902.4503\n",
      "Epoch 7, Step 53, Training Loss: 1999.5475\n",
      "Epoch 7, Step 54, Training Loss: 2021.6949\n",
      "Epoch 7, Step 55, Training Loss: 2165.6707\n",
      "Epoch 7, Step 56, Training Loss: 2227.6682\n",
      "Epoch 7, Step 57, Training Loss: 2018.0950\n",
      "Epoch 7, Step 58, Training Loss: 2144.0066\n",
      "Epoch 7, Step 59, Training Loss: 2044.5674\n",
      "Epoch 7, Step 60, Training Loss: 2211.7261\n",
      "Epoch 7, Step 61, Training Loss: 1898.3274\n",
      "Epoch 7, Step 62, Training Loss: 1938.3951\n",
      "Epoch 7, Step 63, Training Loss: 2007.6525\n",
      "Epoch 7, Step 64, Training Loss: 2053.3792\n",
      "Epoch 7, Step 65, Training Loss: 1955.6877\n",
      "Epoch 7, Step 66, Training Loss: 1954.8422\n",
      "Epoch 7, Step 67, Training Loss: 2196.9304\n",
      "Epoch 7, Step 68, Training Loss: 2007.0386\n",
      "Epoch 7, Step 69, Training Loss: 2210.4766\n",
      "Epoch 7, Step 70, Training Loss: 2034.3949\n",
      "Epoch 7, Step 71, Training Loss: 1986.1470\n",
      "Epoch 7, Step 72, Training Loss: 1948.4365\n",
      "Epoch 7, Step 73, Training Loss: 2038.0621\n",
      "Epoch 7, Step 74, Training Loss: 1953.3745\n",
      "Epoch 7, Step 75, Training Loss: 1967.5892\n",
      "Epoch 7, Step 76, Training Loss: 2183.8569\n",
      "Epoch 7, Step 77, Training Loss: 2038.0383\n",
      "Epoch 7, Step 78, Training Loss: 1889.5293\n",
      "Epoch 7, Step 79, Training Loss: 1886.5817\n",
      "Epoch 7, Step 80, Training Loss: 1885.8422\n",
      "Epoch 7, Step 81, Training Loss: 2125.8999\n",
      "Epoch 7, Step 82, Training Loss: 1917.2944\n",
      "Epoch 7, Step 83, Training Loss: 2017.4326\n",
      "Epoch 7, Step 84, Training Loss: 2010.2168\n",
      "Epoch 7, Step 85, Training Loss: 1986.4038\n",
      "Epoch 7, Step 86, Training Loss: 1845.0597\n",
      "Epoch 7, Step 87, Training Loss: 1828.1616\n",
      "Epoch 7, Step 88, Training Loss: 2144.1187\n",
      "Epoch 7, Step 89, Training Loss: 1890.5425\n",
      "Epoch 7, Step 90, Training Loss: 1836.4038\n",
      "Epoch 7, Step 91, Training Loss: 1991.8860\n",
      "Epoch 7, Step 92, Training Loss: 1899.7043\n",
      "Epoch 7, Step 93, Training Loss: 1992.6658\n",
      "Epoch 7, Step 94, Training Loss: 1917.6956\n",
      "Epoch 7, Step 95, Training Loss: 1855.2465\n",
      "Epoch 7, Step 96, Training Loss: 1877.1633\n",
      "Epoch 7, Step 97, Training Loss: 1901.2467\n",
      "Epoch 7, Step 98, Training Loss: 1962.3185\n",
      "Epoch 7, Step 99, Training Loss: 1975.5825\n",
      "Epoch 7, Step 100, Training Loss: 1884.1022\n",
      "Epoch 7, Step 101, Training Loss: 1914.6804\n",
      "Epoch 7, Step 102, Training Loss: 2051.9033\n",
      "Epoch 7, Step 103, Training Loss: 1910.3149\n",
      "Epoch 7, Step 104, Training Loss: 1906.5520\n",
      "Epoch 7, Step 105, Training Loss: 1808.4607\n",
      "Epoch 7, Step 106, Training Loss: 1954.9690\n",
      "Epoch 7, Step 107, Training Loss: 2034.5166\n",
      "Epoch 7, Step 108, Training Loss: 1865.6703\n",
      "Epoch 7, Step 109, Training Loss: 1854.8151\n",
      "Epoch 7, Step 110, Training Loss: 1957.9854\n",
      "Epoch 7, Step 111, Training Loss: 1873.1722\n",
      "Epoch 7, Step 112, Training Loss: 1867.4025\n",
      "Epoch 7, Step 113, Training Loss: 1875.6379\n",
      "Epoch 7, Step 114, Training Loss: 1791.8170\n",
      "Epoch 7, Step 115, Training Loss: 1900.6707\n",
      "Epoch 7, Step 116, Training Loss: 1790.7633\n",
      "Epoch 7, Step 117, Training Loss: 1887.9814\n",
      "Epoch 7, Step 118, Training Loss: 1852.8528\n",
      "Epoch 7, Step 119, Training Loss: 1783.2974\n",
      "Epoch 7, Step 120, Training Loss: 1871.7682\n",
      "Epoch 7, Step 121, Training Loss: 1937.6417\n",
      "Epoch 7, Step 122, Training Loss: 1745.8394\n",
      "Epoch 7, Step 123, Training Loss: 1870.9431\n",
      "Epoch 7, Step 124, Training Loss: 1985.0355\n",
      "Epoch 7, Step 125, Training Loss: 1829.3324\n",
      "Epoch 7, Step 126, Training Loss: 1745.4205\n",
      "Epoch 7, Step 127, Training Loss: 1706.5511\n",
      "Epoch 7, Step 128, Training Loss: 1767.8503\n",
      "Epoch 7, Step 129, Training Loss: 1835.6123\n",
      "Epoch 7, Step 130, Training Loss: 1816.4094\n",
      "Epoch 7, Step 131, Training Loss: 1741.9409\n",
      "Epoch 7, Step 132, Training Loss: 1810.9865\n",
      "Epoch 7, Step 133, Training Loss: 1793.6958\n",
      "Epoch 7, Step 134, Training Loss: 1899.0375\n",
      "Epoch 7, Step 135, Training Loss: 1817.8708\n",
      "Epoch 7, Step 136, Training Loss: 1793.8737\n",
      "Epoch 7, Step 137, Training Loss: 1813.3354\n",
      "Epoch 7, Step 138, Training Loss: 1770.7104\n",
      "Epoch 7, Step 139, Training Loss: 1714.6469\n",
      "Epoch 7, Step 140, Training Loss: 1694.0629\n",
      "Epoch 7, Step 141, Training Loss: 1780.2595\n",
      "Epoch 7, Step 142, Training Loss: 1673.8845\n",
      "Epoch 7, Step 143, Training Loss: 1806.4847\n",
      "Epoch 7, Step 144, Training Loss: 1694.0406\n",
      "Epoch 7, Step 145, Training Loss: 1734.5267\n",
      "Epoch 7, Step 146, Training Loss: 1642.9797\n",
      "Epoch 7, Step 147, Training Loss: 1688.4849\n",
      "Epoch 7, Step 148, Training Loss: 1811.4814\n",
      "Epoch 7, Step 149, Training Loss: 1799.7386\n",
      "Epoch 7, Step 150, Training Loss: 1637.7856\n",
      "Epoch 7, Step 151, Training Loss: 1622.5562\n",
      "Epoch 7, Step 152, Training Loss: 1746.4954\n",
      "Epoch 7, Step 153, Training Loss: 1682.6429\n",
      "Epoch 7, Step 154, Training Loss: 1709.8461\n",
      "Epoch 7, Step 155, Training Loss: 1700.8270\n",
      "Epoch 7, Step 156, Training Loss: 1712.3097\n",
      "Epoch 7, Step 157, Training Loss: 1760.8966\n",
      "Epoch 7, Step 158, Training Loss: 1748.6056\n",
      "Epoch 7, Step 159, Training Loss: 1669.4370\n",
      "Epoch 7, Step 160, Training Loss: 1795.6069\n",
      "Epoch 7, Step 161, Training Loss: 1659.5555\n",
      "Epoch 7, Step 162, Training Loss: 1715.6056\n",
      "Epoch 7, Step 163, Training Loss: 1716.2870\n",
      "Epoch 7, Step 164, Training Loss: 1617.8859\n",
      "Epoch 7, Step 165, Training Loss: 1607.0383\n",
      "Epoch 7, Step 166, Training Loss: 1620.0354\n",
      "Epoch 7, Step 167, Training Loss: 1680.8561\n",
      "Epoch 7, Step 168, Training Loss: 1615.8016\n",
      "Epoch 7, Step 169, Training Loss: 1731.7350\n",
      "Epoch 7, Step 170, Training Loss: 1714.0425\n",
      "Epoch 7, Step 171, Training Loss: 1630.0671\n",
      "Epoch 7, Step 172, Training Loss: 1633.9880\n",
      "Epoch 7, Step 173, Training Loss: 1655.0905\n",
      "Epoch 7, Step 174, Training Loss: 1611.9263\n",
      "Epoch 7, Step 175, Training Loss: 1731.0863\n",
      "Epoch 7, Step 176, Training Loss: 1627.9833\n",
      "Epoch 7, Step 177, Training Loss: 1816.3418\n",
      "Epoch 7, Step 178, Training Loss: 1751.2397\n",
      "Epoch 7, Step 179, Training Loss: 1643.1769\n",
      "Epoch 7, Step 180, Training Loss: 1528.6466\n",
      "Epoch 7, Step 181, Training Loss: 1673.1316\n",
      "Epoch 7, Step 182, Training Loss: 1736.4071\n",
      "Epoch 7, Step 183, Training Loss: 1550.4791\n",
      "Epoch 7, Step 184, Training Loss: 1593.6783\n",
      "Epoch 7, Step 185, Training Loss: 1479.6949\n",
      "Epoch 7, Step 186, Training Loss: 1714.9537\n",
      "Epoch 7, Step 187, Training Loss: 1589.2600\n",
      "Epoch 7, Step 188, Training Loss: 1559.8168\n",
      "Epoch 7, Step 189, Training Loss: 1544.0348\n",
      "Epoch 7, Step 190, Training Loss: 1920.2708\n",
      "Epoch 7, Step 191, Training Loss: 1577.4253\n",
      "Epoch 7, Step 192, Training Loss: 1679.1873\n",
      "Epoch 7, Step 193, Training Loss: 1632.6001\n",
      "Epoch 7, Step 194, Training Loss: 1652.6805\n",
      "Epoch 7, Step 195, Training Loss: 1660.8929\n",
      "Epoch 7, Step 196, Training Loss: 1667.2872\n",
      "Epoch 7, Step 197, Training Loss: 1564.6536\n",
      "Epoch 7, Step 198, Training Loss: 1541.7174\n",
      "Epoch 7, Step 199, Training Loss: 1660.6440\n",
      "Epoch 7, Step 200, Training Loss: 1474.3490\n",
      "Epoch 7, Step 201, Training Loss: 1526.3452\n",
      "Epoch 7, Step 202, Training Loss: 1490.7505\n",
      "Epoch 7, Step 203, Training Loss: 1600.1736\n",
      "Epoch 7, Step 204, Training Loss: 1732.2009\n",
      "Epoch 7, Step 205, Training Loss: 1669.7743\n",
      "Epoch 7, Step 206, Training Loss: 1541.0428\n",
      "--- Epoch 7, Validation Loss: 1610.7220 ---\n",
      "Epoch 8, Step 0, Training Loss: 1476.0128\n",
      "Epoch 8, Step 1, Training Loss: 1537.8678\n",
      "Epoch 8, Step 2, Training Loss: 1618.9165\n",
      "Epoch 8, Step 3, Training Loss: 1590.2347\n",
      "Epoch 8, Step 4, Training Loss: 1555.2096\n",
      "Epoch 8, Step 5, Training Loss: 1442.1912\n",
      "Epoch 8, Step 6, Training Loss: 1466.7297\n",
      "Epoch 8, Step 7, Training Loss: 1684.5776\n",
      "Epoch 8, Step 8, Training Loss: 1504.3801\n",
      "Epoch 8, Step 9, Training Loss: 1401.1588\n",
      "Epoch 8, Step 10, Training Loss: 1471.9625\n",
      "Epoch 8, Step 11, Training Loss: 1539.6061\n",
      "Epoch 8, Step 12, Training Loss: 1624.5754\n",
      "Epoch 8, Step 13, Training Loss: 1676.1395\n",
      "Epoch 8, Step 14, Training Loss: 1494.5002\n",
      "Epoch 8, Step 15, Training Loss: 1512.4429\n",
      "Epoch 8, Step 16, Training Loss: 1456.5743\n",
      "Epoch 8, Step 17, Training Loss: 1486.6566\n",
      "Epoch 8, Step 18, Training Loss: 1476.5017\n",
      "Epoch 8, Step 19, Training Loss: 1562.2720\n",
      "Epoch 8, Step 20, Training Loss: 1581.1672\n",
      "Epoch 8, Step 21, Training Loss: 1610.1136\n",
      "Epoch 8, Step 22, Training Loss: 1501.4021\n",
      "Epoch 8, Step 23, Training Loss: 1596.1697\n",
      "Epoch 8, Step 24, Training Loss: 1363.1252\n",
      "Epoch 8, Step 25, Training Loss: 1510.7322\n",
      "Epoch 8, Step 26, Training Loss: 1333.1189\n",
      "Epoch 8, Step 27, Training Loss: 1545.6284\n",
      "Epoch 8, Step 28, Training Loss: 1392.8296\n",
      "Epoch 8, Step 29, Training Loss: 1446.0219\n",
      "Epoch 8, Step 30, Training Loss: 1434.5797\n",
      "Epoch 8, Step 31, Training Loss: 1494.6870\n",
      "Epoch 8, Step 32, Training Loss: 1507.0212\n",
      "Epoch 8, Step 33, Training Loss: 1382.6427\n",
      "Epoch 8, Step 34, Training Loss: 1536.7336\n",
      "Epoch 8, Step 35, Training Loss: 1407.8556\n",
      "Epoch 8, Step 36, Training Loss: 1468.2444\n",
      "Epoch 8, Step 37, Training Loss: 1512.6198\n",
      "Epoch 8, Step 38, Training Loss: 1545.4431\n",
      "Epoch 8, Step 39, Training Loss: 1509.6125\n",
      "Epoch 8, Step 40, Training Loss: 1438.3425\n",
      "Epoch 8, Step 41, Training Loss: 1538.5876\n",
      "Epoch 8, Step 42, Training Loss: 1485.4879\n",
      "Epoch 8, Step 43, Training Loss: 1339.2133\n",
      "Epoch 8, Step 44, Training Loss: 1492.0930\n",
      "Epoch 8, Step 45, Training Loss: 1425.2478\n",
      "Epoch 8, Step 46, Training Loss: 1321.0286\n",
      "Epoch 8, Step 47, Training Loss: 1390.0681\n",
      "Epoch 8, Step 48, Training Loss: 1366.9574\n",
      "Epoch 8, Step 49, Training Loss: 1521.6272\n",
      "Epoch 8, Step 50, Training Loss: 1391.9105\n",
      "Epoch 8, Step 51, Training Loss: 1405.4280\n",
      "Epoch 8, Step 52, Training Loss: 1297.0059\n",
      "Epoch 8, Step 53, Training Loss: 1380.6047\n",
      "Epoch 8, Step 54, Training Loss: 1395.1198\n",
      "Epoch 8, Step 55, Training Loss: 1541.3718\n",
      "Epoch 8, Step 56, Training Loss: 1568.2942\n",
      "Epoch 8, Step 57, Training Loss: 1383.0387\n",
      "Epoch 8, Step 58, Training Loss: 1480.7318\n",
      "Epoch 8, Step 59, Training Loss: 1393.0035\n",
      "Epoch 8, Step 60, Training Loss: 1585.4302\n",
      "Epoch 8, Step 61, Training Loss: 1296.6895\n",
      "Epoch 8, Step 62, Training Loss: 1344.6744\n",
      "Epoch 8, Step 63, Training Loss: 1393.8689\n",
      "Epoch 8, Step 64, Training Loss: 1410.7698\n",
      "Epoch 8, Step 65, Training Loss: 1349.6913\n",
      "Epoch 8, Step 66, Training Loss: 1339.6306\n",
      "Epoch 8, Step 67, Training Loss: 1589.5698\n",
      "Epoch 8, Step 68, Training Loss: 1395.1462\n",
      "Epoch 8, Step 69, Training Loss: 1543.9722\n",
      "Epoch 8, Step 70, Training Loss: 1416.1897\n",
      "Epoch 8, Step 71, Training Loss: 1374.6759\n",
      "Epoch 8, Step 72, Training Loss: 1322.9099\n",
      "Epoch 8, Step 73, Training Loss: 1428.3474\n",
      "Epoch 8, Step 74, Training Loss: 1309.8794\n",
      "Epoch 8, Step 75, Training Loss: 1327.6846\n",
      "Epoch 8, Step 76, Training Loss: 1520.0045\n",
      "Epoch 8, Step 77, Training Loss: 1406.1248\n",
      "Epoch 8, Step 78, Training Loss: 1334.5111\n",
      "Epoch 8, Step 79, Training Loss: 1298.2386\n",
      "Epoch 8, Step 80, Training Loss: 1295.7317\n",
      "Epoch 8, Step 81, Training Loss: 1514.4950\n",
      "Epoch 8, Step 82, Training Loss: 1329.2620\n",
      "Epoch 8, Step 83, Training Loss: 1401.3229\n",
      "Epoch 8, Step 84, Training Loss: 1414.0782\n",
      "Epoch 8, Step 85, Training Loss: 1373.1188\n",
      "Epoch 8, Step 86, Training Loss: 1307.4431\n",
      "Epoch 8, Step 87, Training Loss: 1238.5117\n",
      "Epoch 8, Step 88, Training Loss: 1533.2278\n",
      "Epoch 8, Step 89, Training Loss: 1297.9763\n",
      "Epoch 8, Step 90, Training Loss: 1261.8651\n",
      "Epoch 8, Step 91, Training Loss: 1381.8400\n",
      "Epoch 8, Step 92, Training Loss: 1303.4930\n",
      "Epoch 8, Step 93, Training Loss: 1400.0267\n",
      "Epoch 8, Step 94, Training Loss: 1311.1328\n",
      "Epoch 8, Step 95, Training Loss: 1295.2418\n",
      "Epoch 8, Step 96, Training Loss: 1307.4609\n",
      "Epoch 8, Step 97, Training Loss: 1318.3641\n",
      "Epoch 8, Step 98, Training Loss: 1386.0870\n",
      "Epoch 8, Step 99, Training Loss: 1376.4227\n",
      "Epoch 8, Step 100, Training Loss: 1286.4629\n",
      "Epoch 8, Step 101, Training Loss: 1328.3315\n",
      "Epoch 8, Step 102, Training Loss: 1438.2889\n",
      "Epoch 8, Step 103, Training Loss: 1317.0503\n",
      "Epoch 8, Step 104, Training Loss: 1307.9808\n",
      "Epoch 8, Step 105, Training Loss: 1256.1274\n",
      "Epoch 8, Step 106, Training Loss: 1388.7544\n",
      "Epoch 8, Step 107, Training Loss: 1408.1334\n",
      "Epoch 8, Step 108, Training Loss: 1269.7654\n",
      "Epoch 8, Step 109, Training Loss: 1285.6637\n",
      "Epoch 8, Step 110, Training Loss: 1389.8890\n",
      "Epoch 8, Step 111, Training Loss: 1276.9724\n",
      "Epoch 8, Step 112, Training Loss: 1298.7437\n",
      "Epoch 8, Step 113, Training Loss: 1295.5349\n",
      "Epoch 8, Step 114, Training Loss: 1205.8049\n",
      "Epoch 8, Step 115, Training Loss: 1333.4187\n",
      "Epoch 8, Step 116, Training Loss: 1261.9280\n",
      "Epoch 8, Step 117, Training Loss: 1315.1576\n",
      "Epoch 8, Step 118, Training Loss: 1287.2543\n",
      "Epoch 8, Step 119, Training Loss: 1249.6838\n",
      "Epoch 8, Step 120, Training Loss: 1315.8330\n",
      "Epoch 8, Step 121, Training Loss: 1371.8634\n",
      "Epoch 8, Step 122, Training Loss: 1227.5293\n",
      "Epoch 8, Step 123, Training Loss: 1297.6482\n",
      "Epoch 8, Step 124, Training Loss: 1395.7135\n",
      "Epoch 8, Step 125, Training Loss: 1274.7129\n",
      "Epoch 8, Step 126, Training Loss: 1197.9166\n",
      "Epoch 8, Step 127, Training Loss: 1188.9670\n",
      "Epoch 8, Step 128, Training Loss: 1190.6599\n",
      "Epoch 8, Step 129, Training Loss: 1267.9727\n",
      "Epoch 8, Step 130, Training Loss: 1275.9392\n",
      "Epoch 8, Step 131, Training Loss: 1166.2390\n",
      "Epoch 8, Step 132, Training Loss: 1265.3379\n",
      "Epoch 8, Step 133, Training Loss: 1203.9447\n",
      "Epoch 8, Step 134, Training Loss: 1315.9686\n",
      "Epoch 8, Step 135, Training Loss: 1233.6677\n",
      "Epoch 8, Step 136, Training Loss: 1238.3040\n",
      "Epoch 8, Step 137, Training Loss: 1268.7412\n",
      "Epoch 8, Step 138, Training Loss: 1209.4453\n",
      "Epoch 8, Step 139, Training Loss: 1174.1488\n",
      "Epoch 8, Step 140, Training Loss: 1145.3796\n",
      "Epoch 8, Step 141, Training Loss: 1246.1215\n",
      "Epoch 8, Step 142, Training Loss: 1141.8708\n",
      "Epoch 8, Step 143, Training Loss: 1232.9496\n",
      "Epoch 8, Step 144, Training Loss: 1166.0657\n",
      "Epoch 8, Step 145, Training Loss: 1190.1591\n",
      "Epoch 8, Step 146, Training Loss: 1136.6161\n",
      "Epoch 8, Step 147, Training Loss: 1198.3962\n",
      "Epoch 8, Step 148, Training Loss: 1279.8787\n",
      "Epoch 8, Step 149, Training Loss: 1232.8450\n",
      "Epoch 8, Step 150, Training Loss: 1135.3060\n",
      "Epoch 8, Step 151, Training Loss: 1088.1931\n",
      "Epoch 8, Step 152, Training Loss: 1180.4761\n",
      "Epoch 8, Step 153, Training Loss: 1142.7854\n",
      "Epoch 8, Step 154, Training Loss: 1164.5869\n",
      "Epoch 8, Step 155, Training Loss: 1154.0896\n",
      "Epoch 8, Step 156, Training Loss: 1176.3563\n",
      "Epoch 8, Step 157, Training Loss: 1222.5771\n",
      "Epoch 8, Step 158, Training Loss: 1199.4954\n",
      "Epoch 8, Step 159, Training Loss: 1163.5194\n",
      "Epoch 8, Step 160, Training Loss: 1269.7448\n",
      "Epoch 8, Step 161, Training Loss: 1118.6194\n",
      "Epoch 8, Step 162, Training Loss: 1178.6530\n",
      "Epoch 8, Step 163, Training Loss: 1149.6692\n",
      "Epoch 8, Step 164, Training Loss: 1122.8281\n",
      "Epoch 8, Step 165, Training Loss: 1091.1605\n",
      "Epoch 8, Step 166, Training Loss: 1124.4219\n",
      "Epoch 8, Step 167, Training Loss: 1127.6509\n",
      "Epoch 8, Step 168, Training Loss: 1073.9609\n",
      "Epoch 8, Step 169, Training Loss: 1170.9160\n",
      "Epoch 8, Step 170, Training Loss: 1167.7153\n",
      "Epoch 8, Step 171, Training Loss: 1117.2894\n",
      "Epoch 8, Step 172, Training Loss: 1115.2927\n",
      "Epoch 8, Step 173, Training Loss: 1131.1293\n",
      "Epoch 8, Step 174, Training Loss: 1079.9724\n",
      "Epoch 8, Step 175, Training Loss: 1226.1760\n",
      "Epoch 8, Step 176, Training Loss: 1083.8558\n",
      "Epoch 8, Step 177, Training Loss: 1272.1820\n",
      "Epoch 8, Step 178, Training Loss: 1210.9589\n",
      "Epoch 8, Step 179, Training Loss: 1092.1465\n",
      "Epoch 8, Step 180, Training Loss: 1020.5782\n",
      "Epoch 8, Step 181, Training Loss: 1157.2449\n",
      "Epoch 8, Step 182, Training Loss: 1198.7415\n",
      "Epoch 8, Step 183, Training Loss: 1047.4524\n",
      "Epoch 8, Step 184, Training Loss: 1101.9965\n",
      "Epoch 8, Step 185, Training Loss: 969.8508\n",
      "Epoch 8, Step 186, Training Loss: 1174.2832\n",
      "Epoch 8, Step 187, Training Loss: 1085.2430\n",
      "Epoch 8, Step 188, Training Loss: 1109.6923\n",
      "Epoch 8, Step 189, Training Loss: 1039.3983\n",
      "Epoch 8, Step 190, Training Loss: 1368.6228\n",
      "Epoch 8, Step 191, Training Loss: 1036.2037\n",
      "Epoch 8, Step 192, Training Loss: 1143.5955\n",
      "Epoch 8, Step 193, Training Loss: 1125.9369\n",
      "Epoch 8, Step 194, Training Loss: 1138.2220\n",
      "Epoch 8, Step 195, Training Loss: 1130.3464\n",
      "Epoch 8, Step 196, Training Loss: 1178.7678\n",
      "Epoch 8, Step 197, Training Loss: 1055.1112\n",
      "Epoch 8, Step 198, Training Loss: 1051.6174\n",
      "Epoch 8, Step 199, Training Loss: 1148.4807\n",
      "Epoch 8, Step 200, Training Loss: 973.6804\n",
      "Epoch 8, Step 201, Training Loss: 1033.1569\n",
      "Epoch 8, Step 202, Training Loss: 1005.6944\n",
      "Epoch 8, Step 203, Training Loss: 1106.9600\n",
      "Epoch 8, Step 204, Training Loss: 1220.0779\n",
      "Epoch 8, Step 205, Training Loss: 1122.6062\n",
      "Epoch 8, Step 206, Training Loss: 1031.4264\n",
      "--- Epoch 8, Validation Loss: 1118.2509 ---\n",
      "Epoch 9, Step 0, Training Loss: 997.8438\n",
      "Epoch 9, Step 1, Training Loss: 1030.2100\n",
      "Epoch 9, Step 2, Training Loss: 1090.5361\n",
      "Epoch 9, Step 3, Training Loss: 1085.8306\n",
      "Epoch 9, Step 4, Training Loss: 1109.9937\n",
      "Epoch 9, Step 5, Training Loss: 970.5782\n",
      "Epoch 9, Step 6, Training Loss: 977.3526\n",
      "Epoch 9, Step 7, Training Loss: 1183.7454\n",
      "Epoch 9, Step 8, Training Loss: 1034.4120\n",
      "Epoch 9, Step 9, Training Loss: 961.0341\n",
      "Epoch 9, Step 10, Training Loss: 988.4005\n",
      "Epoch 9, Step 11, Training Loss: 1034.5776\n",
      "Epoch 9, Step 12, Training Loss: 1140.3843\n",
      "Epoch 9, Step 13, Training Loss: 1168.9729\n",
      "Epoch 9, Step 14, Training Loss: 1036.5472\n",
      "Epoch 9, Step 15, Training Loss: 1052.1187\n",
      "Epoch 9, Step 16, Training Loss: 970.8798\n",
      "Epoch 9, Step 17, Training Loss: 1027.8381\n",
      "Epoch 9, Step 18, Training Loss: 1005.6426\n",
      "Epoch 9, Step 19, Training Loss: 1083.1960\n",
      "Epoch 9, Step 20, Training Loss: 1068.0536\n",
      "Epoch 9, Step 21, Training Loss: 1154.0199\n",
      "Epoch 9, Step 22, Training Loss: 1019.9276\n",
      "Epoch 9, Step 23, Training Loss: 1097.3873\n",
      "Epoch 9, Step 24, Training Loss: 931.8937\n",
      "Epoch 9, Step 25, Training Loss: 1055.8463\n",
      "Epoch 9, Step 26, Training Loss: 891.1620\n",
      "Epoch 9, Step 27, Training Loss: 1079.5457\n",
      "Epoch 9, Step 28, Training Loss: 942.0772\n",
      "Epoch 9, Step 29, Training Loss: 982.7707\n",
      "Epoch 9, Step 30, Training Loss: 987.7122\n",
      "Epoch 9, Step 31, Training Loss: 1018.6701\n",
      "Epoch 9, Step 32, Training Loss: 1033.9688\n",
      "Epoch 9, Step 33, Training Loss: 925.4429\n",
      "Epoch 9, Step 34, Training Loss: 1028.0492\n",
      "Epoch 9, Step 35, Training Loss: 933.9564\n",
      "Epoch 9, Step 36, Training Loss: 1010.7625\n",
      "Epoch 9, Step 37, Training Loss: 1084.8839\n",
      "Epoch 9, Step 38, Training Loss: 1078.8279\n",
      "Epoch 9, Step 39, Training Loss: 1028.9646\n",
      "Epoch 9, Step 40, Training Loss: 965.4512\n",
      "Epoch 9, Step 41, Training Loss: 1043.1709\n",
      "Epoch 9, Step 42, Training Loss: 996.4702\n",
      "Epoch 9, Step 43, Training Loss: 900.0233\n",
      "Epoch 9, Step 44, Training Loss: 1012.1896\n",
      "Epoch 9, Step 45, Training Loss: 969.9771\n",
      "Epoch 9, Step 46, Training Loss: 888.6704\n",
      "Epoch 9, Step 47, Training Loss: 912.4202\n",
      "Epoch 9, Step 48, Training Loss: 929.4028\n",
      "Epoch 9, Step 49, Training Loss: 1038.3389\n",
      "Epoch 9, Step 50, Training Loss: 948.5432\n",
      "Epoch 9, Step 51, Training Loss: 926.5758\n",
      "Epoch 9, Step 52, Training Loss: 880.4939\n",
      "Epoch 9, Step 53, Training Loss: 914.0656\n",
      "Epoch 9, Step 54, Training Loss: 967.6893\n",
      "Epoch 9, Step 55, Training Loss: 1064.5356\n",
      "Epoch 9, Step 56, Training Loss: 1066.5204\n",
      "Epoch 9, Step 57, Training Loss: 939.6843\n",
      "Epoch 9, Step 58, Training Loss: 1029.0784\n",
      "Epoch 9, Step 59, Training Loss: 961.2938\n",
      "Epoch 9, Step 60, Training Loss: 1072.5228\n",
      "Epoch 9, Step 61, Training Loss: 873.1642\n",
      "Epoch 9, Step 62, Training Loss: 880.3943\n",
      "Epoch 9, Step 63, Training Loss: 935.7908\n",
      "Epoch 9, Step 64, Training Loss: 946.6174\n",
      "Epoch 9, Step 65, Training Loss: 918.5697\n",
      "Epoch 9, Step 66, Training Loss: 893.9356\n",
      "Epoch 9, Step 67, Training Loss: 1067.2874\n",
      "Epoch 9, Step 68, Training Loss: 928.2438\n",
      "Epoch 9, Step 69, Training Loss: 1100.1560\n",
      "Epoch 9, Step 70, Training Loss: 958.7036\n",
      "Epoch 9, Step 71, Training Loss: 934.1644\n",
      "Epoch 9, Step 72, Training Loss: 889.8889\n",
      "Epoch 9, Step 73, Training Loss: 953.8364\n",
      "Epoch 9, Step 74, Training Loss: 912.6600\n",
      "Epoch 9, Step 75, Training Loss: 900.0073\n",
      "Epoch 9, Step 76, Training Loss: 1064.6864\n",
      "Epoch 9, Step 77, Training Loss: 971.2167\n",
      "Epoch 9, Step 78, Training Loss: 878.8788\n",
      "Epoch 9, Step 79, Training Loss: 870.4600\n",
      "Epoch 9, Step 80, Training Loss: 880.8653\n",
      "Epoch 9, Step 81, Training Loss: 1053.2800\n",
      "Epoch 9, Step 82, Training Loss: 890.5584\n",
      "Epoch 9, Step 83, Training Loss: 969.7354\n",
      "Epoch 9, Step 84, Training Loss: 974.9116\n",
      "Epoch 9, Step 85, Training Loss: 928.0227\n",
      "Epoch 9, Step 86, Training Loss: 852.4780\n",
      "Epoch 9, Step 87, Training Loss: 833.2864\n",
      "Epoch 9, Step 88, Training Loss: 1046.0867\n",
      "Epoch 9, Step 89, Training Loss: 863.1077\n",
      "Epoch 9, Step 90, Training Loss: 836.5449\n",
      "Epoch 9, Step 91, Training Loss: 943.4777\n",
      "Epoch 9, Step 92, Training Loss: 904.8096\n",
      "Epoch 9, Step 93, Training Loss: 943.1457\n",
      "Epoch 9, Step 94, Training Loss: 926.0491\n",
      "Epoch 9, Step 95, Training Loss: 863.8282\n",
      "Epoch 9, Step 96, Training Loss: 861.5677\n",
      "Epoch 9, Step 97, Training Loss: 902.9648\n",
      "Epoch 9, Step 98, Training Loss: 935.4606\n",
      "Epoch 9, Step 99, Training Loss: 993.5906\n",
      "Epoch 9, Step 100, Training Loss: 857.6373\n",
      "Epoch 9, Step 101, Training Loss: 898.0848\n",
      "Epoch 9, Step 102, Training Loss: 986.6534\n",
      "Epoch 9, Step 103, Training Loss: 898.3932\n",
      "Epoch 9, Step 104, Training Loss: 896.6526\n",
      "Epoch 9, Step 105, Training Loss: 822.1971\n",
      "Epoch 9, Step 106, Training Loss: 929.6842\n",
      "Epoch 9, Step 107, Training Loss: 954.6951\n",
      "Epoch 9, Step 108, Training Loss: 841.6182\n",
      "Epoch 9, Step 109, Training Loss: 854.8937\n",
      "Epoch 9, Step 110, Training Loss: 938.3430\n",
      "Epoch 9, Step 111, Training Loss: 882.5115\n",
      "Epoch 9, Step 112, Training Loss: 848.7386\n",
      "Epoch 9, Step 113, Training Loss: 878.2889\n",
      "Epoch 9, Step 114, Training Loss: 796.0282\n",
      "Epoch 9, Step 115, Training Loss: 889.6711\n",
      "Epoch 9, Step 116, Training Loss: 822.4916\n",
      "Epoch 9, Step 117, Training Loss: 891.9446\n",
      "Epoch 9, Step 118, Training Loss: 842.7768\n",
      "Epoch 9, Step 119, Training Loss: 833.9732\n",
      "Epoch 9, Step 120, Training Loss: 892.1638\n",
      "Epoch 9, Step 121, Training Loss: 949.8016\n",
      "Epoch 9, Step 122, Training Loss: 817.1186\n",
      "Epoch 9, Step 123, Training Loss: 889.1082\n",
      "Epoch 9, Step 124, Training Loss: 975.5215\n",
      "Epoch 9, Step 125, Training Loss: 861.6181\n",
      "Epoch 9, Step 126, Training Loss: 800.9037\n",
      "Epoch 9, Step 127, Training Loss: 774.1627\n",
      "Epoch 9, Step 128, Training Loss: 811.9741\n",
      "Epoch 9, Step 129, Training Loss: 849.0236\n",
      "Epoch 9, Step 130, Training Loss: 831.8737\n",
      "Epoch 9, Step 131, Training Loss: 797.4379\n",
      "Epoch 9, Step 132, Training Loss: 836.9688\n",
      "Epoch 9, Step 133, Training Loss: 815.9578\n",
      "Epoch 9, Step 134, Training Loss: 880.4219\n",
      "Epoch 9, Step 135, Training Loss: 846.3578\n",
      "Epoch 9, Step 136, Training Loss: 851.8342\n",
      "Epoch 9, Step 137, Training Loss: 844.5696\n",
      "Epoch 9, Step 138, Training Loss: 819.2715\n",
      "Epoch 9, Step 139, Training Loss: 756.4645\n",
      "Epoch 9, Step 140, Training Loss: 798.8242\n",
      "Epoch 9, Step 141, Training Loss: 817.5228\n",
      "Epoch 9, Step 142, Training Loss: 751.1111\n",
      "Epoch 9, Step 143, Training Loss: 822.1848\n",
      "Epoch 9, Step 144, Training Loss: 759.6107\n",
      "Epoch 9, Step 145, Training Loss: 795.2330\n",
      "Epoch 9, Step 146, Training Loss: 729.5926\n",
      "Epoch 9, Step 147, Training Loss: 767.7679\n",
      "Epoch 9, Step 148, Training Loss: 903.2619\n",
      "Epoch 9, Step 149, Training Loss: 839.0521\n",
      "Epoch 9, Step 150, Training Loss: 732.3264\n",
      "Epoch 9, Step 151, Training Loss: 728.2523\n",
      "Epoch 9, Step 152, Training Loss: 782.5722\n",
      "Epoch 9, Step 153, Training Loss: 755.9035\n",
      "Epoch 9, Step 154, Training Loss: 787.5965\n",
      "Epoch 9, Step 155, Training Loss: 764.9122\n",
      "Epoch 9, Step 156, Training Loss: 788.0944\n",
      "Epoch 9, Step 157, Training Loss: 844.2905\n",
      "Epoch 9, Step 158, Training Loss: 804.5135\n",
      "Epoch 9, Step 159, Training Loss: 790.8109\n",
      "Epoch 9, Step 160, Training Loss: 881.9237\n",
      "Epoch 9, Step 161, Training Loss: 734.1883\n",
      "Epoch 9, Step 162, Training Loss: 811.1285\n",
      "Epoch 9, Step 163, Training Loss: 792.5284\n",
      "Epoch 9, Step 164, Training Loss: 750.0506\n",
      "Epoch 9, Step 165, Training Loss: 708.0556\n",
      "Epoch 9, Step 166, Training Loss: 742.9632\n",
      "Epoch 9, Step 167, Training Loss: 778.0560\n",
      "Epoch 9, Step 168, Training Loss: 714.5066\n",
      "Epoch 9, Step 169, Training Loss: 784.3993\n",
      "Epoch 9, Step 170, Training Loss: 792.6291\n",
      "Epoch 9, Step 171, Training Loss: 738.7708\n",
      "Epoch 9, Step 172, Training Loss: 740.2172\n",
      "Epoch 9, Step 173, Training Loss: 744.1502\n",
      "Epoch 9, Step 174, Training Loss: 707.8554\n",
      "Epoch 9, Step 175, Training Loss: 802.3011\n",
      "Epoch 9, Step 176, Training Loss: 751.8212\n",
      "Epoch 9, Step 177, Training Loss: 873.2404\n",
      "Epoch 9, Step 178, Training Loss: 808.3582\n",
      "Epoch 9, Step 179, Training Loss: 709.9352\n",
      "Epoch 9, Step 180, Training Loss: 678.5369\n",
      "Epoch 9, Step 181, Training Loss: 783.8555\n",
      "Epoch 9, Step 182, Training Loss: 819.4579\n",
      "Epoch 9, Step 183, Training Loss: 695.2248\n",
      "Epoch 9, Step 184, Training Loss: 722.9190\n",
      "Epoch 9, Step 185, Training Loss: 622.4938\n",
      "Epoch 9, Step 186, Training Loss: 816.8181\n",
      "Epoch 9, Step 187, Training Loss: 698.0157\n",
      "Epoch 9, Step 188, Training Loss: 726.7938\n",
      "Epoch 9, Step 189, Training Loss: 690.3191\n",
      "Epoch 9, Step 190, Training Loss: 1007.6916\n",
      "Epoch 9, Step 191, Training Loss: 672.2484\n",
      "Epoch 9, Step 192, Training Loss: 768.9980\n",
      "Epoch 9, Step 193, Training Loss: 765.4328\n",
      "Epoch 9, Step 194, Training Loss: 765.5002\n",
      "Epoch 9, Step 195, Training Loss: 777.4151\n",
      "Epoch 9, Step 196, Training Loss: 790.3142\n",
      "Epoch 9, Step 197, Training Loss: 697.7322\n",
      "Epoch 9, Step 198, Training Loss: 692.1467\n",
      "Epoch 9, Step 199, Training Loss: 771.8145\n",
      "Epoch 9, Step 200, Training Loss: 647.2803\n",
      "Epoch 9, Step 201, Training Loss: 666.5901\n",
      "Epoch 9, Step 202, Training Loss: 676.0345\n",
      "Epoch 9, Step 203, Training Loss: 737.3408\n",
      "Epoch 9, Step 204, Training Loss: 824.6838\n",
      "Epoch 9, Step 205, Training Loss: 747.8939\n",
      "Epoch 9, Step 206, Training Loss: 655.9465\n",
      "--- Epoch 9, Validation Loss: 752.0698 ---\n",
      "Epoch 10, Step 0, Training Loss: 646.9850\n",
      "Epoch 10, Step 1, Training Loss: 679.3569\n",
      "Epoch 10, Step 2, Training Loss: 707.9285\n",
      "Epoch 10, Step 3, Training Loss: 726.1829\n",
      "Epoch 10, Step 4, Training Loss: 724.2434\n",
      "Epoch 10, Step 5, Training Loss: 620.0955\n",
      "Epoch 10, Step 6, Training Loss: 636.4875\n",
      "Epoch 10, Step 7, Training Loss: 780.5200\n",
      "Epoch 10, Step 8, Training Loss: 672.7687\n",
      "Epoch 10, Step 9, Training Loss: 604.7733\n",
      "Epoch 10, Step 10, Training Loss: 669.6662\n",
      "Epoch 10, Step 11, Training Loss: 687.7208\n",
      "Epoch 10, Step 12, Training Loss: 753.3453\n",
      "Epoch 10, Step 13, Training Loss: 808.4311\n",
      "Epoch 10, Step 14, Training Loss: 660.1795\n",
      "Epoch 10, Step 15, Training Loss: 690.1361\n",
      "Epoch 10, Step 16, Training Loss: 633.7235\n",
      "Epoch 10, Step 17, Training Loss: 641.3254\n",
      "Epoch 10, Step 18, Training Loss: 635.3025\n",
      "Epoch 10, Step 19, Training Loss: 726.9960\n",
      "Epoch 10, Step 20, Training Loss: 713.5434\n",
      "Epoch 10, Step 21, Training Loss: 753.1707\n",
      "Epoch 10, Step 22, Training Loss: 667.5350\n",
      "Epoch 10, Step 23, Training Loss: 737.3005\n",
      "Epoch 10, Step 24, Training Loss: 604.5273\n",
      "Epoch 10, Step 25, Training Loss: 643.7413\n",
      "Epoch 10, Step 26, Training Loss: 575.7742\n",
      "Epoch 10, Step 27, Training Loss: 714.2560\n",
      "Epoch 10, Step 28, Training Loss: 614.7384\n",
      "Epoch 10, Step 29, Training Loss: 619.4031\n",
      "Epoch 10, Step 30, Training Loss: 645.8104\n",
      "Epoch 10, Step 31, Training Loss: 641.6445\n",
      "Epoch 10, Step 32, Training Loss: 687.5592\n",
      "Epoch 10, Step 33, Training Loss: 593.3246\n",
      "Epoch 10, Step 34, Training Loss: 665.3616\n",
      "Epoch 10, Step 35, Training Loss: 622.2963\n",
      "Epoch 10, Step 36, Training Loss: 659.4891\n",
      "Epoch 10, Step 37, Training Loss: 746.3053\n",
      "Epoch 10, Step 38, Training Loss: 698.8074\n",
      "Epoch 10, Step 39, Training Loss: 680.7158\n",
      "Epoch 10, Step 40, Training Loss: 628.8842\n",
      "Epoch 10, Step 41, Training Loss: 683.0712\n",
      "Epoch 10, Step 42, Training Loss: 662.3893\n",
      "Epoch 10, Step 43, Training Loss: 583.3526\n",
      "Epoch 10, Step 44, Training Loss: 683.7296\n",
      "Epoch 10, Step 45, Training Loss: 609.6362\n",
      "Epoch 10, Step 46, Training Loss: 562.9719\n",
      "Epoch 10, Step 47, Training Loss: 621.9131\n",
      "Epoch 10, Step 48, Training Loss: 596.1482\n",
      "Epoch 10, Step 49, Training Loss: 695.5935\n",
      "Epoch 10, Step 50, Training Loss: 631.9498\n",
      "Epoch 10, Step 51, Training Loss: 622.8079\n",
      "Epoch 10, Step 52, Training Loss: 564.9886\n",
      "Epoch 10, Step 53, Training Loss: 583.8824\n",
      "Epoch 10, Step 54, Training Loss: 626.2394\n",
      "Epoch 10, Step 55, Training Loss: 692.8420\n",
      "Epoch 10, Step 56, Training Loss: 749.3905\n",
      "Epoch 10, Step 57, Training Loss: 628.0518\n",
      "Epoch 10, Step 58, Training Loss: 687.8483\n",
      "Epoch 10, Step 59, Training Loss: 670.4004\n",
      "Epoch 10, Step 60, Training Loss: 754.1080\n",
      "Epoch 10, Step 61, Training Loss: 563.2911\n",
      "Epoch 10, Step 62, Training Loss: 581.3389\n",
      "Epoch 10, Step 63, Training Loss: 607.9913\n",
      "Epoch 10, Step 64, Training Loss: 646.5769\n",
      "Epoch 10, Step 65, Training Loss: 570.6660\n",
      "Epoch 10, Step 66, Training Loss: 585.2319\n",
      "Epoch 10, Step 67, Training Loss: 717.0681\n",
      "Epoch 10, Step 68, Training Loss: 608.8157\n",
      "Epoch 10, Step 69, Training Loss: 733.9635\n",
      "Epoch 10, Step 70, Training Loss: 637.0759\n",
      "Epoch 10, Step 71, Training Loss: 628.9163\n",
      "Epoch 10, Step 72, Training Loss: 594.9117\n",
      "Epoch 10, Step 73, Training Loss: 616.0260\n",
      "Epoch 10, Step 74, Training Loss: 587.7224\n",
      "Epoch 10, Step 75, Training Loss: 596.1487\n",
      "Epoch 10, Step 76, Training Loss: 716.1573\n",
      "Epoch 10, Step 77, Training Loss: 642.8064\n",
      "Epoch 10, Step 78, Training Loss: 569.0193\n",
      "Epoch 10, Step 79, Training Loss: 560.5832\n",
      "Epoch 10, Step 80, Training Loss: 552.5353\n",
      "Epoch 10, Step 81, Training Loss: 734.7328\n",
      "Epoch 10, Step 82, Training Loss: 582.9990\n",
      "Epoch 10, Step 83, Training Loss: 638.9536\n",
      "Epoch 10, Step 84, Training Loss: 655.7626\n",
      "Epoch 10, Step 85, Training Loss: 601.8330\n",
      "Epoch 10, Step 86, Training Loss: 557.0122\n",
      "Epoch 10, Step 87, Training Loss: 539.8279\n",
      "Epoch 10, Step 88, Training Loss: 705.5377\n",
      "Epoch 10, Step 89, Training Loss: 576.2040\n",
      "Epoch 10, Step 90, Training Loss: 514.8465\n",
      "Epoch 10, Step 91, Training Loss: 613.7231\n",
      "Epoch 10, Step 92, Training Loss: 584.5541\n",
      "Epoch 10, Step 93, Training Loss: 604.9889\n",
      "Epoch 10, Step 94, Training Loss: 596.0740\n",
      "Epoch 10, Step 95, Training Loss: 547.0585\n",
      "Epoch 10, Step 96, Training Loss: 557.1763\n",
      "Epoch 10, Step 97, Training Loss: 593.9315\n",
      "Epoch 10, Step 98, Training Loss: 607.8391\n",
      "Epoch 10, Step 99, Training Loss: 621.2606\n",
      "Epoch 10, Step 100, Training Loss: 571.7976\n",
      "Epoch 10, Step 101, Training Loss: 577.0936\n",
      "Epoch 10, Step 102, Training Loss: 658.9955\n",
      "Epoch 10, Step 103, Training Loss: 573.2825\n",
      "Epoch 10, Step 104, Training Loss: 581.4812\n",
      "Epoch 10, Step 105, Training Loss: 529.4180\n",
      "Epoch 10, Step 106, Training Loss: 625.7596\n",
      "Epoch 10, Step 107, Training Loss: 619.5721\n",
      "Epoch 10, Step 108, Training Loss: 554.6980\n",
      "Epoch 10, Step 109, Training Loss: 536.2479\n",
      "Epoch 10, Step 110, Training Loss: 631.7916\n",
      "Epoch 10, Step 111, Training Loss: 609.1611\n",
      "Epoch 10, Step 112, Training Loss: 576.5347\n",
      "Epoch 10, Step 113, Training Loss: 567.5120\n",
      "Epoch 10, Step 114, Training Loss: 512.9380\n",
      "Epoch 10, Step 115, Training Loss: 587.8539\n",
      "Epoch 10, Step 116, Training Loss: 549.8417\n",
      "Epoch 10, Step 117, Training Loss: 591.7770\n",
      "Epoch 10, Step 118, Training Loss: 571.6290\n",
      "Epoch 10, Step 119, Training Loss: 534.1492\n",
      "Epoch 10, Step 120, Training Loss: 562.6440\n",
      "Epoch 10, Step 121, Training Loss: 635.4199\n",
      "Epoch 10, Step 122, Training Loss: 523.0837\n",
      "Epoch 10, Step 123, Training Loss: 572.3730\n",
      "Epoch 10, Step 124, Training Loss: 627.5225\n",
      "Epoch 10, Step 125, Training Loss: 567.1010\n",
      "Epoch 10, Step 126, Training Loss: 525.1577\n",
      "Epoch 10, Step 127, Training Loss: 503.1531\n",
      "Epoch 10, Step 128, Training Loss: 518.3046\n",
      "Epoch 10, Step 129, Training Loss: 568.9672\n",
      "Epoch 10, Step 130, Training Loss: 548.2059\n",
      "Epoch 10, Step 131, Training Loss: 516.8901\n",
      "Epoch 10, Step 132, Training Loss: 553.5204\n",
      "Epoch 10, Step 133, Training Loss: 524.2804\n",
      "Epoch 10, Step 134, Training Loss: 604.0734\n",
      "Epoch 10, Step 135, Training Loss: 550.6711\n",
      "Epoch 10, Step 136, Training Loss: 572.9149\n",
      "Epoch 10, Step 137, Training Loss: 544.1905\n",
      "Epoch 10, Step 138, Training Loss: 526.1416\n",
      "Epoch 10, Step 139, Training Loss: 506.3219\n",
      "Epoch 10, Step 140, Training Loss: 486.3910\n",
      "Epoch 10, Step 141, Training Loss: 526.5773\n",
      "Epoch 10, Step 142, Training Loss: 473.5191\n",
      "Epoch 10, Step 143, Training Loss: 527.7654\n",
      "Epoch 10, Step 144, Training Loss: 514.2693\n",
      "Epoch 10, Step 145, Training Loss: 521.3251\n",
      "Epoch 10, Step 146, Training Loss: 462.5872\n",
      "Epoch 10, Step 147, Training Loss: 513.4218\n",
      "Epoch 10, Step 148, Training Loss: 625.5618\n",
      "Epoch 10, Step 149, Training Loss: 551.2610\n",
      "Epoch 10, Step 150, Training Loss: 464.2227\n",
      "Epoch 10, Step 151, Training Loss: 469.7383\n",
      "Epoch 10, Step 152, Training Loss: 506.2083\n",
      "Epoch 10, Step 153, Training Loss: 486.0909\n",
      "Epoch 10, Step 154, Training Loss: 492.6869\n",
      "Epoch 10, Step 155, Training Loss: 506.8516\n",
      "Epoch 10, Step 156, Training Loss: 518.1039\n",
      "Epoch 10, Step 157, Training Loss: 559.8161\n",
      "Epoch 10, Step 158, Training Loss: 511.4104\n",
      "Epoch 10, Step 159, Training Loss: 497.4697\n",
      "Epoch 10, Step 160, Training Loss: 577.6896\n",
      "Epoch 10, Step 161, Training Loss: 464.6930\n",
      "Epoch 10, Step 162, Training Loss: 518.2566\n",
      "Epoch 10, Step 163, Training Loss: 496.0738\n",
      "Epoch 10, Step 164, Training Loss: 466.3603\n",
      "Epoch 10, Step 165, Training Loss: 448.3043\n",
      "Epoch 10, Step 166, Training Loss: 466.0528\n",
      "Epoch 10, Step 167, Training Loss: 499.4438\n",
      "Epoch 10, Step 168, Training Loss: 461.8965\n",
      "Epoch 10, Step 169, Training Loss: 508.8443\n",
      "Epoch 10, Step 170, Training Loss: 492.9894\n",
      "Epoch 10, Step 171, Training Loss: 485.3776\n",
      "Epoch 10, Step 172, Training Loss: 487.3734\n",
      "Epoch 10, Step 173, Training Loss: 454.5944\n",
      "Epoch 10, Step 174, Training Loss: 441.7640\n",
      "Epoch 10, Step 175, Training Loss: 529.4814\n",
      "Epoch 10, Step 176, Training Loss: 482.2011\n",
      "Epoch 10, Step 177, Training Loss: 571.8303\n",
      "Epoch 10, Step 178, Training Loss: 528.8408\n",
      "Epoch 10, Step 179, Training Loss: 450.1784\n",
      "Epoch 10, Step 180, Training Loss: 434.6177\n",
      "Epoch 10, Step 181, Training Loss: 478.8378\n",
      "Epoch 10, Step 182, Training Loss: 550.5074\n",
      "Epoch 10, Step 183, Training Loss: 427.9240\n",
      "Epoch 10, Step 184, Training Loss: 469.1655\n",
      "Epoch 10, Step 185, Training Loss: 394.7943\n",
      "Epoch 10, Step 186, Training Loss: 546.9307\n",
      "Epoch 10, Step 187, Training Loss: 449.9005\n",
      "Epoch 10, Step 188, Training Loss: 580.1556\n",
      "Epoch 10, Step 189, Training Loss: 450.0952\n",
      "Epoch 10, Step 190, Training Loss: 702.3439\n",
      "Epoch 10, Step 191, Training Loss: 427.3239\n",
      "Epoch 10, Step 192, Training Loss: 512.4507\n",
      "Epoch 10, Step 193, Training Loss: 490.5117\n",
      "Epoch 10, Step 194, Training Loss: 502.9518\n",
      "Epoch 10, Step 195, Training Loss: 528.2685\n",
      "Epoch 10, Step 196, Training Loss: 529.2552\n",
      "Epoch 10, Step 197, Training Loss: 444.8052\n",
      "Epoch 10, Step 198, Training Loss: 464.0971\n",
      "Epoch 10, Step 199, Training Loss: 497.4245\n",
      "Epoch 10, Step 200, Training Loss: 397.2419\n",
      "Epoch 10, Step 201, Training Loss: 416.8576\n",
      "Epoch 10, Step 202, Training Loss: 407.0471\n",
      "Epoch 10, Step 203, Training Loss: 471.6930\n",
      "Epoch 10, Step 204, Training Loss: 566.8116\n",
      "Epoch 10, Step 205, Training Loss: 501.2529\n",
      "Epoch 10, Step 206, Training Loss: 429.4329\n",
      "--- Epoch 10, Validation Loss: 443.6865 ---\n",
      "Epoch 11, Step 0, Training Loss: 406.0317\n",
      "Epoch 11, Step 1, Training Loss: 434.9085\n",
      "Epoch 11, Step 2, Training Loss: 461.3939\n",
      "Epoch 11, Step 3, Training Loss: 456.7567\n",
      "Epoch 11, Step 4, Training Loss: 471.8907\n",
      "Epoch 11, Step 5, Training Loss: 391.1059\n",
      "Epoch 11, Step 6, Training Loss: 398.0184\n",
      "Epoch 11, Step 7, Training Loss: 510.9800\n",
      "Epoch 11, Step 8, Training Loss: 433.4309\n",
      "Epoch 11, Step 9, Training Loss: 389.7637\n",
      "Epoch 11, Step 10, Training Loss: 413.5002\n",
      "Epoch 11, Step 11, Training Loss: 434.0166\n",
      "Epoch 11, Step 12, Training Loss: 490.4691\n",
      "Epoch 11, Step 13, Training Loss: 515.6189\n",
      "Epoch 11, Step 14, Training Loss: 439.6859\n",
      "Epoch 11, Step 15, Training Loss: 428.1743\n",
      "Epoch 11, Step 16, Training Loss: 396.5490\n",
      "Epoch 11, Step 17, Training Loss: 431.2556\n",
      "Epoch 11, Step 18, Training Loss: 408.5894\n",
      "Epoch 11, Step 19, Training Loss: 462.7459\n",
      "Epoch 11, Step 20, Training Loss: 466.1923\n",
      "Epoch 11, Step 21, Training Loss: 509.9030\n",
      "Epoch 11, Step 22, Training Loss: 429.8532\n",
      "Epoch 11, Step 23, Training Loss: 476.9761\n",
      "Epoch 11, Step 24, Training Loss: 390.7371\n",
      "Epoch 11, Step 25, Training Loss: 420.4311\n",
      "Epoch 11, Step 26, Training Loss: 352.0547\n",
      "Epoch 11, Step 27, Training Loss: 481.6527\n",
      "Epoch 11, Step 28, Training Loss: 380.0748\n",
      "Epoch 11, Step 29, Training Loss: 402.4162\n",
      "Epoch 11, Step 30, Training Loss: 403.8075\n",
      "Epoch 11, Step 31, Training Loss: 406.8329\n",
      "Epoch 11, Step 32, Training Loss: 443.7160\n",
      "Epoch 11, Step 33, Training Loss: 370.7043\n",
      "Epoch 11, Step 34, Training Loss: 438.3309\n",
      "Epoch 11, Step 35, Training Loss: 412.0869\n",
      "Epoch 11, Step 36, Training Loss: 432.4652\n",
      "Epoch 11, Step 37, Training Loss: 475.7708\n",
      "Epoch 11, Step 38, Training Loss: 470.8629\n",
      "Epoch 11, Step 39, Training Loss: 432.6385\n",
      "Epoch 11, Step 40, Training Loss: 405.5370\n",
      "Epoch 11, Step 41, Training Loss: 459.0650\n",
      "Epoch 11, Step 42, Training Loss: 438.5784\n",
      "Epoch 11, Step 43, Training Loss: 360.4074\n",
      "Epoch 11, Step 44, Training Loss: 426.4850\n",
      "Epoch 11, Step 45, Training Loss: 372.1066\n",
      "Epoch 11, Step 46, Training Loss: 351.8797\n",
      "Epoch 11, Step 47, Training Loss: 400.4224\n",
      "Epoch 11, Step 48, Training Loss: 377.2644\n",
      "Epoch 11, Step 49, Training Loss: 455.8567\n",
      "Epoch 11, Step 50, Training Loss: 377.2372\n",
      "Epoch 11, Step 51, Training Loss: 389.1849\n",
      "Epoch 11, Step 52, Training Loss: 345.5207\n",
      "Epoch 11, Step 53, Training Loss: 371.4181\n",
      "Epoch 11, Step 54, Training Loss: 409.8038\n",
      "Epoch 11, Step 55, Training Loss: 452.1785\n",
      "Epoch 11, Step 56, Training Loss: 471.6097\n",
      "Epoch 11, Step 57, Training Loss: 377.0977\n",
      "Epoch 11, Step 58, Training Loss: 435.1698\n",
      "Epoch 11, Step 59, Training Loss: 400.0855\n",
      "Epoch 11, Step 60, Training Loss: 500.7833\n",
      "Epoch 11, Step 61, Training Loss: 336.8465\n",
      "Epoch 11, Step 62, Training Loss: 360.0976\n",
      "Epoch 11, Step 63, Training Loss: 401.1920\n",
      "Epoch 11, Step 64, Training Loss: 394.7434\n",
      "Epoch 11, Step 65, Training Loss: 371.4682\n",
      "Epoch 11, Step 66, Training Loss: 380.7602\n",
      "Epoch 11, Step 67, Training Loss: 442.1245\n",
      "Epoch 11, Step 68, Training Loss: 399.2724\n",
      "Epoch 11, Step 69, Training Loss: 514.6794\n",
      "Epoch 11, Step 70, Training Loss: 427.2889\n",
      "Epoch 11, Step 71, Training Loss: 400.7392\n",
      "Epoch 11, Step 72, Training Loss: 382.3031\n",
      "Epoch 11, Step 73, Training Loss: 411.2978\n",
      "Epoch 11, Step 74, Training Loss: 377.9136\n",
      "Epoch 11, Step 75, Training Loss: 369.9422\n",
      "Epoch 11, Step 76, Training Loss: 474.9023\n",
      "Epoch 11, Step 77, Training Loss: 413.2301\n",
      "Epoch 11, Step 78, Training Loss: 366.9735\n",
      "Epoch 11, Step 79, Training Loss: 349.8717\n",
      "Epoch 11, Step 80, Training Loss: 376.9984\n",
      "Epoch 11, Step 81, Training Loss: 498.0588\n",
      "Epoch 11, Step 82, Training Loss: 361.6962\n",
      "Epoch 11, Step 83, Training Loss: 418.5571\n",
      "Epoch 11, Step 84, Training Loss: 420.5775\n",
      "Epoch 11, Step 85, Training Loss: 400.2163\n",
      "Epoch 11, Step 86, Training Loss: 326.7531\n",
      "Epoch 11, Step 87, Training Loss: 340.7935\n",
      "Epoch 11, Step 88, Training Loss: 467.0557\n",
      "Epoch 11, Step 89, Training Loss: 380.3979\n",
      "Epoch 11, Step 90, Training Loss: 328.7353\n",
      "Epoch 11, Step 91, Training Loss: 384.1561\n",
      "Epoch 11, Step 92, Training Loss: 380.2655\n",
      "Epoch 11, Step 93, Training Loss: 405.2985\n",
      "Epoch 11, Step 94, Training Loss: 383.5448\n",
      "Epoch 11, Step 95, Training Loss: 361.9953\n",
      "Epoch 11, Step 96, Training Loss: 369.6544\n",
      "Epoch 11, Step 97, Training Loss: 363.9750\n",
      "Epoch 11, Step 98, Training Loss: 399.0209\n",
      "Epoch 11, Step 99, Training Loss: 429.8942\n",
      "Epoch 11, Step 100, Training Loss: 345.4170\n",
      "Epoch 11, Step 101, Training Loss: 388.8078\n",
      "Epoch 11, Step 102, Training Loss: 436.5352\n",
      "Epoch 11, Step 103, Training Loss: 364.3428\n",
      "Epoch 11, Step 104, Training Loss: 370.7474\n",
      "Epoch 11, Step 105, Training Loss: 338.6093\n",
      "Epoch 11, Step 106, Training Loss: 418.1342\n",
      "Epoch 11, Step 107, Training Loss: 415.8923\n",
      "Epoch 11, Step 108, Training Loss: 356.8528\n",
      "Epoch 11, Step 109, Training Loss: 333.8335\n",
      "Epoch 11, Step 110, Training Loss: 384.5267\n",
      "Epoch 11, Step 111, Training Loss: 368.2659\n",
      "Epoch 11, Step 112, Training Loss: 363.2014\n",
      "Epoch 11, Step 113, Training Loss: 360.3236\n",
      "Epoch 11, Step 114, Training Loss: 322.0651\n",
      "Epoch 11, Step 115, Training Loss: 393.9642\n",
      "Epoch 11, Step 116, Training Loss: 339.0814\n",
      "Epoch 11, Step 117, Training Loss: 377.7471\n",
      "Epoch 11, Step 118, Training Loss: 353.3913\n",
      "Epoch 11, Step 119, Training Loss: 353.9472\n",
      "Epoch 11, Step 120, Training Loss: 358.4521\n",
      "Epoch 11, Step 121, Training Loss: 412.6324\n",
      "Epoch 11, Step 122, Training Loss: 344.0159\n",
      "Epoch 11, Step 123, Training Loss: 373.4042\n",
      "Epoch 11, Step 124, Training Loss: 395.2501\n",
      "Epoch 11, Step 125, Training Loss: 357.6951\n",
      "Epoch 11, Step 126, Training Loss: 327.5381\n",
      "Epoch 11, Step 127, Training Loss: 324.6544\n",
      "Epoch 11, Step 128, Training Loss: 330.9252\n",
      "Epoch 11, Step 129, Training Loss: 350.2843\n",
      "Epoch 11, Step 130, Training Loss: 342.7802\n",
      "Epoch 11, Step 131, Training Loss: 327.0699\n",
      "Epoch 11, Step 132, Training Loss: 356.6974\n",
      "Epoch 11, Step 133, Training Loss: 341.8057\n",
      "Epoch 11, Step 134, Training Loss: 372.4086\n",
      "Epoch 11, Step 135, Training Loss: 341.9039\n",
      "Epoch 11, Step 136, Training Loss: 366.0169\n",
      "Epoch 11, Step 137, Training Loss: 358.8863\n",
      "Epoch 11, Step 138, Training Loss: 318.1293\n",
      "Epoch 11, Step 139, Training Loss: 327.3879\n",
      "Epoch 11, Step 140, Training Loss: 311.8205\n",
      "Epoch 11, Step 141, Training Loss: 354.6178\n",
      "Epoch 11, Step 142, Training Loss: 312.6690\n",
      "Epoch 11, Step 143, Training Loss: 331.6559\n",
      "Epoch 11, Step 144, Training Loss: 311.1494\n",
      "Epoch 11, Step 145, Training Loss: 318.4653\n",
      "Epoch 11, Step 146, Training Loss: 292.3516\n",
      "Epoch 11, Step 147, Training Loss: 316.5668\n",
      "Epoch 11, Step 148, Training Loss: 422.7389\n",
      "Epoch 11, Step 149, Training Loss: 357.6246\n",
      "Epoch 11, Step 150, Training Loss: 290.8370\n",
      "Epoch 11, Step 151, Training Loss: 283.0255\n",
      "Epoch 11, Step 152, Training Loss: 330.2506\n",
      "Epoch 11, Step 153, Training Loss: 306.2189\n",
      "Epoch 11, Step 154, Training Loss: 322.8878\n",
      "Epoch 11, Step 155, Training Loss: 316.8559\n",
      "Epoch 11, Step 156, Training Loss: 325.3871\n",
      "Epoch 11, Step 157, Training Loss: 348.0731\n",
      "Epoch 11, Step 158, Training Loss: 328.6948\n",
      "Epoch 11, Step 159, Training Loss: 327.2654\n",
      "Epoch 11, Step 160, Training Loss: 392.9393\n",
      "Epoch 11, Step 161, Training Loss: 311.6448\n",
      "Epoch 11, Step 162, Training Loss: 332.2759\n",
      "Epoch 11, Step 163, Training Loss: 333.8896\n",
      "Epoch 11, Step 164, Training Loss: 299.3424\n",
      "Epoch 11, Step 165, Training Loss: 276.4102\n",
      "Epoch 11, Step 166, Training Loss: 294.5775\n",
      "Epoch 11, Step 167, Training Loss: 313.0799\n",
      "Epoch 11, Step 168, Training Loss: 284.8071\n",
      "Epoch 11, Step 169, Training Loss: 316.6812\n",
      "Epoch 11, Step 170, Training Loss: 328.1069\n",
      "Epoch 11, Step 171, Training Loss: 291.5519\n",
      "Epoch 11, Step 172, Training Loss: 293.3344\n",
      "Epoch 11, Step 173, Training Loss: 301.5461\n",
      "Epoch 11, Step 174, Training Loss: 272.9492\n",
      "Epoch 11, Step 175, Training Loss: 337.0070\n",
      "Epoch 11, Step 176, Training Loss: 301.1378\n",
      "Epoch 11, Step 177, Training Loss: 398.1890\n",
      "Epoch 11, Step 178, Training Loss: 345.5011\n",
      "Epoch 11, Step 179, Training Loss: 283.1043\n",
      "Epoch 11, Step 180, Training Loss: 274.6006\n",
      "Epoch 11, Step 181, Training Loss: 312.0020\n",
      "Epoch 11, Step 182, Training Loss: 355.7399\n",
      "Epoch 11, Step 183, Training Loss: 261.4079\n",
      "Epoch 11, Step 184, Training Loss: 288.7238\n",
      "Epoch 11, Step 185, Training Loss: 244.0429\n",
      "Epoch 11, Step 186, Training Loss: 357.3984\n",
      "Epoch 11, Step 187, Training Loss: 283.2141\n",
      "Epoch 11, Step 188, Training Loss: 329.0013\n",
      "Epoch 11, Step 189, Training Loss: 292.6633\n",
      "Epoch 11, Step 190, Training Loss: 507.0369\n",
      "Epoch 11, Step 191, Training Loss: 274.0475\n",
      "Epoch 11, Step 192, Training Loss: 319.9597\n",
      "Epoch 11, Step 193, Training Loss: 303.5120\n",
      "Epoch 11, Step 194, Training Loss: 317.3278\n",
      "Epoch 11, Step 195, Training Loss: 306.9141\n",
      "Epoch 11, Step 196, Training Loss: 334.4269\n",
      "Epoch 11, Step 197, Training Loss: 307.4851\n",
      "Epoch 11, Step 198, Training Loss: 272.4899\n",
      "Epoch 11, Step 199, Training Loss: 307.0466\n",
      "Epoch 11, Step 200, Training Loss: 238.5094\n",
      "Epoch 11, Step 201, Training Loss: 262.1920\n",
      "Epoch 11, Step 202, Training Loss: 262.9810\n",
      "Epoch 11, Step 203, Training Loss: 310.2468\n",
      "Epoch 11, Step 204, Training Loss: 365.6316\n",
      "Epoch 11, Step 205, Training Loss: 320.5499\n",
      "Epoch 11, Step 206, Training Loss: 279.8983\n",
      "--- Epoch 11, Validation Loss: 284.2891 ---\n",
      "Epoch 12, Step 0, Training Loss: 253.6562\n",
      "Epoch 12, Step 1, Training Loss: 269.6554\n",
      "Epoch 12, Step 2, Training Loss: 291.7588\n",
      "Epoch 12, Step 3, Training Loss: 315.5364\n",
      "Epoch 12, Step 4, Training Loss: 298.5746\n",
      "Epoch 12, Step 5, Training Loss: 235.6358\n",
      "Epoch 12, Step 6, Training Loss: 248.6401\n",
      "Epoch 12, Step 7, Training Loss: 349.6326\n",
      "Epoch 12, Step 8, Training Loss: 281.1220\n",
      "Epoch 12, Step 9, Training Loss: 233.4820\n",
      "Epoch 12, Step 10, Training Loss: 261.5738\n",
      "Epoch 12, Step 11, Training Loss: 283.6384\n",
      "Epoch 12, Step 12, Training Loss: 346.8622\n",
      "Epoch 12, Step 13, Training Loss: 341.6601\n",
      "Epoch 12, Step 14, Training Loss: 271.9557\n",
      "Epoch 12, Step 15, Training Loss: 280.1293\n",
      "Epoch 12, Step 16, Training Loss: 238.5770\n",
      "Epoch 12, Step 17, Training Loss: 261.4236\n",
      "Epoch 12, Step 18, Training Loss: 254.8927\n",
      "Epoch 12, Step 19, Training Loss: 294.3425\n",
      "Epoch 12, Step 20, Training Loss: 293.5413\n",
      "Epoch 12, Step 21, Training Loss: 329.3370\n",
      "Epoch 12, Step 22, Training Loss: 280.0146\n",
      "Epoch 12, Step 23, Training Loss: 303.7174\n",
      "Epoch 12, Step 24, Training Loss: 230.2610\n",
      "Epoch 12, Step 25, Training Loss: 277.4907\n",
      "Epoch 12, Step 26, Training Loss: 223.9009\n",
      "Epoch 12, Step 27, Training Loss: 291.8999\n",
      "Epoch 12, Step 28, Training Loss: 245.2465\n",
      "Epoch 12, Step 29, Training Loss: 252.6183\n",
      "Epoch 12, Step 30, Training Loss: 247.4018\n",
      "Epoch 12, Step 31, Training Loss: 261.3238\n",
      "Epoch 12, Step 32, Training Loss: 286.9796\n",
      "Epoch 12, Step 33, Training Loss: 221.3632\n",
      "Epoch 12, Step 34, Training Loss: 276.4205\n",
      "Epoch 12, Step 35, Training Loss: 233.6846\n",
      "Epoch 12, Step 36, Training Loss: 284.1764\n",
      "Epoch 12, Step 37, Training Loss: 325.6031\n",
      "Epoch 12, Step 38, Training Loss: 303.9891\n",
      "Epoch 12, Step 39, Training Loss: 272.8582\n",
      "Epoch 12, Step 40, Training Loss: 252.6742\n",
      "Epoch 12, Step 41, Training Loss: 304.1996\n",
      "Epoch 12, Step 42, Training Loss: 272.8426\n",
      "Epoch 12, Step 43, Training Loss: 224.1700\n",
      "Epoch 12, Step 44, Training Loss: 261.1495\n",
      "Epoch 12, Step 45, Training Loss: 246.5974\n",
      "Epoch 12, Step 46, Training Loss: 204.0594\n",
      "Epoch 12, Step 47, Training Loss: 224.1790\n",
      "Epoch 12, Step 48, Training Loss: 223.7776\n",
      "Epoch 12, Step 49, Training Loss: 292.1983\n",
      "Epoch 12, Step 50, Training Loss: 243.8023\n",
      "Epoch 12, Step 51, Training Loss: 244.4858\n",
      "Epoch 12, Step 52, Training Loss: 216.0400\n",
      "Epoch 12, Step 53, Training Loss: 230.6599\n",
      "Epoch 12, Step 54, Training Loss: 245.6554\n",
      "Epoch 12, Step 55, Training Loss: 304.1806\n",
      "Epoch 12, Step 56, Training Loss: 327.6711\n",
      "Epoch 12, Step 57, Training Loss: 235.3581\n",
      "Epoch 12, Step 58, Training Loss: 275.7214\n",
      "Epoch 12, Step 59, Training Loss: 257.1926\n",
      "Epoch 12, Step 60, Training Loss: 335.2280\n",
      "Epoch 12, Step 61, Training Loss: 208.9983\n",
      "Epoch 12, Step 62, Training Loss: 238.2661\n",
      "Epoch 12, Step 63, Training Loss: 260.7228\n",
      "Epoch 12, Step 64, Training Loss: 246.8864\n",
      "Epoch 12, Step 65, Training Loss: 231.3977\n",
      "Epoch 12, Step 66, Training Loss: 235.7398\n",
      "Epoch 12, Step 67, Training Loss: 300.1948\n",
      "Epoch 12, Step 68, Training Loss: 240.6091\n",
      "Epoch 12, Step 69, Training Loss: 330.4009\n",
      "Epoch 12, Step 70, Training Loss: 263.0710\n",
      "Epoch 12, Step 71, Training Loss: 270.0889\n",
      "Epoch 12, Step 72, Training Loss: 253.9455\n",
      "Epoch 12, Step 73, Training Loss: 256.5027\n",
      "Epoch 12, Step 74, Training Loss: 233.1164\n",
      "Epoch 12, Step 75, Training Loss: 248.6315\n",
      "Epoch 12, Step 76, Training Loss: 330.0780\n",
      "Epoch 12, Step 77, Training Loss: 267.4678\n",
      "Epoch 12, Step 78, Training Loss: 217.5883\n",
      "Epoch 12, Step 79, Training Loss: 211.5957\n",
      "Epoch 12, Step 80, Training Loss: 232.3727\n",
      "Epoch 12, Step 81, Training Loss: 331.7235\n",
      "Epoch 12, Step 82, Training Loss: 219.4942\n",
      "Epoch 12, Step 83, Training Loss: 271.5932\n",
      "Epoch 12, Step 84, Training Loss: 289.3021\n",
      "Epoch 12, Step 85, Training Loss: 263.2332\n",
      "Epoch 12, Step 86, Training Loss: 206.4061\n",
      "Epoch 12, Step 87, Training Loss: 198.5147\n",
      "Epoch 12, Step 88, Training Loss: 306.8702\n",
      "Epoch 12, Step 89, Training Loss: 234.9361\n",
      "Epoch 12, Step 90, Training Loss: 204.7867\n",
      "Epoch 12, Step 91, Training Loss: 248.0706\n",
      "Epoch 12, Step 92, Training Loss: 246.1875\n",
      "Epoch 12, Step 93, Training Loss: 265.5447\n",
      "Epoch 12, Step 94, Training Loss: 243.9995\n",
      "Epoch 12, Step 95, Training Loss: 213.4908\n",
      "Epoch 12, Step 96, Training Loss: 221.1882\n",
      "Epoch 12, Step 97, Training Loss: 231.9583\n",
      "Epoch 12, Step 98, Training Loss: 268.3958\n",
      "Epoch 12, Step 99, Training Loss: 262.2495\n",
      "Epoch 12, Step 100, Training Loss: 213.6696\n",
      "Epoch 12, Step 101, Training Loss: 236.7394\n",
      "Epoch 12, Step 102, Training Loss: 292.5993\n",
      "Epoch 12, Step 103, Training Loss: 222.5673\n",
      "Epoch 12, Step 104, Training Loss: 250.2094\n",
      "Epoch 12, Step 105, Training Loss: 206.4677\n",
      "Epoch 12, Step 106, Training Loss: 266.7548\n",
      "Epoch 12, Step 107, Training Loss: 281.9382\n",
      "Epoch 12, Step 108, Training Loss: 217.4750\n",
      "Epoch 12, Step 109, Training Loss: 200.0245\n",
      "Epoch 12, Step 110, Training Loss: 247.9820\n",
      "Epoch 12, Step 111, Training Loss: 229.7050\n",
      "Epoch 12, Step 112, Training Loss: 234.2899\n",
      "Epoch 12, Step 113, Training Loss: 220.6221\n",
      "Epoch 12, Step 114, Training Loss: 189.6470\n",
      "Epoch 12, Step 115, Training Loss: 255.3620\n",
      "Epoch 12, Step 116, Training Loss: 217.4263\n",
      "Epoch 12, Step 117, Training Loss: 246.3840\n",
      "Epoch 12, Step 118, Training Loss: 224.6494\n",
      "Epoch 12, Step 119, Training Loss: 210.0199\n",
      "Epoch 12, Step 120, Training Loss: 247.0199\n",
      "Epoch 12, Step 121, Training Loss: 282.2950\n",
      "Epoch 12, Step 122, Training Loss: 212.6191\n",
      "Epoch 12, Step 123, Training Loss: 238.8890\n",
      "Epoch 12, Step 124, Training Loss: 261.8732\n",
      "Epoch 12, Step 125, Training Loss: 224.0016\n",
      "Epoch 12, Step 126, Training Loss: 208.5805\n",
      "Epoch 12, Step 127, Training Loss: 196.5595\n",
      "Epoch 12, Step 128, Training Loss: 205.4909\n",
      "Epoch 12, Step 129, Training Loss: 248.6103\n",
      "Epoch 12, Step 130, Training Loss: 225.2942\n",
      "Epoch 12, Step 131, Training Loss: 198.6266\n",
      "Epoch 12, Step 132, Training Loss: 229.7297\n",
      "Epoch 12, Step 133, Training Loss: 224.1679\n",
      "Epoch 12, Step 134, Training Loss: 268.2645\n",
      "Epoch 12, Step 135, Training Loss: 212.6729\n",
      "Epoch 12, Step 136, Training Loss: 260.0617\n",
      "Epoch 12, Step 137, Training Loss: 231.8707\n",
      "Epoch 12, Step 138, Training Loss: 200.6989\n",
      "Epoch 12, Step 139, Training Loss: 203.9030\n",
      "Epoch 12, Step 140, Training Loss: 185.3066\n",
      "Epoch 12, Step 141, Training Loss: 229.6122\n",
      "Epoch 12, Step 142, Training Loss: 180.6628\n",
      "Epoch 12, Step 143, Training Loss: 219.3036\n",
      "Epoch 12, Step 144, Training Loss: 189.0942\n",
      "Epoch 12, Step 145, Training Loss: 204.0289\n",
      "Epoch 12, Step 146, Training Loss: 172.2807\n",
      "Epoch 12, Step 147, Training Loss: 195.3924\n",
      "Epoch 12, Step 148, Training Loss: 305.0877\n",
      "Epoch 12, Step 149, Training Loss: 239.8245\n",
      "Epoch 12, Step 150, Training Loss: 183.0453\n",
      "Epoch 12, Step 151, Training Loss: 177.5064\n",
      "Epoch 12, Step 152, Training Loss: 194.0067\n",
      "Epoch 12, Step 153, Training Loss: 181.0302\n",
      "Epoch 12, Step 154, Training Loss: 195.8830\n",
      "Epoch 12, Step 155, Training Loss: 216.4185\n",
      "Epoch 12, Step 156, Training Loss: 205.4678\n",
      "Epoch 12, Step 157, Training Loss: 226.2241\n",
      "Epoch 12, Step 158, Training Loss: 198.0774\n",
      "Epoch 12, Step 159, Training Loss: 208.6580\n",
      "Epoch 12, Step 160, Training Loss: 252.5984\n",
      "Epoch 12, Step 161, Training Loss: 190.2064\n",
      "Epoch 12, Step 162, Training Loss: 202.3706\n",
      "Epoch 12, Step 163, Training Loss: 206.8313\n",
      "Epoch 12, Step 164, Training Loss: 192.9803\n",
      "Epoch 12, Step 165, Training Loss: 172.5428\n",
      "Epoch 12, Step 166, Training Loss: 183.9810\n",
      "Epoch 12, Step 167, Training Loss: 190.6615\n",
      "Epoch 12, Step 168, Training Loss: 190.0293\n",
      "Epoch 12, Step 169, Training Loss: 202.3628\n",
      "Epoch 12, Step 170, Training Loss: 215.3775\n",
      "Epoch 12, Step 171, Training Loss: 182.8099\n",
      "Epoch 12, Step 172, Training Loss: 185.4253\n",
      "Epoch 12, Step 173, Training Loss: 184.8037\n",
      "Epoch 12, Step 174, Training Loss: 178.4975\n",
      "Epoch 12, Step 175, Training Loss: 216.9417\n",
      "Epoch 12, Step 176, Training Loss: 193.5767\n",
      "Epoch 12, Step 177, Training Loss: 255.5205\n",
      "Epoch 12, Step 178, Training Loss: 210.1319\n",
      "Epoch 12, Step 179, Training Loss: 184.0354\n",
      "Epoch 12, Step 180, Training Loss: 165.9801\n",
      "Epoch 12, Step 181, Training Loss: 201.8010\n",
      "Epoch 12, Step 182, Training Loss: 219.8136\n",
      "Epoch 12, Step 183, Training Loss: 163.7400\n",
      "Epoch 12, Step 184, Training Loss: 185.2215\n",
      "Epoch 12, Step 185, Training Loss: 144.8732\n",
      "Epoch 12, Step 186, Training Loss: 233.0829\n",
      "Epoch 12, Step 187, Training Loss: 167.0717\n",
      "Epoch 12, Step 188, Training Loss: 278.4723\n",
      "Epoch 12, Step 189, Training Loss: 185.1997\n",
      "Epoch 12, Step 190, Training Loss: 382.4242\n",
      "Epoch 12, Step 191, Training Loss: 159.3047\n",
      "Epoch 12, Step 192, Training Loss: 195.9620\n",
      "Epoch 12, Step 193, Training Loss: 210.3543\n",
      "Epoch 12, Step 194, Training Loss: 203.3970\n",
      "Epoch 12, Step 195, Training Loss: 199.2101\n",
      "Epoch 12, Step 196, Training Loss: 215.1703\n",
      "Epoch 12, Step 197, Training Loss: 181.1401\n",
      "Epoch 12, Step 198, Training Loss: 181.4883\n",
      "Epoch 12, Step 199, Training Loss: 195.1425\n",
      "Epoch 12, Step 200, Training Loss: 152.2202\n",
      "Epoch 12, Step 201, Training Loss: 165.1732\n",
      "Epoch 12, Step 202, Training Loss: 154.4915\n",
      "Epoch 12, Step 203, Training Loss: 205.4010\n",
      "Epoch 12, Step 204, Training Loss: 243.5793\n",
      "Epoch 12, Step 205, Training Loss: 199.6818\n",
      "Epoch 12, Step 206, Training Loss: 168.1844\n",
      "--- Epoch 12, Validation Loss: 232.0985 ---\n",
      "Epoch 13, Step 0, Training Loss: 151.2471\n",
      "Epoch 13, Step 1, Training Loss: 174.3531\n",
      "Epoch 13, Step 2, Training Loss: 190.8933\n",
      "Epoch 13, Step 3, Training Loss: 209.0293\n",
      "Epoch 13, Step 4, Training Loss: 198.4995\n",
      "Epoch 13, Step 5, Training Loss: 148.9671\n",
      "Epoch 13, Step 6, Training Loss: 162.9082\n",
      "Epoch 13, Step 7, Training Loss: 216.6984\n",
      "Epoch 13, Step 8, Training Loss: 161.9803\n",
      "Epoch 13, Step 9, Training Loss: 149.2139\n",
      "Epoch 13, Step 10, Training Loss: 170.9729\n",
      "Epoch 13, Step 11, Training Loss: 185.7736\n",
      "Epoch 13, Step 12, Training Loss: 216.7228\n",
      "Epoch 13, Step 13, Training Loss: 226.8267\n",
      "Epoch 13, Step 14, Training Loss: 162.6205\n",
      "Epoch 13, Step 15, Training Loss: 173.9713\n",
      "Epoch 13, Step 16, Training Loss: 144.9065\n",
      "Epoch 13, Step 17, Training Loss: 166.8214\n",
      "Epoch 13, Step 18, Training Loss: 154.7410\n",
      "Epoch 13, Step 19, Training Loss: 198.8975\n",
      "Epoch 13, Step 20, Training Loss: 189.1546\n",
      "Epoch 13, Step 21, Training Loss: 209.6268\n",
      "Epoch 13, Step 22, Training Loss: 191.2383\n",
      "Epoch 13, Step 23, Training Loss: 201.4977\n",
      "Epoch 13, Step 24, Training Loss: 146.0996\n",
      "Epoch 13, Step 25, Training Loss: 162.7897\n",
      "Epoch 13, Step 26, Training Loss: 139.0724\n",
      "Epoch 13, Step 27, Training Loss: 188.8996\n",
      "Epoch 13, Step 28, Training Loss: 150.7523\n",
      "Epoch 13, Step 29, Training Loss: 151.1246\n",
      "Epoch 13, Step 30, Training Loss: 155.6273\n",
      "Epoch 13, Step 31, Training Loss: 166.4789\n",
      "Epoch 13, Step 32, Training Loss: 179.3896\n",
      "Epoch 13, Step 33, Training Loss: 142.6388\n",
      "Epoch 13, Step 34, Training Loss: 175.2368\n",
      "Epoch 13, Step 35, Training Loss: 152.4082\n",
      "Epoch 13, Step 36, Training Loss: 172.1836\n",
      "Epoch 13, Step 37, Training Loss: 232.6836\n",
      "Epoch 13, Step 38, Training Loss: 194.8951\n",
      "Epoch 13, Step 39, Training Loss: 180.9332\n",
      "Epoch 13, Step 40, Training Loss: 169.9928\n",
      "Epoch 13, Step 41, Training Loss: 196.0275\n",
      "Epoch 13, Step 42, Training Loss: 180.5277\n",
      "Epoch 13, Step 43, Training Loss: 139.0985\n",
      "Epoch 13, Step 44, Training Loss: 180.0109\n",
      "Epoch 13, Step 45, Training Loss: 152.3809\n",
      "Epoch 13, Step 46, Training Loss: 119.5878\n",
      "Epoch 13, Step 47, Training Loss: 142.0222\n",
      "Epoch 13, Step 48, Training Loss: 136.2422\n",
      "Epoch 13, Step 49, Training Loss: 176.9183\n",
      "Epoch 13, Step 50, Training Loss: 155.7474\n",
      "Epoch 13, Step 51, Training Loss: 162.0945\n",
      "Epoch 13, Step 52, Training Loss: 125.0870\n",
      "Epoch 13, Step 53, Training Loss: 151.3615\n",
      "Epoch 13, Step 54, Training Loss: 157.4157\n",
      "Epoch 13, Step 55, Training Loss: 207.3287\n",
      "Epoch 13, Step 56, Training Loss: 213.0080\n",
      "Epoch 13, Step 57, Training Loss: 148.5216\n",
      "Epoch 13, Step 58, Training Loss: 183.7879\n",
      "Epoch 13, Step 59, Training Loss: 172.1008\n",
      "Epoch 13, Step 60, Training Loss: 237.0986\n",
      "Epoch 13, Step 61, Training Loss: 134.4886\n",
      "Epoch 13, Step 62, Training Loss: 140.4852\n",
      "Epoch 13, Step 63, Training Loss: 169.2545\n",
      "Epoch 13, Step 64, Training Loss: 160.2205\n",
      "Epoch 13, Step 65, Training Loss: 141.5651\n",
      "Epoch 13, Step 66, Training Loss: 145.8180\n",
      "Epoch 13, Step 67, Training Loss: 196.9122\n",
      "Epoch 13, Step 68, Training Loss: 142.8038\n",
      "Epoch 13, Step 69, Training Loss: 225.6437\n",
      "Epoch 13, Step 70, Training Loss: 168.2553\n",
      "Epoch 13, Step 71, Training Loss: 158.3017\n",
      "Epoch 13, Step 72, Training Loss: 150.4461\n",
      "Epoch 13, Step 73, Training Loss: 176.4398\n",
      "Epoch 13, Step 74, Training Loss: 142.5790\n",
      "Epoch 13, Step 75, Training Loss: 157.2931\n",
      "Epoch 13, Step 76, Training Loss: 220.3742\n",
      "Epoch 13, Step 77, Training Loss: 179.2318\n",
      "Epoch 13, Step 78, Training Loss: 136.1599\n",
      "Epoch 13, Step 79, Training Loss: 130.9972\n",
      "Epoch 13, Step 80, Training Loss: 147.3580\n",
      "Epoch 13, Step 81, Training Loss: 234.4675\n",
      "Epoch 13, Step 82, Training Loss: 142.8355\n",
      "Epoch 13, Step 83, Training Loss: 177.6309\n",
      "Epoch 13, Step 84, Training Loss: 213.3795\n",
      "Epoch 13, Step 85, Training Loss: 166.6716\n",
      "Epoch 13, Step 86, Training Loss: 122.8924\n",
      "Epoch 13, Step 87, Training Loss: 128.4875\n",
      "Epoch 13, Step 88, Training Loss: 200.7757\n",
      "Epoch 13, Step 89, Training Loss: 146.0234\n",
      "Epoch 13, Step 90, Training Loss: 122.1208\n",
      "Epoch 13, Step 91, Training Loss: 159.7534\n",
      "Epoch 13, Step 92, Training Loss: 172.9965\n",
      "Epoch 13, Step 93, Training Loss: 158.6332\n",
      "Epoch 13, Step 94, Training Loss: 163.4427\n",
      "Epoch 13, Step 95, Training Loss: 133.4567\n",
      "Epoch 13, Step 96, Training Loss: 142.4227\n",
      "Epoch 13, Step 97, Training Loss: 140.7106\n",
      "Epoch 13, Step 98, Training Loss: 177.3211\n",
      "Epoch 13, Step 99, Training Loss: 184.0765\n",
      "Epoch 13, Step 100, Training Loss: 128.0810\n",
      "Epoch 13, Step 101, Training Loss: 156.0056\n",
      "Epoch 13, Step 102, Training Loss: 189.1135\n",
      "Epoch 13, Step 103, Training Loss: 141.5212\n",
      "Epoch 13, Step 104, Training Loss: 155.6588\n",
      "Epoch 13, Step 105, Training Loss: 121.7114\n",
      "Epoch 13, Step 106, Training Loss: 186.1581\n",
      "Epoch 13, Step 107, Training Loss: 186.2965\n",
      "Epoch 13, Step 108, Training Loss: 139.6682\n",
      "Epoch 13, Step 109, Training Loss: 122.7564\n",
      "Epoch 13, Step 110, Training Loss: 168.3491\n",
      "Epoch 13, Step 111, Training Loss: 152.4796\n",
      "Epoch 13, Step 112, Training Loss: 150.2901\n",
      "Epoch 13, Step 113, Training Loss: 150.9581\n",
      "Epoch 13, Step 114, Training Loss: 115.0679\n",
      "Epoch 13, Step 115, Training Loss: 176.1029\n",
      "Epoch 13, Step 116, Training Loss: 128.9246\n",
      "Epoch 13, Step 117, Training Loss: 165.3940\n",
      "Epoch 13, Step 118, Training Loss: 138.3222\n",
      "Epoch 13, Step 119, Training Loss: 135.4567\n",
      "Epoch 13, Step 120, Training Loss: 147.1785\n",
      "Epoch 13, Step 121, Training Loss: 197.3626\n",
      "Epoch 13, Step 122, Training Loss: 144.2804\n",
      "Epoch 13, Step 123, Training Loss: 153.9460\n",
      "Epoch 13, Step 124, Training Loss: 185.2634\n",
      "Epoch 13, Step 125, Training Loss: 146.8661\n",
      "Epoch 13, Step 126, Training Loss: 132.8497\n",
      "Epoch 13, Step 127, Training Loss: 128.2935\n",
      "Epoch 13, Step 128, Training Loss: 130.4571\n",
      "Epoch 13, Step 129, Training Loss: 158.3172\n",
      "Epoch 13, Step 130, Training Loss: 145.8034\n",
      "Epoch 13, Step 131, Training Loss: 134.5172\n",
      "Epoch 13, Step 132, Training Loss: 154.8093\n",
      "Epoch 13, Step 133, Training Loss: 142.6281\n",
      "Epoch 13, Step 134, Training Loss: 174.9712\n",
      "Epoch 13, Step 135, Training Loss: 139.4772\n",
      "Epoch 13, Step 136, Training Loss: 183.8456\n",
      "Epoch 13, Step 137, Training Loss: 144.2797\n",
      "Epoch 13, Step 138, Training Loss: 126.0598\n",
      "Epoch 13, Step 139, Training Loss: 136.2383\n",
      "Epoch 13, Step 140, Training Loss: 130.2887\n",
      "Epoch 13, Step 141, Training Loss: 153.4227\n",
      "Epoch 13, Step 142, Training Loss: 109.7261\n",
      "Epoch 13, Step 143, Training Loss: 135.8558\n",
      "Epoch 13, Step 144, Training Loss: 122.0239\n",
      "Epoch 13, Step 145, Training Loss: 129.6517\n",
      "Epoch 13, Step 146, Training Loss: 108.8197\n",
      "Epoch 13, Step 147, Training Loss: 122.9437\n",
      "Epoch 13, Step 148, Training Loss: 237.7379\n",
      "Epoch 13, Step 149, Training Loss: 159.2144\n",
      "Epoch 13, Step 150, Training Loss: 125.9658\n",
      "Epoch 13, Step 151, Training Loss: 110.3129\n",
      "Epoch 13, Step 152, Training Loss: 129.4559\n",
      "Epoch 13, Step 153, Training Loss: 102.9820\n",
      "Epoch 13, Step 154, Training Loss: 123.5158\n",
      "Epoch 13, Step 155, Training Loss: 144.5012\n",
      "Epoch 13, Step 156, Training Loss: 128.0209\n",
      "Epoch 13, Step 157, Training Loss: 146.4342\n",
      "Epoch 13, Step 158, Training Loss: 135.6650\n",
      "Epoch 13, Step 159, Training Loss: 140.3692\n",
      "Epoch 13, Step 160, Training Loss: 185.2406\n",
      "Epoch 13, Step 161, Training Loss: 129.0411\n",
      "Epoch 13, Step 162, Training Loss: 142.9651\n",
      "Epoch 13, Step 163, Training Loss: 122.3513\n",
      "Epoch 13, Step 164, Training Loss: 118.0806\n",
      "Epoch 13, Step 165, Training Loss: 108.4843\n",
      "Epoch 13, Step 166, Training Loss: 119.2052\n",
      "Epoch 13, Step 167, Training Loss: 126.2005\n",
      "Epoch 13, Step 168, Training Loss: 124.1629\n",
      "Epoch 13, Step 169, Training Loss: 135.0790\n",
      "Epoch 13, Step 170, Training Loss: 142.8733\n",
      "Epoch 13, Step 171, Training Loss: 106.9494\n",
      "Epoch 13, Step 172, Training Loss: 120.5552\n",
      "Epoch 13, Step 173, Training Loss: 114.7804\n",
      "Epoch 13, Step 174, Training Loss: 108.4558\n",
      "Epoch 13, Step 175, Training Loss: 133.0964\n",
      "Epoch 13, Step 176, Training Loss: 124.7808\n",
      "Epoch 13, Step 177, Training Loss: 177.7309\n",
      "Epoch 13, Step 178, Training Loss: 139.3711\n",
      "Epoch 13, Step 179, Training Loss: 116.1404\n",
      "Epoch 13, Step 180, Training Loss: 112.8747\n",
      "Epoch 13, Step 181, Training Loss: 124.5040\n",
      "Epoch 13, Step 182, Training Loss: 154.4597\n",
      "Epoch 13, Step 183, Training Loss: 110.9918\n",
      "Epoch 13, Step 184, Training Loss: 118.6461\n",
      "Epoch 13, Step 185, Training Loss: 90.1641\n",
      "Epoch 13, Step 186, Training Loss: 161.3362\n",
      "Epoch 13, Step 187, Training Loss: 104.1025\n",
      "Epoch 13, Step 188, Training Loss: 227.1198\n",
      "Epoch 13, Step 189, Training Loss: 122.8471\n",
      "Epoch 13, Step 190, Training Loss: 298.7124\n",
      "Epoch 13, Step 191, Training Loss: 101.3131\n",
      "Epoch 13, Step 192, Training Loss: 132.4733\n",
      "Epoch 13, Step 193, Training Loss: 131.5665\n",
      "Epoch 13, Step 194, Training Loss: 134.7273\n",
      "Epoch 13, Step 195, Training Loss: 138.2014\n",
      "Epoch 13, Step 196, Training Loss: 148.7423\n",
      "Epoch 13, Step 197, Training Loss: 112.1335\n",
      "Epoch 13, Step 198, Training Loss: 118.4745\n",
      "Epoch 13, Step 199, Training Loss: 138.9366\n",
      "Epoch 13, Step 200, Training Loss: 99.5974\n",
      "Epoch 13, Step 201, Training Loss: 99.9121\n",
      "Epoch 13, Step 202, Training Loss: 102.4183\n",
      "Epoch 13, Step 203, Training Loss: 138.9211\n",
      "Epoch 13, Step 204, Training Loss: 172.7262\n",
      "Epoch 13, Step 205, Training Loss: 138.3093\n",
      "Epoch 13, Step 206, Training Loss: 106.7684\n",
      "--- Epoch 13, Validation Loss: 108.0321 ---\n",
      "Epoch 14, Step 0, Training Loss: 93.8347\n",
      "Epoch 14, Step 1, Training Loss: 112.2555\n",
      "Epoch 14, Step 2, Training Loss: 126.6139\n",
      "Epoch 14, Step 3, Training Loss: 133.4672\n",
      "Epoch 14, Step 4, Training Loss: 138.9022\n",
      "Epoch 14, Step 5, Training Loss: 101.9374\n",
      "Epoch 14, Step 6, Training Loss: 101.9826\n",
      "Epoch 14, Step 7, Training Loss: 141.2195\n",
      "Epoch 14, Step 8, Training Loss: 97.3824\n",
      "Epoch 14, Step 9, Training Loss: 85.0933\n",
      "Epoch 14, Step 10, Training Loss: 116.8425\n",
      "Epoch 14, Step 11, Training Loss: 121.7357\n",
      "Epoch 14, Step 12, Training Loss: 150.7224\n",
      "Epoch 14, Step 13, Training Loss: 165.5107\n",
      "Epoch 14, Step 14, Training Loss: 106.5168\n",
      "Epoch 14, Step 15, Training Loss: 102.8875\n",
      "Epoch 14, Step 16, Training Loss: 91.9597\n",
      "Epoch 14, Step 17, Training Loss: 103.3628\n",
      "Epoch 14, Step 18, Training Loss: 98.9361\n",
      "Epoch 14, Step 19, Training Loss: 132.5016\n",
      "Epoch 14, Step 20, Training Loss: 124.5246\n",
      "Epoch 14, Step 21, Training Loss: 147.4651\n",
      "Epoch 14, Step 22, Training Loss: 132.8362\n",
      "Epoch 14, Step 23, Training Loss: 138.5770\n",
      "Epoch 14, Step 24, Training Loss: 92.4904\n",
      "Epoch 14, Step 25, Training Loss: 105.7323\n",
      "Epoch 14, Step 26, Training Loss: 88.9866\n",
      "Epoch 14, Step 27, Training Loss: 136.0392\n",
      "Epoch 14, Step 28, Training Loss: 99.7613\n",
      "Epoch 14, Step 29, Training Loss: 93.1882\n",
      "Epoch 14, Step 30, Training Loss: 94.2407\n",
      "Epoch 14, Step 31, Training Loss: 105.9592\n",
      "Epoch 14, Step 32, Training Loss: 107.2739\n",
      "Epoch 14, Step 33, Training Loss: 85.3695\n",
      "Epoch 14, Step 34, Training Loss: 113.7741\n",
      "Epoch 14, Step 35, Training Loss: 99.8092\n",
      "Epoch 14, Step 36, Training Loss: 119.1967\n",
      "Epoch 14, Step 37, Training Loss: 172.4703\n",
      "Epoch 14, Step 38, Training Loss: 133.6793\n",
      "Epoch 14, Step 39, Training Loss: 117.2383\n",
      "Epoch 14, Step 40, Training Loss: 110.6251\n",
      "Epoch 14, Step 41, Training Loss: 131.6779\n",
      "Epoch 14, Step 42, Training Loss: 123.1379\n",
      "Epoch 14, Step 43, Training Loss: 88.0767\n",
      "Epoch 14, Step 44, Training Loss: 113.1517\n",
      "Epoch 14, Step 45, Training Loss: 86.7822\n",
      "Epoch 14, Step 46, Training Loss: 79.5165\n",
      "Epoch 14, Step 47, Training Loss: 99.9335\n",
      "Epoch 14, Step 48, Training Loss: 89.5583\n",
      "Epoch 14, Step 49, Training Loss: 123.9700\n",
      "Epoch 14, Step 50, Training Loss: 91.9364\n",
      "Epoch 14, Step 51, Training Loss: 103.7495\n",
      "Epoch 14, Step 52, Training Loss: 79.3092\n",
      "Epoch 14, Step 53, Training Loss: 94.5939\n",
      "Epoch 14, Step 54, Training Loss: 112.4254\n",
      "Epoch 14, Step 55, Training Loss: 129.1901\n",
      "Epoch 14, Step 56, Training Loss: 153.7038\n",
      "Epoch 14, Step 57, Training Loss: 94.4535\n",
      "Epoch 14, Step 58, Training Loss: 119.3351\n",
      "Epoch 14, Step 59, Training Loss: 108.5499\n",
      "Epoch 14, Step 60, Training Loss: 170.2316\n",
      "Epoch 14, Step 61, Training Loss: 85.8729\n",
      "Epoch 14, Step 62, Training Loss: 95.2913\n",
      "Epoch 14, Step 63, Training Loss: 122.8004\n",
      "Epoch 14, Step 64, Training Loss: 108.8945\n",
      "Epoch 14, Step 65, Training Loss: 95.0040\n",
      "Epoch 14, Step 66, Training Loss: 99.5288\n",
      "Epoch 14, Step 67, Training Loss: 124.6378\n",
      "Epoch 14, Step 68, Training Loss: 97.1868\n",
      "Epoch 14, Step 69, Training Loss: 159.7049\n",
      "Epoch 14, Step 70, Training Loss: 118.7939\n",
      "Epoch 14, Step 71, Training Loss: 113.9728\n",
      "Epoch 14, Step 72, Training Loss: 107.7972\n",
      "Epoch 14, Step 73, Training Loss: 126.2366\n",
      "Epoch 14, Step 74, Training Loss: 97.1638\n",
      "Epoch 14, Step 75, Training Loss: 108.7529\n",
      "Epoch 14, Step 76, Training Loss: 159.3106\n",
      "Epoch 14, Step 77, Training Loss: 111.9165\n",
      "Epoch 14, Step 78, Training Loss: 79.3377\n",
      "Epoch 14, Step 79, Training Loss: 79.0637\n",
      "Epoch 14, Step 80, Training Loss: 110.0466\n",
      "Epoch 14, Step 81, Training Loss: 171.6399\n",
      "Epoch 14, Step 82, Training Loss: 83.0357\n",
      "Epoch 14, Step 83, Training Loss: 124.5509\n",
      "Epoch 14, Step 84, Training Loss: 151.4417\n",
      "Epoch 14, Step 85, Training Loss: 104.1345\n",
      "Epoch 14, Step 86, Training Loss: 79.0203\n",
      "Epoch 14, Step 87, Training Loss: 89.3598\n",
      "Epoch 14, Step 88, Training Loss: 141.7645\n",
      "Epoch 14, Step 89, Training Loss: 108.8936\n",
      "Epoch 14, Step 90, Training Loss: 80.8591\n",
      "Epoch 14, Step 91, Training Loss: 92.4693\n",
      "Epoch 14, Step 92, Training Loss: 114.3572\n",
      "Epoch 14, Step 93, Training Loss: 114.0024\n",
      "Epoch 14, Step 94, Training Loss: 114.5190\n",
      "Epoch 14, Step 95, Training Loss: 88.7532\n",
      "Epoch 14, Step 96, Training Loss: 95.1100\n",
      "Epoch 14, Step 97, Training Loss: 97.0774\n",
      "Epoch 14, Step 98, Training Loss: 130.6653\n",
      "Epoch 14, Step 99, Training Loss: 123.4948\n",
      "Epoch 14, Step 100, Training Loss: 92.3054\n",
      "Epoch 14, Step 101, Training Loss: 101.8548\n",
      "Epoch 14, Step 102, Training Loss: 119.6991\n",
      "Epoch 14, Step 103, Training Loss: 94.5181\n",
      "Epoch 14, Step 104, Training Loss: 105.8277\n",
      "Epoch 14, Step 105, Training Loss: 81.3801\n",
      "Epoch 14, Step 106, Training Loss: 132.3036\n",
      "Epoch 14, Step 107, Training Loss: 130.8802\n",
      "Epoch 14, Step 108, Training Loss: 86.6880\n",
      "Epoch 14, Step 109, Training Loss: 71.5257\n",
      "Epoch 14, Step 110, Training Loss: 114.4272\n",
      "Epoch 14, Step 111, Training Loss: 103.5177\n",
      "Epoch 14, Step 112, Training Loss: 102.0483\n",
      "Epoch 14, Step 113, Training Loss: 107.9165\n",
      "Epoch 14, Step 114, Training Loss: 78.3072\n",
      "Epoch 14, Step 115, Training Loss: 123.3957\n",
      "Epoch 14, Step 116, Training Loss: 84.2956\n",
      "Epoch 14, Step 117, Training Loss: 106.7771\n",
      "Epoch 14, Step 118, Training Loss: 90.8617\n",
      "Epoch 14, Step 119, Training Loss: 96.5103\n",
      "Epoch 14, Step 120, Training Loss: 100.3697\n",
      "Epoch 14, Step 121, Training Loss: 136.4820\n",
      "Epoch 14, Step 122, Training Loss: 103.3949\n",
      "Epoch 14, Step 123, Training Loss: 105.3211\n",
      "Epoch 14, Step 124, Training Loss: 128.0283\n",
      "Epoch 14, Step 125, Training Loss: 97.9102\n",
      "Epoch 14, Step 126, Training Loss: 94.7144\n",
      "Epoch 14, Step 127, Training Loss: 88.6213\n",
      "Epoch 14, Step 128, Training Loss: 91.7944\n",
      "Epoch 14, Step 129, Training Loss: 110.0635\n",
      "Epoch 14, Step 130, Training Loss: 94.6230\n",
      "Epoch 14, Step 131, Training Loss: 89.4144\n",
      "Epoch 14, Step 132, Training Loss: 103.9910\n",
      "Epoch 14, Step 133, Training Loss: 105.4873\n",
      "Epoch 14, Step 134, Training Loss: 128.8888\n",
      "Epoch 14, Step 135, Training Loss: 94.8584\n",
      "Epoch 14, Step 136, Training Loss: 142.6796\n",
      "Epoch 14, Step 137, Training Loss: 92.9023\n",
      "Epoch 14, Step 138, Training Loss: 85.0210\n",
      "Epoch 14, Step 139, Training Loss: 89.0401\n",
      "Epoch 14, Step 140, Training Loss: 87.1535\n",
      "Epoch 14, Step 141, Training Loss: 110.3240\n",
      "Epoch 14, Step 142, Training Loss: 73.4329\n",
      "Epoch 14, Step 143, Training Loss: 89.8642\n",
      "Epoch 14, Step 144, Training Loss: 80.1691\n",
      "Epoch 14, Step 145, Training Loss: 86.2175\n",
      "Epoch 14, Step 146, Training Loss: 69.1890\n",
      "Epoch 14, Step 147, Training Loss: 81.4197\n",
      "Epoch 14, Step 148, Training Loss: 195.8879\n",
      "Epoch 14, Step 149, Training Loss: 118.0817\n",
      "Epoch 14, Step 150, Training Loss: 87.4700\n",
      "Epoch 14, Step 151, Training Loss: 78.0896\n",
      "Epoch 14, Step 152, Training Loss: 82.8492\n",
      "Epoch 14, Step 153, Training Loss: 71.4538\n",
      "Epoch 14, Step 154, Training Loss: 84.9509\n",
      "Epoch 14, Step 155, Training Loss: 107.5678\n",
      "Epoch 14, Step 156, Training Loss: 89.6953\n",
      "Epoch 14, Step 157, Training Loss: 85.9510\n",
      "Epoch 14, Step 158, Training Loss: 86.2001\n",
      "Epoch 14, Step 159, Training Loss: 105.6572\n",
      "Epoch 14, Step 160, Training Loss: 138.2174\n",
      "Epoch 14, Step 161, Training Loss: 90.5079\n",
      "Epoch 14, Step 162, Training Loss: 91.0178\n",
      "Epoch 14, Step 163, Training Loss: 81.4046\n",
      "Epoch 14, Step 164, Training Loss: 83.9438\n",
      "Epoch 14, Step 165, Training Loss: 77.6745\n",
      "Epoch 14, Step 166, Training Loss: 81.4538\n",
      "Epoch 14, Step 167, Training Loss: 83.9776\n",
      "Epoch 14, Step 168, Training Loss: 93.6793\n",
      "Epoch 14, Step 169, Training Loss: 86.6089\n",
      "Epoch 14, Step 170, Training Loss: 86.2227\n",
      "Epoch 14, Step 171, Training Loss: 69.2679\n",
      "Epoch 14, Step 172, Training Loss: 83.0588\n",
      "Epoch 14, Step 173, Training Loss: 80.1788\n",
      "Epoch 14, Step 174, Training Loss: 72.1321\n",
      "Epoch 14, Step 175, Training Loss: 96.5995\n",
      "Epoch 14, Step 176, Training Loss: 89.1342\n",
      "Epoch 14, Step 177, Training Loss: 128.4569\n",
      "Epoch 14, Step 178, Training Loss: 93.4950\n",
      "Epoch 14, Step 179, Training Loss: 74.6393\n",
      "Epoch 14, Step 180, Training Loss: 79.8654\n",
      "Epoch 14, Step 181, Training Loss: 92.4944\n",
      "Epoch 14, Step 182, Training Loss: 101.3614\n",
      "Epoch 14, Step 183, Training Loss: 73.3822\n",
      "Epoch 14, Step 184, Training Loss: 78.7370\n",
      "Epoch 14, Step 185, Training Loss: 64.3580\n",
      "Epoch 14, Step 186, Training Loss: 130.2958\n",
      "Epoch 14, Step 187, Training Loss: 72.2882\n",
      "Epoch 14, Step 188, Training Loss: 150.7148\n",
      "Epoch 14, Step 189, Training Loss: 80.9424\n",
      "Epoch 14, Step 190, Training Loss: 257.2498\n",
      "Epoch 14, Step 191, Training Loss: 64.7546\n",
      "Epoch 14, Step 192, Training Loss: 97.9569\n",
      "Epoch 14, Step 193, Training Loss: 89.5693\n",
      "Epoch 14, Step 194, Training Loss: 90.7077\n",
      "Epoch 14, Step 195, Training Loss: 95.4285\n",
      "Epoch 14, Step 196, Training Loss: 114.6820\n",
      "Epoch 14, Step 197, Training Loss: 79.5688\n",
      "Epoch 14, Step 198, Training Loss: 80.3907\n",
      "Epoch 14, Step 199, Training Loss: 91.2657\n",
      "Epoch 14, Step 200, Training Loss: 69.9542\n",
      "Epoch 14, Step 201, Training Loss: 69.3791\n",
      "Epoch 14, Step 202, Training Loss: 71.0553\n",
      "Epoch 14, Step 203, Training Loss: 103.2661\n",
      "Epoch 14, Step 204, Training Loss: 127.5925\n",
      "Epoch 14, Step 205, Training Loss: 91.8022\n",
      "Epoch 14, Step 206, Training Loss: 72.3849\n",
      "--- Epoch 14, Validation Loss: 81.1597 ---\n",
      "Epoch 15, Step 0, Training Loss: 66.7445\n",
      "Epoch 15, Step 1, Training Loss: 75.4383\n",
      "Epoch 15, Step 2, Training Loss: 78.8117\n",
      "Epoch 15, Step 3, Training Loss: 100.3932\n",
      "Epoch 15, Step 4, Training Loss: 104.2586\n",
      "Epoch 15, Step 5, Training Loss: 70.1811\n",
      "Epoch 15, Step 6, Training Loss: 71.5545\n",
      "Epoch 15, Step 7, Training Loss: 97.9971\n",
      "Epoch 15, Step 8, Training Loss: 70.2277\n",
      "Epoch 15, Step 9, Training Loss: 61.3270\n",
      "Epoch 15, Step 10, Training Loss: 85.3232\n",
      "Epoch 15, Step 11, Training Loss: 85.1457\n",
      "Epoch 15, Step 12, Training Loss: 102.3288\n",
      "Epoch 15, Step 13, Training Loss: 117.9258\n",
      "Epoch 15, Step 14, Training Loss: 80.4061\n",
      "Epoch 15, Step 15, Training Loss: 67.3126\n",
      "Epoch 15, Step 16, Training Loss: 58.7140\n",
      "Epoch 15, Step 17, Training Loss: 75.7990\n",
      "Epoch 15, Step 18, Training Loss: 62.0875\n",
      "Epoch 15, Step 19, Training Loss: 96.8107\n",
      "Epoch 15, Step 20, Training Loss: 88.3174\n",
      "Epoch 15, Step 21, Training Loss: 110.3657\n",
      "Epoch 15, Step 22, Training Loss: 102.8908\n",
      "Epoch 15, Step 23, Training Loss: 92.9435\n",
      "Epoch 15, Step 24, Training Loss: 67.0692\n",
      "Epoch 15, Step 25, Training Loss: 72.9695\n",
      "Epoch 15, Step 26, Training Loss: 68.4475\n",
      "Epoch 15, Step 27, Training Loss: 91.1349\n",
      "Epoch 15, Step 28, Training Loss: 71.1898\n",
      "Epoch 15, Step 29, Training Loss: 67.7765\n",
      "Epoch 15, Step 30, Training Loss: 58.0519\n",
      "Epoch 15, Step 31, Training Loss: 73.0462\n",
      "Epoch 15, Step 32, Training Loss: 77.6463\n",
      "Epoch 15, Step 33, Training Loss: 61.8572\n",
      "Epoch 15, Step 34, Training Loss: 79.4975\n",
      "Epoch 15, Step 35, Training Loss: 70.1258\n",
      "Epoch 15, Step 36, Training Loss: 88.2874\n",
      "Epoch 15, Step 37, Training Loss: 139.7966\n",
      "Epoch 15, Step 38, Training Loss: 97.7219\n",
      "Epoch 15, Step 39, Training Loss: 85.0702\n",
      "Epoch 15, Step 40, Training Loss: 82.6427\n",
      "Epoch 15, Step 41, Training Loss: 112.6614\n",
      "Epoch 15, Step 42, Training Loss: 82.9084\n",
      "Epoch 15, Step 43, Training Loss: 65.8652\n",
      "Epoch 15, Step 44, Training Loss: 87.8894\n",
      "Epoch 15, Step 45, Training Loss: 63.6510\n",
      "Epoch 15, Step 46, Training Loss: 50.5974\n",
      "Epoch 15, Step 47, Training Loss: 70.1536\n",
      "Epoch 15, Step 48, Training Loss: 57.1945\n",
      "Epoch 15, Step 49, Training Loss: 88.2965\n",
      "Epoch 15, Step 50, Training Loss: 65.0246\n",
      "Epoch 15, Step 51, Training Loss: 76.5296\n",
      "Epoch 15, Step 52, Training Loss: 56.8105\n",
      "Epoch 15, Step 53, Training Loss: 63.3691\n",
      "Epoch 15, Step 54, Training Loss: 80.4529\n",
      "Epoch 15, Step 55, Training Loss: 94.0990\n",
      "Epoch 15, Step 56, Training Loss: 118.7240\n",
      "Epoch 15, Step 57, Training Loss: 61.1202\n",
      "Epoch 15, Step 58, Training Loss: 87.6124\n",
      "Epoch 15, Step 59, Training Loss: 80.2208\n",
      "Epoch 15, Step 60, Training Loss: 141.7008\n",
      "Epoch 15, Step 61, Training Loss: 58.9296\n",
      "Epoch 15, Step 62, Training Loss: 67.6778\n",
      "Epoch 15, Step 63, Training Loss: 85.5452\n",
      "Epoch 15, Step 64, Training Loss: 81.4093\n",
      "Epoch 15, Step 65, Training Loss: 69.0774\n",
      "Epoch 15, Step 66, Training Loss: 73.3362\n",
      "Epoch 15, Step 67, Training Loss: 95.2733\n",
      "Epoch 15, Step 68, Training Loss: 70.7201\n",
      "Epoch 15, Step 69, Training Loss: 128.8598\n",
      "Epoch 15, Step 70, Training Loss: 87.0694\n",
      "Epoch 15, Step 71, Training Loss: 81.3773\n",
      "Epoch 15, Step 72, Training Loss: 81.2625\n",
      "Epoch 15, Step 73, Training Loss: 90.4296\n",
      "Epoch 15, Step 74, Training Loss: 64.5977\n",
      "Epoch 15, Step 75, Training Loss: 87.5899\n",
      "Epoch 15, Step 76, Training Loss: 127.3856\n",
      "Epoch 15, Step 77, Training Loss: 84.4993\n",
      "Epoch 15, Step 78, Training Loss: 54.8898\n",
      "Epoch 15, Step 79, Training Loss: 54.3110\n",
      "Epoch 15, Step 80, Training Loss: 82.6633\n",
      "Epoch 15, Step 81, Training Loss: 136.2785\n",
      "Epoch 15, Step 82, Training Loss: 58.9901\n",
      "Epoch 15, Step 83, Training Loss: 89.2683\n",
      "Epoch 15, Step 84, Training Loss: 121.8654\n",
      "Epoch 15, Step 85, Training Loss: 74.7778\n",
      "Epoch 15, Step 86, Training Loss: 52.2652\n",
      "Epoch 15, Step 87, Training Loss: 69.1736\n",
      "Epoch 15, Step 88, Training Loss: 98.8779\n",
      "Epoch 15, Step 89, Training Loss: 83.9131\n",
      "Epoch 15, Step 90, Training Loss: 59.0814\n",
      "Epoch 15, Step 91, Training Loss: 71.1284\n",
      "Epoch 15, Step 92, Training Loss: 85.0600\n",
      "Epoch 15, Step 93, Training Loss: 80.3182\n",
      "Epoch 15, Step 94, Training Loss: 92.2700\n",
      "Epoch 15, Step 95, Training Loss: 63.0000\n",
      "Epoch 15, Step 96, Training Loss: 71.2911\n",
      "Epoch 15, Step 97, Training Loss: 61.7459\n",
      "Epoch 15, Step 98, Training Loss: 96.6975\n",
      "Epoch 15, Step 99, Training Loss: 93.0347\n",
      "Epoch 15, Step 100, Training Loss: 61.2068\n",
      "Epoch 15, Step 101, Training Loss: 75.2143\n",
      "Epoch 15, Step 102, Training Loss: 85.9584\n",
      "Epoch 15, Step 103, Training Loss: 67.4465\n",
      "Epoch 15, Step 104, Training Loss: 74.9641\n",
      "Epoch 15, Step 105, Training Loss: 56.5237\n",
      "Epoch 15, Step 106, Training Loss: 102.1174\n",
      "Epoch 15, Step 107, Training Loss: 95.7659\n",
      "Epoch 15, Step 108, Training Loss: 59.3434\n",
      "Epoch 15, Step 109, Training Loss: 54.9782\n",
      "Epoch 15, Step 110, Training Loss: 78.2572\n",
      "Epoch 15, Step 111, Training Loss: 73.2560\n",
      "Epoch 15, Step 112, Training Loss: 71.6299\n",
      "Epoch 15, Step 113, Training Loss: 77.4586\n",
      "Epoch 15, Step 114, Training Loss: 54.3762\n",
      "Epoch 15, Step 115, Training Loss: 95.2197\n",
      "Epoch 15, Step 116, Training Loss: 62.0889\n",
      "Epoch 15, Step 117, Training Loss: 87.5612\n",
      "Epoch 15, Step 118, Training Loss: 66.5808\n",
      "Epoch 15, Step 119, Training Loss: 77.0061\n",
      "Epoch 15, Step 120, Training Loss: 72.5107\n",
      "Epoch 15, Step 121, Training Loss: 105.3434\n",
      "Epoch 15, Step 122, Training Loss: 80.8994\n",
      "Epoch 15, Step 123, Training Loss: 76.2043\n",
      "Epoch 15, Step 124, Training Loss: 87.8019\n",
      "Epoch 15, Step 125, Training Loss: 73.4487\n",
      "Epoch 15, Step 126, Training Loss: 72.3171\n",
      "Epoch 15, Step 127, Training Loss: 63.7409\n",
      "Epoch 15, Step 128, Training Loss: 70.7086\n",
      "Epoch 15, Step 129, Training Loss: 83.0662\n",
      "Epoch 15, Step 130, Training Loss: 73.9721\n",
      "Epoch 15, Step 131, Training Loss: 64.4242\n",
      "Epoch 15, Step 132, Training Loss: 74.6864\n",
      "Epoch 15, Step 133, Training Loss: 81.9077\n",
      "Epoch 15, Step 134, Training Loss: 92.4671\n",
      "Epoch 15, Step 135, Training Loss: 73.3926\n",
      "Epoch 15, Step 136, Training Loss: 123.4620\n",
      "Epoch 15, Step 137, Training Loss: 77.0022\n",
      "Epoch 15, Step 138, Training Loss: 61.3381\n",
      "Epoch 15, Step 139, Training Loss: 72.4809\n",
      "Epoch 15, Step 140, Training Loss: 66.0977\n",
      "Epoch 15, Step 141, Training Loss: 89.8644\n",
      "Epoch 15, Step 142, Training Loss: 49.5258\n",
      "Epoch 15, Step 143, Training Loss: 65.1654\n",
      "Epoch 15, Step 144, Training Loss: 61.7376\n",
      "Epoch 15, Step 145, Training Loss: 62.9268\n",
      "Epoch 15, Step 146, Training Loss: 51.9333\n",
      "Epoch 15, Step 147, Training Loss: 57.8579\n",
      "Epoch 15, Step 148, Training Loss: 172.6551\n",
      "Epoch 15, Step 149, Training Loss: 96.3923\n",
      "Epoch 15, Step 150, Training Loss: 76.2930\n",
      "Epoch 15, Step 151, Training Loss: 60.2865\n",
      "Epoch 15, Step 152, Training Loss: 58.9261\n",
      "Epoch 15, Step 153, Training Loss: 49.7644\n",
      "Epoch 15, Step 154, Training Loss: 69.2269\n",
      "Epoch 15, Step 155, Training Loss: 88.8788\n",
      "Epoch 15, Step 156, Training Loss: 71.9279\n",
      "Epoch 15, Step 157, Training Loss: 70.2736\n",
      "Epoch 15, Step 158, Training Loss: 57.4816\n",
      "Epoch 15, Step 159, Training Loss: 87.6746\n",
      "Epoch 15, Step 160, Training Loss: 112.6161\n",
      "Epoch 15, Step 161, Training Loss: 71.9624\n",
      "Epoch 15, Step 162, Training Loss: 69.4221\n",
      "Epoch 15, Step 163, Training Loss: 60.9958\n",
      "Epoch 15, Step 164, Training Loss: 61.7245\n",
      "Epoch 15, Step 165, Training Loss: 60.5474\n",
      "Epoch 15, Step 166, Training Loss: 60.3067\n",
      "Epoch 15, Step 167, Training Loss: 62.1246\n",
      "Epoch 15, Step 168, Training Loss: 77.6303\n",
      "Epoch 15, Step 169, Training Loss: 60.8298\n",
      "Epoch 15, Step 170, Training Loss: 70.2766\n",
      "Epoch 15, Step 171, Training Loss: 55.3999\n",
      "Epoch 15, Step 172, Training Loss: 62.7556\n",
      "Epoch 15, Step 173, Training Loss: 63.2590\n",
      "Epoch 15, Step 174, Training Loss: 52.1219\n",
      "Epoch 15, Step 175, Training Loss: 69.1695\n",
      "Epoch 15, Step 176, Training Loss: 69.6721\n",
      "Epoch 15, Step 177, Training Loss: 96.7271\n",
      "Epoch 15, Step 178, Training Loss: 70.4838\n",
      "Epoch 15, Step 179, Training Loss: 49.4602\n",
      "Epoch 15, Step 180, Training Loss: 62.3820\n",
      "Epoch 15, Step 181, Training Loss: 60.6207\n",
      "Epoch 15, Step 182, Training Loss: 82.9676\n",
      "Epoch 15, Step 183, Training Loss: 59.3680\n",
      "Epoch 15, Step 184, Training Loss: 61.1723\n",
      "Epoch 15, Step 185, Training Loss: 51.4969\n",
      "Epoch 15, Step 186, Training Loss: 105.1882\n",
      "Epoch 15, Step 187, Training Loss: 52.3621\n",
      "Epoch 15, Step 188, Training Loss: 140.7968\n",
      "Epoch 15, Step 189, Training Loss: 69.2886\n",
      "Epoch 15, Step 190, Training Loss: 224.5411\n",
      "Epoch 15, Step 191, Training Loss: 44.9215\n",
      "Epoch 15, Step 192, Training Loss: 73.9361\n",
      "Epoch 15, Step 193, Training Loss: 71.3210\n",
      "Epoch 15, Step 194, Training Loss: 64.1321\n",
      "Epoch 15, Step 195, Training Loss: 69.9316\n",
      "Epoch 15, Step 196, Training Loss: 88.5662\n",
      "Epoch 15, Step 197, Training Loss: 62.8160\n",
      "Epoch 15, Step 198, Training Loss: 61.8746\n",
      "Epoch 15, Step 199, Training Loss: 73.3749\n",
      "Epoch 15, Step 200, Training Loss: 52.6757\n",
      "Epoch 15, Step 201, Training Loss: 52.7052\n",
      "Epoch 15, Step 202, Training Loss: 57.5900\n",
      "Epoch 15, Step 203, Training Loss: 80.8665\n",
      "Epoch 15, Step 204, Training Loss: 104.5872\n",
      "Epoch 15, Step 205, Training Loss: 76.3577\n",
      "Epoch 15, Step 206, Training Loss: 59.4183\n",
      "--- Epoch 15, Validation Loss: 63.8233 ---\n",
      "Epoch 16, Step 0, Training Loss: 46.9232\n",
      "Epoch 16, Step 1, Training Loss: 55.9915\n",
      "Epoch 16, Step 2, Training Loss: 59.2203\n",
      "Epoch 16, Step 3, Training Loss: 79.8159\n",
      "Epoch 16, Step 4, Training Loss: 86.3358\n",
      "Epoch 16, Step 5, Training Loss: 55.6655\n",
      "Epoch 16, Step 6, Training Loss: 56.9466\n",
      "Epoch 16, Step 7, Training Loss: 73.0933\n",
      "Epoch 16, Step 8, Training Loss: 54.3308\n",
      "Epoch 16, Step 9, Training Loss: 48.9857\n",
      "Epoch 16, Step 10, Training Loss: 71.6950\n",
      "Epoch 16, Step 11, Training Loss: 67.8994\n",
      "Epoch 16, Step 12, Training Loss: 83.0601\n",
      "Epoch 16, Step 13, Training Loss: 101.8759\n",
      "Epoch 16, Step 14, Training Loss: 57.3393\n",
      "Epoch 16, Step 15, Training Loss: 45.6609\n",
      "Epoch 16, Step 16, Training Loss: 50.4178\n",
      "Epoch 16, Step 17, Training Loss: 56.7147\n",
      "Epoch 16, Step 18, Training Loss: 49.9822\n",
      "Epoch 16, Step 19, Training Loss: 75.7750\n",
      "Epoch 16, Step 20, Training Loss: 67.0731\n",
      "Epoch 16, Step 21, Training Loss: 86.1433\n",
      "Epoch 16, Step 22, Training Loss: 85.1783\n",
      "Epoch 16, Step 23, Training Loss: 68.4701\n",
      "Epoch 16, Step 24, Training Loss: 53.6049\n",
      "Epoch 16, Step 25, Training Loss: 52.9080\n",
      "Epoch 16, Step 26, Training Loss: 59.0117\n",
      "Epoch 16, Step 27, Training Loss: 73.9107\n",
      "Epoch 16, Step 28, Training Loss: 54.4644\n",
      "Epoch 16, Step 29, Training Loss: 50.0679\n",
      "Epoch 16, Step 30, Training Loss: 44.7827\n",
      "Epoch 16, Step 31, Training Loss: 61.5219\n",
      "Epoch 16, Step 32, Training Loss: 56.7381\n",
      "Epoch 16, Step 33, Training Loss: 49.1606\n",
      "Epoch 16, Step 34, Training Loss: 56.3842\n",
      "Epoch 16, Step 35, Training Loss: 55.1636\n",
      "Epoch 16, Step 36, Training Loss: 67.6319\n",
      "Epoch 16, Step 37, Training Loss: 120.7859\n",
      "Epoch 16, Step 38, Training Loss: 78.9730\n",
      "Epoch 16, Step 39, Training Loss: 61.4931\n",
      "Epoch 16, Step 40, Training Loss: 65.7134\n",
      "Epoch 16, Step 41, Training Loss: 84.1203\n",
      "Epoch 16, Step 42, Training Loss: 68.2812\n",
      "Epoch 16, Step 43, Training Loss: 49.2154\n",
      "Epoch 16, Step 44, Training Loss: 70.9316\n",
      "Epoch 16, Step 45, Training Loss: 42.4810\n",
      "Epoch 16, Step 46, Training Loss: 38.1511\n",
      "Epoch 16, Step 47, Training Loss: 56.1884\n",
      "Epoch 16, Step 48, Training Loss: 46.1094\n",
      "Epoch 16, Step 49, Training Loss: 62.2519\n",
      "Epoch 16, Step 50, Training Loss: 54.6632\n",
      "Epoch 16, Step 51, Training Loss: 61.4210\n",
      "Epoch 16, Step 52, Training Loss: 46.3714\n",
      "Epoch 16, Step 53, Training Loss: 49.4321\n",
      "Epoch 16, Step 54, Training Loss: 62.5713\n",
      "Epoch 16, Step 55, Training Loss: 71.6676\n",
      "Epoch 16, Step 56, Training Loss: 90.3703\n",
      "Epoch 16, Step 57, Training Loss: 48.8693\n",
      "Epoch 16, Step 58, Training Loss: 74.0039\n",
      "Epoch 16, Step 59, Training Loss: 60.8467\n",
      "Epoch 16, Step 60, Training Loss: 113.0892\n",
      "Epoch 16, Step 61, Training Loss: 46.4253\n",
      "Epoch 16, Step 62, Training Loss: 54.0231\n",
      "Epoch 16, Step 63, Training Loss: 72.8660\n",
      "Epoch 16, Step 64, Training Loss: 63.6170\n",
      "Epoch 16, Step 65, Training Loss: 55.4306\n",
      "Epoch 16, Step 66, Training Loss: 59.9787\n",
      "Epoch 16, Step 67, Training Loss: 73.9257\n",
      "Epoch 16, Step 68, Training Loss: 55.0223\n",
      "Epoch 16, Step 69, Training Loss: 104.6191\n",
      "Epoch 16, Step 70, Training Loss: 70.2203\n",
      "Epoch 16, Step 71, Training Loss: 59.8356\n",
      "Epoch 16, Step 72, Training Loss: 71.1902\n",
      "Epoch 16, Step 73, Training Loss: 73.0218\n",
      "Epoch 16, Step 74, Training Loss: 58.6655\n",
      "Epoch 16, Step 75, Training Loss: 76.1160\n",
      "Epoch 16, Step 76, Training Loss: 99.2924\n",
      "Epoch 16, Step 77, Training Loss: 70.1082\n",
      "Epoch 16, Step 78, Training Loss: 41.1330\n",
      "Epoch 16, Step 79, Training Loss: 41.3956\n",
      "Epoch 16, Step 80, Training Loss: 69.7045\n",
      "Epoch 16, Step 81, Training Loss: 114.3852\n",
      "Epoch 16, Step 82, Training Loss: 39.4116\n",
      "Epoch 16, Step 83, Training Loss: 82.8170\n",
      "Epoch 16, Step 84, Training Loss: 105.8203\n",
      "Epoch 16, Step 85, Training Loss: 61.8551\n",
      "Epoch 16, Step 86, Training Loss: 41.6680\n",
      "Epoch 16, Step 87, Training Loss: 60.2663\n",
      "Epoch 16, Step 88, Training Loss: 80.0364\n",
      "Epoch 16, Step 89, Training Loss: 72.7887\n",
      "Epoch 16, Step 90, Training Loss: 50.3199\n",
      "Epoch 16, Step 91, Training Loss: 50.2706\n",
      "Epoch 16, Step 92, Training Loss: 69.8215\n",
      "Epoch 16, Step 93, Training Loss: 62.3302\n",
      "Epoch 16, Step 94, Training Loss: 74.5177\n",
      "Epoch 16, Step 95, Training Loss: 48.1821\n",
      "Epoch 16, Step 96, Training Loss: 56.0227\n",
      "Epoch 16, Step 97, Training Loss: 49.1606\n",
      "Epoch 16, Step 98, Training Loss: 81.5879\n",
      "Epoch 16, Step 99, Training Loss: 79.7586\n",
      "Epoch 16, Step 100, Training Loss: 43.6580\n",
      "Epoch 16, Step 101, Training Loss: 60.1901\n",
      "Epoch 16, Step 102, Training Loss: 67.4741\n",
      "Epoch 16, Step 103, Training Loss: 52.9353\n",
      "Epoch 16, Step 104, Training Loss: 65.3984\n",
      "Epoch 16, Step 105, Training Loss: 48.0971\n",
      "Epoch 16, Step 106, Training Loss: 86.2145\n",
      "Epoch 16, Step 107, Training Loss: 77.1513\n",
      "Epoch 16, Step 108, Training Loss: 44.5571\n",
      "Epoch 16, Step 109, Training Loss: 41.3263\n",
      "Epoch 16, Step 110, Training Loss: 66.0884\n",
      "Epoch 16, Step 111, Training Loss: 63.1379\n",
      "Epoch 16, Step 112, Training Loss: 56.9004\n",
      "Epoch 16, Step 113, Training Loss: 62.3607\n",
      "Epoch 16, Step 114, Training Loss: 44.5543\n",
      "Epoch 16, Step 115, Training Loss: 80.3871\n",
      "Epoch 16, Step 116, Training Loss: 55.4346\n",
      "Epoch 16, Step 117, Training Loss: 71.6922\n",
      "Epoch 16, Step 118, Training Loss: 53.1963\n",
      "Epoch 16, Step 119, Training Loss: 63.1855\n",
      "Epoch 16, Step 120, Training Loss: 61.0170\n",
      "Epoch 16, Step 121, Training Loss: 91.6554\n",
      "Epoch 16, Step 122, Training Loss: 74.2634\n",
      "Epoch 16, Step 123, Training Loss: 61.4147\n",
      "Epoch 16, Step 124, Training Loss: 71.3289\n",
      "Epoch 16, Step 125, Training Loss: 61.1490\n",
      "Epoch 16, Step 126, Training Loss: 57.9179\n",
      "Epoch 16, Step 127, Training Loss: 55.0371\n",
      "Epoch 16, Step 128, Training Loss: 57.8589\n",
      "Epoch 16, Step 129, Training Loss: 73.6606\n",
      "Epoch 16, Step 130, Training Loss: 57.1097\n",
      "Epoch 16, Step 131, Training Loss: 55.3711\n",
      "Epoch 16, Step 132, Training Loss: 63.3772\n",
      "Epoch 16, Step 133, Training Loss: 71.4614\n",
      "Epoch 16, Step 134, Training Loss: 75.1230\n",
      "Epoch 16, Step 135, Training Loss: 60.1060\n",
      "Epoch 16, Step 136, Training Loss: 113.4032\n",
      "Epoch 16, Step 137, Training Loss: 56.0227\n",
      "Epoch 16, Step 138, Training Loss: 48.7536\n",
      "Epoch 16, Step 139, Training Loss: 61.2386\n",
      "Epoch 16, Step 140, Training Loss: 54.4456\n",
      "Epoch 16, Step 141, Training Loss: 77.5645\n",
      "Epoch 16, Step 142, Training Loss: 46.3304\n",
      "Epoch 16, Step 143, Training Loss: 50.8960\n",
      "Epoch 16, Step 144, Training Loss: 50.2042\n",
      "Epoch 16, Step 145, Training Loss: 51.6055\n",
      "Epoch 16, Step 146, Training Loss: 46.5667\n",
      "Epoch 16, Step 147, Training Loss: 48.8355\n",
      "Epoch 16, Step 148, Training Loss: 157.4980\n",
      "Epoch 16, Step 149, Training Loss: 83.6503\n",
      "Epoch 16, Step 150, Training Loss: 67.1734\n",
      "Epoch 16, Step 151, Training Loss: 53.3620\n",
      "Epoch 16, Step 152, Training Loss: 46.2923\n",
      "Epoch 16, Step 153, Training Loss: 41.4924\n",
      "Epoch 16, Step 154, Training Loss: 52.9647\n",
      "Epoch 16, Step 155, Training Loss: 76.0770\n",
      "Epoch 16, Step 156, Training Loss: 59.1667\n",
      "Epoch 16, Step 157, Training Loss: 54.7596\n",
      "Epoch 16, Step 158, Training Loss: 50.1118\n",
      "Epoch 16, Step 159, Training Loss: 77.5860\n",
      "Epoch 16, Step 160, Training Loss: 101.4790\n",
      "Epoch 16, Step 161, Training Loss: 63.1466\n",
      "Epoch 16, Step 162, Training Loss: 52.1776\n",
      "Epoch 16, Step 163, Training Loss: 46.2143\n",
      "Epoch 16, Step 164, Training Loss: 51.7556\n",
      "Epoch 16, Step 165, Training Loss: 54.9024\n",
      "Epoch 16, Step 166, Training Loss: 49.5231\n",
      "Epoch 16, Step 167, Training Loss: 55.1017\n",
      "Epoch 16, Step 168, Training Loss: 69.5569\n",
      "Epoch 16, Step 169, Training Loss: 45.2677\n",
      "Epoch 16, Step 170, Training Loss: 57.9694\n",
      "Epoch 16, Step 171, Training Loss: 43.5571\n",
      "Epoch 16, Step 172, Training Loss: 51.9847\n",
      "Epoch 16, Step 173, Training Loss: 48.4319\n",
      "Epoch 16, Step 174, Training Loss: 43.8825\n",
      "Epoch 16, Step 175, Training Loss: 58.4910\n",
      "Epoch 16, Step 176, Training Loss: 61.2880\n",
      "Epoch 16, Step 177, Training Loss: 83.3981\n",
      "Epoch 16, Step 178, Training Loss: 56.2271\n",
      "Epoch 16, Step 179, Training Loss: 43.4225\n",
      "Epoch 16, Step 180, Training Loss: 57.7330\n",
      "Epoch 16, Step 181, Training Loss: 52.1042\n",
      "Epoch 16, Step 182, Training Loss: 73.1116\n",
      "Epoch 16, Step 183, Training Loss: 48.7913\n",
      "Epoch 16, Step 184, Training Loss: 52.1942\n",
      "Epoch 16, Step 185, Training Loss: 45.5642\n",
      "Epoch 16, Step 186, Training Loss: 89.0453\n",
      "Epoch 16, Step 187, Training Loss: 46.1906\n",
      "Epoch 16, Step 188, Training Loss: 149.6866\n",
      "Epoch 16, Step 189, Training Loss: 58.7035\n",
      "Epoch 16, Step 190, Training Loss: 205.6231\n",
      "Epoch 16, Step 191, Training Loss: 36.8640\n",
      "Epoch 16, Step 192, Training Loss: 59.3841\n",
      "Epoch 16, Step 193, Training Loss: 57.5489\n",
      "Epoch 16, Step 194, Training Loss: 50.1102\n",
      "Epoch 16, Step 195, Training Loss: 58.6015\n",
      "Epoch 16, Step 196, Training Loss: 74.6757\n",
      "Epoch 16, Step 197, Training Loss: 54.8491\n",
      "Epoch 16, Step 198, Training Loss: 54.2999\n",
      "Epoch 16, Step 199, Training Loss: 59.9055\n",
      "Epoch 16, Step 200, Training Loss: 48.3848\n",
      "Epoch 16, Step 201, Training Loss: 44.5188\n",
      "Epoch 16, Step 202, Training Loss: 51.7613\n",
      "Epoch 16, Step 203, Training Loss: 71.4908\n",
      "Epoch 16, Step 204, Training Loss: 92.2736\n",
      "Epoch 16, Step 205, Training Loss: 61.2521\n",
      "Epoch 16, Step 206, Training Loss: 49.9697\n",
      "--- Epoch 16, Validation Loss: 58.3913 ---\n",
      "Epoch 17, Step 0, Training Loss: 39.4520\n",
      "Epoch 17, Step 1, Training Loss: 46.1732\n",
      "Epoch 17, Step 2, Training Loss: 49.9464\n",
      "Epoch 17, Step 3, Training Loss: 69.9548\n",
      "Epoch 17, Step 4, Training Loss: 75.2871\n",
      "Epoch 17, Step 5, Training Loss: 51.2081\n",
      "Epoch 17, Step 6, Training Loss: 52.3571\n",
      "Epoch 17, Step 7, Training Loss: 59.5957\n",
      "Epoch 17, Step 8, Training Loss: 43.7360\n",
      "Epoch 17, Step 9, Training Loss: 41.1442\n",
      "Epoch 17, Step 10, Training Loss: 62.1151\n",
      "Epoch 17, Step 11, Training Loss: 56.9680\n",
      "Epoch 17, Step 12, Training Loss: 74.2757\n",
      "Epoch 17, Step 13, Training Loss: 90.1298\n",
      "Epoch 17, Step 14, Training Loss: 51.4545\n",
      "Epoch 17, Step 15, Training Loss: 37.0094\n",
      "Epoch 17, Step 16, Training Loss: 41.3364\n",
      "Epoch 17, Step 17, Training Loss: 49.9450\n",
      "Epoch 17, Step 18, Training Loss: 40.9824\n",
      "Epoch 17, Step 19, Training Loss: 65.2716\n",
      "Epoch 17, Step 20, Training Loss: 57.0503\n",
      "Epoch 17, Step 21, Training Loss: 76.1978\n",
      "Epoch 17, Step 22, Training Loss: 77.4352\n",
      "Epoch 17, Step 23, Training Loss: 60.2526\n",
      "Epoch 17, Step 24, Training Loss: 49.0163\n",
      "Epoch 17, Step 25, Training Loss: 46.6118\n",
      "Epoch 17, Step 26, Training Loss: 54.2129\n",
      "Epoch 17, Step 27, Training Loss: 61.5834\n",
      "Epoch 17, Step 28, Training Loss: 50.0726\n",
      "Epoch 17, Step 29, Training Loss: 42.9465\n",
      "Epoch 17, Step 30, Training Loss: 38.0463\n",
      "Epoch 17, Step 31, Training Loss: 53.7422\n",
      "Epoch 17, Step 32, Training Loss: 49.3198\n",
      "Epoch 17, Step 33, Training Loss: 44.1300\n",
      "Epoch 17, Step 34, Training Loss: 50.1403\n",
      "Epoch 17, Step 35, Training Loss: 46.9569\n",
      "Epoch 17, Step 36, Training Loss: 60.6142\n",
      "Epoch 17, Step 37, Training Loss: 109.7214\n",
      "Epoch 17, Step 38, Training Loss: 68.1487\n",
      "Epoch 17, Step 39, Training Loss: 53.4972\n",
      "Epoch 17, Step 40, Training Loss: 63.4691\n",
      "Epoch 17, Step 41, Training Loss: 77.7097\n",
      "Epoch 17, Step 42, Training Loss: 58.4672\n",
      "Epoch 17, Step 43, Training Loss: 47.0765\n",
      "Epoch 17, Step 44, Training Loss: 59.0253\n",
      "Epoch 17, Step 45, Training Loss: 38.1059\n",
      "Epoch 17, Step 46, Training Loss: 33.0466\n",
      "Epoch 17, Step 47, Training Loss: 49.8825\n",
      "Epoch 17, Step 48, Training Loss: 41.5494\n",
      "Epoch 17, Step 49, Training Loss: 60.0339\n",
      "Epoch 17, Step 50, Training Loss: 48.3622\n",
      "Epoch 17, Step 51, Training Loss: 55.0369\n",
      "Epoch 17, Step 52, Training Loss: 41.0735\n",
      "Epoch 17, Step 53, Training Loss: 41.9880\n",
      "Epoch 17, Step 54, Training Loss: 55.1033\n",
      "Epoch 17, Step 55, Training Loss: 63.3376\n",
      "Epoch 17, Step 56, Training Loss: 79.9892\n",
      "Epoch 17, Step 57, Training Loss: 39.6078\n",
      "Epoch 17, Step 58, Training Loss: 57.6605\n",
      "Epoch 17, Step 59, Training Loss: 58.1394\n",
      "Epoch 17, Step 60, Training Loss: 97.9486\n",
      "Epoch 17, Step 61, Training Loss: 42.8090\n",
      "Epoch 17, Step 62, Training Loss: 48.1021\n",
      "Epoch 17, Step 63, Training Loss: 68.3639\n",
      "Epoch 17, Step 64, Training Loss: 56.1942\n",
      "Epoch 17, Step 65, Training Loss: 50.1501\n",
      "Epoch 17, Step 66, Training Loss: 53.0827\n",
      "Epoch 17, Step 67, Training Loss: 64.2464\n",
      "Epoch 17, Step 68, Training Loss: 46.8585\n",
      "Epoch 17, Step 69, Training Loss: 93.4666\n",
      "Epoch 17, Step 70, Training Loss: 63.9221\n",
      "Epoch 17, Step 71, Training Loss: 54.6830\n",
      "Epoch 17, Step 72, Training Loss: 65.3139\n",
      "Epoch 17, Step 73, Training Loss: 65.7894\n",
      "Epoch 17, Step 74, Training Loss: 49.7873\n",
      "Epoch 17, Step 75, Training Loss: 73.5488\n",
      "Epoch 17, Step 76, Training Loss: 91.2873\n",
      "Epoch 17, Step 77, Training Loss: 58.2902\n",
      "Epoch 17, Step 78, Training Loss: 34.7671\n",
      "Epoch 17, Step 79, Training Loss: 34.7038\n",
      "Epoch 17, Step 80, Training Loss: 66.1626\n",
      "Epoch 17, Step 81, Training Loss: 106.5434\n",
      "Epoch 17, Step 82, Training Loss: 35.8658\n",
      "Epoch 17, Step 83, Training Loss: 69.9581\n",
      "Epoch 17, Step 84, Training Loss: 97.1334\n",
      "Epoch 17, Step 85, Training Loss: 52.3967\n",
      "Epoch 17, Step 86, Training Loss: 35.8695\n",
      "Epoch 17, Step 87, Training Loss: 57.2859\n",
      "Epoch 17, Step 88, Training Loss: 71.2673\n",
      "Epoch 17, Step 89, Training Loss: 67.5298\n",
      "Epoch 17, Step 90, Training Loss: 44.0152\n",
      "Epoch 17, Step 91, Training Loss: 40.6291\n",
      "Epoch 17, Step 92, Training Loss: 66.4294\n",
      "Epoch 17, Step 93, Training Loss: 55.8505\n",
      "Epoch 17, Step 94, Training Loss: 71.1709\n",
      "Epoch 17, Step 95, Training Loss: 42.6213\n",
      "Epoch 17, Step 96, Training Loss: 52.1664\n",
      "Epoch 17, Step 97, Training Loss: 42.5411\n",
      "Epoch 17, Step 98, Training Loss: 77.5469\n",
      "Epoch 17, Step 99, Training Loss: 70.4261\n",
      "Epoch 17, Step 100, Training Loss: 36.9376\n",
      "Epoch 17, Step 101, Training Loss: 55.0096\n",
      "Epoch 17, Step 102, Training Loss: 58.9500\n",
      "Epoch 17, Step 103, Training Loss: 43.7444\n",
      "Epoch 17, Step 104, Training Loss: 57.4580\n",
      "Epoch 17, Step 105, Training Loss: 43.2287\n",
      "Epoch 17, Step 106, Training Loss: 79.7169\n",
      "Epoch 17, Step 107, Training Loss: 70.4466\n",
      "Epoch 17, Step 108, Training Loss: 40.6804\n",
      "Epoch 17, Step 109, Training Loss: 32.4697\n",
      "Epoch 17, Step 110, Training Loss: 59.1507\n",
      "Epoch 17, Step 111, Training Loss: 54.4859\n",
      "Epoch 17, Step 112, Training Loss: 52.4620\n",
      "Epoch 17, Step 113, Training Loss: 57.8998\n",
      "Epoch 17, Step 114, Training Loss: 40.7889\n",
      "Epoch 17, Step 115, Training Loss: 72.9878\n",
      "Epoch 17, Step 116, Training Loss: 49.2517\n",
      "Epoch 17, Step 117, Training Loss: 65.8477\n",
      "Epoch 17, Step 118, Training Loss: 43.9349\n",
      "Epoch 17, Step 119, Training Loss: 58.4318\n",
      "Epoch 17, Step 120, Training Loss: 56.9481\n",
      "Epoch 17, Step 121, Training Loss: 85.1613\n",
      "Epoch 17, Step 122, Training Loss: 68.8822\n",
      "Epoch 17, Step 123, Training Loss: 52.2221\n",
      "Epoch 17, Step 124, Training Loss: 62.4724\n",
      "Epoch 17, Step 125, Training Loss: 55.4524\n",
      "Epoch 17, Step 126, Training Loss: 55.6773\n",
      "Epoch 17, Step 127, Training Loss: 51.3022\n",
      "Epoch 17, Step 128, Training Loss: 55.0449\n",
      "Epoch 17, Step 129, Training Loss: 64.6751\n",
      "Epoch 17, Step 130, Training Loss: 52.5314\n",
      "Epoch 17, Step 131, Training Loss: 49.8564\n",
      "Epoch 17, Step 132, Training Loss: 60.3937\n",
      "Epoch 17, Step 133, Training Loss: 68.2023\n",
      "Epoch 17, Step 134, Training Loss: 72.6366\n",
      "Epoch 17, Step 135, Training Loss: 53.7528\n",
      "Epoch 17, Step 136, Training Loss: 108.0656\n",
      "Epoch 17, Step 137, Training Loss: 49.6767\n",
      "Epoch 17, Step 138, Training Loss: 45.3528\n",
      "Epoch 17, Step 139, Training Loss: 58.7399\n",
      "Epoch 17, Step 140, Training Loss: 50.1817\n",
      "Epoch 17, Step 141, Training Loss: 69.3314\n",
      "Epoch 17, Step 142, Training Loss: 39.0342\n",
      "Epoch 17, Step 143, Training Loss: 45.0426\n",
      "Epoch 17, Step 144, Training Loss: 46.1356\n",
      "Epoch 17, Step 145, Training Loss: 45.7690\n",
      "Epoch 17, Step 146, Training Loss: 39.9052\n",
      "Epoch 17, Step 147, Training Loss: 46.7636\n",
      "Epoch 17, Step 148, Training Loss: 152.7771\n",
      "Epoch 17, Step 149, Training Loss: 76.4308\n",
      "Epoch 17, Step 150, Training Loss: 65.5010\n",
      "Epoch 17, Step 151, Training Loss: 50.6810\n",
      "Epoch 17, Step 152, Training Loss: 44.7887\n",
      "Epoch 17, Step 153, Training Loss: 38.3790\n",
      "Epoch 17, Step 154, Training Loss: 48.4262\n",
      "Epoch 17, Step 155, Training Loss: 72.3937\n",
      "Epoch 17, Step 156, Training Loss: 54.2948\n",
      "Epoch 17, Step 157, Training Loss: 47.6108\n",
      "Epoch 17, Step 158, Training Loss: 40.7089\n",
      "Epoch 17, Step 159, Training Loss: 73.0661\n",
      "Epoch 17, Step 160, Training Loss: 94.1848\n",
      "Epoch 17, Step 161, Training Loss: 60.8211\n",
      "Epoch 17, Step 162, Training Loss: 47.9099\n",
      "Epoch 17, Step 163, Training Loss: 41.6904\n",
      "Epoch 17, Step 164, Training Loss: 49.7126\n",
      "Epoch 17, Step 165, Training Loss: 49.5864\n",
      "Epoch 17, Step 166, Training Loss: 45.3322\n",
      "Epoch 17, Step 167, Training Loss: 47.2992\n",
      "Epoch 17, Step 168, Training Loss: 66.6890\n",
      "Epoch 17, Step 169, Training Loss: 41.1109\n",
      "Epoch 17, Step 170, Training Loss: 52.1970\n",
      "Epoch 17, Step 171, Training Loss: 36.0006\n",
      "Epoch 17, Step 172, Training Loss: 46.8884\n",
      "Epoch 17, Step 173, Training Loss: 47.9124\n",
      "Epoch 17, Step 174, Training Loss: 37.3491\n",
      "Epoch 17, Step 175, Training Loss: 55.8508\n",
      "Epoch 17, Step 176, Training Loss: 57.2025\n",
      "Epoch 17, Step 177, Training Loss: 77.7202\n",
      "Epoch 17, Step 178, Training Loss: 54.0124\n",
      "Epoch 17, Step 179, Training Loss: 40.5747\n",
      "Epoch 17, Step 180, Training Loss: 55.9746\n",
      "Epoch 17, Step 181, Training Loss: 46.0462\n",
      "Epoch 17, Step 182, Training Loss: 61.4911\n",
      "Epoch 17, Step 183, Training Loss: 48.7547\n",
      "Epoch 17, Step 184, Training Loss: 49.2475\n",
      "Epoch 17, Step 185, Training Loss: 43.8425\n",
      "Epoch 17, Step 186, Training Loss: 81.3905\n",
      "Epoch 17, Step 187, Training Loss: 39.1912\n",
      "Epoch 17, Step 188, Training Loss: 171.9462\n",
      "Epoch 17, Step 189, Training Loss: 55.5711\n",
      "Epoch 17, Step 190, Training Loss: 202.9584\n",
      "Epoch 17, Step 191, Training Loss: 32.6508\n",
      "Epoch 17, Step 192, Training Loss: 57.7628\n",
      "Epoch 17, Step 193, Training Loss: 53.5864\n",
      "Epoch 17, Step 194, Training Loss: 47.4466\n",
      "Epoch 17, Step 195, Training Loss: 55.1100\n",
      "Epoch 17, Step 196, Training Loss: 71.4186\n",
      "Epoch 17, Step 197, Training Loss: 51.3223\n",
      "Epoch 17, Step 198, Training Loss: 49.3981\n",
      "Epoch 17, Step 199, Training Loss: 54.1189\n",
      "Epoch 17, Step 200, Training Loss: 45.1801\n",
      "Epoch 17, Step 201, Training Loss: 43.1901\n",
      "Epoch 17, Step 202, Training Loss: 51.2501\n",
      "Epoch 17, Step 203, Training Loss: 69.8704\n",
      "Epoch 17, Step 204, Training Loss: 85.9674\n",
      "Epoch 17, Step 205, Training Loss: 56.4275\n",
      "Epoch 17, Step 206, Training Loss: 45.5669\n",
      "--- Epoch 17, Validation Loss: 55.6598 ---\n",
      "Epoch 18, Step 0, Training Loss: 37.0250\n",
      "Epoch 18, Step 1, Training Loss: 43.7733\n",
      "Epoch 18, Step 2, Training Loss: 44.3807\n",
      "Epoch 18, Step 3, Training Loss: 64.5666\n",
      "Epoch 18, Step 4, Training Loss: 72.7081\n",
      "Epoch 18, Step 5, Training Loss: 49.4596\n",
      "Epoch 18, Step 6, Training Loss: 47.3068\n",
      "Epoch 18, Step 7, Training Loss: 55.9578\n",
      "Epoch 18, Step 8, Training Loss: 38.9279\n",
      "Epoch 18, Step 9, Training Loss: 37.8529\n",
      "Epoch 18, Step 10, Training Loss: 60.7227\n",
      "Epoch 18, Step 11, Training Loss: 53.8171\n",
      "Epoch 18, Step 12, Training Loss: 65.5561\n",
      "Epoch 18, Step 13, Training Loss: 83.8244\n",
      "Epoch 18, Step 14, Training Loss: 48.7320\n",
      "Epoch 18, Step 15, Training Loss: 32.9669\n",
      "Epoch 18, Step 16, Training Loss: 38.2323\n",
      "Epoch 18, Step 17, Training Loss: 47.4924\n",
      "Epoch 18, Step 18, Training Loss: 38.5360\n",
      "Epoch 18, Step 19, Training Loss: 61.8384\n",
      "Epoch 18, Step 20, Training Loss: 47.5908\n",
      "Epoch 18, Step 21, Training Loss: 74.4699\n",
      "Epoch 18, Step 22, Training Loss: 73.4393\n",
      "Epoch 18, Step 23, Training Loss: 51.1716\n",
      "Epoch 18, Step 24, Training Loss: 48.2386\n",
      "Epoch 18, Step 25, Training Loss: 40.7307\n",
      "Epoch 18, Step 26, Training Loss: 53.4830\n",
      "Epoch 18, Step 27, Training Loss: 54.9446\n",
      "Epoch 18, Step 28, Training Loss: 49.2589\n",
      "Epoch 18, Step 29, Training Loss: 41.0820\n",
      "Epoch 18, Step 30, Training Loss: 37.1871\n",
      "Epoch 18, Step 31, Training Loss: 49.2728\n",
      "Epoch 18, Step 32, Training Loss: 44.3901\n",
      "Epoch 18, Step 33, Training Loss: 39.2588\n",
      "Epoch 18, Step 34, Training Loss: 46.2947\n",
      "Epoch 18, Step 35, Training Loss: 44.0792\n",
      "Epoch 18, Step 36, Training Loss: 56.5454\n",
      "Epoch 18, Step 37, Training Loss: 113.4839\n",
      "Epoch 18, Step 38, Training Loss: 67.0595\n",
      "Epoch 18, Step 39, Training Loss: 49.4264\n",
      "Epoch 18, Step 40, Training Loss: 57.3458\n",
      "Epoch 18, Step 41, Training Loss: 72.8127\n",
      "Epoch 18, Step 42, Training Loss: 52.9510\n",
      "Epoch 18, Step 43, Training Loss: 52.3681\n",
      "Epoch 18, Step 44, Training Loss: 51.2677\n",
      "Epoch 18, Step 45, Training Loss: 33.2682\n",
      "Epoch 18, Step 46, Training Loss: 30.6896\n",
      "Epoch 18, Step 47, Training Loss: 46.3927\n",
      "Epoch 18, Step 48, Training Loss: 39.6946\n",
      "Epoch 18, Step 49, Training Loss: 50.9574\n",
      "Epoch 18, Step 50, Training Loss: 43.3729\n",
      "Epoch 18, Step 51, Training Loss: 52.2233\n",
      "Epoch 18, Step 52, Training Loss: 38.1324\n",
      "Epoch 18, Step 53, Training Loss: 40.6344\n",
      "Epoch 18, Step 54, Training Loss: 52.3184\n",
      "Epoch 18, Step 55, Training Loss: 58.9728\n",
      "Epoch 18, Step 56, Training Loss: 77.6996\n",
      "Epoch 18, Step 57, Training Loss: 36.0090\n",
      "Epoch 18, Step 58, Training Loss: 57.0753\n",
      "Epoch 18, Step 59, Training Loss: 52.2930\n",
      "Epoch 18, Step 60, Training Loss: 93.5274\n",
      "Epoch 18, Step 61, Training Loss: 40.4459\n",
      "Epoch 18, Step 62, Training Loss: 45.5033\n",
      "Epoch 18, Step 63, Training Loss: 64.5259\n",
      "Epoch 18, Step 64, Training Loss: 52.8186\n",
      "Epoch 18, Step 65, Training Loss: 48.4814\n",
      "Epoch 18, Step 66, Training Loss: 52.2050\n",
      "Epoch 18, Step 67, Training Loss: 51.1374\n",
      "Epoch 18, Step 68, Training Loss: 43.7328\n",
      "Epoch 18, Step 69, Training Loss: 88.1446\n",
      "Epoch 18, Step 70, Training Loss: 58.4596\n",
      "Epoch 18, Step 71, Training Loss: 50.1318\n",
      "Epoch 18, Step 72, Training Loss: 61.0833\n",
      "Epoch 18, Step 73, Training Loss: 58.5918\n",
      "Epoch 18, Step 74, Training Loss: 50.0752\n",
      "Epoch 18, Step 75, Training Loss: 67.9557\n",
      "Epoch 18, Step 76, Training Loss: 82.6771\n",
      "Epoch 18, Step 77, Training Loss: 52.4972\n",
      "Epoch 18, Step 78, Training Loss: 31.6380\n",
      "Epoch 18, Step 79, Training Loss: 31.4226\n",
      "Epoch 18, Step 80, Training Loss: 62.4011\n",
      "Epoch 18, Step 81, Training Loss: 102.8168\n",
      "Epoch 18, Step 82, Training Loss: 34.0628\n",
      "Epoch 18, Step 83, Training Loss: 65.6056\n",
      "Epoch 18, Step 84, Training Loss: 93.6116\n",
      "Epoch 18, Step 85, Training Loss: 49.3908\n",
      "Epoch 18, Step 86, Training Loss: 34.2888\n",
      "Epoch 18, Step 87, Training Loss: 57.8078\n",
      "Epoch 18, Step 88, Training Loss: 67.5003\n",
      "Epoch 18, Step 89, Training Loss: 66.4691\n",
      "Epoch 18, Step 90, Training Loss: 44.3562\n",
      "Epoch 18, Step 91, Training Loss: 40.1488\n",
      "Epoch 18, Step 92, Training Loss: 62.4106\n",
      "Epoch 18, Step 93, Training Loss: 54.8170\n",
      "Epoch 18, Step 94, Training Loss: 66.5652\n",
      "Epoch 18, Step 95, Training Loss: 39.3113\n",
      "Epoch 18, Step 96, Training Loss: 47.2989\n",
      "Epoch 18, Step 97, Training Loss: 40.0436\n",
      "Epoch 18, Step 98, Training Loss: 72.8810\n",
      "Epoch 18, Step 99, Training Loss: 68.4732\n",
      "Epoch 18, Step 100, Training Loss: 37.3502\n",
      "Epoch 18, Step 101, Training Loss: 51.5190\n",
      "Epoch 18, Step 102, Training Loss: 52.9994\n",
      "Epoch 18, Step 103, Training Loss: 39.1035\n",
      "Epoch 18, Step 104, Training Loss: 51.5925\n",
      "Epoch 18, Step 105, Training Loss: 43.3150\n",
      "Epoch 18, Step 106, Training Loss: 76.6727\n",
      "Epoch 18, Step 107, Training Loss: 67.2391\n",
      "Epoch 18, Step 108, Training Loss: 38.3505\n",
      "Epoch 18, Step 109, Training Loss: 29.2610\n",
      "Epoch 18, Step 110, Training Loss: 58.9655\n",
      "Epoch 18, Step 111, Training Loss: 53.5911\n",
      "Epoch 18, Step 112, Training Loss: 49.2042\n",
      "Epoch 18, Step 113, Training Loss: 54.0962\n",
      "Epoch 18, Step 114, Training Loss: 39.0535\n",
      "Epoch 18, Step 115, Training Loss: 70.5886\n",
      "Epoch 18, Step 116, Training Loss: 46.3470\n",
      "Epoch 18, Step 117, Training Loss: 62.3358\n",
      "Epoch 18, Step 118, Training Loss: 42.0320\n",
      "Epoch 18, Step 119, Training Loss: 56.9179\n",
      "Epoch 18, Step 120, Training Loss: 55.2459\n",
      "Epoch 18, Step 121, Training Loss: 78.7348\n",
      "Epoch 18, Step 122, Training Loss: 66.6915\n",
      "Epoch 18, Step 123, Training Loss: 47.6461\n",
      "Epoch 18, Step 124, Training Loss: 57.3151\n",
      "Epoch 18, Step 125, Training Loss: 51.9375\n",
      "Epoch 18, Step 126, Training Loss: 53.9670\n",
      "Epoch 18, Step 127, Training Loss: 48.5601\n",
      "Epoch 18, Step 128, Training Loss: 52.5481\n",
      "Epoch 18, Step 129, Training Loss: 60.3308\n",
      "Epoch 18, Step 130, Training Loss: 51.5715\n",
      "Epoch 18, Step 131, Training Loss: 45.7168\n",
      "Epoch 18, Step 132, Training Loss: 57.1810\n",
      "Epoch 18, Step 133, Training Loss: 67.3701\n",
      "Epoch 18, Step 134, Training Loss: 66.1403\n",
      "Epoch 18, Step 135, Training Loss: 49.7960\n",
      "Epoch 18, Step 136, Training Loss: 104.9994\n",
      "Epoch 18, Step 137, Training Loss: 46.8083\n",
      "Epoch 18, Step 138, Training Loss: 42.4306\n",
      "Epoch 18, Step 139, Training Loss: 56.1794\n",
      "Epoch 18, Step 140, Training Loss: 46.3713\n",
      "Epoch 18, Step 141, Training Loss: 67.8195\n",
      "Epoch 18, Step 142, Training Loss: 39.5045\n",
      "Epoch 18, Step 143, Training Loss: 43.0185\n",
      "Epoch 18, Step 144, Training Loss: 45.0730\n",
      "Epoch 18, Step 145, Training Loss: 42.1416\n",
      "Epoch 18, Step 146, Training Loss: 39.3615\n",
      "Epoch 18, Step 147, Training Loss: 41.7543\n",
      "Epoch 18, Step 148, Training Loss: 150.6699\n",
      "Epoch 18, Step 149, Training Loss: 74.9707\n",
      "Epoch 18, Step 150, Training Loss: 66.0186\n",
      "Epoch 18, Step 151, Training Loss: 51.1130\n",
      "Epoch 18, Step 152, Training Loss: 42.5175\n",
      "Epoch 18, Step 153, Training Loss: 38.6210\n",
      "Epoch 18, Step 154, Training Loss: 46.0569\n",
      "Epoch 18, Step 155, Training Loss: 71.5078\n",
      "Epoch 18, Step 156, Training Loss: 51.6237\n",
      "Epoch 18, Step 157, Training Loss: 46.8447\n",
      "Epoch 18, Step 158, Training Loss: 39.4321\n",
      "Epoch 18, Step 159, Training Loss: 73.3055\n",
      "Epoch 18, Step 160, Training Loss: 91.0764\n",
      "Epoch 18, Step 161, Training Loss: 59.0798\n",
      "Epoch 18, Step 162, Training Loss: 45.3856\n",
      "Epoch 18, Step 163, Training Loss: 38.3324\n",
      "Epoch 18, Step 164, Training Loss: 46.1450\n",
      "Epoch 18, Step 165, Training Loss: 49.0038\n",
      "Epoch 18, Step 166, Training Loss: 42.9427\n",
      "Epoch 18, Step 167, Training Loss: 45.6720\n",
      "Epoch 18, Step 168, Training Loss: 67.3508\n",
      "Epoch 18, Step 169, Training Loss: 38.0971\n",
      "Epoch 18, Step 170, Training Loss: 48.7066\n",
      "Epoch 18, Step 171, Training Loss: 34.5732\n",
      "Epoch 18, Step 172, Training Loss: 45.7509\n",
      "Epoch 18, Step 173, Training Loss: 45.1165\n",
      "Epoch 18, Step 174, Training Loss: 36.0686\n",
      "Epoch 18, Step 175, Training Loss: 50.1002\n",
      "Epoch 18, Step 176, Training Loss: 57.5311\n",
      "Epoch 18, Step 177, Training Loss: 71.2428\n",
      "Epoch 18, Step 178, Training Loss: 44.6184\n",
      "Epoch 18, Step 179, Training Loss: 37.9629\n",
      "Epoch 18, Step 180, Training Loss: 52.7597\n",
      "Epoch 18, Step 181, Training Loss: 44.1874\n",
      "Epoch 18, Step 182, Training Loss: 60.0426\n",
      "Epoch 18, Step 183, Training Loss: 45.4538\n",
      "Epoch 18, Step 184, Training Loss: 45.8996\n",
      "Epoch 18, Step 185, Training Loss: 42.5820\n",
      "Epoch 18, Step 186, Training Loss: 77.2520\n",
      "Epoch 18, Step 187, Training Loss: 37.0030\n",
      "Epoch 18, Step 188, Training Loss: 136.6129\n",
      "Epoch 18, Step 189, Training Loss: 53.2712\n",
      "Epoch 18, Step 190, Training Loss: 193.5755\n",
      "Epoch 18, Step 191, Training Loss: 32.8466\n",
      "Epoch 18, Step 192, Training Loss: 52.8456\n",
      "Epoch 18, Step 193, Training Loss: 53.6138\n",
      "Epoch 18, Step 194, Training Loss: 44.7049\n",
      "Epoch 18, Step 195, Training Loss: 48.9609\n",
      "Epoch 18, Step 196, Training Loss: 66.5463\n",
      "Epoch 18, Step 197, Training Loss: 46.6438\n",
      "Epoch 18, Step 198, Training Loss: 48.0810\n",
      "Epoch 18, Step 199, Training Loss: 52.3233\n",
      "Epoch 18, Step 200, Training Loss: 45.9129\n",
      "Epoch 18, Step 201, Training Loss: 40.8215\n",
      "Epoch 18, Step 202, Training Loss: 48.4936\n",
      "Epoch 18, Step 203, Training Loss: 66.5815\n",
      "Epoch 18, Step 204, Training Loss: 77.4956\n",
      "Epoch 18, Step 205, Training Loss: 52.5151\n",
      "Epoch 18, Step 206, Training Loss: 45.4207\n",
      "--- Epoch 18, Validation Loss: 52.0087 ---\n",
      "Epoch 19, Step 0, Training Loss: 37.7422\n",
      "Epoch 19, Step 1, Training Loss: 41.5150\n",
      "Epoch 19, Step 2, Training Loss: 42.3025\n",
      "Epoch 19, Step 3, Training Loss: 64.1218\n",
      "Epoch 19, Step 4, Training Loss: 70.6084\n",
      "Epoch 19, Step 5, Training Loss: 49.5450\n",
      "Epoch 19, Step 6, Training Loss: 46.9274\n",
      "Epoch 19, Step 7, Training Loss: 54.3095\n",
      "Epoch 19, Step 8, Training Loss: 37.2464\n",
      "Epoch 19, Step 9, Training Loss: 39.0474\n",
      "Epoch 19, Step 10, Training Loss: 63.1895\n",
      "Epoch 19, Step 11, Training Loss: 53.3191\n",
      "Epoch 19, Step 12, Training Loss: 63.0654\n",
      "Epoch 19, Step 13, Training Loss: 88.3389\n",
      "Epoch 19, Step 14, Training Loss: 45.1071\n",
      "Epoch 19, Step 15, Training Loss: 31.1199\n",
      "Epoch 19, Step 16, Training Loss: 39.4631\n",
      "Epoch 19, Step 17, Training Loss: 47.3137\n",
      "Epoch 19, Step 18, Training Loss: 36.1176\n",
      "Epoch 19, Step 19, Training Loss: 58.4371\n",
      "Epoch 19, Step 20, Training Loss: 46.1132\n",
      "Epoch 19, Step 21, Training Loss: 70.7407\n",
      "Epoch 19, Step 22, Training Loss: 72.6614\n",
      "Epoch 19, Step 23, Training Loss: 55.8178\n",
      "Epoch 19, Step 24, Training Loss: 47.4750\n",
      "Epoch 19, Step 25, Training Loss: 39.6238\n",
      "Epoch 19, Step 26, Training Loss: 53.8382\n",
      "Epoch 19, Step 27, Training Loss: 55.4077\n",
      "Epoch 19, Step 28, Training Loss: 46.6757\n",
      "Epoch 19, Step 29, Training Loss: 38.3195\n",
      "Epoch 19, Step 30, Training Loss: 33.8255\n",
      "Epoch 19, Step 31, Training Loss: 47.7601\n",
      "Epoch 19, Step 32, Training Loss: 43.2551\n",
      "Epoch 19, Step 33, Training Loss: 40.5219\n",
      "Epoch 19, Step 34, Training Loss: 43.6812\n",
      "Epoch 19, Step 35, Training Loss: 42.3987\n",
      "Epoch 19, Step 36, Training Loss: 54.1189\n",
      "Epoch 19, Step 37, Training Loss: 103.5913\n",
      "Epoch 19, Step 38, Training Loss: 62.3171\n",
      "Epoch 19, Step 39, Training Loss: 48.0362\n",
      "Epoch 19, Step 40, Training Loss: 55.8300\n",
      "Epoch 19, Step 41, Training Loss: 69.7773\n",
      "Epoch 19, Step 42, Training Loss: 51.5675\n",
      "Epoch 19, Step 43, Training Loss: 43.9805\n",
      "Epoch 19, Step 44, Training Loss: 51.3080\n",
      "Epoch 19, Step 45, Training Loss: 31.4377\n",
      "Epoch 19, Step 46, Training Loss: 29.9453\n",
      "Epoch 19, Step 47, Training Loss: 47.2049\n",
      "Epoch 19, Step 48, Training Loss: 36.9721\n",
      "Epoch 19, Step 49, Training Loss: 48.0512\n",
      "Epoch 19, Step 50, Training Loss: 42.5162\n",
      "Epoch 19, Step 51, Training Loss: 51.4062\n",
      "Epoch 19, Step 52, Training Loss: 38.0781\n",
      "Epoch 19, Step 53, Training Loss: 40.2246\n",
      "Epoch 19, Step 54, Training Loss: 53.0978\n",
      "Epoch 19, Step 55, Training Loss: 56.1262\n",
      "Epoch 19, Step 56, Training Loss: 72.9466\n",
      "Epoch 19, Step 57, Training Loss: 33.0306\n",
      "Epoch 19, Step 58, Training Loss: 55.8519\n",
      "Epoch 19, Step 59, Training Loss: 50.5146\n",
      "Epoch 19, Step 60, Training Loss: 90.9181\n",
      "Epoch 19, Step 61, Training Loss: 40.3569\n",
      "Epoch 19, Step 62, Training Loss: 43.3036\n",
      "Epoch 19, Step 63, Training Loss: 62.9061\n",
      "Epoch 19, Step 64, Training Loss: 56.2182\n",
      "Epoch 19, Step 65, Training Loss: 46.6530\n",
      "Epoch 19, Step 66, Training Loss: 50.1758\n",
      "Epoch 19, Step 67, Training Loss: 48.9624\n",
      "Epoch 19, Step 68, Training Loss: 41.5981\n",
      "Epoch 19, Step 69, Training Loss: 85.7012\n",
      "Epoch 19, Step 70, Training Loss: 56.9266\n",
      "Epoch 19, Step 71, Training Loss: 48.6753\n",
      "Epoch 19, Step 72, Training Loss: 61.3245\n",
      "Epoch 19, Step 73, Training Loss: 57.0919\n",
      "Epoch 19, Step 74, Training Loss: 48.1318\n",
      "Epoch 19, Step 75, Training Loss: 68.7740\n",
      "Epoch 19, Step 76, Training Loss: 78.3941\n",
      "Epoch 19, Step 77, Training Loss: 51.4715\n",
      "Epoch 19, Step 78, Training Loss: 30.9661\n",
      "Epoch 19, Step 79, Training Loss: 32.1389\n",
      "Epoch 19, Step 80, Training Loss: 63.1012\n",
      "Epoch 19, Step 81, Training Loss: 97.9861\n",
      "Epoch 19, Step 82, Training Loss: 32.3489\n",
      "Epoch 19, Step 83, Training Loss: 67.0591\n",
      "Epoch 19, Step 84, Training Loss: 93.9353\n",
      "Epoch 19, Step 85, Training Loss: 48.6994\n",
      "Epoch 19, Step 86, Training Loss: 34.4154\n",
      "Epoch 19, Step 87, Training Loss: 57.7173\n",
      "Epoch 19, Step 88, Training Loss: 57.5770\n",
      "Epoch 19, Step 89, Training Loss: 62.6991\n",
      "Epoch 19, Step 90, Training Loss: 45.8834\n",
      "Epoch 19, Step 91, Training Loss: 38.9106\n",
      "Epoch 19, Step 92, Training Loss: 61.1276\n",
      "Epoch 19, Step 93, Training Loss: 52.8490\n",
      "Epoch 19, Step 94, Training Loss: 67.7270\n",
      "Epoch 19, Step 95, Training Loss: 38.9366\n",
      "Epoch 19, Step 96, Training Loss: 44.9001\n",
      "Epoch 19, Step 97, Training Loss: 36.6107\n",
      "Epoch 19, Step 98, Training Loss: 72.0096\n",
      "Epoch 19, Step 99, Training Loss: 65.4729\n",
      "Epoch 19, Step 100, Training Loss: 34.8182\n",
      "Epoch 19, Step 101, Training Loss: 48.5129\n",
      "Epoch 19, Step 102, Training Loss: 47.8649\n",
      "Epoch 19, Step 103, Training Loss: 38.5996\n",
      "Epoch 19, Step 104, Training Loss: 50.0427\n",
      "Epoch 19, Step 105, Training Loss: 41.7177\n",
      "Epoch 19, Step 106, Training Loss: 73.7058\n",
      "Epoch 19, Step 107, Training Loss: 64.3035\n",
      "Epoch 19, Step 108, Training Loss: 37.1207\n",
      "Epoch 19, Step 109, Training Loss: 30.8084\n",
      "Epoch 19, Step 110, Training Loss: 53.9075\n",
      "Epoch 19, Step 111, Training Loss: 50.1633\n",
      "Epoch 19, Step 112, Training Loss: 45.6834\n",
      "Epoch 19, Step 113, Training Loss: 52.1880\n",
      "Epoch 19, Step 114, Training Loss: 38.7368\n",
      "Epoch 19, Step 115, Training Loss: 67.7686\n",
      "Epoch 19, Step 116, Training Loss: 45.4145\n",
      "Epoch 19, Step 117, Training Loss: 59.5729\n",
      "Epoch 19, Step 118, Training Loss: 42.7630\n",
      "Epoch 19, Step 119, Training Loss: 56.1541\n",
      "Epoch 19, Step 120, Training Loss: 54.0455\n",
      "Epoch 19, Step 121, Training Loss: 76.9233\n",
      "Epoch 19, Step 122, Training Loss: 65.7369\n",
      "Epoch 19, Step 123, Training Loss: 48.7957\n",
      "Epoch 19, Step 124, Training Loss: 58.2569\n",
      "Epoch 19, Step 125, Training Loss: 50.1255\n",
      "Epoch 19, Step 126, Training Loss: 52.8231\n",
      "Epoch 19, Step 127, Training Loss: 47.0166\n",
      "Epoch 19, Step 128, Training Loss: 49.4154\n",
      "Epoch 19, Step 129, Training Loss: 60.4944\n",
      "Epoch 19, Step 130, Training Loss: 50.9098\n",
      "Epoch 19, Step 131, Training Loss: 45.4344\n",
      "Epoch 19, Step 132, Training Loss: 56.3797\n",
      "Epoch 19, Step 133, Training Loss: 66.4323\n",
      "Epoch 19, Step 134, Training Loss: 66.3373\n",
      "Epoch 19, Step 135, Training Loss: 49.7652\n",
      "Epoch 19, Step 136, Training Loss: 110.0036\n",
      "Epoch 19, Step 137, Training Loss: 45.1453\n",
      "Epoch 19, Step 138, Training Loss: 40.7915\n",
      "Epoch 19, Step 139, Training Loss: 55.5049\n",
      "Epoch 19, Step 140, Training Loss: 47.0259\n",
      "Epoch 19, Step 141, Training Loss: 68.8399\n",
      "Epoch 19, Step 142, Training Loss: 39.2469\n",
      "Epoch 19, Step 143, Training Loss: 42.4407\n",
      "Epoch 19, Step 144, Training Loss: 46.0301\n",
      "Epoch 19, Step 145, Training Loss: 40.8597\n",
      "Epoch 19, Step 146, Training Loss: 38.6245\n",
      "Epoch 19, Step 147, Training Loss: 41.4470\n",
      "Epoch 19, Step 148, Training Loss: 147.1886\n",
      "Epoch 19, Step 149, Training Loss: 72.1723\n",
      "Epoch 19, Step 150, Training Loss: 65.4389\n",
      "Epoch 19, Step 151, Training Loss: 51.3059\n",
      "Epoch 19, Step 152, Training Loss: 42.1350\n",
      "Epoch 19, Step 153, Training Loss: 37.1920\n",
      "Epoch 19, Step 154, Training Loss: 47.2570\n",
      "Epoch 19, Step 155, Training Loss: 70.5165\n",
      "Epoch 19, Step 156, Training Loss: 50.9053\n",
      "Epoch 19, Step 157, Training Loss: 44.6733\n",
      "Epoch 19, Step 158, Training Loss: 37.2881\n",
      "Epoch 19, Step 159, Training Loss: 70.6271\n",
      "Epoch 19, Step 160, Training Loss: 90.2898\n",
      "Epoch 19, Step 161, Training Loss: 57.6916\n",
      "Epoch 19, Step 162, Training Loss: 42.0323\n",
      "Epoch 19, Step 163, Training Loss: 36.0684\n",
      "Epoch 19, Step 164, Training Loss: 48.9036\n",
      "Epoch 19, Step 165, Training Loss: 50.1299\n",
      "Epoch 19, Step 166, Training Loss: 42.4857\n",
      "Epoch 19, Step 167, Training Loss: 42.2497\n",
      "Epoch 19, Step 168, Training Loss: 66.2780\n",
      "Epoch 19, Step 169, Training Loss: 39.6330\n",
      "Epoch 19, Step 170, Training Loss: 49.2437\n",
      "Epoch 19, Step 171, Training Loss: 33.6634\n",
      "Epoch 19, Step 172, Training Loss: 46.0880\n",
      "Epoch 19, Step 173, Training Loss: 43.2770\n",
      "Epoch 19, Step 174, Training Loss: 37.1654\n",
      "Epoch 19, Step 175, Training Loss: 47.1110\n",
      "Epoch 19, Step 176, Training Loss: 56.6414\n",
      "Epoch 19, Step 177, Training Loss: 69.0456\n",
      "Epoch 19, Step 178, Training Loss: 46.9181\n",
      "Epoch 19, Step 179, Training Loss: 38.8546\n",
      "Epoch 19, Step 180, Training Loss: 52.1875\n",
      "Epoch 19, Step 181, Training Loss: 43.6495\n",
      "Epoch 19, Step 182, Training Loss: 59.0665\n",
      "Epoch 19, Step 183, Training Loss: 45.6456\n",
      "Epoch 19, Step 184, Training Loss: 43.8363\n",
      "Epoch 19, Step 185, Training Loss: 43.9365\n",
      "Epoch 19, Step 186, Training Loss: 76.8556\n",
      "Epoch 19, Step 187, Training Loss: 36.3564\n",
      "Epoch 19, Step 188, Training Loss: 136.3173\n",
      "Epoch 19, Step 189, Training Loss: 54.4514\n",
      "Epoch 19, Step 190, Training Loss: 197.1043\n",
      "Epoch 19, Step 191, Training Loss: 30.8613\n",
      "Epoch 19, Step 192, Training Loss: 51.5701\n",
      "Epoch 19, Step 193, Training Loss: 49.1022\n",
      "Epoch 19, Step 194, Training Loss: 45.9507\n",
      "Epoch 19, Step 195, Training Loss: 46.9332\n",
      "Epoch 19, Step 196, Training Loss: 67.1382\n",
      "Epoch 19, Step 197, Training Loss: 47.0648\n",
      "Epoch 19, Step 198, Training Loss: 46.0234\n",
      "Epoch 19, Step 199, Training Loss: 49.8255\n",
      "Epoch 19, Step 200, Training Loss: 46.4324\n",
      "Epoch 19, Step 201, Training Loss: 40.4008\n",
      "Epoch 19, Step 202, Training Loss: 49.2902\n",
      "Epoch 19, Step 203, Training Loss: 66.5242\n",
      "Epoch 19, Step 204, Training Loss: 75.1500\n",
      "Epoch 19, Step 205, Training Loss: 51.5038\n",
      "Epoch 19, Step 206, Training Loss: 46.1734\n",
      "--- Epoch 19, Validation Loss: 51.6096 ---\n",
      "Epoch 20, Step 0, Training Loss: 36.5455\n",
      "Epoch 20, Step 1, Training Loss: 41.9512\n",
      "Epoch 20, Step 2, Training Loss: 42.6025\n",
      "Epoch 20, Step 3, Training Loss: 64.1269\n",
      "Epoch 20, Step 4, Training Loss: 72.4920\n",
      "Epoch 20, Step 5, Training Loss: 47.4077\n",
      "Epoch 20, Step 6, Training Loss: 45.2469\n",
      "Epoch 20, Step 7, Training Loss: 53.6673\n",
      "Epoch 20, Step 8, Training Loss: 38.7453\n",
      "Epoch 20, Step 9, Training Loss: 38.8672\n",
      "Epoch 20, Step 10, Training Loss: 59.2358\n",
      "Epoch 20, Step 11, Training Loss: 49.6682\n",
      "Epoch 20, Step 12, Training Loss: 61.4677\n",
      "Epoch 20, Step 13, Training Loss: 82.2699\n",
      "Epoch 20, Step 14, Training Loss: 45.6074\n",
      "Epoch 20, Step 15, Training Loss: 31.3042\n",
      "Epoch 20, Step 16, Training Loss: 36.4663\n",
      "Epoch 20, Step 17, Training Loss: 44.9888\n",
      "Epoch 20, Step 18, Training Loss: 35.9251\n",
      "Epoch 20, Step 19, Training Loss: 58.4224\n",
      "Epoch 20, Step 20, Training Loss: 44.3308\n",
      "Epoch 20, Step 21, Training Loss: 70.1359\n",
      "Epoch 20, Step 22, Training Loss: 71.0451\n",
      "Epoch 20, Step 23, Training Loss: 50.5043\n",
      "Epoch 20, Step 24, Training Loss: 44.3635\n",
      "Epoch 20, Step 25, Training Loss: 37.7001\n",
      "Epoch 20, Step 26, Training Loss: 56.6747\n",
      "Epoch 20, Step 27, Training Loss: 51.7232\n",
      "Epoch 20, Step 28, Training Loss: 45.2553\n",
      "Epoch 20, Step 29, Training Loss: 38.3306\n",
      "Epoch 20, Step 30, Training Loss: 32.6015\n",
      "Epoch 20, Step 31, Training Loss: 47.1261\n",
      "Epoch 20, Step 32, Training Loss: 41.6518\n",
      "Epoch 20, Step 33, Training Loss: 38.2199\n",
      "Epoch 20, Step 34, Training Loss: 42.6665\n",
      "Epoch 20, Step 35, Training Loss: 42.2068\n",
      "Epoch 20, Step 36, Training Loss: 52.8439\n",
      "Epoch 20, Step 37, Training Loss: 101.7092\n",
      "Epoch 20, Step 38, Training Loss: 59.6517\n",
      "Epoch 20, Step 39, Training Loss: 45.4433\n",
      "Epoch 20, Step 40, Training Loss: 56.0860\n",
      "Epoch 20, Step 41, Training Loss: 68.7576\n",
      "Epoch 20, Step 42, Training Loss: 49.8667\n",
      "Epoch 20, Step 43, Training Loss: 46.0915\n",
      "Epoch 20, Step 44, Training Loss: 53.0525\n",
      "Epoch 20, Step 45, Training Loss: 31.5872\n",
      "Epoch 20, Step 46, Training Loss: 30.7704\n",
      "Epoch 20, Step 47, Training Loss: 45.8350\n",
      "Epoch 20, Step 48, Training Loss: 37.5872\n",
      "Epoch 20, Step 49, Training Loss: 47.9366\n",
      "Epoch 20, Step 50, Training Loss: 41.6692\n",
      "Epoch 20, Step 51, Training Loss: 51.0986\n",
      "Epoch 20, Step 52, Training Loss: 38.9915\n",
      "Epoch 20, Step 53, Training Loss: 38.5179\n",
      "Epoch 20, Step 54, Training Loss: 51.5402\n",
      "Epoch 20, Step 55, Training Loss: 53.6798\n",
      "Epoch 20, Step 56, Training Loss: 71.8425\n",
      "Epoch 20, Step 57, Training Loss: 35.1233\n",
      "Epoch 20, Step 58, Training Loss: 52.8601\n",
      "Epoch 20, Step 59, Training Loss: 47.3144\n",
      "Epoch 20, Step 60, Training Loss: 89.5644\n",
      "Epoch 20, Step 61, Training Loss: 38.7843\n",
      "Epoch 20, Step 62, Training Loss: 44.6568\n",
      "Epoch 20, Step 63, Training Loss: 63.5527\n",
      "Epoch 20, Step 64, Training Loss: 51.2625\n",
      "Epoch 20, Step 65, Training Loss: 47.3790\n",
      "Epoch 20, Step 66, Training Loss: 50.6619\n",
      "Epoch 20, Step 67, Training Loss: 46.0939\n",
      "Epoch 20, Step 68, Training Loss: 40.1260\n",
      "Epoch 20, Step 69, Training Loss: 82.1141\n",
      "Epoch 20, Step 70, Training Loss: 56.2144\n",
      "Epoch 20, Step 71, Training Loss: 48.1584\n",
      "Epoch 20, Step 72, Training Loss: 61.2023\n",
      "Epoch 20, Step 73, Training Loss: 55.9788\n",
      "Epoch 20, Step 74, Training Loss: 47.3807\n",
      "Epoch 20, Step 75, Training Loss: 68.1206\n",
      "Epoch 20, Step 76, Training Loss: 79.0463\n",
      "Epoch 20, Step 77, Training Loss: 50.2165\n",
      "Epoch 20, Step 78, Training Loss: 31.4922\n",
      "Epoch 20, Step 79, Training Loss: 33.1232\n",
      "Epoch 20, Step 80, Training Loss: 61.3488\n",
      "Epoch 20, Step 81, Training Loss: 94.1950\n",
      "Epoch 20, Step 82, Training Loss: 35.1789\n",
      "Epoch 20, Step 83, Training Loss: 63.3302\n",
      "Epoch 20, Step 84, Training Loss: 92.8164\n",
      "Epoch 20, Step 85, Training Loss: 47.4469\n",
      "Epoch 20, Step 86, Training Loss: 35.4485\n",
      "Epoch 20, Step 87, Training Loss: 60.2741\n",
      "Epoch 20, Step 88, Training Loss: 57.9817\n",
      "Epoch 20, Step 89, Training Loss: 64.4201\n",
      "Epoch 20, Step 90, Training Loss: 45.4197\n",
      "Epoch 20, Step 91, Training Loss: 34.1311\n",
      "Epoch 20, Step 92, Training Loss: 60.6281\n",
      "Epoch 20, Step 93, Training Loss: 54.3580\n",
      "Epoch 20, Step 94, Training Loss: 67.1314\n",
      "Epoch 20, Step 95, Training Loss: 38.1856\n",
      "Epoch 20, Step 96, Training Loss: 45.1998\n",
      "Epoch 20, Step 97, Training Loss: 37.3506\n",
      "Epoch 20, Step 98, Training Loss: 69.5813\n",
      "Epoch 20, Step 99, Training Loss: 64.7259\n",
      "Epoch 20, Step 100, Training Loss: 34.7927\n",
      "Epoch 20, Step 101, Training Loss: 48.4446\n",
      "Epoch 20, Step 102, Training Loss: 48.2655\n",
      "Epoch 20, Step 103, Training Loss: 38.3544\n",
      "Epoch 20, Step 104, Training Loss: 49.6745\n",
      "Epoch 20, Step 105, Training Loss: 40.6402\n",
      "Epoch 20, Step 106, Training Loss: 73.5368\n",
      "Epoch 20, Step 107, Training Loss: 63.2749\n",
      "Epoch 20, Step 108, Training Loss: 37.4590\n",
      "Epoch 20, Step 109, Training Loss: 28.8389\n",
      "Epoch 20, Step 110, Training Loss: 54.3542\n",
      "Epoch 20, Step 111, Training Loss: 51.2597\n",
      "Epoch 20, Step 112, Training Loss: 47.0184\n",
      "Epoch 20, Step 113, Training Loss: 52.8613\n",
      "Epoch 20, Step 114, Training Loss: 37.5628\n",
      "Epoch 20, Step 115, Training Loss: 67.6345\n",
      "Epoch 20, Step 116, Training Loss: 45.1261\n",
      "Epoch 20, Step 117, Training Loss: 59.2719\n",
      "Epoch 20, Step 118, Training Loss: 40.3388\n",
      "Epoch 20, Step 119, Training Loss: 55.4380\n",
      "Epoch 20, Step 120, Training Loss: 50.1934\n",
      "Epoch 20, Step 121, Training Loss: 74.1224\n",
      "Epoch 20, Step 122, Training Loss: 66.9447\n",
      "Epoch 20, Step 123, Training Loss: 45.7702\n",
      "Epoch 20, Step 124, Training Loss: 48.4101\n",
      "Epoch 20, Step 125, Training Loss: 51.2738\n",
      "Epoch 20, Step 126, Training Loss: 52.6017\n",
      "Epoch 20, Step 127, Training Loss: 48.6469\n",
      "Epoch 20, Step 128, Training Loss: 50.5908\n",
      "Epoch 20, Step 129, Training Loss: 58.4509\n",
      "Epoch 20, Step 130, Training Loss: 48.9798\n",
      "Epoch 20, Step 131, Training Loss: 44.5528\n",
      "Epoch 20, Step 132, Training Loss: 54.0228\n",
      "Epoch 20, Step 133, Training Loss: 65.1863\n",
      "Epoch 20, Step 134, Training Loss: 62.2840\n",
      "Epoch 20, Step 135, Training Loss: 49.3862\n",
      "Epoch 20, Step 136, Training Loss: 104.8681\n",
      "Epoch 20, Step 137, Training Loss: 45.8353\n",
      "Epoch 20, Step 138, Training Loss: 39.6853\n",
      "Epoch 20, Step 139, Training Loss: 56.1382\n",
      "Epoch 20, Step 140, Training Loss: 47.5320\n",
      "Epoch 20, Step 141, Training Loss: 66.9827\n",
      "Epoch 20, Step 142, Training Loss: 38.1252\n",
      "Epoch 20, Step 143, Training Loss: 40.7238\n",
      "Epoch 20, Step 144, Training Loss: 44.4460\n",
      "Epoch 20, Step 145, Training Loss: 39.9527\n",
      "Epoch 20, Step 146, Training Loss: 39.4872\n",
      "Epoch 20, Step 147, Training Loss: 39.1593\n",
      "Epoch 20, Step 148, Training Loss: 151.1978\n",
      "Epoch 20, Step 149, Training Loss: 72.3068\n",
      "Epoch 20, Step 150, Training Loss: 64.7883\n",
      "Epoch 20, Step 151, Training Loss: 50.3577\n",
      "Epoch 20, Step 152, Training Loss: 41.6697\n",
      "Epoch 20, Step 153, Training Loss: 37.3563\n",
      "Epoch 20, Step 154, Training Loss: 45.1126\n",
      "Epoch 20, Step 155, Training Loss: 71.6863\n",
      "Epoch 20, Step 156, Training Loss: 51.8784\n",
      "Epoch 20, Step 157, Training Loss: 44.4078\n",
      "Epoch 20, Step 158, Training Loss: 36.9893\n",
      "Epoch 20, Step 159, Training Loss: 70.4758\n",
      "Epoch 20, Step 160, Training Loss: 89.0012\n",
      "Epoch 20, Step 161, Training Loss: 57.9026\n",
      "Epoch 20, Step 162, Training Loss: 41.9657\n",
      "Epoch 20, Step 163, Training Loss: 34.9364\n",
      "Epoch 20, Step 164, Training Loss: 48.3390\n",
      "Epoch 20, Step 165, Training Loss: 50.3245\n",
      "Epoch 20, Step 166, Training Loss: 42.3895\n",
      "Epoch 20, Step 167, Training Loss: 42.6854\n",
      "Epoch 20, Step 168, Training Loss: 67.5817\n",
      "Epoch 20, Step 169, Training Loss: 36.9378\n",
      "Epoch 20, Step 170, Training Loss: 48.2089\n",
      "Epoch 20, Step 171, Training Loss: 34.8807\n",
      "Epoch 20, Step 172, Training Loss: 46.2638\n",
      "Epoch 20, Step 173, Training Loss: 43.1703\n",
      "Epoch 20, Step 174, Training Loss: 36.1783\n",
      "Epoch 20, Step 175, Training Loss: 45.8965\n",
      "Epoch 20, Step 176, Training Loss: 55.2710\n",
      "Epoch 20, Step 177, Training Loss: 70.1211\n",
      "Epoch 20, Step 178, Training Loss: 43.7747\n",
      "Epoch 20, Step 179, Training Loss: 36.9697\n",
      "Epoch 20, Step 180, Training Loss: 53.2405\n",
      "Epoch 20, Step 181, Training Loss: 42.0747\n",
      "Epoch 20, Step 182, Training Loss: 57.0809\n",
      "Epoch 20, Step 183, Training Loss: 45.4298\n",
      "Epoch 20, Step 184, Training Loss: 43.4691\n",
      "Epoch 20, Step 185, Training Loss: 45.6897\n",
      "Epoch 20, Step 186, Training Loss: 75.8497\n",
      "Epoch 20, Step 187, Training Loss: 37.5386\n",
      "Epoch 20, Step 188, Training Loss: 141.9439\n",
      "Epoch 20, Step 189, Training Loss: 52.9691\n",
      "Epoch 20, Step 190, Training Loss: 192.2682\n",
      "Epoch 20, Step 191, Training Loss: 31.0071\n",
      "Epoch 20, Step 192, Training Loss: 50.9270\n",
      "Epoch 20, Step 193, Training Loss: 50.7040\n",
      "Epoch 20, Step 194, Training Loss: 41.9771\n",
      "Epoch 20, Step 195, Training Loss: 46.6643\n",
      "Epoch 20, Step 196, Training Loss: 64.6174\n",
      "Epoch 20, Step 197, Training Loss: 46.3969\n",
      "Epoch 20, Step 198, Training Loss: 47.5020\n",
      "Epoch 20, Step 199, Training Loss: 52.7640\n",
      "Epoch 20, Step 200, Training Loss: 45.7192\n",
      "Epoch 20, Step 201, Training Loss: 41.0093\n",
      "Epoch 20, Step 202, Training Loss: 50.0403\n",
      "Epoch 20, Step 203, Training Loss: 65.1856\n",
      "Epoch 20, Step 204, Training Loss: 75.8195\n",
      "Epoch 20, Step 205, Training Loss: 50.3399\n",
      "Epoch 20, Step 206, Training Loss: 44.2716\n",
      "--- Epoch 20, Validation Loss: 54.9275 ---\n",
      "Epoch 21, Step 0, Training Loss: 36.0792\n",
      "Epoch 21, Step 1, Training Loss: 39.6859\n",
      "Epoch 21, Step 2, Training Loss: 43.1962\n",
      "Epoch 21, Step 3, Training Loss: 61.6958\n",
      "Epoch 21, Step 4, Training Loss: 71.2442\n",
      "Epoch 21, Step 5, Training Loss: 48.7757\n",
      "Epoch 21, Step 6, Training Loss: 46.1978\n",
      "Epoch 21, Step 7, Training Loss: 50.0457\n",
      "Epoch 21, Step 8, Training Loss: 35.5953\n",
      "Epoch 21, Step 9, Training Loss: 38.0428\n",
      "Epoch 21, Step 10, Training Loss: 60.2644\n",
      "Epoch 21, Step 11, Training Loss: 50.9956\n",
      "Epoch 21, Step 12, Training Loss: 60.5139\n",
      "Epoch 21, Step 13, Training Loss: 81.7719\n",
      "Epoch 21, Step 14, Training Loss: 46.1875\n",
      "Epoch 21, Step 15, Training Loss: 30.6795\n",
      "Epoch 21, Step 16, Training Loss: 37.9194\n",
      "Epoch 21, Step 17, Training Loss: 43.8096\n",
      "Epoch 21, Step 18, Training Loss: 37.2030\n",
      "Epoch 21, Step 19, Training Loss: 56.7644\n",
      "Epoch 21, Step 20, Training Loss: 42.3242\n",
      "Epoch 21, Step 21, Training Loss: 73.5343\n",
      "Epoch 21, Step 22, Training Loss: 70.6542\n",
      "Epoch 21, Step 23, Training Loss: 47.8171\n",
      "Epoch 21, Step 24, Training Loss: 47.0635\n",
      "Epoch 21, Step 25, Training Loss: 40.6143\n",
      "Epoch 21, Step 26, Training Loss: 54.9128\n",
      "Epoch 21, Step 27, Training Loss: 51.4793\n",
      "Epoch 21, Step 28, Training Loss: 44.7142\n",
      "Epoch 21, Step 29, Training Loss: 37.5107\n",
      "Epoch 21, Step 30, Training Loss: 32.6583\n",
      "Epoch 21, Step 31, Training Loss: 47.3232\n",
      "Epoch 21, Step 32, Training Loss: 41.0431\n",
      "Epoch 21, Step 33, Training Loss: 39.4326\n",
      "Epoch 21, Step 34, Training Loss: 41.8433\n",
      "Epoch 21, Step 35, Training Loss: 41.5520\n",
      "Epoch 21, Step 36, Training Loss: 54.5779\n",
      "Epoch 21, Step 37, Training Loss: 102.2348\n",
      "Epoch 21, Step 38, Training Loss: 58.2670\n",
      "Epoch 21, Step 39, Training Loss: 46.2748\n",
      "Epoch 21, Step 40, Training Loss: 56.6352\n",
      "Epoch 21, Step 41, Training Loss: 68.2259\n",
      "Epoch 21, Step 42, Training Loss: 49.0910\n",
      "Epoch 21, Step 43, Training Loss: 46.4478\n",
      "Epoch 21, Step 44, Training Loss: 53.6278\n",
      "Epoch 21, Step 45, Training Loss: 31.5628\n",
      "Epoch 21, Step 46, Training Loss: 29.9967\n",
      "Epoch 21, Step 47, Training Loss: 44.8143\n",
      "Epoch 21, Step 48, Training Loss: 38.2505\n",
      "Epoch 21, Step 49, Training Loss: 46.0692\n",
      "Epoch 21, Step 50, Training Loss: 40.5246\n",
      "Epoch 21, Step 51, Training Loss: 50.3006\n",
      "Epoch 21, Step 52, Training Loss: 38.8995\n",
      "Epoch 21, Step 53, Training Loss: 39.5651\n",
      "Epoch 21, Step 54, Training Loss: 52.4958\n",
      "Epoch 21, Step 55, Training Loss: 52.6028\n",
      "Epoch 21, Step 56, Training Loss: 70.9888\n",
      "Epoch 21, Step 57, Training Loss: 33.0651\n",
      "Epoch 21, Step 58, Training Loss: 55.9479\n",
      "Epoch 21, Step 59, Training Loss: 47.3956\n",
      "Epoch 21, Step 60, Training Loss: 92.0173\n",
      "Epoch 21, Step 61, Training Loss: 40.8583\n",
      "Epoch 21, Step 62, Training Loss: 45.9814\n",
      "Epoch 21, Step 63, Training Loss: 63.2879\n",
      "Epoch 21, Step 64, Training Loss: 51.4228\n",
      "Epoch 21, Step 65, Training Loss: 46.3720\n",
      "Epoch 21, Step 66, Training Loss: 50.1591\n",
      "Epoch 21, Step 67, Training Loss: 44.4538\n",
      "Epoch 21, Step 68, Training Loss: 39.4200\n",
      "Epoch 21, Step 69, Training Loss: 86.0734\n",
      "Epoch 21, Step 70, Training Loss: 56.0076\n",
      "Epoch 21, Step 71, Training Loss: 48.6927\n",
      "Epoch 21, Step 72, Training Loss: 58.7173\n",
      "Epoch 21, Step 73, Training Loss: 56.7282\n",
      "Epoch 21, Step 74, Training Loss: 48.7550\n",
      "Epoch 21, Step 75, Training Loss: 69.4316\n",
      "Epoch 21, Step 76, Training Loss: 77.3175\n",
      "Epoch 21, Step 77, Training Loss: 49.5518\n",
      "Epoch 21, Step 78, Training Loss: 30.1932\n",
      "Epoch 21, Step 79, Training Loss: 31.0728\n",
      "Epoch 21, Step 80, Training Loss: 64.4575\n",
      "Epoch 21, Step 81, Training Loss: 94.3862\n",
      "Epoch 21, Step 82, Training Loss: 32.0275\n",
      "Epoch 21, Step 83, Training Loss: 66.5698\n",
      "Epoch 21, Step 84, Training Loss: 91.2198\n",
      "Epoch 21, Step 85, Training Loss: 48.1440\n",
      "Epoch 21, Step 86, Training Loss: 34.8495\n",
      "Epoch 21, Step 87, Training Loss: 57.7087\n",
      "Epoch 21, Step 88, Training Loss: 60.1012\n",
      "Epoch 21, Step 89, Training Loss: 63.2504\n",
      "Epoch 21, Step 90, Training Loss: 44.7077\n",
      "Epoch 21, Step 91, Training Loss: 34.9217\n",
      "Epoch 21, Step 92, Training Loss: 62.0044\n",
      "Epoch 21, Step 93, Training Loss: 49.9845\n",
      "Epoch 21, Step 94, Training Loss: 65.8813\n",
      "Epoch 21, Step 95, Training Loss: 38.6480\n",
      "Epoch 21, Step 96, Training Loss: 45.8184\n",
      "Epoch 21, Step 97, Training Loss: 35.6993\n",
      "Epoch 21, Step 98, Training Loss: 67.4690\n",
      "Epoch 21, Step 99, Training Loss: 63.4616\n",
      "Epoch 21, Step 100, Training Loss: 35.9869\n",
      "Epoch 21, Step 101, Training Loss: 50.1202\n",
      "Epoch 21, Step 102, Training Loss: 45.9524\n",
      "Epoch 21, Step 103, Training Loss: 38.7637\n",
      "Epoch 21, Step 104, Training Loss: 48.2781\n",
      "Epoch 21, Step 105, Training Loss: 39.8167\n",
      "Epoch 21, Step 106, Training Loss: 72.0633\n",
      "Epoch 21, Step 107, Training Loss: 63.7861\n",
      "Epoch 21, Step 108, Training Loss: 37.1083\n",
      "Epoch 21, Step 109, Training Loss: 29.7221\n",
      "Epoch 21, Step 110, Training Loss: 51.2132\n",
      "Epoch 21, Step 111, Training Loss: 49.7651\n",
      "Epoch 21, Step 112, Training Loss: 46.2733\n",
      "Epoch 21, Step 113, Training Loss: 53.2723\n",
      "Epoch 21, Step 114, Training Loss: 38.5730\n",
      "Epoch 21, Step 115, Training Loss: 67.9490\n",
      "Epoch 21, Step 116, Training Loss: 45.8479\n",
      "Epoch 21, Step 117, Training Loss: 58.0621\n",
      "Epoch 21, Step 118, Training Loss: 39.2373\n",
      "Epoch 21, Step 119, Training Loss: 54.3146\n",
      "Epoch 21, Step 120, Training Loss: 53.0011\n",
      "Epoch 21, Step 121, Training Loss: 75.9147\n",
      "Epoch 21, Step 122, Training Loss: 63.7460\n",
      "Epoch 21, Step 123, Training Loss: 47.2140\n",
      "Epoch 21, Step 124, Training Loss: 51.1794\n",
      "Epoch 21, Step 125, Training Loss: 49.3618\n",
      "Epoch 21, Step 126, Training Loss: 51.8846\n",
      "Epoch 21, Step 127, Training Loss: 46.6637\n",
      "Epoch 21, Step 128, Training Loss: 48.6401\n",
      "Epoch 21, Step 129, Training Loss: 58.7174\n",
      "Epoch 21, Step 130, Training Loss: 48.7194\n",
      "Epoch 21, Step 131, Training Loss: 45.3631\n",
      "Epoch 21, Step 132, Training Loss: 53.8453\n",
      "Epoch 21, Step 133, Training Loss: 67.3439\n",
      "Epoch 21, Step 134, Training Loss: 65.8524\n",
      "Epoch 21, Step 135, Training Loss: 47.4345\n",
      "Epoch 21, Step 136, Training Loss: 104.1686\n",
      "Epoch 21, Step 137, Training Loss: 44.5011\n",
      "Epoch 21, Step 138, Training Loss: 39.8063\n",
      "Epoch 21, Step 139, Training Loss: 57.6446\n",
      "Epoch 21, Step 140, Training Loss: 45.4372\n",
      "Epoch 21, Step 141, Training Loss: 66.6713\n",
      "Epoch 21, Step 142, Training Loss: 38.9146\n",
      "Epoch 21, Step 143, Training Loss: 40.4414\n",
      "Epoch 21, Step 144, Training Loss: 44.4743\n",
      "Epoch 21, Step 145, Training Loss: 40.3703\n",
      "Epoch 21, Step 146, Training Loss: 38.3104\n",
      "Epoch 21, Step 147, Training Loss: 38.7669\n",
      "Epoch 21, Step 148, Training Loss: 152.6868\n",
      "Epoch 21, Step 149, Training Loss: 70.2759\n",
      "Epoch 21, Step 150, Training Loss: 64.2726\n",
      "Epoch 21, Step 151, Training Loss: 48.5897\n",
      "Epoch 21, Step 152, Training Loss: 39.5202\n",
      "Epoch 21, Step 153, Training Loss: 35.9935\n",
      "Epoch 21, Step 154, Training Loss: 44.4115\n",
      "Epoch 21, Step 155, Training Loss: 69.2621\n",
      "Epoch 21, Step 156, Training Loss: 51.1047\n",
      "Epoch 21, Step 157, Training Loss: 44.8290\n",
      "Epoch 21, Step 158, Training Loss: 36.6416\n",
      "Epoch 21, Step 159, Training Loss: 69.8767\n",
      "Epoch 21, Step 160, Training Loss: 88.9912\n",
      "Epoch 21, Step 161, Training Loss: 54.0001\n",
      "Epoch 21, Step 162, Training Loss: 40.9623\n",
      "Epoch 21, Step 163, Training Loss: 35.3163\n",
      "Epoch 21, Step 164, Training Loss: 45.4395\n",
      "Epoch 21, Step 165, Training Loss: 48.1022\n",
      "Epoch 21, Step 166, Training Loss: 42.2719\n",
      "Epoch 21, Step 167, Training Loss: 41.8491\n",
      "Epoch 21, Step 168, Training Loss: 64.8987\n",
      "Epoch 21, Step 169, Training Loss: 37.6789\n",
      "Epoch 21, Step 170, Training Loss: 46.1204\n",
      "Epoch 21, Step 171, Training Loss: 32.8150\n",
      "Epoch 21, Step 172, Training Loss: 43.2769\n",
      "Epoch 21, Step 173, Training Loss: 45.0560\n",
      "Epoch 21, Step 174, Training Loss: 34.4295\n",
      "Epoch 21, Step 175, Training Loss: 44.2901\n",
      "Epoch 21, Step 176, Training Loss: 54.8185\n",
      "Epoch 21, Step 177, Training Loss: 70.7026\n",
      "Epoch 21, Step 178, Training Loss: 43.4399\n",
      "Epoch 21, Step 179, Training Loss: 36.8692\n",
      "Epoch 21, Step 180, Training Loss: 50.6985\n",
      "Epoch 21, Step 181, Training Loss: 42.1295\n",
      "Epoch 21, Step 182, Training Loss: 58.1602\n",
      "Epoch 21, Step 183, Training Loss: 43.5647\n",
      "Epoch 21, Step 184, Training Loss: 41.7274\n",
      "Epoch 21, Step 185, Training Loss: 44.0896\n",
      "Epoch 21, Step 186, Training Loss: 73.5908\n",
      "Epoch 21, Step 187, Training Loss: 36.0572\n",
      "Epoch 21, Step 188, Training Loss: 133.5083\n",
      "Epoch 21, Step 189, Training Loss: 49.9223\n",
      "Epoch 21, Step 190, Training Loss: 192.1230\n",
      "Epoch 21, Step 191, Training Loss: 30.3924\n",
      "Epoch 21, Step 192, Training Loss: 54.2290\n",
      "Epoch 21, Step 193, Training Loss: 49.1245\n",
      "Epoch 21, Step 194, Training Loss: 43.2222\n",
      "Epoch 21, Step 195, Training Loss: 44.2639\n",
      "Epoch 21, Step 196, Training Loss: 61.9118\n",
      "Epoch 21, Step 197, Training Loss: 45.7342\n",
      "Epoch 21, Step 198, Training Loss: 44.3781\n",
      "Epoch 21, Step 199, Training Loss: 48.8224\n",
      "Epoch 21, Step 200, Training Loss: 43.6444\n",
      "Epoch 21, Step 201, Training Loss: 39.1505\n",
      "Epoch 21, Step 202, Training Loss: 48.3747\n",
      "Epoch 21, Step 203, Training Loss: 66.8593\n",
      "Epoch 21, Step 204, Training Loss: 75.7448\n",
      "Epoch 21, Step 205, Training Loss: 48.0423\n",
      "Epoch 21, Step 206, Training Loss: 43.2272\n",
      "--- Epoch 21, Validation Loss: 52.2565 ---\n",
      "Epoch 22, Step 0, Training Loss: 35.2821\n",
      "Epoch 22, Step 1, Training Loss: 38.2310\n",
      "Epoch 22, Step 2, Training Loss: 42.0051\n",
      "Epoch 22, Step 3, Training Loss: 59.4560\n",
      "Epoch 22, Step 4, Training Loss: 71.8029\n",
      "Epoch 22, Step 5, Training Loss: 45.9379\n",
      "Epoch 22, Step 6, Training Loss: 43.0811\n",
      "Epoch 22, Step 7, Training Loss: 50.9510\n",
      "Epoch 22, Step 8, Training Loss: 35.1833\n",
      "Epoch 22, Step 9, Training Loss: 34.9480\n",
      "Epoch 22, Step 10, Training Loss: 59.2358\n",
      "Epoch 22, Step 11, Training Loss: 49.8022\n",
      "Epoch 22, Step 12, Training Loss: 57.7786\n",
      "Epoch 22, Step 13, Training Loss: 81.0091\n",
      "Epoch 22, Step 14, Training Loss: 43.3111\n",
      "Epoch 22, Step 15, Training Loss: 29.2383\n",
      "Epoch 22, Step 16, Training Loss: 33.9939\n",
      "Epoch 22, Step 17, Training Loss: 44.2405\n",
      "Epoch 22, Step 18, Training Loss: 35.2243\n",
      "Epoch 22, Step 19, Training Loss: 57.0235\n",
      "Epoch 22, Step 20, Training Loss: 41.5647\n",
      "Epoch 22, Step 21, Training Loss: 67.8790\n",
      "Epoch 22, Step 22, Training Loss: 69.2178\n",
      "Epoch 22, Step 23, Training Loss: 46.2231\n",
      "Epoch 22, Step 24, Training Loss: 44.7543\n",
      "Epoch 22, Step 25, Training Loss: 37.6895\n",
      "Epoch 22, Step 26, Training Loss: 54.4835\n",
      "Epoch 22, Step 27, Training Loss: 49.6511\n",
      "Epoch 22, Step 28, Training Loss: 44.0211\n",
      "Epoch 22, Step 29, Training Loss: 34.9753\n",
      "Epoch 22, Step 30, Training Loss: 32.1527\n",
      "Epoch 22, Step 31, Training Loss: 47.3165\n",
      "Epoch 22, Step 32, Training Loss: 39.9877\n",
      "Epoch 22, Step 33, Training Loss: 39.6331\n",
      "Epoch 22, Step 34, Training Loss: 43.3417\n",
      "Epoch 22, Step 35, Training Loss: 41.8706\n",
      "Epoch 22, Step 36, Training Loss: 51.6401\n",
      "Epoch 22, Step 37, Training Loss: 99.2814\n",
      "Epoch 22, Step 38, Training Loss: 58.4911\n",
      "Epoch 22, Step 39, Training Loss: 46.0061\n",
      "Epoch 22, Step 40, Training Loss: 53.9523\n",
      "Epoch 22, Step 41, Training Loss: 69.8928\n",
      "Epoch 22, Step 42, Training Loss: 48.7710\n",
      "Epoch 22, Step 43, Training Loss: 41.0472\n",
      "Epoch 22, Step 44, Training Loss: 51.0974\n",
      "Epoch 22, Step 45, Training Loss: 30.7153\n",
      "Epoch 22, Step 46, Training Loss: 29.2073\n",
      "Epoch 22, Step 47, Training Loss: 42.2799\n",
      "Epoch 22, Step 48, Training Loss: 35.9729\n",
      "Epoch 22, Step 49, Training Loss: 44.8438\n",
      "Epoch 22, Step 50, Training Loss: 39.7723\n",
      "Epoch 22, Step 51, Training Loss: 49.1665\n",
      "Epoch 22, Step 52, Training Loss: 38.7085\n",
      "Epoch 22, Step 53, Training Loss: 37.9423\n",
      "Epoch 22, Step 54, Training Loss: 50.6953\n",
      "Epoch 22, Step 55, Training Loss: 51.3586\n",
      "Epoch 22, Step 56, Training Loss: 74.4178\n",
      "Epoch 22, Step 57, Training Loss: 32.0438\n",
      "Epoch 22, Step 58, Training Loss: 55.2178\n",
      "Epoch 22, Step 59, Training Loss: 45.2498\n",
      "Epoch 22, Step 60, Training Loss: 92.1383\n",
      "Epoch 22, Step 61, Training Loss: 38.7766\n",
      "Epoch 22, Step 62, Training Loss: 43.9366\n",
      "Epoch 22, Step 63, Training Loss: 60.7385\n",
      "Epoch 22, Step 64, Training Loss: 52.2435\n",
      "Epoch 22, Step 65, Training Loss: 45.1611\n",
      "Epoch 22, Step 66, Training Loss: 48.5096\n",
      "Epoch 22, Step 67, Training Loss: 48.0445\n",
      "Epoch 22, Step 68, Training Loss: 39.2518\n",
      "Epoch 22, Step 69, Training Loss: 85.4177\n",
      "Epoch 22, Step 70, Training Loss: 51.9188\n",
      "Epoch 22, Step 71, Training Loss: 45.9335\n",
      "Epoch 22, Step 72, Training Loss: 57.4088\n",
      "Epoch 22, Step 73, Training Loss: 56.2800\n",
      "Epoch 22, Step 74, Training Loss: 45.6209\n",
      "Epoch 22, Step 75, Training Loss: 64.8829\n",
      "Epoch 22, Step 76, Training Loss: 75.9760\n",
      "Epoch 22, Step 77, Training Loss: 47.4768\n",
      "Epoch 22, Step 78, Training Loss: 29.9456\n",
      "Epoch 22, Step 79, Training Loss: 27.9163\n",
      "Epoch 22, Step 80, Training Loss: 62.2089\n",
      "Epoch 22, Step 81, Training Loss: 92.4605\n",
      "Epoch 22, Step 82, Training Loss: 32.3339\n",
      "Epoch 22, Step 83, Training Loss: 63.3197\n",
      "Epoch 22, Step 84, Training Loss: 89.9745\n",
      "Epoch 22, Step 85, Training Loss: 45.7657\n",
      "Epoch 22, Step 86, Training Loss: 31.6051\n",
      "Epoch 22, Step 87, Training Loss: 52.9384\n",
      "Epoch 22, Step 88, Training Loss: 58.5162\n",
      "Epoch 22, Step 89, Training Loss: 59.1510\n",
      "Epoch 22, Step 90, Training Loss: 40.4851\n",
      "Epoch 22, Step 91, Training Loss: 35.8869\n",
      "Epoch 22, Step 92, Training Loss: 60.4704\n",
      "Epoch 22, Step 93, Training Loss: 49.1128\n",
      "Epoch 22, Step 94, Training Loss: 63.5258\n",
      "Epoch 22, Step 95, Training Loss: 34.2308\n",
      "Epoch 22, Step 96, Training Loss: 40.2747\n",
      "Epoch 22, Step 97, Training Loss: 34.1116\n",
      "Epoch 22, Step 98, Training Loss: 67.5138\n",
      "Epoch 22, Step 99, Training Loss: 59.0619\n",
      "Epoch 22, Step 100, Training Loss: 31.9095\n",
      "Epoch 22, Step 101, Training Loss: 43.9034\n",
      "Epoch 22, Step 102, Training Loss: 43.2395\n",
      "Epoch 22, Step 103, Training Loss: 36.5713\n",
      "Epoch 22, Step 104, Training Loss: 46.5270\n",
      "Epoch 22, Step 105, Training Loss: 36.6825\n",
      "Epoch 22, Step 106, Training Loss: 69.6128\n",
      "Epoch 22, Step 107, Training Loss: 64.9949\n",
      "Epoch 22, Step 108, Training Loss: 35.7097\n",
      "Epoch 22, Step 109, Training Loss: 28.3604\n",
      "Epoch 22, Step 110, Training Loss: 51.8176\n",
      "Epoch 22, Step 111, Training Loss: 45.8290\n",
      "Epoch 22, Step 112, Training Loss: 46.2638\n",
      "Epoch 22, Step 113, Training Loss: 50.0635\n",
      "Epoch 22, Step 114, Training Loss: 37.0393\n",
      "Epoch 22, Step 115, Training Loss: 64.8324\n",
      "Epoch 22, Step 116, Training Loss: 41.8018\n",
      "Epoch 22, Step 117, Training Loss: 56.4064\n",
      "Epoch 22, Step 118, Training Loss: 37.9975\n",
      "Epoch 22, Step 119, Training Loss: 51.6676\n",
      "Epoch 22, Step 120, Training Loss: 49.5599\n",
      "Epoch 22, Step 121, Training Loss: 71.0327\n",
      "Epoch 22, Step 122, Training Loss: 60.2507\n",
      "Epoch 22, Step 123, Training Loss: 43.0790\n",
      "Epoch 22, Step 124, Training Loss: 52.4635\n",
      "Epoch 22, Step 125, Training Loss: 46.9909\n",
      "Epoch 22, Step 126, Training Loss: 51.5403\n",
      "Epoch 22, Step 127, Training Loss: 42.8638\n",
      "Epoch 22, Step 128, Training Loss: 45.4970\n",
      "Epoch 22, Step 129, Training Loss: 55.7093\n",
      "Epoch 22, Step 130, Training Loss: 43.8414\n",
      "Epoch 22, Step 131, Training Loss: 40.0050\n",
      "Epoch 22, Step 132, Training Loss: 52.5721\n",
      "Epoch 22, Step 133, Training Loss: 63.5488\n",
      "Epoch 22, Step 134, Training Loss: 61.3599\n",
      "Epoch 22, Step 135, Training Loss: 46.1019\n",
      "Epoch 22, Step 136, Training Loss: 101.7901\n",
      "Epoch 22, Step 137, Training Loss: 40.7023\n",
      "Epoch 22, Step 138, Training Loss: 35.2634\n",
      "Epoch 22, Step 139, Training Loss: 51.8194\n",
      "Epoch 22, Step 140, Training Loss: 41.9255\n",
      "Epoch 22, Step 141, Training Loss: 62.2151\n",
      "Epoch 22, Step 142, Training Loss: 35.0300\n",
      "Epoch 22, Step 143, Training Loss: 39.6624\n",
      "Epoch 22, Step 144, Training Loss: 40.4169\n",
      "Epoch 22, Step 145, Training Loss: 38.1984\n",
      "Epoch 22, Step 146, Training Loss: 34.7344\n",
      "Epoch 22, Step 147, Training Loss: 40.1046\n",
      "Epoch 22, Step 148, Training Loss: 145.0119\n",
      "Epoch 22, Step 149, Training Loss: 66.8401\n",
      "Epoch 22, Step 150, Training Loss: 61.2495\n",
      "Epoch 22, Step 151, Training Loss: 43.0498\n",
      "Epoch 22, Step 152, Training Loss: 38.5739\n",
      "Epoch 22, Step 153, Training Loss: 31.7981\n",
      "Epoch 22, Step 154, Training Loss: 41.3525\n",
      "Epoch 22, Step 155, Training Loss: 62.1733\n",
      "Epoch 22, Step 156, Training Loss: 51.1386\n",
      "Epoch 22, Step 157, Training Loss: 43.7092\n",
      "Epoch 22, Step 158, Training Loss: 35.2854\n",
      "Epoch 22, Step 159, Training Loss: 66.7046\n",
      "Epoch 22, Step 160, Training Loss: 85.3311\n",
      "Epoch 22, Step 161, Training Loss: 49.1885\n",
      "Epoch 22, Step 162, Training Loss: 37.3394\n",
      "Epoch 22, Step 163, Training Loss: 33.0531\n",
      "Epoch 22, Step 164, Training Loss: 42.4454\n",
      "Epoch 22, Step 165, Training Loss: 46.3470\n",
      "Epoch 22, Step 166, Training Loss: 37.3522\n",
      "Epoch 22, Step 167, Training Loss: 39.6944\n",
      "Epoch 22, Step 168, Training Loss: 63.6839\n",
      "Epoch 22, Step 169, Training Loss: 34.3620\n",
      "Epoch 22, Step 170, Training Loss: 41.9526\n",
      "Epoch 22, Step 171, Training Loss: 29.1858\n",
      "Epoch 22, Step 172, Training Loss: 38.8887\n",
      "Epoch 22, Step 173, Training Loss: 39.6274\n",
      "Epoch 22, Step 174, Training Loss: 30.4787\n",
      "Epoch 22, Step 175, Training Loss: 43.0258\n",
      "Epoch 22, Step 176, Training Loss: 51.4532\n",
      "Epoch 22, Step 177, Training Loss: 63.3752\n",
      "Epoch 22, Step 178, Training Loss: 43.9743\n",
      "Epoch 22, Step 179, Training Loss: 32.0396\n",
      "Epoch 22, Step 180, Training Loss: 46.0861\n",
      "Epoch 22, Step 181, Training Loss: 42.3120\n",
      "Epoch 22, Step 182, Training Loss: 53.9689\n",
      "Epoch 22, Step 183, Training Loss: 36.4466\n",
      "Epoch 22, Step 184, Training Loss: 40.1153\n",
      "Epoch 22, Step 185, Training Loss: 36.1456\n",
      "Epoch 22, Step 186, Training Loss: 72.2190\n",
      "Epoch 22, Step 187, Training Loss: 33.6045\n",
      "Epoch 22, Step 188, Training Loss: 129.6451\n",
      "Epoch 22, Step 189, Training Loss: 46.8516\n",
      "Epoch 22, Step 190, Training Loss: 186.8197\n",
      "Epoch 22, Step 191, Training Loss: 25.3706\n",
      "Epoch 22, Step 192, Training Loss: 49.9207\n",
      "Epoch 22, Step 193, Training Loss: 49.6884\n",
      "Epoch 22, Step 194, Training Loss: 42.6856\n",
      "Epoch 22, Step 195, Training Loss: 42.0731\n",
      "Epoch 22, Step 196, Training Loss: 57.1341\n",
      "Epoch 22, Step 197, Training Loss: 44.1576\n",
      "Epoch 22, Step 198, Training Loss: 40.5751\n",
      "Epoch 22, Step 199, Training Loss: 49.0542\n",
      "Epoch 22, Step 200, Training Loss: 39.6892\n",
      "Epoch 22, Step 201, Training Loss: 34.3782\n",
      "Epoch 22, Step 202, Training Loss: 43.1954\n",
      "Epoch 22, Step 203, Training Loss: 64.2487\n",
      "Epoch 22, Step 204, Training Loss: 73.6782\n",
      "Epoch 22, Step 205, Training Loss: 48.7118\n",
      "Epoch 22, Step 206, Training Loss: 40.5717\n",
      "--- Epoch 22, Validation Loss: 48.0585 ---\n",
      "Epoch 23, Step 0, Training Loss: 32.1296\n",
      "Epoch 23, Step 1, Training Loss: 34.2666\n",
      "Epoch 23, Step 2, Training Loss: 37.0719\n",
      "Epoch 23, Step 3, Training Loss: 55.1878\n",
      "Epoch 23, Step 4, Training Loss: 68.0243\n",
      "Epoch 23, Step 5, Training Loss: 43.4352\n",
      "Epoch 23, Step 6, Training Loss: 39.8269\n",
      "Epoch 23, Step 7, Training Loss: 46.6557\n",
      "Epoch 23, Step 8, Training Loss: 31.0780\n",
      "Epoch 23, Step 9, Training Loss: 31.8908\n",
      "Epoch 23, Step 10, Training Loss: 60.6009\n",
      "Epoch 23, Step 11, Training Loss: 43.8534\n",
      "Epoch 23, Step 12, Training Loss: 59.6978\n",
      "Epoch 23, Step 13, Training Loss: 81.6305\n",
      "Epoch 23, Step 14, Training Loss: 39.0786\n",
      "Epoch 23, Step 15, Training Loss: 29.1595\n",
      "Epoch 23, Step 16, Training Loss: 31.0569\n",
      "Epoch 23, Step 17, Training Loss: 38.7041\n",
      "Epoch 23, Step 18, Training Loss: 31.8358\n",
      "Epoch 23, Step 19, Training Loss: 55.7915\n",
      "Epoch 23, Step 20, Training Loss: 41.3457\n",
      "Epoch 23, Step 21, Training Loss: 67.0148\n",
      "Epoch 23, Step 22, Training Loss: 65.7746\n",
      "Epoch 23, Step 23, Training Loss: 46.2628\n",
      "Epoch 23, Step 24, Training Loss: 39.5058\n",
      "Epoch 23, Step 25, Training Loss: 35.2664\n",
      "Epoch 23, Step 26, Training Loss: 45.7401\n",
      "Epoch 23, Step 27, Training Loss: 46.8515\n",
      "Epoch 23, Step 28, Training Loss: 38.9147\n",
      "Epoch 23, Step 29, Training Loss: 31.3056\n",
      "Epoch 23, Step 30, Training Loss: 27.6976\n",
      "Epoch 23, Step 31, Training Loss: 40.5750\n",
      "Epoch 23, Step 32, Training Loss: 35.3041\n",
      "Epoch 23, Step 33, Training Loss: 32.0129\n",
      "Epoch 23, Step 34, Training Loss: 36.7676\n",
      "Epoch 23, Step 35, Training Loss: 38.3238\n",
      "Epoch 23, Step 36, Training Loss: 49.1445\n",
      "Epoch 23, Step 37, Training Loss: 98.8606\n",
      "Epoch 23, Step 38, Training Loss: 55.2217\n",
      "Epoch 23, Step 39, Training Loss: 42.4989\n",
      "Epoch 23, Step 40, Training Loss: 47.4912\n",
      "Epoch 23, Step 41, Training Loss: 65.6419\n",
      "Epoch 23, Step 42, Training Loss: 44.7307\n",
      "Epoch 23, Step 43, Training Loss: 37.3007\n",
      "Epoch 23, Step 44, Training Loss: 46.4400\n",
      "Epoch 23, Step 45, Training Loss: 25.9474\n",
      "Epoch 23, Step 46, Training Loss: 26.5435\n",
      "Epoch 23, Step 47, Training Loss: 37.4044\n",
      "Epoch 23, Step 48, Training Loss: 33.9394\n",
      "Epoch 23, Step 49, Training Loss: 43.9344\n",
      "Epoch 23, Step 50, Training Loss: 34.7286\n",
      "Epoch 23, Step 51, Training Loss: 43.0961\n",
      "Epoch 23, Step 52, Training Loss: 34.0165\n",
      "Epoch 23, Step 53, Training Loss: 32.7598\n",
      "Epoch 23, Step 54, Training Loss: 43.7768\n",
      "Epoch 23, Step 55, Training Loss: 49.2119\n",
      "Epoch 23, Step 56, Training Loss: 65.7555\n",
      "Epoch 23, Step 57, Training Loss: 28.5469\n",
      "Epoch 23, Step 58, Training Loss: 46.9579\n",
      "Epoch 23, Step 59, Training Loss: 41.2569\n",
      "Epoch 23, Step 60, Training Loss: 85.9384\n",
      "Epoch 23, Step 61, Training Loss: 34.5211\n",
      "Epoch 23, Step 62, Training Loss: 39.7657\n",
      "Epoch 23, Step 63, Training Loss: 57.2098\n",
      "Epoch 23, Step 64, Training Loss: 48.1520\n",
      "Epoch 23, Step 65, Training Loss: 41.0113\n",
      "Epoch 23, Step 66, Training Loss: 43.0009\n",
      "Epoch 23, Step 67, Training Loss: 45.9144\n",
      "Epoch 23, Step 68, Training Loss: 36.6442\n",
      "Epoch 23, Step 69, Training Loss: 78.5581\n",
      "Epoch 23, Step 70, Training Loss: 48.8391\n",
      "Epoch 23, Step 71, Training Loss: 41.1925\n",
      "Epoch 23, Step 72, Training Loss: 52.7841\n",
      "Epoch 23, Step 73, Training Loss: 48.6011\n",
      "Epoch 23, Step 74, Training Loss: 41.6647\n",
      "Epoch 23, Step 75, Training Loss: 60.9788\n",
      "Epoch 23, Step 76, Training Loss: 72.9288\n",
      "Epoch 23, Step 77, Training Loss: 47.1307\n",
      "Epoch 23, Step 78, Training Loss: 25.5268\n",
      "Epoch 23, Step 79, Training Loss: 27.1148\n",
      "Epoch 23, Step 80, Training Loss: 57.3144\n",
      "Epoch 23, Step 81, Training Loss: 90.8543\n",
      "Epoch 23, Step 82, Training Loss: 28.5245\n",
      "Epoch 23, Step 83, Training Loss: 61.3218\n",
      "Epoch 23, Step 84, Training Loss: 83.8205\n",
      "Epoch 23, Step 85, Training Loss: 40.5756\n",
      "Epoch 23, Step 86, Training Loss: 28.6681\n",
      "Epoch 23, Step 87, Training Loss: 47.9532\n",
      "Epoch 23, Step 88, Training Loss: 47.4569\n",
      "Epoch 23, Step 89, Training Loss: 51.3375\n",
      "Epoch 23, Step 90, Training Loss: 36.0354\n",
      "Epoch 23, Step 91, Training Loss: 28.9913\n",
      "Epoch 23, Step 92, Training Loss: 54.9072\n",
      "Epoch 23, Step 93, Training Loss: 44.0950\n",
      "Epoch 23, Step 94, Training Loss: 60.6208\n",
      "Epoch 23, Step 95, Training Loss: 30.9879\n",
      "Epoch 23, Step 96, Training Loss: 37.9445\n",
      "Epoch 23, Step 97, Training Loss: 29.0516\n",
      "Epoch 23, Step 98, Training Loss: 60.5503\n",
      "Epoch 23, Step 99, Training Loss: 56.1489\n",
      "Epoch 23, Step 100, Training Loss: 28.5778\n",
      "Epoch 23, Step 101, Training Loss: 39.3144\n",
      "Epoch 23, Step 102, Training Loss: 40.2125\n",
      "Epoch 23, Step 103, Training Loss: 32.3102\n",
      "Epoch 23, Step 104, Training Loss: 45.4163\n",
      "Epoch 23, Step 105, Training Loss: 37.6719\n",
      "Epoch 23, Step 106, Training Loss: 64.8363\n",
      "Epoch 23, Step 107, Training Loss: 54.6803\n",
      "Epoch 23, Step 108, Training Loss: 32.4911\n",
      "Epoch 23, Step 109, Training Loss: 25.4122\n",
      "Epoch 23, Step 110, Training Loss: 48.7717\n",
      "Epoch 23, Step 111, Training Loss: 44.1205\n",
      "Epoch 23, Step 112, Training Loss: 41.0921\n",
      "Epoch 23, Step 113, Training Loss: 47.1945\n",
      "Epoch 23, Step 114, Training Loss: 33.0599\n",
      "Epoch 23, Step 115, Training Loss: 61.1114\n",
      "Epoch 23, Step 116, Training Loss: 37.6695\n",
      "Epoch 23, Step 117, Training Loss: 54.6135\n",
      "Epoch 23, Step 118, Training Loss: 33.1565\n",
      "Epoch 23, Step 119, Training Loss: 45.6477\n",
      "Epoch 23, Step 120, Training Loss: 44.2756\n",
      "Epoch 23, Step 121, Training Loss: 69.7453\n",
      "Epoch 23, Step 122, Training Loss: 55.3603\n",
      "Epoch 23, Step 123, Training Loss: 39.5199\n",
      "Epoch 23, Step 124, Training Loss: 44.2494\n",
      "Epoch 23, Step 125, Training Loss: 47.4762\n",
      "Epoch 23, Step 126, Training Loss: 48.1859\n",
      "Epoch 23, Step 127, Training Loss: 40.0273\n",
      "Epoch 23, Step 128, Training Loss: 40.9409\n",
      "Epoch 23, Step 129, Training Loss: 50.8937\n",
      "Epoch 23, Step 130, Training Loss: 40.6128\n",
      "Epoch 23, Step 131, Training Loss: 37.2729\n",
      "Epoch 23, Step 132, Training Loss: 47.4392\n",
      "Epoch 23, Step 133, Training Loss: 59.5084\n",
      "Epoch 23, Step 134, Training Loss: 56.7860\n",
      "Epoch 23, Step 135, Training Loss: 42.9928\n",
      "Epoch 23, Step 136, Training Loss: 92.6465\n",
      "Epoch 23, Step 137, Training Loss: 35.3423\n",
      "Epoch 23, Step 138, Training Loss: 31.9315\n",
      "Epoch 23, Step 139, Training Loss: 42.3998\n",
      "Epoch 23, Step 140, Training Loss: 37.2160\n",
      "Epoch 23, Step 141, Training Loss: 57.7856\n",
      "Epoch 23, Step 142, Training Loss: 32.2477\n",
      "Epoch 23, Step 143, Training Loss: 36.1288\n",
      "Epoch 23, Step 144, Training Loss: 35.1735\n",
      "Epoch 23, Step 145, Training Loss: 31.9019\n",
      "Epoch 23, Step 146, Training Loss: 32.6410\n",
      "Epoch 23, Step 147, Training Loss: 35.4751\n",
      "Epoch 23, Step 148, Training Loss: 132.6949\n",
      "Epoch 23, Step 149, Training Loss: 59.1354\n",
      "Epoch 23, Step 150, Training Loss: 51.7830\n",
      "Epoch 23, Step 151, Training Loss: 37.8786\n",
      "Epoch 23, Step 152, Training Loss: 35.3301\n",
      "Epoch 23, Step 153, Training Loss: 28.4400\n",
      "Epoch 23, Step 154, Training Loss: 38.2611\n",
      "Epoch 23, Step 155, Training Loss: 57.3208\n",
      "Epoch 23, Step 156, Training Loss: 41.5194\n",
      "Epoch 23, Step 157, Training Loss: 40.0615\n",
      "Epoch 23, Step 158, Training Loss: 32.6660\n",
      "Epoch 23, Step 159, Training Loss: 58.6225\n",
      "Epoch 23, Step 160, Training Loss: 80.1503\n",
      "Epoch 23, Step 161, Training Loss: 45.5752\n",
      "Epoch 23, Step 162, Training Loss: 35.0833\n",
      "Epoch 23, Step 163, Training Loss: 29.4134\n",
      "Epoch 23, Step 164, Training Loss: 37.5515\n",
      "Epoch 23, Step 165, Training Loss: 38.8974\n",
      "Epoch 23, Step 166, Training Loss: 33.3383\n",
      "Epoch 23, Step 167, Training Loss: 39.4616\n",
      "Epoch 23, Step 168, Training Loss: 57.5599\n",
      "Epoch 23, Step 169, Training Loss: 27.3222\n",
      "Epoch 23, Step 170, Training Loss: 35.4482\n",
      "Epoch 23, Step 171, Training Loss: 26.0520\n",
      "Epoch 23, Step 172, Training Loss: 35.7955\n",
      "Epoch 23, Step 173, Training Loss: 36.2058\n",
      "Epoch 23, Step 174, Training Loss: 30.2964\n",
      "Epoch 23, Step 175, Training Loss: 38.3220\n",
      "Epoch 23, Step 176, Training Loss: 45.8738\n",
      "Epoch 23, Step 177, Training Loss: 61.3771\n",
      "Epoch 23, Step 178, Training Loss: 38.5652\n",
      "Epoch 23, Step 179, Training Loss: 28.2320\n",
      "Epoch 23, Step 180, Training Loss: 38.6410\n",
      "Epoch 23, Step 181, Training Loss: 36.4555\n",
      "Epoch 23, Step 182, Training Loss: 47.2318\n",
      "Epoch 23, Step 183, Training Loss: 30.7524\n",
      "Epoch 23, Step 184, Training Loss: 34.9521\n",
      "Epoch 23, Step 185, Training Loss: 32.4974\n",
      "Epoch 23, Step 186, Training Loss: 66.5193\n",
      "Epoch 23, Step 187, Training Loss: 28.1239\n",
      "Epoch 23, Step 188, Training Loss: 138.3228\n",
      "Epoch 23, Step 189, Training Loss: 42.8638\n",
      "Epoch 23, Step 190, Training Loss: 179.4921\n",
      "Epoch 23, Step 191, Training Loss: 23.7413\n",
      "Epoch 23, Step 192, Training Loss: 42.7669\n",
      "Epoch 23, Step 193, Training Loss: 45.1049\n",
      "Epoch 23, Step 194, Training Loss: 35.3374\n",
      "Epoch 23, Step 195, Training Loss: 41.9706\n",
      "Epoch 23, Step 196, Training Loss: 53.9061\n",
      "Epoch 23, Step 197, Training Loss: 38.4995\n",
      "Epoch 23, Step 198, Training Loss: 35.6061\n",
      "Epoch 23, Step 199, Training Loss: 42.6478\n",
      "Epoch 23, Step 200, Training Loss: 34.0686\n",
      "Epoch 23, Step 201, Training Loss: 29.7279\n",
      "Epoch 23, Step 202, Training Loss: 36.3665\n",
      "Epoch 23, Step 203, Training Loss: 57.1028\n",
      "Epoch 23, Step 204, Training Loss: 69.7723\n",
      "Epoch 23, Step 205, Training Loss: 41.9541\n",
      "Epoch 23, Step 206, Training Loss: 36.1159\n",
      "--- Epoch 23, Validation Loss: 41.6273 ---\n",
      "Epoch 24, Step 0, Training Loss: 26.8477\n",
      "Epoch 24, Step 1, Training Loss: 32.0917\n",
      "Epoch 24, Step 2, Training Loss: 31.5151\n",
      "Epoch 24, Step 3, Training Loss: 50.1596\n",
      "Epoch 24, Step 4, Training Loss: 66.7385\n",
      "Epoch 24, Step 5, Training Loss: 37.3160\n",
      "Epoch 24, Step 6, Training Loss: 35.5627\n",
      "Epoch 24, Step 7, Training Loss: 38.0145\n",
      "Epoch 24, Step 8, Training Loss: 25.1323\n",
      "Epoch 24, Step 9, Training Loss: 28.4591\n",
      "Epoch 24, Step 10, Training Loss: 54.6108\n",
      "Epoch 24, Step 11, Training Loss: 39.9306\n",
      "Epoch 24, Step 12, Training Loss: 55.7675\n",
      "Epoch 24, Step 13, Training Loss: 77.9318\n",
      "Epoch 24, Step 14, Training Loss: 34.0126\n",
      "Epoch 24, Step 15, Training Loss: 24.5485\n",
      "Epoch 24, Step 16, Training Loss: 27.5141\n",
      "Epoch 24, Step 17, Training Loss: 34.5045\n",
      "Epoch 24, Step 18, Training Loss: 27.5420\n",
      "Epoch 24, Step 19, Training Loss: 49.5045\n",
      "Epoch 24, Step 20, Training Loss: 35.7896\n",
      "Epoch 24, Step 21, Training Loss: 59.5111\n",
      "Epoch 24, Step 22, Training Loss: 60.5150\n",
      "Epoch 24, Step 23, Training Loss: 39.0687\n",
      "Epoch 24, Step 24, Training Loss: 35.4300\n",
      "Epoch 24, Step 25, Training Loss: 33.1659\n",
      "Epoch 24, Step 26, Training Loss: 41.6872\n",
      "Epoch 24, Step 27, Training Loss: 43.0152\n",
      "Epoch 24, Step 28, Training Loss: 33.9450\n",
      "Epoch 24, Step 29, Training Loss: 26.0746\n",
      "Epoch 24, Step 30, Training Loss: 24.9801\n",
      "Epoch 24, Step 31, Training Loss: 36.7242\n",
      "Epoch 24, Step 32, Training Loss: 32.5278\n",
      "Epoch 24, Step 33, Training Loss: 30.2882\n",
      "Epoch 24, Step 34, Training Loss: 32.6708\n",
      "Epoch 24, Step 35, Training Loss: 31.9247\n",
      "Epoch 24, Step 36, Training Loss: 42.3091\n",
      "Epoch 24, Step 37, Training Loss: 89.9448\n",
      "Epoch 24, Step 38, Training Loss: 50.4392\n",
      "Epoch 24, Step 39, Training Loss: 38.6505\n",
      "Epoch 24, Step 40, Training Loss: 43.8662\n",
      "Epoch 24, Step 41, Training Loss: 61.3177\n",
      "Epoch 24, Step 42, Training Loss: 39.2951\n",
      "Epoch 24, Step 43, Training Loss: 33.2316\n",
      "Epoch 24, Step 44, Training Loss: 39.4409\n",
      "Epoch 24, Step 45, Training Loss: 23.4214\n",
      "Epoch 24, Step 46, Training Loss: 22.6124\n",
      "Epoch 24, Step 47, Training Loss: 33.6591\n",
      "Epoch 24, Step 48, Training Loss: 28.0731\n",
      "Epoch 24, Step 49, Training Loss: 36.6820\n",
      "Epoch 24, Step 50, Training Loss: 30.3074\n",
      "Epoch 24, Step 51, Training Loss: 39.1311\n",
      "Epoch 24, Step 52, Training Loss: 30.7615\n",
      "Epoch 24, Step 53, Training Loss: 28.0747\n",
      "Epoch 24, Step 54, Training Loss: 39.7424\n",
      "Epoch 24, Step 55, Training Loss: 43.3773\n",
      "Epoch 24, Step 56, Training Loss: 64.6504\n",
      "Epoch 24, Step 57, Training Loss: 24.7635\n",
      "Epoch 24, Step 58, Training Loss: 46.0735\n",
      "Epoch 24, Step 59, Training Loss: 35.1636\n",
      "Epoch 24, Step 60, Training Loss: 84.0304\n",
      "Epoch 24, Step 61, Training Loss: 28.8277\n",
      "Epoch 24, Step 62, Training Loss: 36.3649\n",
      "Epoch 24, Step 63, Training Loss: 50.3259\n",
      "Epoch 24, Step 64, Training Loss: 40.9711\n",
      "Epoch 24, Step 65, Training Loss: 36.0433\n",
      "Epoch 24, Step 66, Training Loss: 37.4864\n",
      "Epoch 24, Step 67, Training Loss: 40.4790\n",
      "Epoch 24, Step 68, Training Loss: 31.3081\n",
      "Epoch 24, Step 69, Training Loss: 70.0426\n",
      "Epoch 24, Step 70, Training Loss: 41.1721\n",
      "Epoch 24, Step 71, Training Loss: 37.9264\n",
      "Epoch 24, Step 72, Training Loss: 47.3023\n",
      "Epoch 24, Step 73, Training Loss: 45.9337\n",
      "Epoch 24, Step 74, Training Loss: 34.0044\n",
      "Epoch 24, Step 75, Training Loss: 53.8576\n",
      "Epoch 24, Step 76, Training Loss: 68.8411\n",
      "Epoch 24, Step 77, Training Loss: 41.6062\n",
      "Epoch 24, Step 78, Training Loss: 22.3802\n",
      "Epoch 24, Step 79, Training Loss: 21.8882\n",
      "Epoch 24, Step 80, Training Loss: 52.3206\n",
      "Epoch 24, Step 81, Training Loss: 86.5526\n",
      "Epoch 24, Step 82, Training Loss: 24.4581\n",
      "Epoch 24, Step 83, Training Loss: 56.9368\n",
      "Epoch 24, Step 84, Training Loss: 82.6272\n",
      "Epoch 24, Step 85, Training Loss: 37.6066\n",
      "Epoch 24, Step 86, Training Loss: 26.7200\n",
      "Epoch 24, Step 87, Training Loss: 40.7157\n",
      "Epoch 24, Step 88, Training Loss: 48.9728\n",
      "Epoch 24, Step 89, Training Loss: 43.3617\n",
      "Epoch 24, Step 90, Training Loss: 29.6905\n",
      "Epoch 24, Step 91, Training Loss: 26.8663\n",
      "Epoch 24, Step 92, Training Loss: 51.6864\n",
      "Epoch 24, Step 93, Training Loss: 42.6346\n",
      "Epoch 24, Step 94, Training Loss: 54.4487\n",
      "Epoch 24, Step 95, Training Loss: 25.2739\n",
      "Epoch 24, Step 96, Training Loss: 32.8512\n",
      "Epoch 24, Step 97, Training Loss: 26.8892\n",
      "Epoch 24, Step 98, Training Loss: 54.2630\n",
      "Epoch 24, Step 99, Training Loss: 52.6055\n",
      "Epoch 24, Step 100, Training Loss: 26.7220\n",
      "Epoch 24, Step 101, Training Loss: 34.6714\n",
      "Epoch 24, Step 102, Training Loss: 34.2168\n",
      "Epoch 24, Step 103, Training Loss: 31.5311\n",
      "Epoch 24, Step 104, Training Loss: 39.6996\n",
      "Epoch 24, Step 105, Training Loss: 29.3434\n",
      "Epoch 24, Step 106, Training Loss: 56.0884\n",
      "Epoch 24, Step 107, Training Loss: 48.4318\n",
      "Epoch 24, Step 108, Training Loss: 28.0219\n",
      "Epoch 24, Step 109, Training Loss: 19.0243\n",
      "Epoch 24, Step 110, Training Loss: 42.4242\n",
      "Epoch 24, Step 111, Training Loss: 38.9824\n",
      "Epoch 24, Step 112, Training Loss: 35.9118\n",
      "Epoch 24, Step 113, Training Loss: 40.3329\n",
      "Epoch 24, Step 114, Training Loss: 27.5608\n",
      "Epoch 24, Step 115, Training Loss: 56.8894\n",
      "Epoch 24, Step 116, Training Loss: 29.8980\n",
      "Epoch 24, Step 117, Training Loss: 43.4202\n",
      "Epoch 24, Step 118, Training Loss: 29.1378\n",
      "Epoch 24, Step 119, Training Loss: 38.8973\n",
      "Epoch 24, Step 120, Training Loss: 40.7430\n",
      "Epoch 24, Step 121, Training Loss: 65.0871\n",
      "Epoch 24, Step 122, Training Loss: 50.5147\n",
      "Epoch 24, Step 123, Training Loss: 37.1959\n",
      "Epoch 24, Step 124, Training Loss: 41.6086\n",
      "Epoch 24, Step 125, Training Loss: 41.1502\n",
      "Epoch 24, Step 126, Training Loss: 44.1580\n",
      "Epoch 24, Step 127, Training Loss: 34.8287\n",
      "Epoch 24, Step 128, Training Loss: 35.8419\n",
      "Epoch 24, Step 129, Training Loss: 47.7492\n",
      "Epoch 24, Step 130, Training Loss: 36.2650\n",
      "Epoch 24, Step 131, Training Loss: 32.0158\n",
      "Epoch 24, Step 132, Training Loss: 42.0534\n",
      "Epoch 24, Step 133, Training Loss: 54.7602\n",
      "Epoch 24, Step 134, Training Loss: 55.0019\n",
      "Epoch 24, Step 135, Training Loss: 38.8035\n",
      "Epoch 24, Step 136, Training Loss: 85.1305\n",
      "Epoch 24, Step 137, Training Loss: 34.5796\n",
      "Epoch 24, Step 138, Training Loss: 28.0183\n",
      "Epoch 24, Step 139, Training Loss: 37.6229\n",
      "Epoch 24, Step 140, Training Loss: 32.9528\n",
      "Epoch 24, Step 141, Training Loss: 52.0096\n",
      "Epoch 24, Step 142, Training Loss: 28.5356\n",
      "Epoch 24, Step 143, Training Loss: 32.1195\n",
      "Epoch 24, Step 144, Training Loss: 33.0412\n",
      "Epoch 24, Step 145, Training Loss: 32.5899\n",
      "Epoch 24, Step 146, Training Loss: 30.9313\n",
      "Epoch 24, Step 147, Training Loss: 29.6285\n",
      "Epoch 24, Step 148, Training Loss: 126.9627\n",
      "Epoch 24, Step 149, Training Loss: 58.1913\n",
      "Epoch 24, Step 150, Training Loss: 48.6654\n",
      "Epoch 24, Step 151, Training Loss: 34.0573\n",
      "Epoch 24, Step 152, Training Loss: 27.9698\n",
      "Epoch 24, Step 153, Training Loss: 26.7534\n",
      "Epoch 24, Step 154, Training Loss: 34.6807\n",
      "Epoch 24, Step 155, Training Loss: 53.4127\n",
      "Epoch 24, Step 156, Training Loss: 35.8157\n",
      "Epoch 24, Step 157, Training Loss: 38.1290\n",
      "Epoch 24, Step 158, Training Loss: 28.2198\n",
      "Epoch 24, Step 159, Training Loss: 52.6516\n",
      "Epoch 24, Step 160, Training Loss: 74.3211\n",
      "Epoch 24, Step 161, Training Loss: 37.0826\n",
      "Epoch 24, Step 162, Training Loss: 30.5933\n",
      "Epoch 24, Step 163, Training Loss: 26.7347\n",
      "Epoch 24, Step 164, Training Loss: 31.9642\n",
      "Epoch 24, Step 165, Training Loss: 35.0547\n",
      "Epoch 24, Step 166, Training Loss: 28.1620\n",
      "Epoch 24, Step 167, Training Loss: 37.7489\n",
      "Epoch 24, Step 168, Training Loss: 51.8584\n",
      "Epoch 24, Step 169, Training Loss: 24.8363\n",
      "Epoch 24, Step 170, Training Loss: 30.2854\n",
      "Epoch 24, Step 171, Training Loss: 25.1367\n",
      "Epoch 24, Step 172, Training Loss: 32.5795\n",
      "Epoch 24, Step 173, Training Loss: 33.6590\n",
      "Epoch 24, Step 174, Training Loss: 24.9732\n",
      "Epoch 24, Step 175, Training Loss: 32.8440\n",
      "Epoch 24, Step 176, Training Loss: 42.6167\n",
      "Epoch 24, Step 177, Training Loss: 61.8139\n",
      "Epoch 24, Step 178, Training Loss: 31.9305\n",
      "Epoch 24, Step 179, Training Loss: 25.6639\n",
      "Epoch 24, Step 180, Training Loss: 35.6047\n",
      "Epoch 24, Step 181, Training Loss: 31.8866\n",
      "Epoch 24, Step 182, Training Loss: 43.6589\n",
      "Epoch 24, Step 183, Training Loss: 27.3415\n",
      "Epoch 24, Step 184, Training Loss: 32.9285\n",
      "Epoch 24, Step 185, Training Loss: 27.4904\n",
      "Epoch 24, Step 186, Training Loss: 65.4869\n",
      "Epoch 24, Step 187, Training Loss: 29.0023\n",
      "Epoch 24, Step 188, Training Loss: 123.7692\n",
      "Epoch 24, Step 189, Training Loss: 37.6972\n",
      "Epoch 24, Step 190, Training Loss: 178.6858\n",
      "Epoch 24, Step 191, Training Loss: 20.5767\n",
      "Epoch 24, Step 192, Training Loss: 38.4075\n",
      "Epoch 24, Step 193, Training Loss: 35.7143\n",
      "Epoch 24, Step 194, Training Loss: 37.0723\n",
      "Epoch 24, Step 195, Training Loss: 37.4355\n",
      "Epoch 24, Step 196, Training Loss: 48.6864\n",
      "Epoch 24, Step 197, Training Loss: 35.4773\n",
      "Epoch 24, Step 198, Training Loss: 30.4603\n",
      "Epoch 24, Step 199, Training Loss: 35.9574\n",
      "Epoch 24, Step 200, Training Loss: 28.1506\n",
      "Epoch 24, Step 201, Training Loss: 23.8952\n",
      "Epoch 24, Step 202, Training Loss: 33.5918\n",
      "Epoch 24, Step 203, Training Loss: 54.3238\n",
      "Epoch 24, Step 204, Training Loss: 56.6786\n",
      "Epoch 24, Step 205, Training Loss: 37.2652\n",
      "Epoch 24, Step 206, Training Loss: 30.6010\n",
      "--- Epoch 24, Validation Loss: 36.9240 ---\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam( efficientnetb0.parameters(), lr=1e-4 )\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(25):\n",
    "\n",
    "    efficientnetb0.train()\n",
    "    for step, (images, keypoints) in enumerate(cour_keypoints_train_dataloader):\n",
    "\n",
    "        images = images.to(device)\n",
    "        keypoints = keypoints.to(device) # Moving to GPU\n",
    "\n",
    "        optimizer.zero_grad() # Flush gradients\n",
    "        outputs = efficientnetb0(images) # Get output of a model\n",
    "        loss = mse_loss( outputs, keypoints ) # Coompute loss \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        print(f'Epoch {epoch}, Step {step}, Training Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "    efficientnetb0.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, keypoints in cour_keypoints_val_dataloader:\n",
    "\n",
    "            images = images.to(device)\n",
    "            keypoints = keypoints.to(device)\n",
    "            outputs = efficientnetb0(images)\n",
    "  \n",
    "            val_loss_computed = mse_loss( outputs, keypoints )\n",
    "            val_loss += val_loss_computed.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(cour_keypoints_val_dataloader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        print(f'--- Epoch {epoch}, Validation Loss: {avg_val_loss:.4f} ---')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2f7cb1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 0, Training Loss: 21.6299\n",
      "Epoch 0, Step 1, Training Loss: 28.4326\n",
      "Epoch 0, Step 2, Training Loss: 24.3367\n",
      "Epoch 0, Step 3, Training Loss: 47.0435\n",
      "Epoch 0, Step 4, Training Loss: 63.3651\n",
      "Epoch 0, Step 5, Training Loss: 34.0175\n",
      "Epoch 0, Step 6, Training Loss: 33.4225\n",
      "Epoch 0, Step 7, Training Loss: 35.5992\n",
      "Epoch 0, Step 8, Training Loss: 21.9672\n",
      "Epoch 0, Step 9, Training Loss: 25.0670\n",
      "Epoch 0, Step 10, Training Loss: 53.8814\n",
      "Epoch 0, Step 11, Training Loss: 36.4046\n",
      "Epoch 0, Step 12, Training Loss: 48.4474\n",
      "Epoch 0, Step 13, Training Loss: 70.5909\n",
      "Epoch 0, Step 14, Training Loss: 29.4468\n",
      "Epoch 0, Step 15, Training Loss: 21.0102\n",
      "Epoch 0, Step 16, Training Loss: 20.6722\n",
      "Epoch 0, Step 17, Training Loss: 31.6865\n",
      "Epoch 0, Step 18, Training Loss: 22.6681\n",
      "Epoch 0, Step 19, Training Loss: 44.6915\n",
      "Epoch 0, Step 20, Training Loss: 31.1437\n",
      "Epoch 0, Step 21, Training Loss: 54.1156\n",
      "Epoch 0, Step 22, Training Loss: 54.7572\n",
      "Epoch 0, Step 23, Training Loss: 35.0997\n",
      "Epoch 0, Step 24, Training Loss: 29.6604\n",
      "Epoch 0, Step 25, Training Loss: 29.3836\n",
      "Epoch 0, Step 26, Training Loss: 40.1389\n",
      "Epoch 0, Step 27, Training Loss: 38.1292\n",
      "Epoch 0, Step 28, Training Loss: 27.0715\n",
      "Epoch 0, Step 29, Training Loss: 25.3597\n",
      "Epoch 0, Step 30, Training Loss: 21.4445\n",
      "Epoch 0, Step 31, Training Loss: 31.7491\n",
      "Epoch 0, Step 32, Training Loss: 28.0270\n",
      "Epoch 0, Step 33, Training Loss: 24.7076\n",
      "Epoch 0, Step 34, Training Loss: 31.6037\n",
      "Epoch 0, Step 35, Training Loss: 29.1025\n",
      "Epoch 0, Step 36, Training Loss: 39.9716\n",
      "Epoch 0, Step 37, Training Loss: 84.1248\n",
      "Epoch 0, Step 38, Training Loss: 41.9525\n",
      "Epoch 0, Step 39, Training Loss: 36.4279\n",
      "Epoch 0, Step 40, Training Loss: 39.0369\n",
      "Epoch 0, Step 41, Training Loss: 55.3375\n",
      "Epoch 0, Step 42, Training Loss: 35.8700\n",
      "Epoch 0, Step 43, Training Loss: 31.3195\n",
      "Epoch 0, Step 44, Training Loss: 36.6453\n",
      "Epoch 0, Step 45, Training Loss: 22.2171\n",
      "Epoch 0, Step 46, Training Loss: 19.6677\n",
      "Epoch 0, Step 47, Training Loss: 30.0252\n",
      "Epoch 0, Step 48, Training Loss: 27.7589\n",
      "Epoch 0, Step 49, Training Loss: 33.3866\n",
      "Epoch 0, Step 50, Training Loss: 28.9976\n",
      "Epoch 0, Step 51, Training Loss: 35.9760\n",
      "Epoch 0, Step 52, Training Loss: 28.8523\n",
      "Epoch 0, Step 53, Training Loss: 27.2051\n",
      "Epoch 0, Step 54, Training Loss: 35.5888\n",
      "Epoch 0, Step 55, Training Loss: 43.4497\n",
      "Epoch 0, Step 56, Training Loss: 57.9296\n",
      "Epoch 0, Step 57, Training Loss: 20.4369\n",
      "Epoch 0, Step 58, Training Loss: 42.7897\n",
      "Epoch 0, Step 59, Training Loss: 34.0854\n",
      "Epoch 0, Step 60, Training Loss: 77.8214\n",
      "Epoch 0, Step 61, Training Loss: 29.2164\n",
      "Epoch 0, Step 62, Training Loss: 32.5753\n",
      "Epoch 0, Step 63, Training Loss: 45.7176\n",
      "Epoch 0, Step 64, Training Loss: 36.9437\n",
      "Epoch 0, Step 65, Training Loss: 38.3758\n",
      "Epoch 0, Step 66, Training Loss: 37.7764\n",
      "Epoch 0, Step 67, Training Loss: 30.9462\n",
      "Epoch 0, Step 68, Training Loss: 29.9966\n",
      "Epoch 0, Step 69, Training Loss: 63.5807\n",
      "Epoch 0, Step 70, Training Loss: 38.4748\n",
      "Epoch 0, Step 71, Training Loss: 35.3376\n",
      "Epoch 0, Step 72, Training Loss: 44.9257\n",
      "Epoch 0, Step 73, Training Loss: 44.3526\n",
      "Epoch 0, Step 74, Training Loss: 29.9669\n",
      "Epoch 0, Step 75, Training Loss: 50.7367\n",
      "Epoch 0, Step 76, Training Loss: 63.0639\n",
      "Epoch 0, Step 77, Training Loss: 38.1328\n",
      "Epoch 0, Step 78, Training Loss: 21.1441\n",
      "Epoch 0, Step 79, Training Loss: 21.6406\n",
      "Epoch 0, Step 80, Training Loss: 52.1923\n",
      "Epoch 0, Step 81, Training Loss: 82.1040\n",
      "Epoch 0, Step 82, Training Loss: 23.6499\n",
      "Epoch 0, Step 83, Training Loss: 55.5848\n",
      "Epoch 0, Step 84, Training Loss: 71.3027\n",
      "Epoch 0, Step 85, Training Loss: 34.0913\n",
      "Epoch 0, Step 86, Training Loss: 23.3969\n",
      "Epoch 0, Step 87, Training Loss: 33.7218\n",
      "Epoch 0, Step 88, Training Loss: 45.1274\n",
      "Epoch 0, Step 89, Training Loss: 38.2626\n",
      "Epoch 0, Step 90, Training Loss: 26.5431\n",
      "Epoch 0, Step 91, Training Loss: 20.9876\n",
      "Epoch 0, Step 92, Training Loss: 48.8373\n",
      "Epoch 0, Step 93, Training Loss: 35.8731\n",
      "Epoch 0, Step 94, Training Loss: 50.7541\n",
      "Epoch 0, Step 95, Training Loss: 24.1873\n",
      "Epoch 0, Step 96, Training Loss: 26.7494\n",
      "Epoch 0, Step 97, Training Loss: 25.7245\n",
      "Epoch 0, Step 98, Training Loss: 45.7046\n",
      "Epoch 0, Step 99, Training Loss: 48.0597\n",
      "Epoch 0, Step 100, Training Loss: 24.0686\n",
      "Epoch 0, Step 101, Training Loss: 29.3684\n",
      "Epoch 0, Step 102, Training Loss: 30.3737\n",
      "Epoch 0, Step 103, Training Loss: 24.0094\n",
      "Epoch 0, Step 104, Training Loss: 36.7214\n",
      "Epoch 0, Step 105, Training Loss: 26.2652\n",
      "Epoch 0, Step 106, Training Loss: 51.8384\n",
      "Epoch 0, Step 107, Training Loss: 44.6654\n",
      "Epoch 0, Step 108, Training Loss: 28.3542\n",
      "Epoch 0, Step 109, Training Loss: 18.3077\n",
      "Epoch 0, Step 110, Training Loss: 39.7264\n",
      "Epoch 0, Step 111, Training Loss: 34.2315\n",
      "Epoch 0, Step 112, Training Loss: 32.9791\n",
      "Epoch 0, Step 113, Training Loss: 34.6656\n",
      "Epoch 0, Step 114, Training Loss: 25.6849\n",
      "Epoch 0, Step 115, Training Loss: 55.8622\n",
      "Epoch 0, Step 116, Training Loss: 27.0022\n",
      "Epoch 0, Step 117, Training Loss: 41.0980\n",
      "Epoch 0, Step 118, Training Loss: 26.2638\n",
      "Epoch 0, Step 119, Training Loss: 33.1110\n",
      "Epoch 0, Step 120, Training Loss: 34.2149\n",
      "Epoch 0, Step 121, Training Loss: 58.6019\n",
      "Epoch 0, Step 122, Training Loss: 48.5096\n",
      "Epoch 0, Step 123, Training Loss: 35.1100\n",
      "Epoch 0, Step 124, Training Loss: 40.3962\n",
      "Epoch 0, Step 125, Training Loss: 38.1512\n",
      "Epoch 0, Step 126, Training Loss: 39.7656\n",
      "Epoch 0, Step 127, Training Loss: 34.9642\n",
      "Epoch 0, Step 128, Training Loss: 31.3616\n",
      "Epoch 0, Step 129, Training Loss: 45.5009\n",
      "Epoch 0, Step 130, Training Loss: 27.6198\n",
      "Epoch 0, Step 131, Training Loss: 27.5533\n",
      "Epoch 0, Step 132, Training Loss: 41.0004\n",
      "Epoch 0, Step 133, Training Loss: 54.0385\n",
      "Epoch 0, Step 134, Training Loss: 49.1717\n",
      "Epoch 0, Step 135, Training Loss: 36.5355\n",
      "Epoch 0, Step 136, Training Loss: 75.0853\n",
      "Epoch 0, Step 137, Training Loss: 32.1954\n",
      "Epoch 0, Step 138, Training Loss: 23.3141\n",
      "Epoch 0, Step 139, Training Loss: 32.5307\n",
      "Epoch 0, Step 140, Training Loss: 27.9544\n",
      "Epoch 0, Step 141, Training Loss: 49.2426\n",
      "Epoch 0, Step 142, Training Loss: 24.1100\n",
      "Epoch 0, Step 143, Training Loss: 28.0034\n",
      "Epoch 0, Step 144, Training Loss: 29.0782\n",
      "Epoch 0, Step 145, Training Loss: 24.4613\n",
      "Epoch 0, Step 146, Training Loss: 25.6373\n",
      "Epoch 0, Step 147, Training Loss: 27.9921\n",
      "Epoch 0, Step 148, Training Loss: 116.3839\n",
      "Epoch 0, Step 149, Training Loss: 47.3279\n",
      "Epoch 0, Step 150, Training Loss: 42.6805\n",
      "Epoch 0, Step 151, Training Loss: 28.0817\n",
      "Epoch 0, Step 152, Training Loss: 28.4722\n",
      "Epoch 0, Step 153, Training Loss: 22.5219\n",
      "Epoch 0, Step 154, Training Loss: 30.1784\n",
      "Epoch 0, Step 155, Training Loss: 50.0856\n",
      "Epoch 0, Step 156, Training Loss: 32.2514\n",
      "Epoch 0, Step 157, Training Loss: 35.3393\n",
      "Epoch 0, Step 158, Training Loss: 25.4653\n",
      "Epoch 0, Step 159, Training Loss: 48.8068\n",
      "Epoch 0, Step 160, Training Loss: 70.2204\n",
      "Epoch 0, Step 161, Training Loss: 32.6781\n",
      "Epoch 0, Step 162, Training Loss: 24.2534\n",
      "Epoch 0, Step 163, Training Loss: 20.7269\n",
      "Epoch 0, Step 164, Training Loss: 31.3954\n",
      "Epoch 0, Step 165, Training Loss: 30.0120\n",
      "Epoch 0, Step 166, Training Loss: 24.6504\n",
      "Epoch 0, Step 167, Training Loss: 37.0336\n",
      "Epoch 0, Step 168, Training Loss: 49.2458\n",
      "Epoch 0, Step 169, Training Loss: 22.4236\n",
      "Epoch 0, Step 170, Training Loss: 25.5763\n",
      "Epoch 0, Step 171, Training Loss: 23.4381\n",
      "Epoch 0, Step 172, Training Loss: 31.6717\n",
      "Epoch 0, Step 173, Training Loss: 30.3637\n",
      "Epoch 0, Step 174, Training Loss: 25.2362\n",
      "Epoch 0, Step 175, Training Loss: 31.8954\n",
      "Epoch 0, Step 176, Training Loss: 35.4688\n",
      "Epoch 0, Step 177, Training Loss: 52.5439\n",
      "Epoch 0, Step 178, Training Loss: 29.1275\n",
      "Epoch 0, Step 179, Training Loss: 23.7077\n",
      "Epoch 0, Step 180, Training Loss: 28.2814\n",
      "Epoch 0, Step 181, Training Loss: 31.7620\n",
      "Epoch 0, Step 182, Training Loss: 37.9166\n",
      "Epoch 0, Step 183, Training Loss: 24.1036\n",
      "Epoch 0, Step 184, Training Loss: 29.5998\n",
      "Epoch 0, Step 185, Training Loss: 24.5965\n",
      "Epoch 0, Step 186, Training Loss: 63.1306\n",
      "Epoch 0, Step 187, Training Loss: 25.0150\n",
      "Epoch 0, Step 188, Training Loss: 138.0124\n",
      "Epoch 0, Step 189, Training Loss: 34.1588\n",
      "Epoch 0, Step 190, Training Loss: 169.6369\n",
      "Epoch 0, Step 191, Training Loss: 20.9586\n",
      "Epoch 0, Step 192, Training Loss: 38.9126\n",
      "Epoch 0, Step 193, Training Loss: 32.6631\n",
      "Epoch 0, Step 194, Training Loss: 26.1374\n",
      "Epoch 0, Step 195, Training Loss: 34.7456\n",
      "Epoch 0, Step 196, Training Loss: 46.6482\n",
      "Epoch 0, Step 197, Training Loss: 30.7552\n",
      "Epoch 0, Step 198, Training Loss: 29.3346\n",
      "Epoch 0, Step 199, Training Loss: 33.6167\n",
      "Epoch 0, Step 200, Training Loss: 29.2503\n",
      "Epoch 0, Step 201, Training Loss: 22.7100\n",
      "Epoch 0, Step 202, Training Loss: 31.3524\n",
      "Epoch 0, Step 203, Training Loss: 52.1545\n",
      "Epoch 0, Step 204, Training Loss: 55.4265\n",
      "Epoch 0, Step 205, Training Loss: 37.0840\n",
      "Epoch 0, Step 206, Training Loss: 30.1451\n",
      "--- Epoch 0, Validation Loss: 34.5364 ---\n",
      "Epoch 1, Step 0, Training Loss: 20.3348\n",
      "Epoch 1, Step 1, Training Loss: 22.5778\n",
      "Epoch 1, Step 2, Training Loss: 25.8651\n",
      "Epoch 1, Step 3, Training Loss: 42.8325\n",
      "Epoch 1, Step 4, Training Loss: 65.5599\n",
      "Epoch 1, Step 5, Training Loss: 29.0441\n",
      "Epoch 1, Step 6, Training Loss: 29.2830\n",
      "Epoch 1, Step 7, Training Loss: 36.3260\n",
      "Epoch 1, Step 8, Training Loss: 18.5723\n",
      "Epoch 1, Step 9, Training Loss: 22.9382\n",
      "Epoch 1, Step 10, Training Loss: 54.6167\n",
      "Epoch 1, Step 11, Training Loss: 33.0831\n",
      "Epoch 1, Step 12, Training Loss: 45.4132\n",
      "Epoch 1, Step 13, Training Loss: 68.4754\n",
      "Epoch 1, Step 14, Training Loss: 28.1992\n",
      "Epoch 1, Step 15, Training Loss: 19.1643\n",
      "Epoch 1, Step 16, Training Loss: 20.3445\n",
      "Epoch 1, Step 17, Training Loss: 27.9862\n",
      "Epoch 1, Step 18, Training Loss: 21.5606\n",
      "Epoch 1, Step 19, Training Loss: 44.3085\n",
      "Epoch 1, Step 20, Training Loss: 26.7428\n",
      "Epoch 1, Step 21, Training Loss: 50.8446\n",
      "Epoch 1, Step 22, Training Loss: 53.3468\n",
      "Epoch 1, Step 23, Training Loss: 33.1475\n",
      "Epoch 1, Step 24, Training Loss: 30.0112\n",
      "Epoch 1, Step 25, Training Loss: 27.9075\n",
      "Epoch 1, Step 26, Training Loss: 35.6157\n",
      "Epoch 1, Step 27, Training Loss: 37.3479\n",
      "Epoch 1, Step 28, Training Loss: 26.8747\n",
      "Epoch 1, Step 29, Training Loss: 20.2683\n",
      "Epoch 1, Step 30, Training Loss: 19.0326\n",
      "Epoch 1, Step 31, Training Loss: 28.1010\n",
      "Epoch 1, Step 32, Training Loss: 26.1612\n",
      "Epoch 1, Step 33, Training Loss: 22.4590\n",
      "Epoch 1, Step 34, Training Loss: 27.8227\n",
      "Epoch 1, Step 35, Training Loss: 30.0189\n",
      "Epoch 1, Step 36, Training Loss: 37.0012\n",
      "Epoch 1, Step 37, Training Loss: 82.2284\n",
      "Epoch 1, Step 38, Training Loss: 39.2430\n",
      "Epoch 1, Step 39, Training Loss: 34.2241\n",
      "Epoch 1, Step 40, Training Loss: 36.9737\n",
      "Epoch 1, Step 41, Training Loss: 54.9757\n",
      "Epoch 1, Step 42, Training Loss: 36.0093\n",
      "Epoch 1, Step 43, Training Loss: 27.9472\n",
      "Epoch 1, Step 44, Training Loss: 36.7416\n",
      "Epoch 1, Step 45, Training Loss: 21.5718\n",
      "Epoch 1, Step 46, Training Loss: 20.7740\n",
      "Epoch 1, Step 47, Training Loss: 27.0591\n",
      "Epoch 1, Step 48, Training Loss: 23.0608\n",
      "Epoch 1, Step 49, Training Loss: 31.0980\n",
      "Epoch 1, Step 50, Training Loss: 26.9167\n",
      "Epoch 1, Step 51, Training Loss: 32.4646\n",
      "Epoch 1, Step 52, Training Loss: 30.3146\n",
      "Epoch 1, Step 53, Training Loss: 23.0520\n",
      "Epoch 1, Step 54, Training Loss: 32.6391\n",
      "Epoch 1, Step 55, Training Loss: 36.6984\n",
      "Epoch 1, Step 56, Training Loss: 57.3409\n",
      "Epoch 1, Step 57, Training Loss: 19.5837\n",
      "Epoch 1, Step 58, Training Loss: 40.0650\n",
      "Epoch 1, Step 59, Training Loss: 30.7677\n",
      "Epoch 1, Step 60, Training Loss: 71.6842\n",
      "Epoch 1, Step 61, Training Loss: 22.3577\n",
      "Epoch 1, Step 62, Training Loss: 34.5801\n",
      "Epoch 1, Step 63, Training Loss: 41.8462\n",
      "Epoch 1, Step 64, Training Loss: 36.0985\n",
      "Epoch 1, Step 65, Training Loss: 31.2314\n",
      "Epoch 1, Step 66, Training Loss: 31.7035\n",
      "Epoch 1, Step 67, Training Loss: 29.5487\n",
      "Epoch 1, Step 68, Training Loss: 26.9006\n",
      "Epoch 1, Step 69, Training Loss: 61.6293\n",
      "Epoch 1, Step 70, Training Loss: 33.8526\n",
      "Epoch 1, Step 71, Training Loss: 31.5781\n",
      "Epoch 1, Step 72, Training Loss: 37.9136\n",
      "Epoch 1, Step 73, Training Loss: 40.1215\n",
      "Epoch 1, Step 74, Training Loss: 28.3805\n",
      "Epoch 1, Step 75, Training Loss: 46.3401\n",
      "Epoch 1, Step 76, Training Loss: 63.1951\n",
      "Epoch 1, Step 77, Training Loss: 35.0885\n",
      "Epoch 1, Step 78, Training Loss: 16.8920\n",
      "Epoch 1, Step 79, Training Loss: 19.8777\n",
      "Epoch 1, Step 80, Training Loss: 49.2853\n",
      "Epoch 1, Step 81, Training Loss: 81.3736\n",
      "Epoch 1, Step 82, Training Loss: 20.5518\n",
      "Epoch 1, Step 83, Training Loss: 50.5326\n",
      "Epoch 1, Step 84, Training Loss: 68.1909\n",
      "Epoch 1, Step 85, Training Loss: 31.8845\n",
      "Epoch 1, Step 86, Training Loss: 21.9842\n",
      "Epoch 1, Step 87, Training Loss: 32.4478\n",
      "Epoch 1, Step 88, Training Loss: 41.3060\n",
      "Epoch 1, Step 89, Training Loss: 34.2579\n",
      "Epoch 1, Step 90, Training Loss: 24.9856\n",
      "Epoch 1, Step 91, Training Loss: 21.0921\n",
      "Epoch 1, Step 92, Training Loss: 50.3592\n",
      "Epoch 1, Step 93, Training Loss: 31.9403\n",
      "Epoch 1, Step 94, Training Loss: 50.3471\n",
      "Epoch 1, Step 95, Training Loss: 19.6097\n",
      "Epoch 1, Step 96, Training Loss: 27.5318\n",
      "Epoch 1, Step 97, Training Loss: 22.3219\n",
      "Epoch 1, Step 98, Training Loss: 44.1515\n",
      "Epoch 1, Step 99, Training Loss: 43.9875\n",
      "Epoch 1, Step 100, Training Loss: 21.9289\n",
      "Epoch 1, Step 101, Training Loss: 25.5231\n",
      "Epoch 1, Step 102, Training Loss: 30.0095\n",
      "Epoch 1, Step 103, Training Loss: 23.4102\n",
      "Epoch 1, Step 104, Training Loss: 33.3248\n",
      "Epoch 1, Step 105, Training Loss: 24.3949\n",
      "Epoch 1, Step 106, Training Loss: 46.1009\n",
      "Epoch 1, Step 107, Training Loss: 44.1257\n",
      "Epoch 1, Step 108, Training Loss: 23.8638\n",
      "Epoch 1, Step 109, Training Loss: 16.2195\n",
      "Epoch 1, Step 110, Training Loss: 37.9326\n",
      "Epoch 1, Step 111, Training Loss: 33.3119\n",
      "Epoch 1, Step 112, Training Loss: 34.4591\n",
      "Epoch 1, Step 113, Training Loss: 33.1234\n",
      "Epoch 1, Step 114, Training Loss: 26.3661\n",
      "Epoch 1, Step 115, Training Loss: 54.4330\n",
      "Epoch 1, Step 116, Training Loss: 24.1487\n",
      "Epoch 1, Step 117, Training Loss: 39.7014\n",
      "Epoch 1, Step 118, Training Loss: 24.0500\n",
      "Epoch 1, Step 119, Training Loss: 32.4138\n",
      "Epoch 1, Step 120, Training Loss: 33.5648\n",
      "Epoch 1, Step 121, Training Loss: 58.7165\n",
      "Epoch 1, Step 122, Training Loss: 44.9978\n",
      "Epoch 1, Step 123, Training Loss: 32.9070\n",
      "Epoch 1, Step 124, Training Loss: 33.1983\n",
      "Epoch 1, Step 125, Training Loss: 37.6964\n",
      "Epoch 1, Step 126, Training Loss: 40.3201\n",
      "Epoch 1, Step 127, Training Loss: 32.0906\n",
      "Epoch 1, Step 128, Training Loss: 30.0426\n",
      "Epoch 1, Step 129, Training Loss: 43.3173\n",
      "Epoch 1, Step 130, Training Loss: 24.1044\n",
      "Epoch 1, Step 131, Training Loss: 26.3221\n",
      "Epoch 1, Step 132, Training Loss: 38.3311\n",
      "Epoch 1, Step 133, Training Loss: 53.4993\n",
      "Epoch 1, Step 134, Training Loss: 50.1959\n",
      "Epoch 1, Step 135, Training Loss: 35.8279\n",
      "Epoch 1, Step 136, Training Loss: 71.2990\n",
      "Epoch 1, Step 137, Training Loss: 30.9543\n",
      "Epoch 1, Step 138, Training Loss: 24.2775\n",
      "Epoch 1, Step 139, Training Loss: 31.0350\n",
      "Epoch 1, Step 140, Training Loss: 26.6931\n",
      "Epoch 1, Step 141, Training Loss: 45.3888\n",
      "Epoch 1, Step 142, Training Loss: 25.6460\n",
      "Epoch 1, Step 143, Training Loss: 30.2261\n",
      "Epoch 1, Step 144, Training Loss: 29.2290\n",
      "Epoch 1, Step 145, Training Loss: 22.0109\n",
      "Epoch 1, Step 146, Training Loss: 25.7102\n",
      "Epoch 1, Step 147, Training Loss: 27.6095\n",
      "Epoch 1, Step 148, Training Loss: 112.8468\n",
      "Epoch 1, Step 149, Training Loss: 49.3239\n",
      "Epoch 1, Step 150, Training Loss: 41.6462\n",
      "Epoch 1, Step 151, Training Loss: 28.6566\n",
      "Epoch 1, Step 152, Training Loss: 25.0416\n",
      "Epoch 1, Step 153, Training Loss: 24.1946\n",
      "Epoch 1, Step 154, Training Loss: 29.2804\n",
      "Epoch 1, Step 155, Training Loss: 50.0601\n",
      "Epoch 1, Step 156, Training Loss: 28.4478\n",
      "Epoch 1, Step 157, Training Loss: 31.6290\n",
      "Epoch 1, Step 158, Training Loss: 24.7268\n",
      "Epoch 1, Step 159, Training Loss: 46.3705\n",
      "Epoch 1, Step 160, Training Loss: 66.2434\n",
      "Epoch 1, Step 161, Training Loss: 31.5693\n",
      "Epoch 1, Step 162, Training Loss: 21.9320\n",
      "Epoch 1, Step 163, Training Loss: 21.0070\n",
      "Epoch 1, Step 164, Training Loss: 27.6771\n",
      "Epoch 1, Step 165, Training Loss: 29.2805\n",
      "Epoch 1, Step 166, Training Loss: 22.8596\n",
      "Epoch 1, Step 167, Training Loss: 39.5759\n",
      "Epoch 1, Step 168, Training Loss: 47.8760\n",
      "Epoch 1, Step 169, Training Loss: 21.2899\n",
      "Epoch 1, Step 170, Training Loss: 24.7047\n",
      "Epoch 1, Step 171, Training Loss: 19.3495\n",
      "Epoch 1, Step 172, Training Loss: 27.7514\n",
      "Epoch 1, Step 173, Training Loss: 30.8931\n",
      "Epoch 1, Step 174, Training Loss: 23.5351\n",
      "Epoch 1, Step 175, Training Loss: 29.8966\n",
      "Epoch 1, Step 176, Training Loss: 34.7930\n",
      "Epoch 1, Step 177, Training Loss: 52.8568\n",
      "Epoch 1, Step 178, Training Loss: 26.7211\n",
      "Epoch 1, Step 179, Training Loss: 22.8369\n",
      "Epoch 1, Step 180, Training Loss: 30.4140\n",
      "Epoch 1, Step 181, Training Loss: 29.3975\n",
      "Epoch 1, Step 182, Training Loss: 37.7444\n",
      "Epoch 1, Step 183, Training Loss: 21.7751\n",
      "Epoch 1, Step 184, Training Loss: 28.4210\n",
      "Epoch 1, Step 185, Training Loss: 26.7239\n",
      "Epoch 1, Step 186, Training Loss: 60.7738\n",
      "Epoch 1, Step 187, Training Loss: 24.1470\n",
      "Epoch 1, Step 188, Training Loss: 126.2277\n",
      "Epoch 1, Step 189, Training Loss: 32.4212\n",
      "Epoch 1, Step 190, Training Loss: 169.1088\n",
      "Epoch 1, Step 191, Training Loss: 19.3002\n",
      "Epoch 1, Step 192, Training Loss: 34.7272\n",
      "Epoch 1, Step 193, Training Loss: 33.6475\n",
      "Epoch 1, Step 194, Training Loss: 27.8093\n",
      "Epoch 1, Step 195, Training Loss: 35.5626\n",
      "Epoch 1, Step 196, Training Loss: 42.4848\n",
      "Epoch 1, Step 197, Training Loss: 30.7295\n",
      "Epoch 1, Step 198, Training Loss: 25.4660\n",
      "Epoch 1, Step 199, Training Loss: 32.1783\n",
      "Epoch 1, Step 200, Training Loss: 25.4210\n",
      "Epoch 1, Step 201, Training Loss: 21.4210\n",
      "Epoch 1, Step 202, Training Loss: 25.3371\n",
      "Epoch 1, Step 203, Training Loss: 50.9414\n",
      "Epoch 1, Step 204, Training Loss: 52.3565\n",
      "Epoch 1, Step 205, Training Loss: 33.3447\n",
      "Epoch 1, Step 206, Training Loss: 27.4443\n",
      "--- Epoch 1, Validation Loss: 34.5702 ---\n",
      "Epoch 2, Step 0, Training Loss: 21.8522\n",
      "Epoch 2, Step 1, Training Loss: 25.1652\n",
      "Epoch 2, Step 2, Training Loss: 21.6885\n",
      "Epoch 2, Step 3, Training Loss: 42.4674\n",
      "Epoch 2, Step 4, Training Loss: 63.6094\n",
      "Epoch 2, Step 5, Training Loss: 26.8095\n",
      "Epoch 2, Step 6, Training Loss: 27.0850\n",
      "Epoch 2, Step 7, Training Loss: 30.7963\n",
      "Epoch 2, Step 8, Training Loss: 16.3417\n",
      "Epoch 2, Step 9, Training Loss: 21.2406\n",
      "Epoch 2, Step 10, Training Loss: 56.0607\n",
      "Epoch 2, Step 11, Training Loss: 30.2681\n",
      "Epoch 2, Step 12, Training Loss: 46.3705\n",
      "Epoch 2, Step 13, Training Loss: 62.7248\n",
      "Epoch 2, Step 14, Training Loss: 25.4130\n",
      "Epoch 2, Step 15, Training Loss: 19.2476\n",
      "Epoch 2, Step 16, Training Loss: 19.0738\n",
      "Epoch 2, Step 17, Training Loss: 28.6843\n",
      "Epoch 2, Step 18, Training Loss: 20.2784\n",
      "Epoch 2, Step 19, Training Loss: 42.0644\n",
      "Epoch 2, Step 20, Training Loss: 26.8548\n",
      "Epoch 2, Step 21, Training Loss: 50.3631\n",
      "Epoch 2, Step 22, Training Loss: 50.8308\n",
      "Epoch 2, Step 23, Training Loss: 33.2078\n",
      "Epoch 2, Step 24, Training Loss: 31.8092\n",
      "Epoch 2, Step 25, Training Loss: 29.0678\n",
      "Epoch 2, Step 26, Training Loss: 35.8045\n",
      "Epoch 2, Step 27, Training Loss: 35.4815\n",
      "Epoch 2, Step 28, Training Loss: 26.5746\n",
      "Epoch 2, Step 29, Training Loss: 20.4655\n",
      "Epoch 2, Step 30, Training Loss: 19.1235\n",
      "Epoch 2, Step 31, Training Loss: 27.3971\n",
      "Epoch 2, Step 32, Training Loss: 25.6790\n",
      "Epoch 2, Step 33, Training Loss: 25.4815\n",
      "Epoch 2, Step 34, Training Loss: 29.4000\n",
      "Epoch 2, Step 35, Training Loss: 28.4559\n",
      "Epoch 2, Step 36, Training Loss: 35.0503\n",
      "Epoch 2, Step 37, Training Loss: 76.5186\n",
      "Epoch 2, Step 38, Training Loss: 39.0470\n",
      "Epoch 2, Step 39, Training Loss: 32.8243\n",
      "Epoch 2, Step 40, Training Loss: 34.8474\n",
      "Epoch 2, Step 41, Training Loss: 54.3573\n",
      "Epoch 2, Step 42, Training Loss: 32.3553\n",
      "Epoch 2, Step 43, Training Loss: 26.9768\n",
      "Epoch 2, Step 44, Training Loss: 32.2727\n",
      "Epoch 2, Step 45, Training Loss: 20.4037\n",
      "Epoch 2, Step 46, Training Loss: 19.0420\n",
      "Epoch 2, Step 47, Training Loss: 27.2389\n",
      "Epoch 2, Step 48, Training Loss: 22.2194\n",
      "Epoch 2, Step 49, Training Loss: 27.6872\n",
      "Epoch 2, Step 50, Training Loss: 25.5615\n",
      "Epoch 2, Step 51, Training Loss: 32.4128\n",
      "Epoch 2, Step 52, Training Loss: 26.8967\n",
      "Epoch 2, Step 53, Training Loss: 24.6676\n",
      "Epoch 2, Step 54, Training Loss: 29.6918\n",
      "Epoch 2, Step 55, Training Loss: 38.4015\n",
      "Epoch 2, Step 56, Training Loss: 52.8674\n",
      "Epoch 2, Step 57, Training Loss: 19.9373\n",
      "Epoch 2, Step 58, Training Loss: 39.2586\n",
      "Epoch 2, Step 59, Training Loss: 30.1757\n",
      "Epoch 2, Step 60, Training Loss: 69.2929\n",
      "Epoch 2, Step 61, Training Loss: 23.0176\n",
      "Epoch 2, Step 62, Training Loss: 32.0558\n",
      "Epoch 2, Step 63, Training Loss: 42.5455\n",
      "Epoch 2, Step 64, Training Loss: 33.3164\n",
      "Epoch 2, Step 65, Training Loss: 31.0012\n",
      "Epoch 2, Step 66, Training Loss: 28.5067\n",
      "Epoch 2, Step 67, Training Loss: 27.5808\n",
      "Epoch 2, Step 68, Training Loss: 26.3805\n",
      "Epoch 2, Step 69, Training Loss: 56.7982\n",
      "Epoch 2, Step 70, Training Loss: 31.3461\n",
      "Epoch 2, Step 71, Training Loss: 29.7384\n",
      "Epoch 2, Step 72, Training Loss: 38.4843\n",
      "Epoch 2, Step 73, Training Loss: 39.7357\n",
      "Epoch 2, Step 74, Training Loss: 28.2552\n",
      "Epoch 2, Step 75, Training Loss: 45.3890\n",
      "Epoch 2, Step 76, Training Loss: 61.8537\n",
      "Epoch 2, Step 77, Training Loss: 35.1769\n",
      "Epoch 2, Step 78, Training Loss: 17.2651\n",
      "Epoch 2, Step 79, Training Loss: 21.2729\n",
      "Epoch 2, Step 80, Training Loss: 48.1149\n",
      "Epoch 2, Step 81, Training Loss: 75.9314\n",
      "Epoch 2, Step 82, Training Loss: 21.6958\n",
      "Epoch 2, Step 83, Training Loss: 52.5603\n",
      "Epoch 2, Step 84, Training Loss: 67.0311\n",
      "Epoch 2, Step 85, Training Loss: 31.0805\n",
      "Epoch 2, Step 86, Training Loss: 22.7253\n",
      "Epoch 2, Step 87, Training Loss: 30.2871\n",
      "Epoch 2, Step 88, Training Loss: 38.2007\n",
      "Epoch 2, Step 89, Training Loss: 31.7250\n",
      "Epoch 2, Step 90, Training Loss: 24.6191\n",
      "Epoch 2, Step 91, Training Loss: 21.3176\n",
      "Epoch 2, Step 92, Training Loss: 47.9453\n",
      "Epoch 2, Step 93, Training Loss: 28.2737\n",
      "Epoch 2, Step 94, Training Loss: 45.6172\n",
      "Epoch 2, Step 95, Training Loss: 17.9086\n",
      "Epoch 2, Step 96, Training Loss: 25.8868\n",
      "Epoch 2, Step 97, Training Loss: 22.6481\n",
      "Epoch 2, Step 98, Training Loss: 39.7116\n",
      "Epoch 2, Step 99, Training Loss: 43.9779\n",
      "Epoch 2, Step 100, Training Loss: 23.6425\n",
      "Epoch 2, Step 101, Training Loss: 24.1717\n",
      "Epoch 2, Step 102, Training Loss: 30.1285\n",
      "Epoch 2, Step 103, Training Loss: 22.3028\n",
      "Epoch 2, Step 104, Training Loss: 32.9524\n",
      "Epoch 2, Step 105, Training Loss: 27.2831\n",
      "Epoch 2, Step 106, Training Loss: 45.2812\n",
      "Epoch 2, Step 107, Training Loss: 38.7230\n",
      "Epoch 2, Step 108, Training Loss: 24.6745\n",
      "Epoch 2, Step 109, Training Loss: 17.7272\n",
      "Epoch 2, Step 110, Training Loss: 39.8878\n",
      "Epoch 2, Step 111, Training Loss: 32.1072\n",
      "Epoch 2, Step 112, Training Loss: 32.2535\n",
      "Epoch 2, Step 113, Training Loss: 33.1613\n",
      "Epoch 2, Step 114, Training Loss: 24.6051\n",
      "Epoch 2, Step 115, Training Loss: 51.5375\n",
      "Epoch 2, Step 116, Training Loss: 21.4754\n",
      "Epoch 2, Step 117, Training Loss: 37.3234\n",
      "Epoch 2, Step 118, Training Loss: 23.4878\n",
      "Epoch 2, Step 119, Training Loss: 32.1458\n",
      "Epoch 2, Step 120, Training Loss: 31.2589\n",
      "Epoch 2, Step 121, Training Loss: 57.4692\n",
      "Epoch 2, Step 122, Training Loss: 44.7172\n",
      "Epoch 2, Step 123, Training Loss: 34.6542\n",
      "Epoch 2, Step 124, Training Loss: 30.5563\n",
      "Epoch 2, Step 125, Training Loss: 35.7670\n",
      "Epoch 2, Step 126, Training Loss: 42.9025\n",
      "Epoch 2, Step 127, Training Loss: 33.1094\n",
      "Epoch 2, Step 128, Training Loss: 30.7176\n",
      "Epoch 2, Step 129, Training Loss: 41.4083\n",
      "Epoch 2, Step 130, Training Loss: 24.1331\n",
      "Epoch 2, Step 131, Training Loss: 25.8746\n",
      "Epoch 2, Step 132, Training Loss: 36.4716\n",
      "Epoch 2, Step 133, Training Loss: 51.6504\n",
      "Epoch 2, Step 134, Training Loss: 47.0451\n",
      "Epoch 2, Step 135, Training Loss: 33.9030\n",
      "Epoch 2, Step 136, Training Loss: 67.1712\n",
      "Epoch 2, Step 137, Training Loss: 31.8273\n",
      "Epoch 2, Step 138, Training Loss: 20.4143\n",
      "Epoch 2, Step 139, Training Loss: 27.2502\n",
      "Epoch 2, Step 140, Training Loss: 25.7760\n",
      "Epoch 2, Step 141, Training Loss: 44.9165\n",
      "Epoch 2, Step 142, Training Loss: 25.5838\n",
      "Epoch 2, Step 143, Training Loss: 29.6639\n",
      "Epoch 2, Step 144, Training Loss: 34.4385\n",
      "Epoch 2, Step 145, Training Loss: 21.4697\n",
      "Epoch 2, Step 146, Training Loss: 25.2198\n",
      "Epoch 2, Step 147, Training Loss: 24.3519\n",
      "Epoch 2, Step 148, Training Loss: 110.1945\n",
      "Epoch 2, Step 149, Training Loss: 42.8735\n",
      "Epoch 2, Step 150, Training Loss: 41.4404\n",
      "Epoch 2, Step 151, Training Loss: 24.0108\n",
      "Epoch 2, Step 152, Training Loss: 21.3673\n",
      "Epoch 2, Step 153, Training Loss: 21.8208\n",
      "Epoch 2, Step 154, Training Loss: 29.8978\n",
      "Epoch 2, Step 155, Training Loss: 45.8053\n",
      "Epoch 2, Step 156, Training Loss: 24.6488\n",
      "Epoch 2, Step 157, Training Loss: 31.1111\n",
      "Epoch 2, Step 158, Training Loss: 23.8238\n",
      "Epoch 2, Step 159, Training Loss: 42.9154\n",
      "Epoch 2, Step 160, Training Loss: 66.3933\n",
      "Epoch 2, Step 161, Training Loss: 29.2721\n",
      "Epoch 2, Step 162, Training Loss: 22.1353\n",
      "Epoch 2, Step 163, Training Loss: 20.0747\n",
      "Epoch 2, Step 164, Training Loss: 24.9647\n",
      "Epoch 2, Step 165, Training Loss: 28.5667\n",
      "Epoch 2, Step 166, Training Loss: 22.6834\n",
      "Epoch 2, Step 167, Training Loss: 36.2391\n",
      "Epoch 2, Step 168, Training Loss: 44.5612\n",
      "Epoch 2, Step 169, Training Loss: 19.7337\n",
      "Epoch 2, Step 170, Training Loss: 20.7907\n",
      "Epoch 2, Step 171, Training Loss: 19.5467\n",
      "Epoch 2, Step 172, Training Loss: 26.3013\n",
      "Epoch 2, Step 173, Training Loss: 27.8546\n",
      "Epoch 2, Step 174, Training Loss: 24.3628\n",
      "Epoch 2, Step 175, Training Loss: 27.1537\n",
      "Epoch 2, Step 176, Training Loss: 33.8614\n",
      "Epoch 2, Step 177, Training Loss: 55.3559\n",
      "Epoch 2, Step 178, Training Loss: 26.1371\n",
      "Epoch 2, Step 179, Training Loss: 24.3615\n",
      "Epoch 2, Step 180, Training Loss: 28.2688\n",
      "Epoch 2, Step 181, Training Loss: 27.8861\n",
      "Epoch 2, Step 182, Training Loss: 34.7689\n",
      "Epoch 2, Step 183, Training Loss: 19.9079\n",
      "Epoch 2, Step 184, Training Loss: 28.3679\n",
      "Epoch 2, Step 185, Training Loss: 22.3141\n",
      "Epoch 2, Step 186, Training Loss: 63.5328\n",
      "Epoch 2, Step 187, Training Loss: 25.0883\n",
      "Epoch 2, Step 188, Training Loss: 125.4222\n",
      "Epoch 2, Step 189, Training Loss: 31.9372\n",
      "Epoch 2, Step 190, Training Loss: 164.3822\n",
      "Epoch 2, Step 191, Training Loss: 20.0196\n",
      "Epoch 2, Step 192, Training Loss: 29.8804\n",
      "Epoch 2, Step 193, Training Loss: 29.2318\n",
      "Epoch 2, Step 194, Training Loss: 25.6266\n",
      "Epoch 2, Step 195, Training Loss: 32.9312\n",
      "Epoch 2, Step 196, Training Loss: 45.7195\n",
      "Epoch 2, Step 197, Training Loss: 31.6240\n",
      "Epoch 2, Step 198, Training Loss: 26.1143\n",
      "Epoch 2, Step 199, Training Loss: 32.0035\n",
      "Epoch 2, Step 200, Training Loss: 21.8070\n",
      "Epoch 2, Step 201, Training Loss: 18.6307\n",
      "Epoch 2, Step 202, Training Loss: 24.5995\n",
      "Epoch 2, Step 203, Training Loss: 49.1280\n",
      "Epoch 2, Step 204, Training Loss: 53.5762\n",
      "Epoch 2, Step 205, Training Loss: 35.8336\n",
      "Epoch 2, Step 206, Training Loss: 26.0139\n",
      "--- Epoch 2, Validation Loss: 33.4895 ---\n",
      "Epoch 3, Step 0, Training Loss: 18.4929\n",
      "Epoch 3, Step 1, Training Loss: 24.0609\n",
      "Epoch 3, Step 2, Training Loss: 21.8557\n",
      "Epoch 3, Step 3, Training Loss: 43.4680\n",
      "Epoch 3, Step 4, Training Loss: 57.4730\n",
      "Epoch 3, Step 5, Training Loss: 27.8668\n",
      "Epoch 3, Step 6, Training Loss: 26.4839\n",
      "Epoch 3, Step 7, Training Loss: 28.3832\n",
      "Epoch 3, Step 8, Training Loss: 18.0677\n",
      "Epoch 3, Step 9, Training Loss: 20.5765\n",
      "Epoch 3, Step 10, Training Loss: 51.7796\n",
      "Epoch 3, Step 11, Training Loss: 30.5803\n",
      "Epoch 3, Step 12, Training Loss: 43.2971\n",
      "Epoch 3, Step 13, Training Loss: 62.9943\n",
      "Epoch 3, Step 14, Training Loss: 24.0043\n",
      "Epoch 3, Step 15, Training Loss: 20.7965\n",
      "Epoch 3, Step 16, Training Loss: 20.8571\n",
      "Epoch 3, Step 17, Training Loss: 30.0557\n",
      "Epoch 3, Step 18, Training Loss: 20.4427\n",
      "Epoch 3, Step 19, Training Loss: 41.5135\n",
      "Epoch 3, Step 20, Training Loss: 29.5885\n",
      "Epoch 3, Step 21, Training Loss: 49.9896\n",
      "Epoch 3, Step 22, Training Loss: 49.7758\n",
      "Epoch 3, Step 23, Training Loss: 31.3112\n",
      "Epoch 3, Step 24, Training Loss: 29.5056\n",
      "Epoch 3, Step 25, Training Loss: 29.3156\n",
      "Epoch 3, Step 26, Training Loss: 36.5936\n",
      "Epoch 3, Step 27, Training Loss: 33.1379\n",
      "Epoch 3, Step 28, Training Loss: 23.7402\n",
      "Epoch 3, Step 29, Training Loss: 19.6912\n",
      "Epoch 3, Step 30, Training Loss: 18.1649\n",
      "Epoch 3, Step 31, Training Loss: 26.4042\n",
      "Epoch 3, Step 32, Training Loss: 26.9794\n",
      "Epoch 3, Step 33, Training Loss: 22.8809\n",
      "Epoch 3, Step 34, Training Loss: 28.9174\n",
      "Epoch 3, Step 35, Training Loss: 28.8668\n",
      "Epoch 3, Step 36, Training Loss: 32.4904\n",
      "Epoch 3, Step 37, Training Loss: 74.6959\n",
      "Epoch 3, Step 38, Training Loss: 38.8809\n",
      "Epoch 3, Step 39, Training Loss: 32.4144\n",
      "Epoch 3, Step 40, Training Loss: 32.6490\n",
      "Epoch 3, Step 41, Training Loss: 52.3937\n",
      "Epoch 3, Step 42, Training Loss: 32.8999\n",
      "Epoch 3, Step 43, Training Loss: 28.0694\n",
      "Epoch 3, Step 44, Training Loss: 28.3140\n",
      "Epoch 3, Step 45, Training Loss: 20.7548\n",
      "Epoch 3, Step 46, Training Loss: 20.3429\n",
      "Epoch 3, Step 47, Training Loss: 26.5160\n",
      "Epoch 3, Step 48, Training Loss: 20.8181\n",
      "Epoch 3, Step 49, Training Loss: 29.4274\n",
      "Epoch 3, Step 50, Training Loss: 25.2397\n",
      "Epoch 3, Step 51, Training Loss: 29.2271\n",
      "Epoch 3, Step 52, Training Loss: 25.8487\n",
      "Epoch 3, Step 53, Training Loss: 21.5924\n",
      "Epoch 3, Step 54, Training Loss: 30.6540\n",
      "Epoch 3, Step 55, Training Loss: 37.9580\n",
      "Epoch 3, Step 56, Training Loss: 49.8367\n",
      "Epoch 3, Step 57, Training Loss: 17.3493\n",
      "Epoch 3, Step 58, Training Loss: 40.7411\n",
      "Epoch 3, Step 59, Training Loss: 32.4105\n",
      "Epoch 3, Step 60, Training Loss: 68.2024\n",
      "Epoch 3, Step 61, Training Loss: 21.7411\n",
      "Epoch 3, Step 62, Training Loss: 32.2882\n",
      "Epoch 3, Step 63, Training Loss: 40.1246\n",
      "Epoch 3, Step 64, Training Loss: 32.0257\n",
      "Epoch 3, Step 65, Training Loss: 30.4802\n",
      "Epoch 3, Step 66, Training Loss: 29.9767\n",
      "Epoch 3, Step 67, Training Loss: 27.1750\n",
      "Epoch 3, Step 68, Training Loss: 27.6438\n",
      "Epoch 3, Step 69, Training Loss: 57.9805\n",
      "Epoch 3, Step 70, Training Loss: 27.9675\n",
      "Epoch 3, Step 71, Training Loss: 31.3832\n",
      "Epoch 3, Step 72, Training Loss: 37.4265\n",
      "Epoch 3, Step 73, Training Loss: 41.0302\n",
      "Epoch 3, Step 74, Training Loss: 25.5776\n",
      "Epoch 3, Step 75, Training Loss: 43.1196\n",
      "Epoch 3, Step 76, Training Loss: 61.7915\n",
      "Epoch 3, Step 77, Training Loss: 36.6886\n",
      "Epoch 3, Step 78, Training Loss: 18.6622\n",
      "Epoch 3, Step 79, Training Loss: 18.3397\n",
      "Epoch 3, Step 80, Training Loss: 47.5864\n",
      "Epoch 3, Step 81, Training Loss: 77.0745\n",
      "Epoch 3, Step 82, Training Loss: 21.9722\n",
      "Epoch 3, Step 83, Training Loss: 51.7475\n",
      "Epoch 3, Step 84, Training Loss: 66.3566\n",
      "Epoch 3, Step 85, Training Loss: 30.2634\n",
      "Epoch 3, Step 86, Training Loss: 23.2496\n",
      "Epoch 3, Step 87, Training Loss: 29.8512\n",
      "Epoch 3, Step 88, Training Loss: 40.7602\n",
      "Epoch 3, Step 89, Training Loss: 31.2100\n",
      "Epoch 3, Step 90, Training Loss: 22.3869\n",
      "Epoch 3, Step 91, Training Loss: 18.2637\n",
      "Epoch 3, Step 92, Training Loss: 46.6318\n",
      "Epoch 3, Step 93, Training Loss: 28.9955\n",
      "Epoch 3, Step 94, Training Loss: 45.2620\n",
      "Epoch 3, Step 95, Training Loss: 17.4421\n",
      "Epoch 3, Step 96, Training Loss: 25.5756\n",
      "Epoch 3, Step 97, Training Loss: 22.3923\n",
      "Epoch 3, Step 98, Training Loss: 37.4404\n",
      "Epoch 3, Step 99, Training Loss: 43.5670\n",
      "Epoch 3, Step 100, Training Loss: 21.4665\n",
      "Epoch 3, Step 101, Training Loss: 23.0584\n",
      "Epoch 3, Step 102, Training Loss: 30.1115\n",
      "Epoch 3, Step 103, Training Loss: 23.9113\n",
      "Epoch 3, Step 104, Training Loss: 34.8066\n",
      "Epoch 3, Step 105, Training Loss: 23.9474\n",
      "Epoch 3, Step 106, Training Loss: 42.9190\n",
      "Epoch 3, Step 107, Training Loss: 37.7507\n",
      "Epoch 3, Step 108, Training Loss: 25.0054\n",
      "Epoch 3, Step 109, Training Loss: 18.1316\n",
      "Epoch 3, Step 110, Training Loss: 34.4246\n",
      "Epoch 3, Step 111, Training Loss: 29.9642\n",
      "Epoch 3, Step 112, Training Loss: 31.0537\n",
      "Epoch 3, Step 113, Training Loss: 33.4930\n",
      "Epoch 3, Step 114, Training Loss: 23.6157\n",
      "Epoch 3, Step 115, Training Loss: 51.4109\n",
      "Epoch 3, Step 116, Training Loss: 21.9952\n",
      "Epoch 3, Step 117, Training Loss: 38.0931\n",
      "Epoch 3, Step 118, Training Loss: 24.8830\n",
      "Epoch 3, Step 119, Training Loss: 31.6053\n",
      "Epoch 3, Step 120, Training Loss: 30.3669\n",
      "Epoch 3, Step 121, Training Loss: 54.3978\n",
      "Epoch 3, Step 122, Training Loss: 47.2472\n",
      "Epoch 3, Step 123, Training Loss: 33.3802\n",
      "Epoch 3, Step 124, Training Loss: 32.0001\n",
      "Epoch 3, Step 125, Training Loss: 36.4757\n",
      "Epoch 3, Step 126, Training Loss: 41.4381\n",
      "Epoch 3, Step 127, Training Loss: 30.5074\n",
      "Epoch 3, Step 128, Training Loss: 28.2091\n",
      "Epoch 3, Step 129, Training Loss: 41.6412\n",
      "Epoch 3, Step 130, Training Loss: 23.0920\n",
      "Epoch 3, Step 131, Training Loss: 24.3723\n",
      "Epoch 3, Step 132, Training Loss: 37.5189\n",
      "Epoch 3, Step 133, Training Loss: 51.4264\n",
      "Epoch 3, Step 134, Training Loss: 46.5119\n",
      "Epoch 3, Step 135, Training Loss: 32.9499\n",
      "Epoch 3, Step 136, Training Loss: 68.2061\n",
      "Epoch 3, Step 137, Training Loss: 31.8334\n",
      "Epoch 3, Step 138, Training Loss: 23.7695\n",
      "Epoch 3, Step 139, Training Loss: 30.1822\n",
      "Epoch 3, Step 140, Training Loss: 26.2504\n",
      "Epoch 3, Step 141, Training Loss: 46.2748\n",
      "Epoch 3, Step 142, Training Loss: 27.4490\n",
      "Epoch 3, Step 143, Training Loss: 30.6955\n",
      "Epoch 3, Step 144, Training Loss: 26.6637\n",
      "Epoch 3, Step 145, Training Loss: 22.5558\n",
      "Epoch 3, Step 146, Training Loss: 23.1751\n",
      "Epoch 3, Step 147, Training Loss: 25.9467\n",
      "Epoch 3, Step 148, Training Loss: 108.1443\n",
      "Epoch 3, Step 149, Training Loss: 43.7046\n",
      "Epoch 3, Step 150, Training Loss: 39.1720\n",
      "Epoch 3, Step 151, Training Loss: 23.9777\n",
      "Epoch 3, Step 152, Training Loss: 19.2677\n",
      "Epoch 3, Step 153, Training Loss: 20.6685\n",
      "Epoch 3, Step 154, Training Loss: 28.1302\n",
      "Epoch 3, Step 155, Training Loss: 45.1235\n",
      "Epoch 3, Step 156, Training Loss: 26.0681\n",
      "Epoch 3, Step 157, Training Loss: 33.2174\n",
      "Epoch 3, Step 158, Training Loss: 25.4019\n",
      "Epoch 3, Step 159, Training Loss: 40.4936\n",
      "Epoch 3, Step 160, Training Loss: 64.3692\n",
      "Epoch 3, Step 161, Training Loss: 30.9878\n",
      "Epoch 3, Step 162, Training Loss: 19.8658\n",
      "Epoch 3, Step 163, Training Loss: 19.1125\n",
      "Epoch 3, Step 164, Training Loss: 23.9082\n",
      "Epoch 3, Step 165, Training Loss: 25.6127\n",
      "Epoch 3, Step 166, Training Loss: 19.8912\n",
      "Epoch 3, Step 167, Training Loss: 35.6795\n",
      "Epoch 3, Step 168, Training Loss: 44.0417\n",
      "Epoch 3, Step 169, Training Loss: 19.4596\n",
      "Epoch 3, Step 170, Training Loss: 20.5610\n",
      "Epoch 3, Step 171, Training Loss: 18.7051\n",
      "Epoch 3, Step 172, Training Loss: 28.4906\n",
      "Epoch 3, Step 173, Training Loss: 28.4092\n",
      "Epoch 3, Step 174, Training Loss: 24.6948\n",
      "Epoch 3, Step 175, Training Loss: 26.5970\n",
      "Epoch 3, Step 176, Training Loss: 35.9449\n",
      "Epoch 3, Step 177, Training Loss: 46.9075\n",
      "Epoch 3, Step 178, Training Loss: 24.7942\n",
      "Epoch 3, Step 179, Training Loss: 21.9600\n",
      "Epoch 3, Step 180, Training Loss: 26.2068\n",
      "Epoch 3, Step 181, Training Loss: 26.8758\n",
      "Epoch 3, Step 182, Training Loss: 35.7239\n",
      "Epoch 3, Step 183, Training Loss: 21.6778\n",
      "Epoch 3, Step 184, Training Loss: 28.4334\n",
      "Epoch 3, Step 185, Training Loss: 23.0201\n",
      "Epoch 3, Step 186, Training Loss: 58.9042\n",
      "Epoch 3, Step 187, Training Loss: 21.6915\n",
      "Epoch 3, Step 188, Training Loss: 127.4947\n",
      "Epoch 3, Step 189, Training Loss: 31.2143\n",
      "Epoch 3, Step 190, Training Loss: 162.5078\n",
      "Epoch 3, Step 191, Training Loss: 19.9340\n",
      "Epoch 3, Step 192, Training Loss: 33.7600\n",
      "Epoch 3, Step 193, Training Loss: 27.5418\n",
      "Epoch 3, Step 194, Training Loss: 23.9979\n",
      "Epoch 3, Step 195, Training Loss: 32.0498\n",
      "Epoch 3, Step 196, Training Loss: 41.0768\n",
      "Epoch 3, Step 197, Training Loss: 30.6513\n",
      "Epoch 3, Step 198, Training Loss: 25.2084\n",
      "Epoch 3, Step 199, Training Loss: 30.8325\n",
      "Epoch 3, Step 200, Training Loss: 23.2755\n",
      "Epoch 3, Step 201, Training Loss: 18.0918\n",
      "Epoch 3, Step 202, Training Loss: 24.6919\n",
      "Epoch 3, Step 203, Training Loss: 47.9044\n",
      "Epoch 3, Step 204, Training Loss: 47.1991\n",
      "Epoch 3, Step 205, Training Loss: 34.7752\n",
      "Epoch 3, Step 206, Training Loss: 30.9835\n",
      "--- Epoch 3, Validation Loss: 32.4529 ---\n",
      "Epoch 4, Step 0, Training Loss: 20.9155\n",
      "Epoch 4, Step 1, Training Loss: 22.8570\n",
      "Epoch 4, Step 2, Training Loss: 21.4839\n",
      "Epoch 4, Step 3, Training Loss: 43.1181\n",
      "Epoch 4, Step 4, Training Loss: 59.2280\n",
      "Epoch 4, Step 5, Training Loss: 30.2618\n",
      "Epoch 4, Step 6, Training Loss: 26.4166\n",
      "Epoch 4, Step 7, Training Loss: 30.1270\n",
      "Epoch 4, Step 8, Training Loss: 15.8849\n",
      "Epoch 4, Step 9, Training Loss: 20.5111\n",
      "Epoch 4, Step 10, Training Loss: 53.3799\n",
      "Epoch 4, Step 11, Training Loss: 30.8953\n",
      "Epoch 4, Step 12, Training Loss: 42.7335\n",
      "Epoch 4, Step 13, Training Loss: 61.1083\n",
      "Epoch 4, Step 14, Training Loss: 25.4513\n",
      "Epoch 4, Step 15, Training Loss: 20.8481\n",
      "Epoch 4, Step 16, Training Loss: 18.6316\n",
      "Epoch 4, Step 17, Training Loss: 27.9969\n",
      "Epoch 4, Step 18, Training Loss: 20.3160\n",
      "Epoch 4, Step 19, Training Loss: 42.3161\n",
      "Epoch 4, Step 20, Training Loss: 27.4363\n",
      "Epoch 4, Step 21, Training Loss: 44.2100\n",
      "Epoch 4, Step 22, Training Loss: 51.1719\n",
      "Epoch 4, Step 23, Training Loss: 31.8910\n",
      "Epoch 4, Step 24, Training Loss: 27.7250\n",
      "Epoch 4, Step 25, Training Loss: 25.8118\n",
      "Epoch 4, Step 26, Training Loss: 33.4410\n",
      "Epoch 4, Step 27, Training Loss: 33.4691\n",
      "Epoch 4, Step 28, Training Loss: 27.2686\n",
      "Epoch 4, Step 29, Training Loss: 17.8876\n",
      "Epoch 4, Step 30, Training Loss: 19.9171\n",
      "Epoch 4, Step 31, Training Loss: 23.8436\n",
      "Epoch 4, Step 32, Training Loss: 24.4936\n",
      "Epoch 4, Step 33, Training Loss: 25.1234\n",
      "Epoch 4, Step 34, Training Loss: 27.2865\n",
      "Epoch 4, Step 35, Training Loss: 27.1208\n",
      "Epoch 4, Step 36, Training Loss: 32.8186\n",
      "Epoch 4, Step 37, Training Loss: 72.0488\n",
      "Epoch 4, Step 38, Training Loss: 35.5856\n",
      "Epoch 4, Step 39, Training Loss: 30.7984\n",
      "Epoch 4, Step 40, Training Loss: 29.7056\n",
      "Epoch 4, Step 41, Training Loss: 53.0816\n",
      "Epoch 4, Step 42, Training Loss: 32.3994\n",
      "Epoch 4, Step 43, Training Loss: 25.3651\n",
      "Epoch 4, Step 44, Training Loss: 30.8671\n",
      "Epoch 4, Step 45, Training Loss: 20.4478\n",
      "Epoch 4, Step 46, Training Loss: 19.3028\n",
      "Epoch 4, Step 47, Training Loss: 23.7580\n",
      "Epoch 4, Step 48, Training Loss: 21.1786\n",
      "Epoch 4, Step 49, Training Loss: 26.5984\n",
      "Epoch 4, Step 50, Training Loss: 27.1794\n",
      "Epoch 4, Step 51, Training Loss: 29.5929\n",
      "Epoch 4, Step 52, Training Loss: 26.3268\n",
      "Epoch 4, Step 53, Training Loss: 19.7468\n",
      "Epoch 4, Step 54, Training Loss: 30.5328\n",
      "Epoch 4, Step 55, Training Loss: 35.9386\n",
      "Epoch 4, Step 56, Training Loss: 50.9220\n",
      "Epoch 4, Step 57, Training Loss: 16.2832\n",
      "Epoch 4, Step 58, Training Loss: 41.1728\n",
      "Epoch 4, Step 59, Training Loss: 27.4469\n",
      "Epoch 4, Step 60, Training Loss: 66.7076\n",
      "Epoch 4, Step 61, Training Loss: 20.7001\n",
      "Epoch 4, Step 62, Training Loss: 33.6300\n",
      "Epoch 4, Step 63, Training Loss: 39.5321\n",
      "Epoch 4, Step 64, Training Loss: 32.7390\n",
      "Epoch 4, Step 65, Training Loss: 33.7603\n",
      "Epoch 4, Step 66, Training Loss: 27.1554\n",
      "Epoch 4, Step 67, Training Loss: 24.7191\n",
      "Epoch 4, Step 68, Training Loss: 26.6135\n",
      "Epoch 4, Step 69, Training Loss: 56.7709\n",
      "Epoch 4, Step 70, Training Loss: 28.1303\n",
      "Epoch 4, Step 71, Training Loss: 25.7986\n",
      "Epoch 4, Step 72, Training Loss: 37.5387\n",
      "Epoch 4, Step 73, Training Loss: 36.5512\n",
      "Epoch 4, Step 74, Training Loss: 25.1824\n",
      "Epoch 4, Step 75, Training Loss: 43.6077\n",
      "Epoch 4, Step 76, Training Loss: 59.9979\n",
      "Epoch 4, Step 77, Training Loss: 35.3408\n",
      "Epoch 4, Step 78, Training Loss: 15.2874\n",
      "Epoch 4, Step 79, Training Loss: 23.1786\n",
      "Epoch 4, Step 80, Training Loss: 47.3538\n",
      "Epoch 4, Step 81, Training Loss: 72.4565\n",
      "Epoch 4, Step 82, Training Loss: 21.0029\n",
      "Epoch 4, Step 83, Training Loss: 48.9361\n",
      "Epoch 4, Step 84, Training Loss: 64.5683\n",
      "Epoch 4, Step 85, Training Loss: 28.3597\n",
      "Epoch 4, Step 86, Training Loss: 22.4458\n",
      "Epoch 4, Step 87, Training Loss: 27.7323\n",
      "Epoch 4, Step 88, Training Loss: 38.8561\n",
      "Epoch 4, Step 89, Training Loss: 29.9412\n",
      "Epoch 4, Step 90, Training Loss: 22.1172\n",
      "Epoch 4, Step 91, Training Loss: 20.7115\n",
      "Epoch 4, Step 92, Training Loss: 45.5531\n",
      "Epoch 4, Step 93, Training Loss: 28.0949\n",
      "Epoch 4, Step 94, Training Loss: 44.6455\n",
      "Epoch 4, Step 95, Training Loss: 18.0585\n",
      "Epoch 4, Step 96, Training Loss: 25.4504\n",
      "Epoch 4, Step 97, Training Loss: 21.4518\n",
      "Epoch 4, Step 98, Training Loss: 36.2171\n",
      "Epoch 4, Step 99, Training Loss: 42.7576\n",
      "Epoch 4, Step 100, Training Loss: 20.8725\n",
      "Epoch 4, Step 101, Training Loss: 23.2513\n",
      "Epoch 4, Step 102, Training Loss: 25.6166\n",
      "Epoch 4, Step 103, Training Loss: 22.9679\n",
      "Epoch 4, Step 104, Training Loss: 32.9887\n",
      "Epoch 4, Step 105, Training Loss: 24.5925\n",
      "Epoch 4, Step 106, Training Loss: 41.7656\n",
      "Epoch 4, Step 107, Training Loss: 34.5036\n",
      "Epoch 4, Step 108, Training Loss: 22.1153\n",
      "Epoch 4, Step 109, Training Loss: 15.1254\n",
      "Epoch 4, Step 110, Training Loss: 35.7585\n",
      "Epoch 4, Step 111, Training Loss: 27.6424\n",
      "Epoch 4, Step 112, Training Loss: 30.1670\n",
      "Epoch 4, Step 113, Training Loss: 31.6536\n",
      "Epoch 4, Step 114, Training Loss: 21.0876\n",
      "Epoch 4, Step 115, Training Loss: 49.8728\n",
      "Epoch 4, Step 116, Training Loss: 20.6915\n",
      "Epoch 4, Step 117, Training Loss: 34.3686\n",
      "Epoch 4, Step 118, Training Loss: 20.4753\n",
      "Epoch 4, Step 119, Training Loss: 30.6360\n",
      "Epoch 4, Step 120, Training Loss: 30.0458\n",
      "Epoch 4, Step 121, Training Loss: 54.9506\n",
      "Epoch 4, Step 122, Training Loss: 44.3585\n",
      "Epoch 4, Step 123, Training Loss: 33.3709\n",
      "Epoch 4, Step 124, Training Loss: 27.2152\n",
      "Epoch 4, Step 125, Training Loss: 35.8605\n",
      "Epoch 4, Step 126, Training Loss: 38.2491\n",
      "Epoch 4, Step 127, Training Loss: 30.8787\n",
      "Epoch 4, Step 128, Training Loss: 26.8680\n",
      "Epoch 4, Step 129, Training Loss: 41.5789\n",
      "Epoch 4, Step 130, Training Loss: 21.1434\n",
      "Epoch 4, Step 131, Training Loss: 24.2319\n",
      "Epoch 4, Step 132, Training Loss: 38.7470\n",
      "Epoch 4, Step 133, Training Loss: 52.6811\n",
      "Epoch 4, Step 134, Training Loss: 44.1581\n",
      "Epoch 4, Step 135, Training Loss: 33.0603\n",
      "Epoch 4, Step 136, Training Loss: 72.0921\n",
      "Epoch 4, Step 137, Training Loss: 26.6300\n",
      "Epoch 4, Step 138, Training Loss: 19.0594\n",
      "Epoch 4, Step 139, Training Loss: 28.0078\n",
      "Epoch 4, Step 140, Training Loss: 22.5968\n",
      "Epoch 4, Step 141, Training Loss: 44.4666\n",
      "Epoch 4, Step 142, Training Loss: 26.4025\n",
      "Epoch 4, Step 143, Training Loss: 27.5047\n",
      "Epoch 4, Step 144, Training Loss: 25.0185\n",
      "Epoch 4, Step 145, Training Loss: 21.9260\n",
      "Epoch 4, Step 146, Training Loss: 25.9103\n",
      "Epoch 4, Step 147, Training Loss: 22.4205\n",
      "Epoch 4, Step 148, Training Loss: 107.4646\n",
      "Epoch 4, Step 149, Training Loss: 45.0450\n",
      "Epoch 4, Step 150, Training Loss: 38.0700\n",
      "Epoch 4, Step 151, Training Loss: 23.6781\n",
      "Epoch 4, Step 152, Training Loss: 21.5595\n",
      "Epoch 4, Step 153, Training Loss: 23.1377\n",
      "Epoch 4, Step 154, Training Loss: 27.5889\n",
      "Epoch 4, Step 155, Training Loss: 42.8106\n",
      "Epoch 4, Step 156, Training Loss: 24.9532\n",
      "Epoch 4, Step 157, Training Loss: 28.7254\n",
      "Epoch 4, Step 158, Training Loss: 24.3165\n",
      "Epoch 4, Step 159, Training Loss: 39.5979\n",
      "Epoch 4, Step 160, Training Loss: 64.3894\n",
      "Epoch 4, Step 161, Training Loss: 27.2479\n",
      "Epoch 4, Step 162, Training Loss: 19.1338\n",
      "Epoch 4, Step 163, Training Loss: 21.0345\n",
      "Epoch 4, Step 164, Training Loss: 25.0464\n",
      "Epoch 4, Step 165, Training Loss: 24.9246\n",
      "Epoch 4, Step 166, Training Loss: 21.2474\n",
      "Epoch 4, Step 167, Training Loss: 34.6225\n",
      "Epoch 4, Step 168, Training Loss: 44.9223\n",
      "Epoch 4, Step 169, Training Loss: 21.8553\n",
      "Epoch 4, Step 170, Training Loss: 19.3251\n",
      "Epoch 4, Step 171, Training Loss: 17.9023\n",
      "Epoch 4, Step 172, Training Loss: 27.3605\n",
      "Epoch 4, Step 173, Training Loss: 27.9809\n",
      "Epoch 4, Step 174, Training Loss: 24.3597\n",
      "Epoch 4, Step 175, Training Loss: 25.5109\n",
      "Epoch 4, Step 176, Training Loss: 31.7115\n",
      "Epoch 4, Step 177, Training Loss: 45.7048\n",
      "Epoch 4, Step 178, Training Loss: 22.0530\n",
      "Epoch 4, Step 179, Training Loss: 23.3454\n",
      "Epoch 4, Step 180, Training Loss: 24.4727\n",
      "Epoch 4, Step 181, Training Loss: 26.3144\n",
      "Epoch 4, Step 182, Training Loss: 31.4821\n",
      "Epoch 4, Step 183, Training Loss: 19.1376\n",
      "Epoch 4, Step 184, Training Loss: 26.3833\n",
      "Epoch 4, Step 185, Training Loss: 24.3576\n",
      "Epoch 4, Step 186, Training Loss: 57.4788\n",
      "Epoch 4, Step 187, Training Loss: 20.6853\n",
      "Epoch 4, Step 188, Training Loss: 131.0688\n",
      "Epoch 4, Step 189, Training Loss: 29.6808\n",
      "Epoch 4, Step 190, Training Loss: 165.0130\n",
      "Epoch 4, Step 191, Training Loss: 19.0074\n",
      "Epoch 4, Step 192, Training Loss: 30.4515\n",
      "Epoch 4, Step 193, Training Loss: 28.2466\n",
      "Epoch 4, Step 194, Training Loss: 20.1986\n",
      "Epoch 4, Step 195, Training Loss: 30.4551\n",
      "Epoch 4, Step 196, Training Loss: 40.9611\n",
      "Epoch 4, Step 197, Training Loss: 29.4068\n",
      "Epoch 4, Step 198, Training Loss: 25.8874\n",
      "Epoch 4, Step 199, Training Loss: 29.4437\n",
      "Epoch 4, Step 200, Training Loss: 20.8219\n",
      "Epoch 4, Step 201, Training Loss: 16.9072\n",
      "Epoch 4, Step 202, Training Loss: 21.7052\n",
      "Epoch 4, Step 203, Training Loss: 46.7169\n",
      "Epoch 4, Step 204, Training Loss: 44.4449\n",
      "Epoch 4, Step 205, Training Loss: 29.3003\n",
      "Epoch 4, Step 206, Training Loss: 24.3856\n",
      "--- Epoch 4, Validation Loss: 35.1639 ---\n",
      "Epoch 5, Step 0, Training Loss: 17.7212\n",
      "Epoch 5, Step 1, Training Loss: 23.4503\n",
      "Epoch 5, Step 2, Training Loss: 19.6703\n",
      "Epoch 5, Step 3, Training Loss: 39.7615\n",
      "Epoch 5, Step 4, Training Loss: 56.1925\n",
      "Epoch 5, Step 5, Training Loss: 23.5718\n",
      "Epoch 5, Step 6, Training Loss: 24.0365\n",
      "Epoch 5, Step 7, Training Loss: 29.2515\n",
      "Epoch 5, Step 8, Training Loss: 16.1544\n",
      "Epoch 5, Step 9, Training Loss: 19.5009\n",
      "Epoch 5, Step 10, Training Loss: 51.7997\n",
      "Epoch 5, Step 11, Training Loss: 27.7989\n",
      "Epoch 5, Step 12, Training Loss: 38.6337\n",
      "Epoch 5, Step 13, Training Loss: 58.4282\n",
      "Epoch 5, Step 14, Training Loss: 23.8171\n",
      "Epoch 5, Step 15, Training Loss: 19.2913\n",
      "Epoch 5, Step 16, Training Loss: 18.6246\n",
      "Epoch 5, Step 17, Training Loss: 24.0640\n",
      "Epoch 5, Step 18, Training Loss: 20.1523\n",
      "Epoch 5, Step 19, Training Loss: 40.6546\n",
      "Epoch 5, Step 20, Training Loss: 22.7970\n",
      "Epoch 5, Step 21, Training Loss: 43.2495\n",
      "Epoch 5, Step 22, Training Loss: 47.2634\n",
      "Epoch 5, Step 23, Training Loss: 28.1592\n",
      "Epoch 5, Step 24, Training Loss: 25.2887\n",
      "Epoch 5, Step 25, Training Loss: 24.6730\n",
      "Epoch 5, Step 26, Training Loss: 27.6749\n",
      "Epoch 5, Step 27, Training Loss: 30.7312\n",
      "Epoch 5, Step 28, Training Loss: 21.5898\n",
      "Epoch 5, Step 29, Training Loss: 16.7322\n",
      "Epoch 5, Step 30, Training Loss: 19.5384\n",
      "Epoch 5, Step 31, Training Loss: 22.8379\n",
      "Epoch 5, Step 32, Training Loss: 25.5496\n",
      "Epoch 5, Step 33, Training Loss: 22.6714\n",
      "Epoch 5, Step 34, Training Loss: 23.4354\n",
      "Epoch 5, Step 35, Training Loss: 24.2636\n",
      "Epoch 5, Step 36, Training Loss: 30.8539\n",
      "Epoch 5, Step 37, Training Loss: 72.5751\n",
      "Epoch 5, Step 38, Training Loss: 29.9770\n",
      "Epoch 5, Step 39, Training Loss: 26.6877\n",
      "Epoch 5, Step 40, Training Loss: 28.0993\n",
      "Epoch 5, Step 41, Training Loss: 47.7728\n",
      "Epoch 5, Step 42, Training Loss: 29.6411\n",
      "Epoch 5, Step 43, Training Loss: 25.0396\n",
      "Epoch 5, Step 44, Training Loss: 27.8412\n",
      "Epoch 5, Step 45, Training Loss: 19.2569\n",
      "Epoch 5, Step 46, Training Loss: 17.7725\n",
      "Epoch 5, Step 47, Training Loss: 21.2297\n",
      "Epoch 5, Step 48, Training Loss: 17.4479\n",
      "Epoch 5, Step 49, Training Loss: 23.4864\n",
      "Epoch 5, Step 50, Training Loss: 22.1274\n",
      "Epoch 5, Step 51, Training Loss: 25.2797\n",
      "Epoch 5, Step 52, Training Loss: 20.1950\n",
      "Epoch 5, Step 53, Training Loss: 17.3751\n",
      "Epoch 5, Step 54, Training Loss: 26.3609\n",
      "Epoch 5, Step 55, Training Loss: 33.5406\n",
      "Epoch 5, Step 56, Training Loss: 47.0846\n",
      "Epoch 5, Step 57, Training Loss: 16.1720\n",
      "Epoch 5, Step 58, Training Loss: 35.5928\n",
      "Epoch 5, Step 59, Training Loss: 27.1527\n",
      "Epoch 5, Step 60, Training Loss: 60.7414\n",
      "Epoch 5, Step 61, Training Loss: 21.8608\n",
      "Epoch 5, Step 62, Training Loss: 30.0367\n",
      "Epoch 5, Step 63, Training Loss: 36.7747\n",
      "Epoch 5, Step 64, Training Loss: 27.9027\n",
      "Epoch 5, Step 65, Training Loss: 27.1702\n",
      "Epoch 5, Step 66, Training Loss: 25.2491\n",
      "Epoch 5, Step 67, Training Loss: 20.8265\n",
      "Epoch 5, Step 68, Training Loss: 22.3362\n",
      "Epoch 5, Step 69, Training Loss: 54.2272\n",
      "Epoch 5, Step 70, Training Loss: 27.9625\n",
      "Epoch 5, Step 71, Training Loss: 22.9263\n",
      "Epoch 5, Step 72, Training Loss: 30.9839\n",
      "Epoch 5, Step 73, Training Loss: 33.5499\n",
      "Epoch 5, Step 74, Training Loss: 23.3644\n",
      "Epoch 5, Step 75, Training Loss: 39.8956\n",
      "Epoch 5, Step 76, Training Loss: 58.1658\n",
      "Epoch 5, Step 77, Training Loss: 32.1944\n",
      "Epoch 5, Step 78, Training Loss: 13.0610\n",
      "Epoch 5, Step 79, Training Loss: 19.2218\n",
      "Epoch 5, Step 80, Training Loss: 40.8957\n",
      "Epoch 5, Step 81, Training Loss: 71.4538\n",
      "Epoch 5, Step 82, Training Loss: 17.8258\n",
      "Epoch 5, Step 83, Training Loss: 45.7137\n",
      "Epoch 5, Step 84, Training Loss: 60.8582\n",
      "Epoch 5, Step 85, Training Loss: 26.4592\n",
      "Epoch 5, Step 86, Training Loss: 19.2648\n",
      "Epoch 5, Step 87, Training Loss: 23.3902\n",
      "Epoch 5, Step 88, Training Loss: 34.5036\n",
      "Epoch 5, Step 89, Training Loss: 27.2704\n",
      "Epoch 5, Step 90, Training Loss: 20.2273\n",
      "Epoch 5, Step 91, Training Loss: 18.2744\n",
      "Epoch 5, Step 92, Training Loss: 41.9198\n",
      "Epoch 5, Step 93, Training Loss: 25.0530\n",
      "Epoch 5, Step 94, Training Loss: 40.2159\n",
      "Epoch 5, Step 95, Training Loss: 15.3788\n",
      "Epoch 5, Step 96, Training Loss: 22.7590\n",
      "Epoch 5, Step 97, Training Loss: 20.5887\n",
      "Epoch 5, Step 98, Training Loss: 33.8255\n",
      "Epoch 5, Step 99, Training Loss: 41.5992\n",
      "Epoch 5, Step 100, Training Loss: 16.5632\n",
      "Epoch 5, Step 101, Training Loss: 21.2158\n",
      "Epoch 5, Step 102, Training Loss: 23.9901\n",
      "Epoch 5, Step 103, Training Loss: 18.3684\n",
      "Epoch 5, Step 104, Training Loss: 29.9293\n",
      "Epoch 5, Step 105, Training Loss: 19.3816\n",
      "Epoch 5, Step 106, Training Loss: 37.4007\n",
      "Epoch 5, Step 107, Training Loss: 31.9536\n",
      "Epoch 5, Step 108, Training Loss: 20.3542\n",
      "Epoch 5, Step 109, Training Loss: 15.2285\n",
      "Epoch 5, Step 110, Training Loss: 32.8228\n",
      "Epoch 5, Step 111, Training Loss: 24.8836\n",
      "Epoch 5, Step 112, Training Loss: 26.2559\n",
      "Epoch 5, Step 113, Training Loss: 27.1681\n",
      "Epoch 5, Step 114, Training Loss: 19.5340\n",
      "Epoch 5, Step 115, Training Loss: 43.4998\n",
      "Epoch 5, Step 116, Training Loss: 17.4536\n",
      "Epoch 5, Step 117, Training Loss: 30.4493\n",
      "Epoch 5, Step 118, Training Loss: 21.0121\n",
      "Epoch 5, Step 119, Training Loss: 26.5457\n",
      "Epoch 5, Step 120, Training Loss: 24.0097\n",
      "Epoch 5, Step 121, Training Loss: 51.3211\n",
      "Epoch 5, Step 122, Training Loss: 40.5829\n",
      "Epoch 5, Step 123, Training Loss: 27.1822\n",
      "Epoch 5, Step 124, Training Loss: 23.6142\n",
      "Epoch 5, Step 125, Training Loss: 31.5981\n",
      "Epoch 5, Step 126, Training Loss: 33.3369\n",
      "Epoch 5, Step 127, Training Loss: 25.0321\n",
      "Epoch 5, Step 128, Training Loss: 22.4849\n",
      "Epoch 5, Step 129, Training Loss: 36.8622\n",
      "Epoch 5, Step 130, Training Loss: 21.6681\n",
      "Epoch 5, Step 131, Training Loss: 20.1412\n",
      "Epoch 5, Step 132, Training Loss: 32.5977\n",
      "Epoch 5, Step 133, Training Loss: 46.8029\n",
      "Epoch 5, Step 134, Training Loss: 44.0734\n",
      "Epoch 5, Step 135, Training Loss: 28.0205\n",
      "Epoch 5, Step 136, Training Loss: 63.4063\n",
      "Epoch 5, Step 137, Training Loss: 21.6364\n",
      "Epoch 5, Step 138, Training Loss: 17.0121\n",
      "Epoch 5, Step 139, Training Loss: 27.5251\n",
      "Epoch 5, Step 140, Training Loss: 19.8504\n",
      "Epoch 5, Step 141, Training Loss: 37.6073\n",
      "Epoch 5, Step 142, Training Loss: 18.7211\n",
      "Epoch 5, Step 143, Training Loss: 23.3441\n",
      "Epoch 5, Step 144, Training Loss: 21.1842\n",
      "Epoch 5, Step 145, Training Loss: 19.8568\n",
      "Epoch 5, Step 146, Training Loss: 17.1511\n",
      "Epoch 5, Step 147, Training Loss: 21.2924\n",
      "Epoch 5, Step 148, Training Loss: 104.8422\n",
      "Epoch 5, Step 149, Training Loss: 39.2582\n",
      "Epoch 5, Step 150, Training Loss: 38.7138\n",
      "Epoch 5, Step 151, Training Loss: 24.1142\n",
      "Epoch 5, Step 152, Training Loss: 18.5664\n",
      "Epoch 5, Step 153, Training Loss: 19.1106\n",
      "Epoch 5, Step 154, Training Loss: 21.9871\n",
      "Epoch 5, Step 155, Training Loss: 37.5822\n",
      "Epoch 5, Step 156, Training Loss: 23.4025\n",
      "Epoch 5, Step 157, Training Loss: 28.1853\n",
      "Epoch 5, Step 158, Training Loss: 19.3623\n",
      "Epoch 5, Step 159, Training Loss: 35.5769\n",
      "Epoch 5, Step 160, Training Loss: 60.4000\n",
      "Epoch 5, Step 161, Training Loss: 24.2737\n",
      "Epoch 5, Step 162, Training Loss: 17.7808\n",
      "Epoch 5, Step 163, Training Loss: 15.7169\n",
      "Epoch 5, Step 164, Training Loss: 20.2278\n",
      "Epoch 5, Step 165, Training Loss: 22.9683\n",
      "Epoch 5, Step 166, Training Loss: 14.3256\n",
      "Epoch 5, Step 167, Training Loss: 28.2579\n",
      "Epoch 5, Step 168, Training Loss: 37.6476\n",
      "Epoch 5, Step 169, Training Loss: 20.2592\n",
      "Epoch 5, Step 170, Training Loss: 18.7485\n",
      "Epoch 5, Step 171, Training Loss: 12.1130\n",
      "Epoch 5, Step 172, Training Loss: 24.9051\n",
      "Epoch 5, Step 173, Training Loss: 22.8040\n",
      "Epoch 5, Step 174, Training Loss: 18.9446\n",
      "Epoch 5, Step 175, Training Loss: 21.8596\n",
      "Epoch 5, Step 176, Training Loss: 25.9202\n",
      "Epoch 5, Step 177, Training Loss: 47.1701\n",
      "Epoch 5, Step 178, Training Loss: 20.7071\n",
      "Epoch 5, Step 179, Training Loss: 16.0453\n",
      "Epoch 5, Step 180, Training Loss: 24.1754\n",
      "Epoch 5, Step 181, Training Loss: 20.5311\n",
      "Epoch 5, Step 182, Training Loss: 27.1105\n",
      "Epoch 5, Step 183, Training Loss: 15.2032\n",
      "Epoch 5, Step 184, Training Loss: 20.4358\n",
      "Epoch 5, Step 185, Training Loss: 17.7452\n",
      "Epoch 5, Step 186, Training Loss: 45.2597\n",
      "Epoch 5, Step 187, Training Loss: 17.3227\n",
      "Epoch 5, Step 188, Training Loss: 114.1580\n",
      "Epoch 5, Step 189, Training Loss: 24.3931\n",
      "Epoch 5, Step 190, Training Loss: 150.1954\n",
      "Epoch 5, Step 191, Training Loss: 14.9388\n",
      "Epoch 5, Step 192, Training Loss: 27.0585\n",
      "Epoch 5, Step 193, Training Loss: 26.0122\n",
      "Epoch 5, Step 194, Training Loss: 16.8380\n",
      "Epoch 5, Step 195, Training Loss: 24.9111\n",
      "Epoch 5, Step 196, Training Loss: 35.7921\n",
      "Epoch 5, Step 197, Training Loss: 23.6210\n",
      "Epoch 5, Step 198, Training Loss: 18.8416\n",
      "Epoch 5, Step 199, Training Loss: 21.5927\n",
      "Epoch 5, Step 200, Training Loss: 17.2364\n",
      "Epoch 5, Step 201, Training Loss: 13.7360\n",
      "Epoch 5, Step 202, Training Loss: 19.7563\n",
      "Epoch 5, Step 203, Training Loss: 42.5145\n",
      "Epoch 5, Step 204, Training Loss: 45.8429\n",
      "Epoch 5, Step 205, Training Loss: 24.3258\n",
      "Epoch 5, Step 206, Training Loss: 19.9483\n",
      "--- Epoch 5, Validation Loss: 27.9721 ---\n",
      "Epoch 6, Step 0, Training Loss: 16.6922\n",
      "Epoch 6, Step 1, Training Loss: 16.7443\n",
      "Epoch 6, Step 2, Training Loss: 16.6864\n",
      "Epoch 6, Step 3, Training Loss: 35.0434\n",
      "Epoch 6, Step 4, Training Loss: 49.5203\n",
      "Epoch 6, Step 5, Training Loss: 17.7519\n",
      "Epoch 6, Step 6, Training Loss: 18.1011\n",
      "Epoch 6, Step 7, Training Loss: 23.8173\n",
      "Epoch 6, Step 8, Training Loss: 12.5479\n",
      "Epoch 6, Step 9, Training Loss: 15.1425\n",
      "Epoch 6, Step 10, Training Loss: 49.8558\n",
      "Epoch 6, Step 11, Training Loss: 21.5730\n",
      "Epoch 6, Step 12, Training Loss: 32.6294\n",
      "Epoch 6, Step 13, Training Loss: 51.3997\n",
      "Epoch 6, Step 14, Training Loss: 22.8957\n",
      "Epoch 6, Step 15, Training Loss: 16.2180\n",
      "Epoch 6, Step 16, Training Loss: 14.7040\n",
      "Epoch 6, Step 17, Training Loss: 21.6120\n",
      "Epoch 6, Step 18, Training Loss: 14.5354\n",
      "Epoch 6, Step 19, Training Loss: 37.6165\n",
      "Epoch 6, Step 20, Training Loss: 21.5190\n",
      "Epoch 6, Step 21, Training Loss: 34.3208\n",
      "Epoch 6, Step 22, Training Loss: 41.1844\n",
      "Epoch 6, Step 23, Training Loss: 23.5632\n",
      "Epoch 6, Step 24, Training Loss: 21.2353\n",
      "Epoch 6, Step 25, Training Loss: 20.2294\n",
      "Epoch 6, Step 26, Training Loss: 24.2405\n",
      "Epoch 6, Step 27, Training Loss: 27.5738\n",
      "Epoch 6, Step 28, Training Loss: 18.7321\n",
      "Epoch 6, Step 29, Training Loss: 12.6676\n",
      "Epoch 6, Step 30, Training Loss: 14.0541\n",
      "Epoch 6, Step 31, Training Loss: 22.2971\n",
      "Epoch 6, Step 32, Training Loss: 21.8732\n",
      "Epoch 6, Step 33, Training Loss: 19.6553\n",
      "Epoch 6, Step 34, Training Loss: 20.7339\n",
      "Epoch 6, Step 35, Training Loss: 20.0404\n",
      "Epoch 6, Step 36, Training Loss: 24.7455\n",
      "Epoch 6, Step 37, Training Loss: 58.5243\n",
      "Epoch 6, Step 38, Training Loss: 29.2548\n",
      "Epoch 6, Step 39, Training Loss: 22.0624\n",
      "Epoch 6, Step 40, Training Loss: 24.8261\n",
      "Epoch 6, Step 41, Training Loss: 39.8535\n",
      "Epoch 6, Step 42, Training Loss: 21.8196\n",
      "Epoch 6, Step 43, Training Loss: 18.4748\n",
      "Epoch 6, Step 44, Training Loss: 22.7754\n",
      "Epoch 6, Step 45, Training Loss: 14.7323\n",
      "Epoch 6, Step 46, Training Loss: 11.9500\n",
      "Epoch 6, Step 47, Training Loss: 19.4890\n",
      "Epoch 6, Step 48, Training Loss: 16.3006\n",
      "Epoch 6, Step 49, Training Loss: 19.2299\n",
      "Epoch 6, Step 50, Training Loss: 18.0876\n",
      "Epoch 6, Step 51, Training Loss: 21.9120\n",
      "Epoch 6, Step 52, Training Loss: 16.1076\n",
      "Epoch 6, Step 53, Training Loss: 13.6744\n",
      "Epoch 6, Step 54, Training Loss: 21.0406\n",
      "Epoch 6, Step 55, Training Loss: 27.3896\n",
      "Epoch 6, Step 56, Training Loss: 43.1548\n",
      "Epoch 6, Step 57, Training Loss: 15.8492\n",
      "Epoch 6, Step 58, Training Loss: 30.8836\n",
      "Epoch 6, Step 59, Training Loss: 22.9077\n",
      "Epoch 6, Step 60, Training Loss: 55.7487\n",
      "Epoch 6, Step 61, Training Loss: 19.3473\n",
      "Epoch 6, Step 62, Training Loss: 26.2926\n",
      "Epoch 6, Step 63, Training Loss: 35.7758\n",
      "Epoch 6, Step 64, Training Loss: 27.1920\n",
      "Epoch 6, Step 65, Training Loss: 23.9840\n",
      "Epoch 6, Step 66, Training Loss: 19.9608\n",
      "Epoch 6, Step 67, Training Loss: 24.3032\n",
      "Epoch 6, Step 68, Training Loss: 19.2280\n",
      "Epoch 6, Step 69, Training Loss: 53.8436\n",
      "Epoch 6, Step 70, Training Loss: 22.7761\n",
      "Epoch 6, Step 71, Training Loss: 18.9025\n",
      "Epoch 6, Step 72, Training Loss: 27.2170\n",
      "Epoch 6, Step 73, Training Loss: 31.2882\n",
      "Epoch 6, Step 74, Training Loss: 18.4363\n",
      "Epoch 6, Step 75, Training Loss: 38.4217\n",
      "Epoch 6, Step 76, Training Loss: 47.1323\n",
      "Epoch 6, Step 77, Training Loss: 28.1247\n",
      "Epoch 6, Step 78, Training Loss: 13.4061\n",
      "Epoch 6, Step 79, Training Loss: 15.5135\n",
      "Epoch 6, Step 80, Training Loss: 35.7730\n",
      "Epoch 6, Step 81, Training Loss: 60.3678\n",
      "Epoch 6, Step 82, Training Loss: 13.9772\n",
      "Epoch 6, Step 83, Training Loss: 43.3302\n",
      "Epoch 6, Step 84, Training Loss: 52.3776\n",
      "Epoch 6, Step 85, Training Loss: 19.3830\n",
      "Epoch 6, Step 86, Training Loss: 17.0208\n",
      "Epoch 6, Step 87, Training Loss: 20.5571\n",
      "Epoch 6, Step 88, Training Loss: 29.9632\n",
      "Epoch 6, Step 89, Training Loss: 23.2531\n",
      "Epoch 6, Step 90, Training Loss: 18.3471\n",
      "Epoch 6, Step 91, Training Loss: 13.5871\n",
      "Epoch 6, Step 92, Training Loss: 36.2789\n",
      "Epoch 6, Step 93, Training Loss: 21.6710\n",
      "Epoch 6, Step 94, Training Loss: 37.5226\n",
      "Epoch 6, Step 95, Training Loss: 12.7749\n",
      "Epoch 6, Step 96, Training Loss: 19.3572\n",
      "Epoch 6, Step 97, Training Loss: 17.6286\n",
      "Epoch 6, Step 98, Training Loss: 27.8302\n",
      "Epoch 6, Step 99, Training Loss: 35.3591\n",
      "Epoch 6, Step 100, Training Loss: 13.7913\n",
      "Epoch 6, Step 101, Training Loss: 16.8870\n",
      "Epoch 6, Step 102, Training Loss: 21.1198\n",
      "Epoch 6, Step 103, Training Loss: 17.4984\n",
      "Epoch 6, Step 104, Training Loss: 26.9623\n",
      "Epoch 6, Step 105, Training Loss: 15.3694\n",
      "Epoch 6, Step 106, Training Loss: 32.8728\n",
      "Epoch 6, Step 107, Training Loss: 28.5213\n",
      "Epoch 6, Step 108, Training Loss: 17.3278\n",
      "Epoch 6, Step 109, Training Loss: 12.3129\n",
      "Epoch 6, Step 110, Training Loss: 24.2787\n",
      "Epoch 6, Step 111, Training Loss: 20.0658\n",
      "Epoch 6, Step 112, Training Loss: 22.2661\n",
      "Epoch 6, Step 113, Training Loss: 25.9241\n",
      "Epoch 6, Step 114, Training Loss: 15.7534\n",
      "Epoch 6, Step 115, Training Loss: 35.6103\n",
      "Epoch 6, Step 116, Training Loss: 15.8091\n",
      "Epoch 6, Step 117, Training Loss: 25.3528\n",
      "Epoch 6, Step 118, Training Loss: 18.6127\n",
      "Epoch 6, Step 119, Training Loss: 19.1016\n",
      "Epoch 6, Step 120, Training Loss: 20.7117\n",
      "Epoch 6, Step 121, Training Loss: 45.1825\n",
      "Epoch 6, Step 122, Training Loss: 37.0860\n",
      "Epoch 6, Step 123, Training Loss: 25.9947\n",
      "Epoch 6, Step 124, Training Loss: 20.5363\n",
      "Epoch 6, Step 125, Training Loss: 25.6794\n",
      "Epoch 6, Step 126, Training Loss: 29.0008\n",
      "Epoch 6, Step 127, Training Loss: 21.6151\n",
      "Epoch 6, Step 128, Training Loss: 19.8767\n",
      "Epoch 6, Step 129, Training Loss: 33.2329\n",
      "Epoch 6, Step 130, Training Loss: 14.5065\n",
      "Epoch 6, Step 131, Training Loss: 17.2734\n",
      "Epoch 6, Step 132, Training Loss: 26.0843\n",
      "Epoch 6, Step 133, Training Loss: 43.2339\n",
      "Epoch 6, Step 134, Training Loss: 32.3030\n",
      "Epoch 6, Step 135, Training Loss: 24.1735\n",
      "Epoch 6, Step 136, Training Loss: 57.5071\n",
      "Epoch 6, Step 137, Training Loss: 17.6399\n",
      "Epoch 6, Step 138, Training Loss: 16.3613\n",
      "Epoch 6, Step 139, Training Loss: 23.1386\n",
      "Epoch 6, Step 140, Training Loss: 16.3088\n",
      "Epoch 6, Step 141, Training Loss: 29.5547\n",
      "Epoch 6, Step 142, Training Loss: 14.9767\n",
      "Epoch 6, Step 143, Training Loss: 19.1794\n",
      "Epoch 6, Step 144, Training Loss: 17.3430\n",
      "Epoch 6, Step 145, Training Loss: 15.9298\n",
      "Epoch 6, Step 146, Training Loss: 15.4465\n",
      "Epoch 6, Step 147, Training Loss: 18.3873\n",
      "Epoch 6, Step 148, Training Loss: 89.1090\n",
      "Epoch 6, Step 149, Training Loss: 31.0747\n",
      "Epoch 6, Step 150, Training Loss: 29.7902\n",
      "Epoch 6, Step 151, Training Loss: 18.4812\n",
      "Epoch 6, Step 152, Training Loss: 13.9442\n",
      "Epoch 6, Step 153, Training Loss: 14.9803\n",
      "Epoch 6, Step 154, Training Loss: 21.5144\n",
      "Epoch 6, Step 155, Training Loss: 30.3254\n",
      "Epoch 6, Step 156, Training Loss: 18.1598\n",
      "Epoch 6, Step 157, Training Loss: 24.0393\n",
      "Epoch 6, Step 158, Training Loss: 15.6998\n",
      "Epoch 6, Step 159, Training Loss: 29.4354\n",
      "Epoch 6, Step 160, Training Loss: 57.0948\n",
      "Epoch 6, Step 161, Training Loss: 21.5183\n",
      "Epoch 6, Step 162, Training Loss: 14.9036\n",
      "Epoch 6, Step 163, Training Loss: 19.2381\n",
      "Epoch 6, Step 164, Training Loss: 15.9604\n",
      "Epoch 6, Step 165, Training Loss: 19.8257\n",
      "Epoch 6, Step 166, Training Loss: 11.4261\n",
      "Epoch 6, Step 167, Training Loss: 20.8492\n",
      "Epoch 6, Step 168, Training Loss: 32.0708\n",
      "Epoch 6, Step 169, Training Loss: 13.1127\n",
      "Epoch 6, Step 170, Training Loss: 18.2414\n",
      "Epoch 6, Step 171, Training Loss: 11.9046\n",
      "Epoch 6, Step 172, Training Loss: 22.9937\n",
      "Epoch 6, Step 173, Training Loss: 17.8210\n",
      "Epoch 6, Step 174, Training Loss: 14.3074\n",
      "Epoch 6, Step 175, Training Loss: 21.1781\n",
      "Epoch 6, Step 176, Training Loss: 21.0048\n",
      "Epoch 6, Step 177, Training Loss: 39.4776\n",
      "Epoch 6, Step 178, Training Loss: 18.0920\n",
      "Epoch 6, Step 179, Training Loss: 16.2277\n",
      "Epoch 6, Step 180, Training Loss: 20.1078\n",
      "Epoch 6, Step 181, Training Loss: 17.8018\n",
      "Epoch 6, Step 182, Training Loss: 26.0053\n",
      "Epoch 6, Step 183, Training Loss: 12.5710\n",
      "Epoch 6, Step 184, Training Loss: 16.3344\n",
      "Epoch 6, Step 185, Training Loss: 14.7398\n",
      "Epoch 6, Step 186, Training Loss: 39.3459\n",
      "Epoch 6, Step 187, Training Loss: 13.5405\n",
      "Epoch 6, Step 188, Training Loss: 108.7704\n",
      "Epoch 6, Step 189, Training Loss: 20.0703\n",
      "Epoch 6, Step 190, Training Loss: 137.4773\n",
      "Epoch 6, Step 191, Training Loss: 12.1383\n",
      "Epoch 6, Step 192, Training Loss: 21.6236\n",
      "Epoch 6, Step 193, Training Loss: 20.2860\n",
      "Epoch 6, Step 194, Training Loss: 13.3892\n",
      "Epoch 6, Step 195, Training Loss: 23.1284\n",
      "Epoch 6, Step 196, Training Loss: 29.2802\n",
      "Epoch 6, Step 197, Training Loss: 21.2261\n",
      "Epoch 6, Step 198, Training Loss: 15.8422\n",
      "Epoch 6, Step 199, Training Loss: 19.6663\n",
      "Epoch 6, Step 200, Training Loss: 14.1594\n",
      "Epoch 6, Step 201, Training Loss: 12.5698\n",
      "Epoch 6, Step 202, Training Loss: 17.9003\n",
      "Epoch 6, Step 203, Training Loss: 35.8693\n",
      "Epoch 6, Step 204, Training Loss: 33.1584\n",
      "Epoch 6, Step 205, Training Loss: 20.7086\n",
      "Epoch 6, Step 206, Training Loss: 16.9681\n",
      "--- Epoch 6, Validation Loss: 21.2425 ---\n",
      "Epoch 7, Step 0, Training Loss: 17.3192\n",
      "Epoch 7, Step 1, Training Loss: 17.7590\n",
      "Epoch 7, Step 2, Training Loss: 16.5290\n",
      "Epoch 7, Step 3, Training Loss: 32.8207\n",
      "Epoch 7, Step 4, Training Loss: 47.5561\n",
      "Epoch 7, Step 5, Training Loss: 15.2589\n",
      "Epoch 7, Step 6, Training Loss: 17.2126\n",
      "Epoch 7, Step 7, Training Loss: 18.5196\n",
      "Epoch 7, Step 8, Training Loss: 10.1175\n",
      "Epoch 7, Step 9, Training Loss: 15.3247\n",
      "Epoch 7, Step 10, Training Loss: 42.1051\n",
      "Epoch 7, Step 11, Training Loss: 17.7353\n",
      "Epoch 7, Step 12, Training Loss: 30.1241\n",
      "Epoch 7, Step 13, Training Loss: 46.3294\n",
      "Epoch 7, Step 14, Training Loss: 17.7766\n",
      "Epoch 7, Step 15, Training Loss: 17.3373\n",
      "Epoch 7, Step 16, Training Loss: 13.5142\n",
      "Epoch 7, Step 17, Training Loss: 17.3983\n",
      "Epoch 7, Step 18, Training Loss: 12.8560\n",
      "Epoch 7, Step 19, Training Loss: 32.4882\n",
      "Epoch 7, Step 20, Training Loss: 17.0340\n",
      "Epoch 7, Step 21, Training Loss: 31.2789\n",
      "Epoch 7, Step 22, Training Loss: 36.3397\n",
      "Epoch 7, Step 23, Training Loss: 19.3775\n",
      "Epoch 7, Step 24, Training Loss: 17.6037\n",
      "Epoch 7, Step 25, Training Loss: 17.4039\n",
      "Epoch 7, Step 26, Training Loss: 19.9078\n",
      "Epoch 7, Step 27, Training Loss: 23.2052\n",
      "Epoch 7, Step 28, Training Loss: 18.5181\n",
      "Epoch 7, Step 29, Training Loss: 13.3139\n",
      "Epoch 7, Step 30, Training Loss: 13.4382\n",
      "Epoch 7, Step 31, Training Loss: 17.5384\n",
      "Epoch 7, Step 32, Training Loss: 17.2025\n",
      "Epoch 7, Step 33, Training Loss: 17.7641\n",
      "Epoch 7, Step 34, Training Loss: 16.4014\n",
      "Epoch 7, Step 35, Training Loss: 15.2036\n",
      "Epoch 7, Step 36, Training Loss: 23.5234\n",
      "Epoch 7, Step 37, Training Loss: 51.9346\n",
      "Epoch 7, Step 38, Training Loss: 23.3266\n",
      "Epoch 7, Step 39, Training Loss: 20.2526\n",
      "Epoch 7, Step 40, Training Loss: 20.7983\n",
      "Epoch 7, Step 41, Training Loss: 33.6619\n",
      "Epoch 7, Step 42, Training Loss: 21.5480\n",
      "Epoch 7, Step 43, Training Loss: 17.8922\n",
      "Epoch 7, Step 44, Training Loss: 17.7352\n",
      "Epoch 7, Step 45, Training Loss: 16.8741\n",
      "Epoch 7, Step 46, Training Loss: 10.6879\n",
      "Epoch 7, Step 47, Training Loss: 15.1238\n",
      "Epoch 7, Step 48, Training Loss: 12.3074\n",
      "Epoch 7, Step 49, Training Loss: 17.6791\n",
      "Epoch 7, Step 50, Training Loss: 13.2692\n",
      "Epoch 7, Step 51, Training Loss: 14.9135\n",
      "Epoch 7, Step 52, Training Loss: 14.5647\n",
      "Epoch 7, Step 53, Training Loss: 12.9804\n",
      "Epoch 7, Step 54, Training Loss: 16.6598\n",
      "Epoch 7, Step 55, Training Loss: 21.8303\n",
      "Epoch 7, Step 56, Training Loss: 33.9789\n",
      "Epoch 7, Step 57, Training Loss: 14.2634\n",
      "Epoch 7, Step 58, Training Loss: 25.6743\n",
      "Epoch 7, Step 59, Training Loss: 18.9549\n",
      "Epoch 7, Step 60, Training Loss: 52.9040\n",
      "Epoch 7, Step 61, Training Loss: 15.3692\n",
      "Epoch 7, Step 62, Training Loss: 23.3406\n",
      "Epoch 7, Step 63, Training Loss: 33.6154\n",
      "Epoch 7, Step 64, Training Loss: 20.5028\n",
      "Epoch 7, Step 65, Training Loss: 23.0023\n",
      "Epoch 7, Step 66, Training Loss: 17.3824\n",
      "Epoch 7, Step 67, Training Loss: 18.8282\n",
      "Epoch 7, Step 68, Training Loss: 14.9418\n",
      "Epoch 7, Step 69, Training Loss: 43.8872\n",
      "Epoch 7, Step 70, Training Loss: 18.5032\n",
      "Epoch 7, Step 71, Training Loss: 18.0644\n",
      "Epoch 7, Step 72, Training Loss: 23.7870\n",
      "Epoch 7, Step 73, Training Loss: 24.1321\n",
      "Epoch 7, Step 74, Training Loss: 17.3462\n",
      "Epoch 7, Step 75, Training Loss: 35.0576\n",
      "Epoch 7, Step 76, Training Loss: 43.2407\n",
      "Epoch 7, Step 77, Training Loss: 25.9331\n",
      "Epoch 7, Step 78, Training Loss: 11.2732\n",
      "Epoch 7, Step 79, Training Loss: 15.8510\n",
      "Epoch 7, Step 80, Training Loss: 31.4269\n",
      "Epoch 7, Step 81, Training Loss: 53.0795\n",
      "Epoch 7, Step 82, Training Loss: 11.3138\n",
      "Epoch 7, Step 83, Training Loss: 40.0676\n",
      "Epoch 7, Step 84, Training Loss: 46.8580\n",
      "Epoch 7, Step 85, Training Loss: 15.8894\n",
      "Epoch 7, Step 86, Training Loss: 13.5299\n",
      "Epoch 7, Step 87, Training Loss: 17.8588\n",
      "Epoch 7, Step 88, Training Loss: 26.1066\n",
      "Epoch 7, Step 89, Training Loss: 23.3349\n",
      "Epoch 7, Step 90, Training Loss: 16.3227\n",
      "Epoch 7, Step 91, Training Loss: 14.1788\n",
      "Epoch 7, Step 92, Training Loss: 34.9329\n",
      "Epoch 7, Step 93, Training Loss: 20.0602\n",
      "Epoch 7, Step 94, Training Loss: 32.7692\n",
      "Epoch 7, Step 95, Training Loss: 11.3138\n",
      "Epoch 7, Step 96, Training Loss: 19.3524\n",
      "Epoch 7, Step 97, Training Loss: 17.2661\n",
      "Epoch 7, Step 98, Training Loss: 24.9498\n",
      "Epoch 7, Step 99, Training Loss: 36.3715\n",
      "Epoch 7, Step 100, Training Loss: 13.7481\n",
      "Epoch 7, Step 101, Training Loss: 13.3066\n",
      "Epoch 7, Step 102, Training Loss: 15.6223\n",
      "Epoch 7, Step 103, Training Loss: 14.4322\n",
      "Epoch 7, Step 104, Training Loss: 24.2029\n",
      "Epoch 7, Step 105, Training Loss: 12.6723\n",
      "Epoch 7, Step 106, Training Loss: 29.8922\n",
      "Epoch 7, Step 107, Training Loss: 27.9825\n",
      "Epoch 7, Step 108, Training Loss: 13.1802\n",
      "Epoch 7, Step 109, Training Loss: 9.1393\n",
      "Epoch 7, Step 110, Training Loss: 22.1480\n",
      "Epoch 7, Step 111, Training Loss: 16.5563\n",
      "Epoch 7, Step 112, Training Loss: 17.3047\n",
      "Epoch 7, Step 113, Training Loss: 20.8656\n",
      "Epoch 7, Step 114, Training Loss: 13.4253\n",
      "Epoch 7, Step 115, Training Loss: 32.1423\n",
      "Epoch 7, Step 116, Training Loss: 11.2223\n",
      "Epoch 7, Step 117, Training Loss: 20.4828\n",
      "Epoch 7, Step 118, Training Loss: 18.9669\n",
      "Epoch 7, Step 119, Training Loss: 17.7048\n",
      "Epoch 7, Step 120, Training Loss: 20.5535\n",
      "Epoch 7, Step 121, Training Loss: 38.3894\n",
      "Epoch 7, Step 122, Training Loss: 36.0910\n",
      "Epoch 7, Step 123, Training Loss: 18.6199\n",
      "Epoch 7, Step 124, Training Loss: 21.7275\n",
      "Epoch 7, Step 125, Training Loss: 22.8198\n",
      "Epoch 7, Step 126, Training Loss: 22.4299\n",
      "Epoch 7, Step 127, Training Loss: 20.3371\n",
      "Epoch 7, Step 128, Training Loss: 18.2696\n",
      "Epoch 7, Step 129, Training Loss: 31.9069\n",
      "Epoch 7, Step 130, Training Loss: 15.3475\n",
      "Epoch 7, Step 131, Training Loss: 15.0090\n",
      "Epoch 7, Step 132, Training Loss: 25.0685\n",
      "Epoch 7, Step 133, Training Loss: 43.2070\n",
      "Epoch 7, Step 134, Training Loss: 30.5998\n",
      "Epoch 7, Step 135, Training Loss: 24.7619\n",
      "Epoch 7, Step 136, Training Loss: 54.6812\n",
      "Epoch 7, Step 137, Training Loss: 15.7871\n",
      "Epoch 7, Step 138, Training Loss: 14.7674\n",
      "Epoch 7, Step 139, Training Loss: 21.9429\n",
      "Epoch 7, Step 140, Training Loss: 15.7312\n",
      "Epoch 7, Step 141, Training Loss: 29.9110\n",
      "Epoch 7, Step 142, Training Loss: 16.1730\n",
      "Epoch 7, Step 143, Training Loss: 17.5030\n",
      "Epoch 7, Step 144, Training Loss: 16.8602\n",
      "Epoch 7, Step 145, Training Loss: 14.8147\n",
      "Epoch 7, Step 146, Training Loss: 13.6635\n",
      "Epoch 7, Step 147, Training Loss: 17.8715\n",
      "Epoch 7, Step 148, Training Loss: 77.4248\n",
      "Epoch 7, Step 149, Training Loss: 29.8610\n",
      "Epoch 7, Step 150, Training Loss: 26.7149\n",
      "Epoch 7, Step 151, Training Loss: 15.3747\n",
      "Epoch 7, Step 152, Training Loss: 13.0091\n",
      "Epoch 7, Step 153, Training Loss: 14.9999\n",
      "Epoch 7, Step 154, Training Loss: 19.2152\n",
      "Epoch 7, Step 155, Training Loss: 27.8325\n",
      "Epoch 7, Step 156, Training Loss: 15.0279\n",
      "Epoch 7, Step 157, Training Loss: 21.7410\n",
      "Epoch 7, Step 158, Training Loss: 14.7624\n",
      "Epoch 7, Step 159, Training Loss: 31.1330\n",
      "Epoch 7, Step 160, Training Loss: 50.1373\n",
      "Epoch 7, Step 161, Training Loss: 17.7034\n",
      "Epoch 7, Step 162, Training Loss: 11.4066\n",
      "Epoch 7, Step 163, Training Loss: 16.0590\n",
      "Epoch 7, Step 164, Training Loss: 13.5005\n",
      "Epoch 7, Step 165, Training Loss: 20.0201\n",
      "Epoch 7, Step 166, Training Loss: 11.3220\n",
      "Epoch 7, Step 167, Training Loss: 18.8864\n",
      "Epoch 7, Step 168, Training Loss: 28.4989\n",
      "Epoch 7, Step 169, Training Loss: 14.6283\n",
      "Epoch 7, Step 170, Training Loss: 13.8518\n",
      "Epoch 7, Step 171, Training Loss: 10.0523\n",
      "Epoch 7, Step 172, Training Loss: 23.4676\n",
      "Epoch 7, Step 173, Training Loss: 16.0526\n",
      "Epoch 7, Step 174, Training Loss: 12.8431\n",
      "Epoch 7, Step 175, Training Loss: 19.5479\n",
      "Epoch 7, Step 176, Training Loss: 20.4776\n",
      "Epoch 7, Step 177, Training Loss: 32.7431\n",
      "Epoch 7, Step 178, Training Loss: 16.1828\n",
      "Epoch 7, Step 179, Training Loss: 12.2319\n",
      "Epoch 7, Step 180, Training Loss: 20.7113\n",
      "Epoch 7, Step 181, Training Loss: 14.8828\n",
      "Epoch 7, Step 182, Training Loss: 23.0224\n",
      "Epoch 7, Step 183, Training Loss: 13.5047\n",
      "Epoch 7, Step 184, Training Loss: 13.4840\n",
      "Epoch 7, Step 185, Training Loss: 15.6984\n",
      "Epoch 7, Step 186, Training Loss: 35.8753\n",
      "Epoch 7, Step 187, Training Loss: 14.2022\n",
      "Epoch 7, Step 188, Training Loss: 110.2957\n",
      "Epoch 7, Step 189, Training Loss: 19.6649\n",
      "Epoch 7, Step 190, Training Loss: 127.1068\n",
      "Epoch 7, Step 191, Training Loss: 11.0045\n",
      "Epoch 7, Step 192, Training Loss: 22.8105\n",
      "Epoch 7, Step 193, Training Loss: 17.8244\n",
      "Epoch 7, Step 194, Training Loss: 19.0134\n",
      "Epoch 7, Step 195, Training Loss: 24.2227\n",
      "Epoch 7, Step 196, Training Loss: 29.1484\n",
      "Epoch 7, Step 197, Training Loss: 17.7928\n",
      "Epoch 7, Step 198, Training Loss: 15.2979\n",
      "Epoch 7, Step 199, Training Loss: 17.3284\n",
      "Epoch 7, Step 200, Training Loss: 12.7191\n",
      "Epoch 7, Step 201, Training Loss: 14.3600\n",
      "Epoch 7, Step 202, Training Loss: 17.4027\n",
      "Epoch 7, Step 203, Training Loss: 37.5834\n",
      "Epoch 7, Step 204, Training Loss: 29.8911\n",
      "Epoch 7, Step 205, Training Loss: 18.1327\n",
      "Epoch 7, Step 206, Training Loss: 18.5889\n",
      "--- Epoch 7, Validation Loss: 23.3625 ---\n",
      "Epoch 8, Step 0, Training Loss: 14.9555\n",
      "Epoch 8, Step 1, Training Loss: 16.4348\n",
      "Epoch 8, Step 2, Training Loss: 14.8124\n",
      "Epoch 8, Step 3, Training Loss: 30.6418\n",
      "Epoch 8, Step 4, Training Loss: 47.3685\n",
      "Epoch 8, Step 5, Training Loss: 15.2766\n",
      "Epoch 8, Step 6, Training Loss: 14.1266\n",
      "Epoch 8, Step 7, Training Loss: 21.2690\n",
      "Epoch 8, Step 8, Training Loss: 10.9705\n",
      "Epoch 8, Step 9, Training Loss: 14.3585\n",
      "Epoch 8, Step 10, Training Loss: 49.1173\n",
      "Epoch 8, Step 11, Training Loss: 18.6641\n",
      "Epoch 8, Step 12, Training Loss: 23.7674\n",
      "Epoch 8, Step 13, Training Loss: 48.8455\n",
      "Epoch 8, Step 14, Training Loss: 16.7859\n",
      "Epoch 8, Step 15, Training Loss: 14.9046\n",
      "Epoch 8, Step 16, Training Loss: 11.3611\n",
      "Epoch 8, Step 17, Training Loss: 16.4036\n",
      "Epoch 8, Step 18, Training Loss: 12.1283\n",
      "Epoch 8, Step 19, Training Loss: 33.5170\n",
      "Epoch 8, Step 20, Training Loss: 19.1392\n",
      "Epoch 8, Step 21, Training Loss: 30.4669\n",
      "Epoch 8, Step 22, Training Loss: 34.0740\n",
      "Epoch 8, Step 23, Training Loss: 15.9815\n",
      "Epoch 8, Step 24, Training Loss: 13.9703\n",
      "Epoch 8, Step 25, Training Loss: 16.9749\n",
      "Epoch 8, Step 26, Training Loss: 19.3564\n",
      "Epoch 8, Step 27, Training Loss: 19.0031\n",
      "Epoch 8, Step 28, Training Loss: 16.2716\n",
      "Epoch 8, Step 29, Training Loss: 10.8844\n",
      "Epoch 8, Step 30, Training Loss: 12.0836\n",
      "Epoch 8, Step 31, Training Loss: 17.6724\n",
      "Epoch 8, Step 32, Training Loss: 16.9090\n",
      "Epoch 8, Step 33, Training Loss: 15.4513\n",
      "Epoch 8, Step 34, Training Loss: 17.6804\n",
      "Epoch 8, Step 35, Training Loss: 12.5993\n",
      "Epoch 8, Step 36, Training Loss: 20.9120\n",
      "Epoch 8, Step 37, Training Loss: 45.5585\n",
      "Epoch 8, Step 38, Training Loss: 22.7523\n",
      "Epoch 8, Step 39, Training Loss: 18.0703\n",
      "Epoch 8, Step 40, Training Loss: 18.8517\n",
      "Epoch 8, Step 41, Training Loss: 31.4837\n",
      "Epoch 8, Step 42, Training Loss: 18.9586\n",
      "Epoch 8, Step 43, Training Loss: 18.2206\n",
      "Epoch 8, Step 44, Training Loss: 16.7324\n",
      "Epoch 8, Step 45, Training Loss: 16.9531\n",
      "Epoch 8, Step 46, Training Loss: 15.7296\n",
      "Epoch 8, Step 47, Training Loss: 17.3586\n",
      "Epoch 8, Step 48, Training Loss: 14.1542\n",
      "Epoch 8, Step 49, Training Loss: 14.7975\n",
      "Epoch 8, Step 50, Training Loss: 11.7742\n",
      "Epoch 8, Step 51, Training Loss: 15.0295\n",
      "Epoch 8, Step 52, Training Loss: 15.0160\n",
      "Epoch 8, Step 53, Training Loss: 12.4079\n",
      "Epoch 8, Step 54, Training Loss: 16.4618\n",
      "Epoch 8, Step 55, Training Loss: 18.3037\n",
      "Epoch 8, Step 56, Training Loss: 31.0774\n",
      "Epoch 8, Step 57, Training Loss: 13.6914\n",
      "Epoch 8, Step 58, Training Loss: 22.9774\n",
      "Epoch 8, Step 59, Training Loss: 18.8365\n",
      "Epoch 8, Step 60, Training Loss: 54.3937\n",
      "Epoch 8, Step 61, Training Loss: 11.5891\n",
      "Epoch 8, Step 62, Training Loss: 22.8739\n",
      "Epoch 8, Step 63, Training Loss: 34.4043\n",
      "Epoch 8, Step 64, Training Loss: 18.5712\n",
      "Epoch 8, Step 65, Training Loss: 19.3223\n",
      "Epoch 8, Step 66, Training Loss: 16.1815\n",
      "Epoch 8, Step 67, Training Loss: 15.1444\n",
      "Epoch 8, Step 68, Training Loss: 14.4795\n",
      "Epoch 8, Step 69, Training Loss: 38.2235\n",
      "Epoch 8, Step 70, Training Loss: 14.3560\n",
      "Epoch 8, Step 71, Training Loss: 13.3669\n",
      "Epoch 8, Step 72, Training Loss: 24.0860\n",
      "Epoch 8, Step 73, Training Loss: 23.2476\n",
      "Epoch 8, Step 74, Training Loss: 15.6396\n",
      "Epoch 8, Step 75, Training Loss: 32.9813\n",
      "Epoch 8, Step 76, Training Loss: 40.1156\n",
      "Epoch 8, Step 77, Training Loss: 23.4882\n",
      "Epoch 8, Step 78, Training Loss: 10.7631\n",
      "Epoch 8, Step 79, Training Loss: 12.5415\n",
      "Epoch 8, Step 80, Training Loss: 29.2070\n",
      "Epoch 8, Step 81, Training Loss: 48.4116\n",
      "Epoch 8, Step 82, Training Loss: 12.8603\n",
      "Epoch 8, Step 83, Training Loss: 39.4645\n",
      "Epoch 8, Step 84, Training Loss: 48.8546\n",
      "Epoch 8, Step 85, Training Loss: 20.2767\n",
      "Epoch 8, Step 86, Training Loss: 14.3663\n",
      "Epoch 8, Step 87, Training Loss: 17.4702\n",
      "Epoch 8, Step 88, Training Loss: 23.5104\n",
      "Epoch 8, Step 89, Training Loss: 19.0934\n",
      "Epoch 8, Step 90, Training Loss: 17.7387\n",
      "Epoch 8, Step 91, Training Loss: 13.8307\n",
      "Epoch 8, Step 92, Training Loss: 30.5221\n",
      "Epoch 8, Step 93, Training Loss: 16.8790\n",
      "Epoch 8, Step 94, Training Loss: 32.7822\n",
      "Epoch 8, Step 95, Training Loss: 10.1388\n",
      "Epoch 8, Step 96, Training Loss: 17.7114\n",
      "Epoch 8, Step 97, Training Loss: 16.0929\n",
      "Epoch 8, Step 98, Training Loss: 26.4722\n",
      "Epoch 8, Step 99, Training Loss: 32.7851\n",
      "Epoch 8, Step 100, Training Loss: 13.4034\n",
      "Epoch 8, Step 101, Training Loss: 15.6990\n",
      "Epoch 8, Step 102, Training Loss: 14.7381\n",
      "Epoch 8, Step 103, Training Loss: 12.9531\n",
      "Epoch 8, Step 104, Training Loss: 23.8868\n",
      "Epoch 8, Step 105, Training Loss: 10.8300\n",
      "Epoch 8, Step 106, Training Loss: 27.1150\n",
      "Epoch 8, Step 107, Training Loss: 27.0682\n",
      "Epoch 8, Step 108, Training Loss: 13.8691\n",
      "Epoch 8, Step 109, Training Loss: 11.2762\n",
      "Epoch 8, Step 110, Training Loss: 18.1679\n",
      "Epoch 8, Step 111, Training Loss: 13.4125\n",
      "Epoch 8, Step 112, Training Loss: 17.1515\n",
      "Epoch 8, Step 113, Training Loss: 21.0556\n",
      "Epoch 8, Step 114, Training Loss: 14.6145\n",
      "Epoch 8, Step 115, Training Loss: 31.1440\n",
      "Epoch 8, Step 116, Training Loss: 14.8640\n",
      "Epoch 8, Step 117, Training Loss: 18.6880\n",
      "Epoch 8, Step 118, Training Loss: 16.3618\n",
      "Epoch 8, Step 119, Training Loss: 16.6813\n",
      "Epoch 8, Step 120, Training Loss: 16.2548\n",
      "Epoch 8, Step 121, Training Loss: 35.2579\n",
      "Epoch 8, Step 122, Training Loss: 32.7124\n",
      "Epoch 8, Step 123, Training Loss: 19.7188\n",
      "Epoch 8, Step 124, Training Loss: 21.0355\n",
      "Epoch 8, Step 125, Training Loss: 21.7762\n",
      "Epoch 8, Step 126, Training Loss: 21.8198\n",
      "Epoch 8, Step 127, Training Loss: 19.2804\n",
      "Epoch 8, Step 128, Training Loss: 16.6210\n",
      "Epoch 8, Step 129, Training Loss: 31.0565\n",
      "Epoch 8, Step 130, Training Loss: 14.2952\n",
      "Epoch 8, Step 131, Training Loss: 14.7769\n",
      "Epoch 8, Step 132, Training Loss: 24.6504\n",
      "Epoch 8, Step 133, Training Loss: 41.7390\n",
      "Epoch 8, Step 134, Training Loss: 29.5553\n",
      "Epoch 8, Step 135, Training Loss: 24.6089\n",
      "Epoch 8, Step 136, Training Loss: 49.3374\n",
      "Epoch 8, Step 137, Training Loss: 15.7975\n",
      "Epoch 8, Step 138, Training Loss: 15.3557\n",
      "Epoch 8, Step 139, Training Loss: 19.3301\n",
      "Epoch 8, Step 140, Training Loss: 13.8868\n",
      "Epoch 8, Step 141, Training Loss: 25.2973\n",
      "Epoch 8, Step 142, Training Loss: 13.1700\n",
      "Epoch 8, Step 143, Training Loss: 14.2664\n",
      "Epoch 8, Step 144, Training Loss: 11.4667\n",
      "Epoch 8, Step 145, Training Loss: 12.1242\n",
      "Epoch 8, Step 146, Training Loss: 13.9387\n",
      "Epoch 8, Step 147, Training Loss: 14.6441\n",
      "Epoch 8, Step 148, Training Loss: 70.9007\n",
      "Epoch 8, Step 149, Training Loss: 26.7696\n",
      "Epoch 8, Step 150, Training Loss: 25.9011\n",
      "Epoch 8, Step 151, Training Loss: 16.5238\n",
      "Epoch 8, Step 152, Training Loss: 12.1690\n",
      "Epoch 8, Step 153, Training Loss: 17.1147\n",
      "Epoch 8, Step 154, Training Loss: 15.5378\n",
      "Epoch 8, Step 155, Training Loss: 26.2436\n",
      "Epoch 8, Step 156, Training Loss: 13.7787\n",
      "Epoch 8, Step 157, Training Loss: 21.8484\n",
      "Epoch 8, Step 158, Training Loss: 14.0645\n",
      "Epoch 8, Step 159, Training Loss: 28.2393\n",
      "Epoch 8, Step 160, Training Loss: 50.8759\n",
      "Epoch 8, Step 161, Training Loss: 17.5742\n",
      "Epoch 8, Step 162, Training Loss: 11.5316\n",
      "Epoch 8, Step 163, Training Loss: 15.5551\n",
      "Epoch 8, Step 164, Training Loss: 13.4931\n",
      "Epoch 8, Step 165, Training Loss: 16.4397\n",
      "Epoch 8, Step 166, Training Loss: 10.2746\n",
      "Epoch 8, Step 167, Training Loss: 16.7203\n",
      "Epoch 8, Step 168, Training Loss: 27.4652\n",
      "Epoch 8, Step 169, Training Loss: 12.8658\n",
      "Epoch 8, Step 170, Training Loss: 12.7740\n",
      "Epoch 8, Step 171, Training Loss: 9.3885\n",
      "Epoch 8, Step 172, Training Loss: 24.7978\n",
      "Epoch 8, Step 173, Training Loss: 19.5199\n",
      "Epoch 8, Step 174, Training Loss: 14.7652\n",
      "Epoch 8, Step 175, Training Loss: 20.5489\n",
      "Epoch 8, Step 176, Training Loss: 16.2768\n",
      "Epoch 8, Step 177, Training Loss: 31.1330\n",
      "Epoch 8, Step 178, Training Loss: 20.4158\n",
      "Epoch 8, Step 179, Training Loss: 12.2123\n",
      "Epoch 8, Step 180, Training Loss: 21.4874\n",
      "Epoch 8, Step 181, Training Loss: 14.9599\n",
      "Epoch 8, Step 182, Training Loss: 19.2417\n",
      "Epoch 8, Step 183, Training Loss: 12.0712\n",
      "Epoch 8, Step 184, Training Loss: 10.8472\n",
      "Epoch 8, Step 185, Training Loss: 21.1058\n",
      "Epoch 8, Step 186, Training Loss: 30.4377\n",
      "Epoch 8, Step 187, Training Loss: 14.9091\n",
      "Epoch 8, Step 188, Training Loss: 111.2659\n",
      "Epoch 8, Step 189, Training Loss: 18.7998\n",
      "Epoch 8, Step 190, Training Loss: 119.3449\n",
      "Epoch 8, Step 191, Training Loss: 13.3690\n",
      "Epoch 8, Step 192, Training Loss: 19.7067\n",
      "Epoch 8, Step 193, Training Loss: 18.5589\n",
      "Epoch 8, Step 194, Training Loss: 13.9961\n",
      "Epoch 8, Step 195, Training Loss: 19.0136\n",
      "Epoch 8, Step 196, Training Loss: 29.6295\n",
      "Epoch 8, Step 197, Training Loss: 15.3937\n",
      "Epoch 8, Step 198, Training Loss: 14.4087\n",
      "Epoch 8, Step 199, Training Loss: 16.1908\n",
      "Epoch 8, Step 200, Training Loss: 10.9646\n",
      "Epoch 8, Step 201, Training Loss: 10.4529\n",
      "Epoch 8, Step 202, Training Loss: 14.4033\n",
      "Epoch 8, Step 203, Training Loss: 35.1604\n",
      "Epoch 8, Step 204, Training Loss: 31.5632\n",
      "Epoch 8, Step 205, Training Loss: 17.6170\n",
      "Epoch 8, Step 206, Training Loss: 16.4790\n",
      "--- Epoch 8, Validation Loss: 19.3064 ---\n",
      "Epoch 9, Step 0, Training Loss: 12.9094\n",
      "Epoch 9, Step 1, Training Loss: 13.2099\n",
      "Epoch 9, Step 2, Training Loss: 14.4037\n",
      "Epoch 9, Step 3, Training Loss: 32.0026\n",
      "Epoch 9, Step 4, Training Loss: 40.5576\n",
      "Epoch 9, Step 5, Training Loss: 11.3109\n",
      "Epoch 9, Step 6, Training Loss: 14.3579\n",
      "Epoch 9, Step 7, Training Loss: 17.1546\n",
      "Epoch 9, Step 8, Training Loss: 10.2896\n",
      "Epoch 9, Step 9, Training Loss: 14.4971\n",
      "Epoch 9, Step 10, Training Loss: 39.7706\n",
      "Epoch 9, Step 11, Training Loss: 16.7799\n",
      "Epoch 9, Step 12, Training Loss: 23.9667\n",
      "Epoch 9, Step 13, Training Loss: 44.7503\n",
      "Epoch 9, Step 14, Training Loss: 19.7676\n",
      "Epoch 9, Step 15, Training Loss: 17.2517\n",
      "Epoch 9, Step 16, Training Loss: 9.6009\n",
      "Epoch 9, Step 17, Training Loss: 12.8875\n",
      "Epoch 9, Step 18, Training Loss: 12.9694\n",
      "Epoch 9, Step 19, Training Loss: 33.2855\n",
      "Epoch 9, Step 20, Training Loss: 17.0933\n",
      "Epoch 9, Step 21, Training Loss: 21.9953\n",
      "Epoch 9, Step 22, Training Loss: 32.3466\n",
      "Epoch 9, Step 23, Training Loss: 16.0491\n",
      "Epoch 9, Step 24, Training Loss: 16.8017\n",
      "Epoch 9, Step 25, Training Loss: 16.4874\n",
      "Epoch 9, Step 26, Training Loss: 19.5606\n",
      "Epoch 9, Step 27, Training Loss: 20.2296\n",
      "Epoch 9, Step 28, Training Loss: 16.4150\n",
      "Epoch 9, Step 29, Training Loss: 9.3193\n",
      "Epoch 9, Step 30, Training Loss: 12.1429\n",
      "Epoch 9, Step 31, Training Loss: 16.4780\n",
      "Epoch 9, Step 32, Training Loss: 15.9765\n",
      "Epoch 9, Step 33, Training Loss: 16.0401\n",
      "Epoch 9, Step 34, Training Loss: 16.1201\n",
      "Epoch 9, Step 35, Training Loss: 14.2424\n",
      "Epoch 9, Step 36, Training Loss: 19.6483\n",
      "Epoch 9, Step 37, Training Loss: 45.8260\n",
      "Epoch 9, Step 38, Training Loss: 21.9732\n",
      "Epoch 9, Step 39, Training Loss: 18.1697\n",
      "Epoch 9, Step 40, Training Loss: 21.0651\n",
      "Epoch 9, Step 41, Training Loss: 25.8335\n",
      "Epoch 9, Step 42, Training Loss: 18.4427\n",
      "Epoch 9, Step 43, Training Loss: 17.7636\n",
      "Epoch 9, Step 44, Training Loss: 17.3174\n",
      "Epoch 9, Step 45, Training Loss: 14.9086\n",
      "Epoch 9, Step 46, Training Loss: 11.0538\n",
      "Epoch 9, Step 47, Training Loss: 13.2913\n",
      "Epoch 9, Step 48, Training Loss: 14.3071\n",
      "Epoch 9, Step 49, Training Loss: 15.6050\n",
      "Epoch 9, Step 50, Training Loss: 11.2662\n",
      "Epoch 9, Step 51, Training Loss: 13.2688\n",
      "Epoch 9, Step 52, Training Loss: 15.0276\n",
      "Epoch 9, Step 53, Training Loss: 10.7784\n",
      "Epoch 9, Step 54, Training Loss: 19.2952\n",
      "Epoch 9, Step 55, Training Loss: 20.0537\n",
      "Epoch 9, Step 56, Training Loss: 28.9771\n",
      "Epoch 9, Step 57, Training Loss: 13.7100\n",
      "Epoch 9, Step 58, Training Loss: 23.0088\n",
      "Epoch 9, Step 59, Training Loss: 16.3724\n",
      "Epoch 9, Step 60, Training Loss: 51.6801\n",
      "Epoch 9, Step 61, Training Loss: 13.2369\n",
      "Epoch 9, Step 62, Training Loss: 21.9378\n",
      "Epoch 9, Step 63, Training Loss: 32.8065\n",
      "Epoch 9, Step 64, Training Loss: 16.9060\n",
      "Epoch 9, Step 65, Training Loss: 19.3419\n",
      "Epoch 9, Step 66, Training Loss: 16.1485\n",
      "Epoch 9, Step 67, Training Loss: 15.6374\n",
      "Epoch 9, Step 68, Training Loss: 12.0575\n",
      "Epoch 9, Step 69, Training Loss: 35.2705\n",
      "Epoch 9, Step 70, Training Loss: 15.0906\n",
      "Epoch 9, Step 71, Training Loss: 13.6876\n",
      "Epoch 9, Step 72, Training Loss: 23.0776\n",
      "Epoch 9, Step 73, Training Loss: 19.8396\n",
      "Epoch 9, Step 74, Training Loss: 15.5352\n",
      "Epoch 9, Step 75, Training Loss: 35.3789\n",
      "Epoch 9, Step 76, Training Loss: 37.8462\n",
      "Epoch 9, Step 77, Training Loss: 26.8473\n",
      "Epoch 9, Step 78, Training Loss: 11.5017\n",
      "Epoch 9, Step 79, Training Loss: 14.3594\n",
      "Epoch 9, Step 80, Training Loss: 26.8268\n",
      "Epoch 9, Step 81, Training Loss: 41.0784\n",
      "Epoch 9, Step 82, Training Loss: 12.5268\n",
      "Epoch 9, Step 83, Training Loss: 38.3865\n",
      "Epoch 9, Step 84, Training Loss: 41.9564\n",
      "Epoch 9, Step 85, Training Loss: 14.4596\n",
      "Epoch 9, Step 86, Training Loss: 14.1136\n",
      "Epoch 9, Step 87, Training Loss: 19.0573\n",
      "Epoch 9, Step 88, Training Loss: 23.5777\n",
      "Epoch 9, Step 89, Training Loss: 19.3435\n",
      "Epoch 9, Step 90, Training Loss: 17.7169\n",
      "Epoch 9, Step 91, Training Loss: 13.9155\n",
      "Epoch 9, Step 92, Training Loss: 28.9654\n",
      "Epoch 9, Step 93, Training Loss: 17.4642\n",
      "Epoch 9, Step 94, Training Loss: 29.7407\n",
      "Epoch 9, Step 95, Training Loss: 11.1051\n",
      "Epoch 9, Step 96, Training Loss: 19.7037\n",
      "Epoch 9, Step 97, Training Loss: 17.1609\n",
      "Epoch 9, Step 98, Training Loss: 23.6182\n",
      "Epoch 9, Step 99, Training Loss: 33.9167\n",
      "Epoch 9, Step 100, Training Loss: 12.7726\n",
      "Epoch 9, Step 101, Training Loss: 13.4820\n",
      "Epoch 9, Step 102, Training Loss: 15.2507\n",
      "Epoch 9, Step 103, Training Loss: 13.4084\n",
      "Epoch 9, Step 104, Training Loss: 21.3013\n",
      "Epoch 9, Step 105, Training Loss: 10.8321\n",
      "Epoch 9, Step 106, Training Loss: 22.9701\n",
      "Epoch 9, Step 107, Training Loss: 21.0169\n",
      "Epoch 9, Step 108, Training Loss: 12.9757\n",
      "Epoch 9, Step 109, Training Loss: 12.0476\n",
      "Epoch 9, Step 110, Training Loss: 17.0487\n",
      "Epoch 9, Step 111, Training Loss: 11.3436\n",
      "Epoch 9, Step 112, Training Loss: 16.6914\n",
      "Epoch 9, Step 113, Training Loss: 20.3400\n",
      "Epoch 9, Step 114, Training Loss: 13.1942\n",
      "Epoch 9, Step 115, Training Loss: 29.3983\n",
      "Epoch 9, Step 116, Training Loss: 10.8835\n",
      "Epoch 9, Step 117, Training Loss: 21.9849\n",
      "Epoch 9, Step 118, Training Loss: 12.4838\n",
      "Epoch 9, Step 119, Training Loss: 14.7613\n",
      "Epoch 9, Step 120, Training Loss: 18.8780\n",
      "Epoch 9, Step 121, Training Loss: 35.7321\n",
      "Epoch 9, Step 122, Training Loss: 33.4270\n",
      "Epoch 9, Step 123, Training Loss: 16.3417\n",
      "Epoch 9, Step 124, Training Loss: 21.6875\n",
      "Epoch 9, Step 125, Training Loss: 21.2329\n",
      "Epoch 9, Step 126, Training Loss: 24.5775\n",
      "Epoch 9, Step 127, Training Loss: 16.3463\n",
      "Epoch 9, Step 128, Training Loss: 15.3211\n",
      "Epoch 9, Step 129, Training Loss: 27.7054\n",
      "Epoch 9, Step 130, Training Loss: 9.9794\n",
      "Epoch 9, Step 131, Training Loss: 14.3365\n",
      "Epoch 9, Step 132, Training Loss: 23.5301\n",
      "Epoch 9, Step 133, Training Loss: 38.9024\n",
      "Epoch 9, Step 134, Training Loss: 28.4238\n",
      "Epoch 9, Step 135, Training Loss: 19.6410\n",
      "Epoch 9, Step 136, Training Loss: 54.7829\n",
      "Epoch 9, Step 137, Training Loss: 13.7135\n",
      "Epoch 9, Step 138, Training Loss: 14.4925\n",
      "Epoch 9, Step 139, Training Loss: 25.1780\n",
      "Epoch 9, Step 140, Training Loss: 13.7856\n",
      "Epoch 9, Step 141, Training Loss: 22.8517\n",
      "Epoch 9, Step 142, Training Loss: 12.2463\n",
      "Epoch 9, Step 143, Training Loss: 12.6083\n",
      "Epoch 9, Step 144, Training Loss: 15.6514\n",
      "Epoch 9, Step 145, Training Loss: 14.1583\n",
      "Epoch 9, Step 146, Training Loss: 13.1070\n",
      "Epoch 9, Step 147, Training Loss: 15.6676\n",
      "Epoch 9, Step 148, Training Loss: 69.5786\n",
      "Epoch 9, Step 149, Training Loss: 23.2288\n",
      "Epoch 9, Step 150, Training Loss: 25.7955\n",
      "Epoch 9, Step 151, Training Loss: 14.7031\n",
      "Epoch 9, Step 152, Training Loss: 10.6524\n",
      "Epoch 9, Step 153, Training Loss: 14.5393\n",
      "Epoch 9, Step 154, Training Loss: 15.3148\n",
      "Epoch 9, Step 155, Training Loss: 23.3078\n",
      "Epoch 9, Step 156, Training Loss: 14.5766\n",
      "Epoch 9, Step 157, Training Loss: 19.2139\n",
      "Epoch 9, Step 158, Training Loss: 14.2009\n",
      "Epoch 9, Step 159, Training Loss: 24.9579\n",
      "Epoch 9, Step 160, Training Loss: 50.9699\n",
      "Epoch 9, Step 161, Training Loss: 16.2146\n",
      "Epoch 9, Step 162, Training Loss: 10.4920\n",
      "Epoch 9, Step 163, Training Loss: 14.7275\n",
      "Epoch 9, Step 164, Training Loss: 13.0523\n",
      "Epoch 9, Step 165, Training Loss: 18.6790\n",
      "Epoch 9, Step 166, Training Loss: 9.7375\n",
      "Epoch 9, Step 167, Training Loss: 17.4397\n",
      "Epoch 9, Step 168, Training Loss: 28.9540\n",
      "Epoch 9, Step 169, Training Loss: 9.0742\n",
      "Epoch 9, Step 170, Training Loss: 15.7922\n",
      "Epoch 9, Step 171, Training Loss: 13.8569\n",
      "Epoch 9, Step 172, Training Loss: 24.0724\n",
      "Epoch 9, Step 173, Training Loss: 14.8697\n",
      "Epoch 9, Step 174, Training Loss: 13.9885\n",
      "Epoch 9, Step 175, Training Loss: 19.8376\n",
      "Epoch 9, Step 176, Training Loss: 15.7044\n",
      "Epoch 9, Step 177, Training Loss: 26.1616\n",
      "Epoch 9, Step 178, Training Loss: 16.3322\n",
      "Epoch 9, Step 179, Training Loss: 11.2032\n",
      "Epoch 9, Step 180, Training Loss: 20.9826\n",
      "Epoch 9, Step 181, Training Loss: 13.8622\n",
      "Epoch 9, Step 182, Training Loss: 18.0678\n",
      "Epoch 9, Step 183, Training Loss: 11.7670\n",
      "Epoch 9, Step 184, Training Loss: 12.1751\n",
      "Epoch 9, Step 185, Training Loss: 15.3203\n",
      "Epoch 9, Step 186, Training Loss: 27.4153\n",
      "Epoch 9, Step 187, Training Loss: 12.9306\n",
      "Epoch 9, Step 188, Training Loss: 110.0943\n",
      "Epoch 9, Step 189, Training Loss: 17.6173\n",
      "Epoch 9, Step 190, Training Loss: 120.1217\n",
      "Epoch 9, Step 191, Training Loss: 12.0940\n",
      "Epoch 9, Step 192, Training Loss: 18.9060\n",
      "Epoch 9, Step 193, Training Loss: 16.0042\n",
      "Epoch 9, Step 194, Training Loss: 14.9425\n",
      "Epoch 9, Step 195, Training Loss: 17.9870\n",
      "Epoch 9, Step 196, Training Loss: 25.1335\n",
      "Epoch 9, Step 197, Training Loss: 22.6474\n",
      "Epoch 9, Step 198, Training Loss: 13.8898\n",
      "Epoch 9, Step 199, Training Loss: 13.9743\n",
      "Epoch 9, Step 200, Training Loss: 13.4266\n",
      "Epoch 9, Step 201, Training Loss: 13.0608\n",
      "Epoch 9, Step 202, Training Loss: 14.8338\n",
      "Epoch 9, Step 203, Training Loss: 36.7755\n",
      "Epoch 9, Step 204, Training Loss: 25.2157\n",
      "Epoch 9, Step 205, Training Loss: 17.3342\n",
      "Epoch 9, Step 206, Training Loss: 13.4214\n",
      "--- Epoch 9, Validation Loss: 18.1957 ---\n",
      "Epoch 10, Step 0, Training Loss: 12.3261\n",
      "Epoch 10, Step 1, Training Loss: 16.0164\n",
      "Epoch 10, Step 2, Training Loss: 13.1367\n",
      "Epoch 10, Step 3, Training Loss: 32.0069\n",
      "Epoch 10, Step 4, Training Loss: 40.6909\n",
      "Epoch 10, Step 5, Training Loss: 11.0307\n",
      "Epoch 10, Step 6, Training Loss: 17.2284\n",
      "Epoch 10, Step 7, Training Loss: 14.6619\n",
      "Epoch 10, Step 8, Training Loss: 9.5048\n",
      "Epoch 10, Step 9, Training Loss: 14.6990\n",
      "Epoch 10, Step 10, Training Loss: 35.6656\n",
      "Epoch 10, Step 11, Training Loss: 17.1577\n",
      "Epoch 10, Step 12, Training Loss: 22.1243\n",
      "Epoch 10, Step 13, Training Loss: 43.4628\n",
      "Epoch 10, Step 14, Training Loss: 16.8143\n",
      "Epoch 10, Step 15, Training Loss: 17.3426\n",
      "Epoch 10, Step 16, Training Loss: 11.7987\n",
      "Epoch 10, Step 17, Training Loss: 14.6523\n",
      "Epoch 10, Step 18, Training Loss: 11.1812\n",
      "Epoch 10, Step 19, Training Loss: 31.6503\n",
      "Epoch 10, Step 20, Training Loss: 17.4479\n",
      "Epoch 10, Step 21, Training Loss: 24.1903\n",
      "Epoch 10, Step 22, Training Loss: 32.4723\n",
      "Epoch 10, Step 23, Training Loss: 15.9762\n",
      "Epoch 10, Step 24, Training Loss: 13.2018\n",
      "Epoch 10, Step 25, Training Loss: 16.5976\n",
      "Epoch 10, Step 26, Training Loss: 16.0105\n",
      "Epoch 10, Step 27, Training Loss: 17.7246\n",
      "Epoch 10, Step 28, Training Loss: 15.0193\n",
      "Epoch 10, Step 29, Training Loss: 8.4070\n",
      "Epoch 10, Step 30, Training Loss: 11.5152\n",
      "Epoch 10, Step 31, Training Loss: 13.5812\n",
      "Epoch 10, Step 32, Training Loss: 17.8759\n",
      "Epoch 10, Step 33, Training Loss: 16.0093\n",
      "Epoch 10, Step 34, Training Loss: 13.5622\n",
      "Epoch 10, Step 35, Training Loss: 11.2426\n",
      "Epoch 10, Step 36, Training Loss: 19.1438\n",
      "Epoch 10, Step 37, Training Loss: 45.5393\n",
      "Epoch 10, Step 38, Training Loss: 18.7714\n",
      "Epoch 10, Step 39, Training Loss: 14.8661\n",
      "Epoch 10, Step 40, Training Loss: 18.2395\n",
      "Epoch 10, Step 41, Training Loss: 30.2662\n",
      "Epoch 10, Step 42, Training Loss: 17.6934\n",
      "Epoch 10, Step 43, Training Loss: 15.0983\n",
      "Epoch 10, Step 44, Training Loss: 15.7900\n",
      "Epoch 10, Step 45, Training Loss: 14.3554\n",
      "Epoch 10, Step 46, Training Loss: 13.5573\n",
      "Epoch 10, Step 47, Training Loss: 13.8978\n",
      "Epoch 10, Step 48, Training Loss: 12.2957\n",
      "Epoch 10, Step 49, Training Loss: 13.7214\n",
      "Epoch 10, Step 50, Training Loss: 9.3705\n",
      "Epoch 10, Step 51, Training Loss: 12.7122\n",
      "Epoch 10, Step 52, Training Loss: 11.7446\n",
      "Epoch 10, Step 53, Training Loss: 11.2065\n",
      "Epoch 10, Step 54, Training Loss: 15.4722\n",
      "Epoch 10, Step 55, Training Loss: 19.5102\n",
      "Epoch 10, Step 56, Training Loss: 26.3984\n",
      "Epoch 10, Step 57, Training Loss: 12.4954\n",
      "Epoch 10, Step 58, Training Loss: 20.0657\n",
      "Epoch 10, Step 59, Training Loss: 17.6343\n",
      "Epoch 10, Step 60, Training Loss: 51.6854\n",
      "Epoch 10, Step 61, Training Loss: 12.6080\n",
      "Epoch 10, Step 62, Training Loss: 19.2760\n",
      "Epoch 10, Step 63, Training Loss: 31.2655\n",
      "Epoch 10, Step 64, Training Loss: 17.6892\n",
      "Epoch 10, Step 65, Training Loss: 18.1544\n",
      "Epoch 10, Step 66, Training Loss: 12.6189\n",
      "Epoch 10, Step 67, Training Loss: 15.4048\n",
      "Epoch 10, Step 68, Training Loss: 13.5980\n",
      "Epoch 10, Step 69, Training Loss: 28.0877\n",
      "Epoch 10, Step 70, Training Loss: 13.7659\n",
      "Epoch 10, Step 71, Training Loss: 13.8206\n",
      "Epoch 10, Step 72, Training Loss: 22.8230\n",
      "Epoch 10, Step 73, Training Loss: 18.7916\n",
      "Epoch 10, Step 74, Training Loss: 15.5192\n",
      "Epoch 10, Step 75, Training Loss: 38.8702\n",
      "Epoch 10, Step 76, Training Loss: 33.5680\n",
      "Epoch 10, Step 77, Training Loss: 21.0602\n",
      "Epoch 10, Step 78, Training Loss: 9.6531\n",
      "Epoch 10, Step 79, Training Loss: 13.8460\n",
      "Epoch 10, Step 80, Training Loss: 27.3646\n",
      "Epoch 10, Step 81, Training Loss: 41.4950\n",
      "Epoch 10, Step 82, Training Loss: 13.2635\n",
      "Epoch 10, Step 83, Training Loss: 39.3517\n",
      "Epoch 10, Step 84, Training Loss: 40.5632\n",
      "Epoch 10, Step 85, Training Loss: 12.7995\n",
      "Epoch 10, Step 86, Training Loss: 14.7496\n",
      "Epoch 10, Step 87, Training Loss: 14.6578\n",
      "Epoch 10, Step 88, Training Loss: 20.3675\n",
      "Epoch 10, Step 89, Training Loss: 17.8889\n",
      "Epoch 10, Step 90, Training Loss: 18.0053\n",
      "Epoch 10, Step 91, Training Loss: 13.9326\n",
      "Epoch 10, Step 92, Training Loss: 29.4976\n",
      "Epoch 10, Step 93, Training Loss: 16.1462\n",
      "Epoch 10, Step 94, Training Loss: 30.7847\n",
      "Epoch 10, Step 95, Training Loss: 8.3366\n",
      "Epoch 10, Step 96, Training Loss: 19.9806\n",
      "Epoch 10, Step 97, Training Loss: 17.4781\n",
      "Epoch 10, Step 98, Training Loss: 22.7970\n",
      "Epoch 10, Step 99, Training Loss: 32.3356\n",
      "Epoch 10, Step 100, Training Loss: 12.7888\n",
      "Epoch 10, Step 101, Training Loss: 12.3650\n",
      "Epoch 10, Step 102, Training Loss: 15.0842\n",
      "Epoch 10, Step 103, Training Loss: 14.0090\n",
      "Epoch 10, Step 104, Training Loss: 21.7316\n",
      "Epoch 10, Step 105, Training Loss: 11.4106\n",
      "Epoch 10, Step 106, Training Loss: 23.5498\n",
      "Epoch 10, Step 107, Training Loss: 22.9969\n",
      "Epoch 10, Step 108, Training Loss: 13.4912\n",
      "Epoch 10, Step 109, Training Loss: 13.8097\n",
      "Epoch 10, Step 110, Training Loss: 15.4433\n",
      "Epoch 10, Step 111, Training Loss: 14.9146\n",
      "Epoch 10, Step 112, Training Loss: 13.6787\n",
      "Epoch 10, Step 113, Training Loss: 19.7959\n",
      "Epoch 10, Step 114, Training Loss: 16.3054\n",
      "Epoch 10, Step 115, Training Loss: 25.7512\n",
      "Epoch 10, Step 116, Training Loss: 14.0493\n",
      "Epoch 10, Step 117, Training Loss: 16.0731\n",
      "Epoch 10, Step 118, Training Loss: 14.2862\n",
      "Epoch 10, Step 119, Training Loss: 13.0599\n",
      "Epoch 10, Step 120, Training Loss: 17.0022\n",
      "Epoch 10, Step 121, Training Loss: 35.9890\n",
      "Epoch 10, Step 122, Training Loss: 34.7518\n",
      "Epoch 10, Step 123, Training Loss: 16.2312\n",
      "Epoch 10, Step 124, Training Loss: 18.3943\n",
      "Epoch 10, Step 125, Training Loss: 21.4255\n",
      "Epoch 10, Step 126, Training Loss: 17.8788\n",
      "Epoch 10, Step 127, Training Loss: 15.7422\n",
      "Epoch 10, Step 128, Training Loss: 14.3818\n",
      "Epoch 10, Step 129, Training Loss: 27.4874\n",
      "Epoch 10, Step 130, Training Loss: 16.9612\n",
      "Epoch 10, Step 131, Training Loss: 13.3901\n",
      "Epoch 10, Step 132, Training Loss: 22.4438\n",
      "Epoch 10, Step 133, Training Loss: 41.5914\n",
      "Epoch 10, Step 134, Training Loss: 24.6248\n",
      "Epoch 10, Step 135, Training Loss: 23.2637\n",
      "Epoch 10, Step 136, Training Loss: 53.3296\n",
      "Epoch 10, Step 137, Training Loss: 16.1832\n",
      "Epoch 10, Step 138, Training Loss: 17.7371\n",
      "Epoch 10, Step 139, Training Loss: 23.6893\n",
      "Epoch 10, Step 140, Training Loss: 11.6179\n",
      "Epoch 10, Step 141, Training Loss: 23.7395\n",
      "Epoch 10, Step 142, Training Loss: 13.6399\n",
      "Epoch 10, Step 143, Training Loss: 13.3444\n",
      "Epoch 10, Step 144, Training Loss: 12.8368\n",
      "Epoch 10, Step 145, Training Loss: 13.2035\n",
      "Epoch 10, Step 146, Training Loss: 12.3794\n",
      "Epoch 10, Step 147, Training Loss: 16.5506\n",
      "Epoch 10, Step 148, Training Loss: 66.9304\n",
      "Epoch 10, Step 149, Training Loss: 25.0847\n",
      "Epoch 10, Step 150, Training Loss: 24.1342\n",
      "Epoch 10, Step 151, Training Loss: 15.8379\n",
      "Epoch 10, Step 152, Training Loss: 10.8969\n",
      "Epoch 10, Step 153, Training Loss: 16.9658\n",
      "Epoch 10, Step 154, Training Loss: 16.7250\n",
      "Epoch 10, Step 155, Training Loss: 25.0410\n",
      "Epoch 10, Step 156, Training Loss: 16.4972\n",
      "Epoch 10, Step 157, Training Loss: 19.4861\n",
      "Epoch 10, Step 158, Training Loss: 14.2946\n",
      "Epoch 10, Step 159, Training Loss: 23.3007\n",
      "Epoch 10, Step 160, Training Loss: 50.6724\n",
      "Epoch 10, Step 161, Training Loss: 14.0200\n",
      "Epoch 10, Step 162, Training Loss: 10.9302\n",
      "Epoch 10, Step 163, Training Loss: 14.9131\n",
      "Epoch 10, Step 164, Training Loss: 11.7541\n",
      "Epoch 10, Step 165, Training Loss: 14.3737\n",
      "Epoch 10, Step 166, Training Loss: 8.9932\n",
      "Epoch 10, Step 167, Training Loss: 16.1497\n",
      "Epoch 10, Step 168, Training Loss: 25.7647\n",
      "Epoch 10, Step 169, Training Loss: 10.6404\n",
      "Epoch 10, Step 170, Training Loss: 12.7489\n",
      "Epoch 10, Step 171, Training Loss: 10.7305\n",
      "Epoch 10, Step 172, Training Loss: 21.6844\n",
      "Epoch 10, Step 173, Training Loss: 14.1954\n",
      "Epoch 10, Step 174, Training Loss: 15.0851\n",
      "Epoch 10, Step 175, Training Loss: 17.4486\n",
      "Epoch 10, Step 176, Training Loss: 15.9266\n",
      "Epoch 10, Step 177, Training Loss: 24.6966\n",
      "Epoch 10, Step 178, Training Loss: 13.6252\n",
      "Epoch 10, Step 179, Training Loss: 12.2101\n",
      "Epoch 10, Step 180, Training Loss: 17.0110\n",
      "Epoch 10, Step 181, Training Loss: 16.7141\n",
      "Epoch 10, Step 182, Training Loss: 18.2344\n",
      "Epoch 10, Step 183, Training Loss: 12.8629\n",
      "Epoch 10, Step 184, Training Loss: 10.8933\n",
      "Epoch 10, Step 185, Training Loss: 13.5273\n",
      "Epoch 10, Step 186, Training Loss: 24.2786\n",
      "Epoch 10, Step 187, Training Loss: 10.0954\n",
      "Epoch 10, Step 188, Training Loss: 111.4367\n",
      "Epoch 10, Step 189, Training Loss: 14.7098\n",
      "Epoch 10, Step 190, Training Loss: 107.4547\n",
      "Epoch 10, Step 191, Training Loss: 13.8859\n",
      "Epoch 10, Step 192, Training Loss: 19.3146\n",
      "Epoch 10, Step 193, Training Loss: 17.3441\n",
      "Epoch 10, Step 194, Training Loss: 14.9969\n",
      "Epoch 10, Step 195, Training Loss: 20.3502\n",
      "Epoch 10, Step 196, Training Loss: 23.3051\n",
      "Epoch 10, Step 197, Training Loss: 18.4885\n",
      "Epoch 10, Step 198, Training Loss: 13.8790\n",
      "Epoch 10, Step 199, Training Loss: 14.4289\n",
      "Epoch 10, Step 200, Training Loss: 9.2967\n",
      "Epoch 10, Step 201, Training Loss: 11.3934\n",
      "Epoch 10, Step 202, Training Loss: 14.5739\n",
      "Epoch 10, Step 203, Training Loss: 34.6132\n",
      "Epoch 10, Step 204, Training Loss: 26.4155\n",
      "Epoch 10, Step 205, Training Loss: 17.1329\n",
      "Epoch 10, Step 206, Training Loss: 13.4023\n",
      "--- Epoch 10, Validation Loss: 16.6996 ---\n",
      "Epoch 11, Step 0, Training Loss: 14.6655\n",
      "Epoch 11, Step 1, Training Loss: 13.7206\n",
      "Epoch 11, Step 2, Training Loss: 15.9810\n",
      "Epoch 11, Step 3, Training Loss: 31.9390\n",
      "Epoch 11, Step 4, Training Loss: 37.6349\n",
      "Epoch 11, Step 5, Training Loss: 12.6202\n",
      "Epoch 11, Step 6, Training Loss: 14.5553\n",
      "Epoch 11, Step 7, Training Loss: 14.9701\n",
      "Epoch 11, Step 8, Training Loss: 12.3256\n",
      "Epoch 11, Step 9, Training Loss: 15.1705\n",
      "Epoch 11, Step 10, Training Loss: 42.6409\n",
      "Epoch 11, Step 11, Training Loss: 15.3376\n",
      "Epoch 11, Step 12, Training Loss: 20.2798\n",
      "Epoch 11, Step 13, Training Loss: 44.6624\n",
      "Epoch 11, Step 14, Training Loss: 15.7031\n",
      "Epoch 11, Step 15, Training Loss: 15.9420\n",
      "Epoch 11, Step 16, Training Loss: 11.1000\n",
      "Epoch 11, Step 17, Training Loss: 13.2075\n",
      "Epoch 11, Step 18, Training Loss: 14.9897\n",
      "Epoch 11, Step 19, Training Loss: 31.3910\n",
      "Epoch 11, Step 20, Training Loss: 18.6213\n",
      "Epoch 11, Step 21, Training Loss: 20.4972\n",
      "Epoch 11, Step 22, Training Loss: 30.7023\n",
      "Epoch 11, Step 23, Training Loss: 13.6828\n",
      "Epoch 11, Step 24, Training Loss: 14.0729\n",
      "Epoch 11, Step 25, Training Loss: 16.0325\n",
      "Epoch 11, Step 26, Training Loss: 17.7138\n",
      "Epoch 11, Step 27, Training Loss: 20.8654\n",
      "Epoch 11, Step 28, Training Loss: 14.3296\n",
      "Epoch 11, Step 29, Training Loss: 9.4970\n",
      "Epoch 11, Step 30, Training Loss: 12.3571\n",
      "Epoch 11, Step 31, Training Loss: 14.9999\n",
      "Epoch 11, Step 32, Training Loss: 18.6671\n",
      "Epoch 11, Step 33, Training Loss: 17.8632\n",
      "Epoch 11, Step 34, Training Loss: 15.1508\n",
      "Epoch 11, Step 35, Training Loss: 14.0507\n",
      "Epoch 11, Step 36, Training Loss: 19.4780\n",
      "Epoch 11, Step 37, Training Loss: 40.4864\n",
      "Epoch 11, Step 38, Training Loss: 18.9284\n",
      "Epoch 11, Step 39, Training Loss: 14.6321\n",
      "Epoch 11, Step 40, Training Loss: 15.2495\n",
      "Epoch 11, Step 41, Training Loss: 23.4602\n",
      "Epoch 11, Step 42, Training Loss: 16.2494\n",
      "Epoch 11, Step 43, Training Loss: 16.0314\n",
      "Epoch 11, Step 44, Training Loss: 18.5272\n",
      "Epoch 11, Step 45, Training Loss: 13.5467\n",
      "Epoch 11, Step 46, Training Loss: 12.7838\n",
      "Epoch 11, Step 47, Training Loss: 12.7777\n",
      "Epoch 11, Step 48, Training Loss: 11.8838\n",
      "Epoch 11, Step 49, Training Loss: 16.7533\n",
      "Epoch 11, Step 50, Training Loss: 9.9414\n",
      "Epoch 11, Step 51, Training Loss: 11.6844\n",
      "Epoch 11, Step 52, Training Loss: 11.8546\n",
      "Epoch 11, Step 53, Training Loss: 11.8391\n",
      "Epoch 11, Step 54, Training Loss: 15.2303\n",
      "Epoch 11, Step 55, Training Loss: 18.3557\n",
      "Epoch 11, Step 56, Training Loss: 26.4082\n",
      "Epoch 11, Step 57, Training Loss: 14.6264\n",
      "Epoch 11, Step 58, Training Loss: 22.3672\n",
      "Epoch 11, Step 59, Training Loss: 15.2214\n",
      "Epoch 11, Step 60, Training Loss: 50.4145\n",
      "Epoch 11, Step 61, Training Loss: 15.0682\n",
      "Epoch 11, Step 62, Training Loss: 19.9275\n",
      "Epoch 11, Step 63, Training Loss: 33.1731\n",
      "Epoch 11, Step 64, Training Loss: 16.9249\n",
      "Epoch 11, Step 65, Training Loss: 19.1401\n",
      "Epoch 11, Step 66, Training Loss: 13.5051\n",
      "Epoch 11, Step 67, Training Loss: 13.9613\n",
      "Epoch 11, Step 68, Training Loss: 12.1083\n",
      "Epoch 11, Step 69, Training Loss: 35.2043\n",
      "Epoch 11, Step 70, Training Loss: 17.3530\n",
      "Epoch 11, Step 71, Training Loss: 11.4262\n",
      "Epoch 11, Step 72, Training Loss: 21.4052\n",
      "Epoch 11, Step 73, Training Loss: 19.0053\n",
      "Epoch 11, Step 74, Training Loss: 16.2293\n",
      "Epoch 11, Step 75, Training Loss: 33.5300\n",
      "Epoch 11, Step 76, Training Loss: 35.5558\n",
      "Epoch 11, Step 77, Training Loss: 23.7758\n",
      "Epoch 11, Step 78, Training Loss: 14.0188\n",
      "Epoch 11, Step 79, Training Loss: 17.5569\n",
      "Epoch 11, Step 80, Training Loss: 27.6074\n",
      "Epoch 11, Step 81, Training Loss: 40.2044\n",
      "Epoch 11, Step 82, Training Loss: 12.7392\n",
      "Epoch 11, Step 83, Training Loss: 38.6771\n",
      "Epoch 11, Step 84, Training Loss: 39.7100\n",
      "Epoch 11, Step 85, Training Loss: 15.4377\n",
      "Epoch 11, Step 86, Training Loss: 14.7774\n",
      "Epoch 11, Step 87, Training Loss: 17.3173\n",
      "Epoch 11, Step 88, Training Loss: 20.6257\n",
      "Epoch 11, Step 89, Training Loss: 17.8541\n",
      "Epoch 11, Step 90, Training Loss: 15.7538\n",
      "Epoch 11, Step 91, Training Loss: 11.5588\n",
      "Epoch 11, Step 92, Training Loss: 27.3337\n",
      "Epoch 11, Step 93, Training Loss: 15.1209\n",
      "Epoch 11, Step 94, Training Loss: 30.8900\n",
      "Epoch 11, Step 95, Training Loss: 11.5222\n",
      "Epoch 11, Step 96, Training Loss: 17.0220\n",
      "Epoch 11, Step 97, Training Loss: 18.2046\n",
      "Epoch 11, Step 98, Training Loss: 24.1468\n",
      "Epoch 11, Step 99, Training Loss: 32.6588\n",
      "Epoch 11, Step 100, Training Loss: 14.2408\n",
      "Epoch 11, Step 101, Training Loss: 11.9646\n",
      "Epoch 11, Step 102, Training Loss: 12.3871\n",
      "Epoch 11, Step 103, Training Loss: 15.1895\n",
      "Epoch 11, Step 104, Training Loss: 20.7666\n",
      "Epoch 11, Step 105, Training Loss: 12.4746\n",
      "Epoch 11, Step 106, Training Loss: 22.6454\n",
      "Epoch 11, Step 107, Training Loss: 21.4549\n",
      "Epoch 11, Step 108, Training Loss: 11.9167\n",
      "Epoch 11, Step 109, Training Loss: 9.6638\n",
      "Epoch 11, Step 110, Training Loss: 15.4831\n",
      "Epoch 11, Step 111, Training Loss: 12.8114\n",
      "Epoch 11, Step 112, Training Loss: 14.2980\n",
      "Epoch 11, Step 113, Training Loss: 19.8864\n",
      "Epoch 11, Step 114, Training Loss: 15.6436\n",
      "Epoch 11, Step 115, Training Loss: 25.3059\n",
      "Epoch 11, Step 116, Training Loss: 11.6914\n",
      "Epoch 11, Step 117, Training Loss: 15.6736\n",
      "Epoch 11, Step 118, Training Loss: 12.5986\n",
      "Epoch 11, Step 119, Training Loss: 13.9625\n",
      "Epoch 11, Step 120, Training Loss: 14.9703\n",
      "Epoch 11, Step 121, Training Loss: 37.5776\n",
      "Epoch 11, Step 122, Training Loss: 35.3487\n",
      "Epoch 11, Step 123, Training Loss: 12.4667\n",
      "Epoch 11, Step 124, Training Loss: 19.5903\n",
      "Epoch 11, Step 125, Training Loss: 21.3792\n",
      "Epoch 11, Step 126, Training Loss: 16.3055\n",
      "Epoch 11, Step 127, Training Loss: 16.6799\n",
      "Epoch 11, Step 128, Training Loss: 14.5563\n",
      "Epoch 11, Step 129, Training Loss: 26.5826\n",
      "Epoch 11, Step 130, Training Loss: 11.0986\n",
      "Epoch 11, Step 131, Training Loss: 12.8567\n",
      "Epoch 11, Step 132, Training Loss: 21.8306\n",
      "Epoch 11, Step 133, Training Loss: 38.9422\n",
      "Epoch 11, Step 134, Training Loss: 24.8844\n",
      "Epoch 11, Step 135, Training Loss: 19.6293\n",
      "Epoch 11, Step 136, Training Loss: 43.6165\n",
      "Epoch 11, Step 137, Training Loss: 13.6488\n",
      "Epoch 11, Step 138, Training Loss: 15.0257\n",
      "Epoch 11, Step 139, Training Loss: 18.6920\n",
      "Epoch 11, Step 140, Training Loss: 12.0598\n",
      "Epoch 11, Step 141, Training Loss: 23.3693\n",
      "Epoch 11, Step 142, Training Loss: 11.5393\n",
      "Epoch 11, Step 143, Training Loss: 12.5323\n",
      "Epoch 11, Step 144, Training Loss: 11.1105\n",
      "Epoch 11, Step 145, Training Loss: 11.5306\n",
      "Epoch 11, Step 146, Training Loss: 14.5859\n",
      "Epoch 11, Step 147, Training Loss: 13.9849\n",
      "Epoch 11, Step 148, Training Loss: 63.4693\n",
      "Epoch 11, Step 149, Training Loss: 20.6091\n",
      "Epoch 11, Step 150, Training Loss: 25.0659\n",
      "Epoch 11, Step 151, Training Loss: 13.4919\n",
      "Epoch 11, Step 152, Training Loss: 12.0734\n",
      "Epoch 11, Step 153, Training Loss: 15.7590\n",
      "Epoch 11, Step 154, Training Loss: 14.1111\n",
      "Epoch 11, Step 155, Training Loss: 19.7276\n",
      "Epoch 11, Step 156, Training Loss: 12.9633\n",
      "Epoch 11, Step 157, Training Loss: 18.5331\n",
      "Epoch 11, Step 158, Training Loss: 13.2088\n",
      "Epoch 11, Step 159, Training Loss: 21.3055\n",
      "Epoch 11, Step 160, Training Loss: 46.5726\n",
      "Epoch 11, Step 161, Training Loss: 13.3122\n",
      "Epoch 11, Step 162, Training Loss: 12.7483\n",
      "Epoch 11, Step 163, Training Loss: 15.0773\n",
      "Epoch 11, Step 164, Training Loss: 12.1511\n",
      "Epoch 11, Step 165, Training Loss: 14.5918\n",
      "Epoch 11, Step 166, Training Loss: 9.7454\n",
      "Epoch 11, Step 167, Training Loss: 13.9847\n",
      "Epoch 11, Step 168, Training Loss: 26.5719\n",
      "Epoch 11, Step 169, Training Loss: 10.6698\n",
      "Epoch 11, Step 170, Training Loss: 13.1320\n",
      "Epoch 11, Step 171, Training Loss: 10.8290\n",
      "Epoch 11, Step 172, Training Loss: 23.1284\n",
      "Epoch 11, Step 173, Training Loss: 16.4808\n",
      "Epoch 11, Step 174, Training Loss: 12.7176\n",
      "Epoch 11, Step 175, Training Loss: 19.3366\n",
      "Epoch 11, Step 176, Training Loss: 13.6583\n",
      "Epoch 11, Step 177, Training Loss: 24.9430\n",
      "Epoch 11, Step 178, Training Loss: 14.8494\n",
      "Epoch 11, Step 179, Training Loss: 11.8525\n",
      "Epoch 11, Step 180, Training Loss: 17.4305\n",
      "Epoch 11, Step 181, Training Loss: 12.2053\n",
      "Epoch 11, Step 182, Training Loss: 18.4157\n",
      "Epoch 11, Step 183, Training Loss: 13.4200\n",
      "Epoch 11, Step 184, Training Loss: 12.2795\n",
      "Epoch 11, Step 185, Training Loss: 12.8948\n",
      "Epoch 11, Step 186, Training Loss: 23.6663\n",
      "Epoch 11, Step 187, Training Loss: 12.7409\n",
      "Epoch 11, Step 188, Training Loss: 109.9353\n",
      "Epoch 11, Step 189, Training Loss: 15.0998\n",
      "Epoch 11, Step 190, Training Loss: 104.7265\n",
      "Epoch 11, Step 191, Training Loss: 14.5694\n",
      "Epoch 11, Step 192, Training Loss: 19.0742\n",
      "Epoch 11, Step 193, Training Loss: 15.5944\n",
      "Epoch 11, Step 194, Training Loss: 11.8301\n",
      "Epoch 11, Step 195, Training Loss: 16.0359\n",
      "Epoch 11, Step 196, Training Loss: 24.9153\n",
      "Epoch 11, Step 197, Training Loss: 16.0574\n",
      "Epoch 11, Step 198, Training Loss: 14.2488\n",
      "Epoch 11, Step 199, Training Loss: 13.2310\n",
      "Epoch 11, Step 200, Training Loss: 10.6679\n",
      "Epoch 11, Step 201, Training Loss: 11.8202\n",
      "Epoch 11, Step 202, Training Loss: 14.5988\n",
      "Epoch 11, Step 203, Training Loss: 31.2782\n",
      "Epoch 11, Step 204, Training Loss: 23.0760\n",
      "Epoch 11, Step 205, Training Loss: 13.8109\n",
      "Epoch 11, Step 206, Training Loss: 12.0054\n",
      "--- Epoch 11, Validation Loss: 17.1922 ---\n",
      "Epoch 12, Step 0, Training Loss: 14.6020\n",
      "Epoch 12, Step 1, Training Loss: 12.4397\n",
      "Epoch 12, Step 2, Training Loss: 12.5895\n",
      "Epoch 12, Step 3, Training Loss: 30.3802\n",
      "Epoch 12, Step 4, Training Loss: 37.0434\n",
      "Epoch 12, Step 5, Training Loss: 11.7258\n",
      "Epoch 12, Step 6, Training Loss: 15.4053\n",
      "Epoch 12, Step 7, Training Loss: 16.3731\n",
      "Epoch 12, Step 8, Training Loss: 9.9668\n",
      "Epoch 12, Step 9, Training Loss: 12.5795\n",
      "Epoch 12, Step 10, Training Loss: 37.9139\n",
      "Epoch 12, Step 11, Training Loss: 15.5914\n",
      "Epoch 12, Step 12, Training Loss: 17.2161\n",
      "Epoch 12, Step 13, Training Loss: 43.4611\n",
      "Epoch 12, Step 14, Training Loss: 14.6473\n",
      "Epoch 12, Step 15, Training Loss: 16.2152\n",
      "Epoch 12, Step 16, Training Loss: 11.8525\n",
      "Epoch 12, Step 17, Training Loss: 12.9351\n",
      "Epoch 12, Step 18, Training Loss: 10.2099\n",
      "Epoch 12, Step 19, Training Loss: 30.0566\n",
      "Epoch 12, Step 20, Training Loss: 15.3699\n",
      "Epoch 12, Step 21, Training Loss: 19.3799\n",
      "Epoch 12, Step 22, Training Loss: 29.7139\n",
      "Epoch 12, Step 23, Training Loss: 15.8793\n",
      "Epoch 12, Step 24, Training Loss: 12.6372\n",
      "Epoch 12, Step 25, Training Loss: 16.6568\n",
      "Epoch 12, Step 26, Training Loss: 15.2023\n",
      "Epoch 12, Step 27, Training Loss: 16.5946\n",
      "Epoch 12, Step 28, Training Loss: 13.7914\n",
      "Epoch 12, Step 29, Training Loss: 9.2035\n",
      "Epoch 12, Step 30, Training Loss: 10.0497\n",
      "Epoch 12, Step 31, Training Loss: 13.5828\n",
      "Epoch 12, Step 32, Training Loss: 16.5054\n",
      "Epoch 12, Step 33, Training Loss: 15.5773\n",
      "Epoch 12, Step 34, Training Loss: 16.0618\n",
      "Epoch 12, Step 35, Training Loss: 10.6171\n",
      "Epoch 12, Step 36, Training Loss: 20.2667\n",
      "Epoch 12, Step 37, Training Loss: 37.7378\n",
      "Epoch 12, Step 38, Training Loss: 20.2254\n",
      "Epoch 12, Step 39, Training Loss: 15.9988\n",
      "Epoch 12, Step 40, Training Loss: 19.3783\n",
      "Epoch 12, Step 41, Training Loss: 24.9851\n",
      "Epoch 12, Step 42, Training Loss: 14.5093\n",
      "Epoch 12, Step 43, Training Loss: 15.4232\n",
      "Epoch 12, Step 44, Training Loss: 16.9036\n",
      "Epoch 12, Step 45, Training Loss: 13.1930\n",
      "Epoch 12, Step 46, Training Loss: 9.1146\n",
      "Epoch 12, Step 47, Training Loss: 12.6584\n",
      "Epoch 12, Step 48, Training Loss: 9.8279\n",
      "Epoch 12, Step 49, Training Loss: 14.6112\n",
      "Epoch 12, Step 50, Training Loss: 9.2056\n",
      "Epoch 12, Step 51, Training Loss: 12.1571\n",
      "Epoch 12, Step 52, Training Loss: 12.5586\n",
      "Epoch 12, Step 53, Training Loss: 7.9294\n",
      "Epoch 12, Step 54, Training Loss: 14.1536\n",
      "Epoch 12, Step 55, Training Loss: 13.3993\n",
      "Epoch 12, Step 56, Training Loss: 23.4846\n",
      "Epoch 12, Step 57, Training Loss: 11.3869\n",
      "Epoch 12, Step 58, Training Loss: 19.2936\n",
      "Epoch 12, Step 59, Training Loss: 16.5076\n",
      "Epoch 12, Step 60, Training Loss: 47.3699\n",
      "Epoch 12, Step 61, Training Loss: 10.7321\n",
      "Epoch 12, Step 62, Training Loss: 20.0625\n",
      "Epoch 12, Step 63, Training Loss: 32.4575\n",
      "Epoch 12, Step 64, Training Loss: 15.8749\n",
      "Epoch 12, Step 65, Training Loss: 18.0470\n",
      "Epoch 12, Step 66, Training Loss: 11.7007\n",
      "Epoch 12, Step 67, Training Loss: 16.3085\n",
      "Epoch 12, Step 68, Training Loss: 16.0967\n",
      "Epoch 12, Step 69, Training Loss: 34.0939\n",
      "Epoch 12, Step 70, Training Loss: 13.5274\n",
      "Epoch 12, Step 71, Training Loss: 9.6053\n",
      "Epoch 12, Step 72, Training Loss: 19.7932\n",
      "Epoch 12, Step 73, Training Loss: 17.7384\n",
      "Epoch 12, Step 74, Training Loss: 13.5494\n",
      "Epoch 12, Step 75, Training Loss: 35.5440\n",
      "Epoch 12, Step 76, Training Loss: 34.1749\n",
      "Epoch 12, Step 77, Training Loss: 26.6445\n",
      "Epoch 12, Step 78, Training Loss: 9.6265\n",
      "Epoch 12, Step 79, Training Loss: 14.6566\n",
      "Epoch 12, Step 80, Training Loss: 25.2927\n",
      "Epoch 12, Step 81, Training Loss: 39.0353\n",
      "Epoch 12, Step 82, Training Loss: 11.3454\n",
      "Epoch 12, Step 83, Training Loss: 36.5883\n",
      "Epoch 12, Step 84, Training Loss: 36.8477\n",
      "Epoch 12, Step 85, Training Loss: 12.2287\n",
      "Epoch 12, Step 86, Training Loss: 14.3726\n",
      "Epoch 12, Step 87, Training Loss: 16.5076\n",
      "Epoch 12, Step 88, Training Loss: 20.9381\n",
      "Epoch 12, Step 89, Training Loss: 17.4324\n",
      "Epoch 12, Step 90, Training Loss: 15.6597\n",
      "Epoch 12, Step 91, Training Loss: 12.7561\n",
      "Epoch 12, Step 92, Training Loss: 26.0421\n",
      "Epoch 12, Step 93, Training Loss: 13.8496\n",
      "Epoch 12, Step 94, Training Loss: 29.0586\n",
      "Epoch 12, Step 95, Training Loss: 9.9982\n",
      "Epoch 12, Step 96, Training Loss: 14.1653\n",
      "Epoch 12, Step 97, Training Loss: 14.1385\n",
      "Epoch 12, Step 98, Training Loss: 20.3220\n",
      "Epoch 12, Step 99, Training Loss: 31.8969\n",
      "Epoch 12, Step 100, Training Loss: 11.8758\n",
      "Epoch 12, Step 101, Training Loss: 10.8115\n",
      "Epoch 12, Step 102, Training Loss: 12.5971\n",
      "Epoch 12, Step 103, Training Loss: 11.6295\n",
      "Epoch 12, Step 104, Training Loss: 17.8907\n",
      "Epoch 12, Step 105, Training Loss: 10.8596\n",
      "Epoch 12, Step 106, Training Loss: 22.0918\n",
      "Epoch 12, Step 107, Training Loss: 19.1710\n",
      "Epoch 12, Step 108, Training Loss: 9.7980\n",
      "Epoch 12, Step 109, Training Loss: 9.3170\n",
      "Epoch 12, Step 110, Training Loss: 15.6929\n",
      "Epoch 12, Step 111, Training Loss: 11.4253\n",
      "Epoch 12, Step 112, Training Loss: 14.6714\n",
      "Epoch 12, Step 113, Training Loss: 16.2656\n",
      "Epoch 12, Step 114, Training Loss: 12.1965\n",
      "Epoch 12, Step 115, Training Loss: 23.5719\n",
      "Epoch 12, Step 116, Training Loss: 10.7187\n",
      "Epoch 12, Step 117, Training Loss: 13.4627\n",
      "Epoch 12, Step 118, Training Loss: 9.8714\n",
      "Epoch 12, Step 119, Training Loss: 11.6242\n",
      "Epoch 12, Step 120, Training Loss: 14.8300\n",
      "Epoch 12, Step 121, Training Loss: 34.2304\n",
      "Epoch 12, Step 122, Training Loss: 35.0670\n",
      "Epoch 12, Step 123, Training Loss: 15.1383\n",
      "Epoch 12, Step 124, Training Loss: 17.5933\n",
      "Epoch 12, Step 125, Training Loss: 20.1401\n",
      "Epoch 12, Step 126, Training Loss: 15.8199\n",
      "Epoch 12, Step 127, Training Loss: 15.0859\n",
      "Epoch 12, Step 128, Training Loss: 12.9875\n",
      "Epoch 12, Step 129, Training Loss: 25.4550\n",
      "Epoch 12, Step 130, Training Loss: 10.8687\n",
      "Epoch 12, Step 131, Training Loss: 13.2359\n",
      "Epoch 12, Step 132, Training Loss: 17.2395\n",
      "Epoch 12, Step 133, Training Loss: 38.9258\n",
      "Epoch 12, Step 134, Training Loss: 21.3631\n",
      "Epoch 12, Step 135, Training Loss: 18.5679\n",
      "Epoch 12, Step 136, Training Loss: 43.9270\n",
      "Epoch 12, Step 137, Training Loss: 11.2692\n",
      "Epoch 12, Step 138, Training Loss: 12.4038\n",
      "Epoch 12, Step 139, Training Loss: 17.6493\n",
      "Epoch 12, Step 140, Training Loss: 12.1371\n",
      "Epoch 12, Step 141, Training Loss: 20.8118\n",
      "Epoch 12, Step 142, Training Loss: 10.9679\n",
      "Epoch 12, Step 143, Training Loss: 12.5673\n",
      "Epoch 12, Step 144, Training Loss: 10.0407\n",
      "Epoch 12, Step 145, Training Loss: 13.0103\n",
      "Epoch 12, Step 146, Training Loss: 15.8441\n",
      "Epoch 12, Step 147, Training Loss: 13.7273\n",
      "Epoch 12, Step 148, Training Loss: 67.4558\n",
      "Epoch 12, Step 149, Training Loss: 19.5976\n",
      "Epoch 12, Step 150, Training Loss: 24.1570\n",
      "Epoch 12, Step 151, Training Loss: 14.6010\n",
      "Epoch 12, Step 152, Training Loss: 11.1964\n",
      "Epoch 12, Step 153, Training Loss: 13.7900\n",
      "Epoch 12, Step 154, Training Loss: 12.1084\n",
      "Epoch 12, Step 155, Training Loss: 20.9375\n",
      "Epoch 12, Step 156, Training Loss: 14.1070\n",
      "Epoch 12, Step 157, Training Loss: 19.4524\n",
      "Epoch 12, Step 158, Training Loss: 12.0615\n",
      "Epoch 12, Step 159, Training Loss: 22.4771\n",
      "Epoch 12, Step 160, Training Loss: 47.3265\n",
      "Epoch 12, Step 161, Training Loss: 19.4981\n",
      "Epoch 12, Step 162, Training Loss: 11.2690\n",
      "Epoch 12, Step 163, Training Loss: 13.2277\n",
      "Epoch 12, Step 164, Training Loss: 10.5088\n",
      "Epoch 12, Step 165, Training Loss: 15.2549\n",
      "Epoch 12, Step 166, Training Loss: 10.4899\n",
      "Epoch 12, Step 167, Training Loss: 17.1691\n",
      "Epoch 12, Step 168, Training Loss: 20.6269\n",
      "Epoch 12, Step 169, Training Loss: 12.5061\n",
      "Epoch 12, Step 170, Training Loss: 12.7425\n",
      "Epoch 12, Step 171, Training Loss: 9.1471\n",
      "Epoch 12, Step 172, Training Loss: 19.9158\n",
      "Epoch 12, Step 173, Training Loss: 16.2863\n",
      "Epoch 12, Step 174, Training Loss: 12.9765\n",
      "Epoch 12, Step 175, Training Loss: 17.0290\n",
      "Epoch 12, Step 176, Training Loss: 16.0791\n",
      "Epoch 12, Step 177, Training Loss: 32.5406\n",
      "Epoch 12, Step 178, Training Loss: 13.9404\n",
      "Epoch 12, Step 179, Training Loss: 10.3756\n",
      "Epoch 12, Step 180, Training Loss: 13.3992\n",
      "Epoch 12, Step 181, Training Loss: 10.3142\n",
      "Epoch 12, Step 182, Training Loss: 15.4951\n",
      "Epoch 12, Step 183, Training Loss: 12.4099\n",
      "Epoch 12, Step 184, Training Loss: 9.9415\n",
      "Epoch 12, Step 185, Training Loss: 16.8548\n",
      "Epoch 12, Step 186, Training Loss: 29.1527\n",
      "Epoch 12, Step 187, Training Loss: 9.5777\n",
      "Epoch 12, Step 188, Training Loss: 110.6570\n",
      "Epoch 12, Step 189, Training Loss: 12.8566\n",
      "Epoch 12, Step 190, Training Loss: 105.5113\n",
      "Epoch 12, Step 191, Training Loss: 11.4084\n",
      "Epoch 12, Step 192, Training Loss: 13.7383\n",
      "Epoch 12, Step 193, Training Loss: 16.9929\n",
      "Epoch 12, Step 194, Training Loss: 12.4243\n",
      "Epoch 12, Step 195, Training Loss: 14.2611\n",
      "Epoch 12, Step 196, Training Loss: 23.1485\n",
      "Epoch 12, Step 197, Training Loss: 17.7104\n",
      "Epoch 12, Step 198, Training Loss: 12.2408\n",
      "Epoch 12, Step 199, Training Loss: 13.8163\n",
      "Epoch 12, Step 200, Training Loss: 10.2872\n",
      "Epoch 12, Step 201, Training Loss: 10.1268\n",
      "Epoch 12, Step 202, Training Loss: 12.3277\n",
      "Epoch 12, Step 203, Training Loss: 31.2379\n",
      "Epoch 12, Step 204, Training Loss: 28.2999\n",
      "Epoch 12, Step 205, Training Loss: 15.6371\n",
      "Epoch 12, Step 206, Training Loss: 12.4777\n",
      "--- Epoch 12, Validation Loss: 15.7737 ---\n",
      "Epoch 13, Step 0, Training Loss: 14.2356\n",
      "Epoch 13, Step 1, Training Loss: 14.5626\n",
      "Epoch 13, Step 2, Training Loss: 10.6377\n",
      "Epoch 13, Step 3, Training Loss: 30.6819\n",
      "Epoch 13, Step 4, Training Loss: 29.3078\n",
      "Epoch 13, Step 5, Training Loss: 10.3132\n",
      "Epoch 13, Step 6, Training Loss: 13.5865\n",
      "Epoch 13, Step 7, Training Loss: 16.7699\n",
      "Epoch 13, Step 8, Training Loss: 9.3382\n",
      "Epoch 13, Step 9, Training Loss: 13.0985\n",
      "Epoch 13, Step 10, Training Loss: 39.3310\n",
      "Epoch 13, Step 11, Training Loss: 14.2223\n",
      "Epoch 13, Step 12, Training Loss: 17.5086\n",
      "Epoch 13, Step 13, Training Loss: 39.9781\n",
      "Epoch 13, Step 14, Training Loss: 13.5664\n",
      "Epoch 13, Step 15, Training Loss: 16.2050\n",
      "Epoch 13, Step 16, Training Loss: 8.0293\n",
      "Epoch 13, Step 17, Training Loss: 10.3279\n",
      "Epoch 13, Step 18, Training Loss: 10.3863\n",
      "Epoch 13, Step 19, Training Loss: 29.5845\n",
      "Epoch 13, Step 20, Training Loss: 13.3213\n",
      "Epoch 13, Step 21, Training Loss: 15.6789\n",
      "Epoch 13, Step 22, Training Loss: 25.3760\n",
      "Epoch 13, Step 23, Training Loss: 12.8289\n",
      "Epoch 13, Step 24, Training Loss: 10.9513\n",
      "Epoch 13, Step 25, Training Loss: 15.8656\n",
      "Epoch 13, Step 26, Training Loss: 15.2192\n",
      "Epoch 13, Step 27, Training Loss: 17.5265\n",
      "Epoch 13, Step 28, Training Loss: 12.5796\n",
      "Epoch 13, Step 29, Training Loss: 8.1411\n",
      "Epoch 13, Step 30, Training Loss: 11.9393\n",
      "Epoch 13, Step 31, Training Loss: 12.5311\n",
      "Epoch 13, Step 32, Training Loss: 14.7098\n",
      "Epoch 13, Step 33, Training Loss: 18.3716\n",
      "Epoch 13, Step 34, Training Loss: 10.7247\n",
      "Epoch 13, Step 35, Training Loss: 10.7873\n",
      "Epoch 13, Step 36, Training Loss: 17.7299\n",
      "Epoch 13, Step 37, Training Loss: 32.7437\n",
      "Epoch 13, Step 38, Training Loss: 16.8318\n",
      "Epoch 13, Step 39, Training Loss: 12.6007\n",
      "Epoch 13, Step 40, Training Loss: 16.3075\n",
      "Epoch 13, Step 41, Training Loss: 21.4159\n",
      "Epoch 13, Step 42, Training Loss: 13.1224\n",
      "Epoch 13, Step 43, Training Loss: 12.1888\n",
      "Epoch 13, Step 44, Training Loss: 16.2658\n",
      "Epoch 13, Step 45, Training Loss: 10.0019\n",
      "Epoch 13, Step 46, Training Loss: 9.6389\n",
      "Epoch 13, Step 47, Training Loss: 12.0885\n",
      "Epoch 13, Step 48, Training Loss: 9.7902\n",
      "Epoch 13, Step 49, Training Loss: 13.6362\n",
      "Epoch 13, Step 50, Training Loss: 8.0843\n",
      "Epoch 13, Step 51, Training Loss: 11.2807\n",
      "Epoch 13, Step 52, Training Loss: 10.9904\n",
      "Epoch 13, Step 53, Training Loss: 7.0342\n",
      "Epoch 13, Step 54, Training Loss: 11.7198\n",
      "Epoch 13, Step 55, Training Loss: 14.3600\n",
      "Epoch 13, Step 56, Training Loss: 24.8961\n",
      "Epoch 13, Step 57, Training Loss: 10.4115\n",
      "Epoch 13, Step 58, Training Loss: 19.6828\n",
      "Epoch 13, Step 59, Training Loss: 13.9880\n",
      "Epoch 13, Step 60, Training Loss: 44.6595\n",
      "Epoch 13, Step 61, Training Loss: 8.4696\n",
      "Epoch 13, Step 62, Training Loss: 17.2498\n",
      "Epoch 13, Step 63, Training Loss: 30.2395\n",
      "Epoch 13, Step 64, Training Loss: 14.7285\n",
      "Epoch 13, Step 65, Training Loss: 14.0973\n",
      "Epoch 13, Step 66, Training Loss: 13.3294\n",
      "Epoch 13, Step 67, Training Loss: 14.0571\n",
      "Epoch 13, Step 68, Training Loss: 9.9728\n",
      "Epoch 13, Step 69, Training Loss: 28.5454\n",
      "Epoch 13, Step 70, Training Loss: 9.5050\n",
      "Epoch 13, Step 71, Training Loss: 9.9628\n",
      "Epoch 13, Step 72, Training Loss: 18.3230\n",
      "Epoch 13, Step 73, Training Loss: 20.4117\n",
      "Epoch 13, Step 74, Training Loss: 12.1620\n",
      "Epoch 13, Step 75, Training Loss: 30.1290\n",
      "Epoch 13, Step 76, Training Loss: 29.4866\n",
      "Epoch 13, Step 77, Training Loss: 17.2657\n",
      "Epoch 13, Step 78, Training Loss: 8.4304\n",
      "Epoch 13, Step 79, Training Loss: 14.1194\n",
      "Epoch 13, Step 80, Training Loss: 21.5554\n",
      "Epoch 13, Step 81, Training Loss: 35.3790\n",
      "Epoch 13, Step 82, Training Loss: 12.5253\n",
      "Epoch 13, Step 83, Training Loss: 36.6271\n",
      "Epoch 13, Step 84, Training Loss: 35.9634\n",
      "Epoch 13, Step 85, Training Loss: 11.8133\n",
      "Epoch 13, Step 86, Training Loss: 11.3409\n",
      "Epoch 13, Step 87, Training Loss: 14.3301\n",
      "Epoch 13, Step 88, Training Loss: 21.9170\n",
      "Epoch 13, Step 89, Training Loss: 14.8468\n",
      "Epoch 13, Step 90, Training Loss: 13.8751\n",
      "Epoch 13, Step 91, Training Loss: 7.8672\n",
      "Epoch 13, Step 92, Training Loss: 25.1921\n",
      "Epoch 13, Step 93, Training Loss: 14.0774\n",
      "Epoch 13, Step 94, Training Loss: 25.7948\n",
      "Epoch 13, Step 95, Training Loss: 8.8949\n",
      "Epoch 13, Step 96, Training Loss: 15.1927\n",
      "Epoch 13, Step 97, Training Loss: 12.2593\n",
      "Epoch 13, Step 98, Training Loss: 23.2560\n",
      "Epoch 13, Step 99, Training Loss: 30.9666\n",
      "Epoch 13, Step 100, Training Loss: 10.2372\n",
      "Epoch 13, Step 101, Training Loss: 11.0296\n",
      "Epoch 13, Step 102, Training Loss: 12.7379\n",
      "Epoch 13, Step 103, Training Loss: 9.7421\n",
      "Epoch 13, Step 104, Training Loss: 15.2624\n",
      "Epoch 13, Step 105, Training Loss: 9.3931\n",
      "Epoch 13, Step 106, Training Loss: 22.1037\n",
      "Epoch 13, Step 107, Training Loss: 17.2954\n",
      "Epoch 13, Step 108, Training Loss: 8.7582\n",
      "Epoch 13, Step 109, Training Loss: 8.6218\n",
      "Epoch 13, Step 110, Training Loss: 12.5985\n",
      "Epoch 13, Step 111, Training Loss: 8.3247\n",
      "Epoch 13, Step 112, Training Loss: 13.0119\n",
      "Epoch 13, Step 113, Training Loss: 16.0656\n",
      "Epoch 13, Step 114, Training Loss: 9.0607\n",
      "Epoch 13, Step 115, Training Loss: 21.0162\n",
      "Epoch 13, Step 116, Training Loss: 10.9230\n",
      "Epoch 13, Step 117, Training Loss: 13.4762\n",
      "Epoch 13, Step 118, Training Loss: 8.4974\n",
      "Epoch 13, Step 119, Training Loss: 11.4562\n",
      "Epoch 13, Step 120, Training Loss: 12.8797\n",
      "Epoch 13, Step 121, Training Loss: 30.2225\n",
      "Epoch 13, Step 122, Training Loss: 33.9350\n",
      "Epoch 13, Step 123, Training Loss: 13.7530\n",
      "Epoch 13, Step 124, Training Loss: 15.2214\n",
      "Epoch 13, Step 125, Training Loss: 17.4261\n",
      "Epoch 13, Step 126, Training Loss: 13.7835\n",
      "Epoch 13, Step 127, Training Loss: 16.2449\n",
      "Epoch 13, Step 128, Training Loss: 9.8376\n",
      "Epoch 13, Step 129, Training Loss: 22.8426\n",
      "Epoch 13, Step 130, Training Loss: 10.0507\n",
      "Epoch 13, Step 131, Training Loss: 12.5992\n",
      "Epoch 13, Step 132, Training Loss: 17.4186\n",
      "Epoch 13, Step 133, Training Loss: 40.1493\n",
      "Epoch 13, Step 134, Training Loss: 23.0344\n",
      "Epoch 13, Step 135, Training Loss: 15.7990\n",
      "Epoch 13, Step 136, Training Loss: 48.6139\n",
      "Epoch 13, Step 137, Training Loss: 12.7163\n",
      "Epoch 13, Step 138, Training Loss: 10.8197\n",
      "Epoch 13, Step 139, Training Loss: 14.6825\n",
      "Epoch 13, Step 140, Training Loss: 11.8520\n",
      "Epoch 13, Step 141, Training Loss: 18.8816\n",
      "Epoch 13, Step 142, Training Loss: 10.6901\n",
      "Epoch 13, Step 143, Training Loss: 9.3638\n",
      "Epoch 13, Step 144, Training Loss: 8.3465\n",
      "Epoch 13, Step 145, Training Loss: 10.7338\n",
      "Epoch 13, Step 146, Training Loss: 13.1022\n",
      "Epoch 13, Step 147, Training Loss: 12.4077\n",
      "Epoch 13, Step 148, Training Loss: 71.6555\n",
      "Epoch 13, Step 149, Training Loss: 20.3611\n",
      "Epoch 13, Step 150, Training Loss: 20.1513\n",
      "Epoch 13, Step 151, Training Loss: 11.7702\n",
      "Epoch 13, Step 152, Training Loss: 9.5382\n",
      "Epoch 13, Step 153, Training Loss: 10.8596\n",
      "Epoch 13, Step 154, Training Loss: 10.7865\n",
      "Epoch 13, Step 155, Training Loss: 18.5525\n",
      "Epoch 13, Step 156, Training Loss: 14.0028\n",
      "Epoch 13, Step 157, Training Loss: 17.1551\n",
      "Epoch 13, Step 158, Training Loss: 9.8112\n",
      "Epoch 13, Step 159, Training Loss: 20.7186\n",
      "Epoch 13, Step 160, Training Loss: 44.1606\n",
      "Epoch 13, Step 161, Training Loss: 15.2475\n",
      "Epoch 13, Step 162, Training Loss: 8.7784\n",
      "Epoch 13, Step 163, Training Loss: 13.2864\n",
      "Epoch 13, Step 164, Training Loss: 11.1187\n",
      "Epoch 13, Step 165, Training Loss: 13.0611\n",
      "Epoch 13, Step 166, Training Loss: 12.1190\n",
      "Epoch 13, Step 167, Training Loss: 12.8281\n",
      "Epoch 13, Step 168, Training Loss: 18.5436\n",
      "Epoch 13, Step 169, Training Loss: 7.3865\n",
      "Epoch 13, Step 170, Training Loss: 8.8269\n",
      "Epoch 13, Step 171, Training Loss: 10.1232\n",
      "Epoch 13, Step 172, Training Loss: 16.7894\n",
      "Epoch 13, Step 173, Training Loss: 12.9692\n",
      "Epoch 13, Step 174, Training Loss: 11.4856\n",
      "Epoch 13, Step 175, Training Loss: 15.5810\n",
      "Epoch 13, Step 176, Training Loss: 12.0722\n",
      "Epoch 13, Step 177, Training Loss: 20.0261\n",
      "Epoch 13, Step 178, Training Loss: 13.5849\n",
      "Epoch 13, Step 179, Training Loss: 8.1833\n",
      "Epoch 13, Step 180, Training Loss: 14.9597\n",
      "Epoch 13, Step 181, Training Loss: 12.8609\n",
      "Epoch 13, Step 182, Training Loss: 16.3216\n",
      "Epoch 13, Step 183, Training Loss: 11.0509\n",
      "Epoch 13, Step 184, Training Loss: 8.6580\n",
      "Epoch 13, Step 185, Training Loss: 12.6693\n",
      "Epoch 13, Step 186, Training Loss: 23.4700\n",
      "Epoch 13, Step 187, Training Loss: 8.5415\n",
      "Epoch 13, Step 188, Training Loss: 119.8918\n",
      "Epoch 13, Step 189, Training Loss: 11.2608\n",
      "Epoch 13, Step 190, Training Loss: 98.6345\n",
      "Epoch 13, Step 191, Training Loss: 9.5482\n",
      "Epoch 13, Step 192, Training Loss: 13.3001\n",
      "Epoch 13, Step 193, Training Loss: 14.4556\n",
      "Epoch 13, Step 194, Training Loss: 10.1523\n",
      "Epoch 13, Step 195, Training Loss: 11.2334\n",
      "Epoch 13, Step 196, Training Loss: 19.9293\n",
      "Epoch 13, Step 197, Training Loss: 16.9073\n",
      "Epoch 13, Step 198, Training Loss: 12.6083\n",
      "Epoch 13, Step 199, Training Loss: 10.8751\n",
      "Epoch 13, Step 200, Training Loss: 8.1583\n",
      "Epoch 13, Step 201, Training Loss: 9.0098\n",
      "Epoch 13, Step 202, Training Loss: 12.9259\n",
      "Epoch 13, Step 203, Training Loss: 31.3456\n",
      "Epoch 13, Step 204, Training Loss: 21.0203\n",
      "Epoch 13, Step 205, Training Loss: 12.3479\n",
      "Epoch 13, Step 206, Training Loss: 12.1656\n",
      "--- Epoch 13, Validation Loss: 12.8603 ---\n",
      "Epoch 14, Step 0, Training Loss: 12.5869\n",
      "Epoch 14, Step 1, Training Loss: 11.4465\n",
      "Epoch 14, Step 2, Training Loss: 8.3949\n",
      "Epoch 14, Step 3, Training Loss: 27.5986\n",
      "Epoch 14, Step 4, Training Loss: 43.3018\n",
      "Epoch 14, Step 5, Training Loss: 7.7469\n",
      "Epoch 14, Step 6, Training Loss: 10.8089\n",
      "Epoch 14, Step 7, Training Loss: 13.5046\n",
      "Epoch 14, Step 8, Training Loss: 6.2368\n",
      "Epoch 14, Step 9, Training Loss: 11.3386\n",
      "Epoch 14, Step 10, Training Loss: 29.2882\n",
      "Epoch 14, Step 11, Training Loss: 10.1972\n",
      "Epoch 14, Step 12, Training Loss: 15.1927\n",
      "Epoch 14, Step 13, Training Loss: 43.5206\n",
      "Epoch 14, Step 14, Training Loss: 14.7622\n",
      "Epoch 14, Step 15, Training Loss: 11.4874\n",
      "Epoch 14, Step 16, Training Loss: 10.1267\n",
      "Epoch 14, Step 17, Training Loss: 10.0038\n",
      "Epoch 14, Step 18, Training Loss: 9.4308\n",
      "Epoch 14, Step 19, Training Loss: 31.5005\n",
      "Epoch 14, Step 20, Training Loss: 12.6438\n",
      "Epoch 14, Step 21, Training Loss: 18.0615\n",
      "Epoch 14, Step 22, Training Loss: 23.4160\n",
      "Epoch 14, Step 23, Training Loss: 17.0097\n",
      "Epoch 14, Step 24, Training Loss: 9.3977\n",
      "Epoch 14, Step 25, Training Loss: 12.8590\n",
      "Epoch 14, Step 26, Training Loss: 14.3651\n",
      "Epoch 14, Step 27, Training Loss: 13.9985\n",
      "Epoch 14, Step 28, Training Loss: 13.2395\n",
      "Epoch 14, Step 29, Training Loss: 6.1461\n",
      "Epoch 14, Step 30, Training Loss: 12.7188\n",
      "Epoch 14, Step 31, Training Loss: 9.4999\n",
      "Epoch 14, Step 32, Training Loss: 11.1703\n",
      "Epoch 14, Step 33, Training Loss: 10.1060\n",
      "Epoch 14, Step 34, Training Loss: 10.9448\n",
      "Epoch 14, Step 35, Training Loss: 10.9356\n",
      "Epoch 14, Step 36, Training Loss: 16.6945\n",
      "Epoch 14, Step 37, Training Loss: 38.6489\n",
      "Epoch 14, Step 38, Training Loss: 16.5844\n",
      "Epoch 14, Step 39, Training Loss: 11.2618\n",
      "Epoch 14, Step 40, Training Loss: 15.0875\n",
      "Epoch 14, Step 41, Training Loss: 17.6720\n",
      "Epoch 14, Step 42, Training Loss: 11.9416\n",
      "Epoch 14, Step 43, Training Loss: 10.9378\n",
      "Epoch 14, Step 44, Training Loss: 15.6358\n",
      "Epoch 14, Step 45, Training Loss: 9.9090\n",
      "Epoch 14, Step 46, Training Loss: 7.7637\n",
      "Epoch 14, Step 47, Training Loss: 10.9451\n",
      "Epoch 14, Step 48, Training Loss: 9.8185\n",
      "Epoch 14, Step 49, Training Loss: 12.9055\n",
      "Epoch 14, Step 50, Training Loss: 6.2224\n",
      "Epoch 14, Step 51, Training Loss: 10.4241\n",
      "Epoch 14, Step 52, Training Loss: 10.4353\n",
      "Epoch 14, Step 53, Training Loss: 7.6332\n",
      "Epoch 14, Step 54, Training Loss: 12.7647\n",
      "Epoch 14, Step 55, Training Loss: 12.8172\n",
      "Epoch 14, Step 56, Training Loss: 23.3137\n",
      "Epoch 14, Step 57, Training Loss: 10.2982\n",
      "Epoch 14, Step 58, Training Loss: 19.7137\n",
      "Epoch 14, Step 59, Training Loss: 10.3284\n",
      "Epoch 14, Step 60, Training Loss: 45.1977\n",
      "Epoch 14, Step 61, Training Loss: 8.1233\n",
      "Epoch 14, Step 62, Training Loss: 21.2087\n",
      "Epoch 14, Step 63, Training Loss: 28.6685\n",
      "Epoch 14, Step 64, Training Loss: 12.7412\n",
      "Epoch 14, Step 65, Training Loss: 13.0804\n",
      "Epoch 14, Step 66, Training Loss: 8.8756\n",
      "Epoch 14, Step 67, Training Loss: 10.5116\n",
      "Epoch 14, Step 68, Training Loss: 10.6396\n",
      "Epoch 14, Step 69, Training Loss: 25.5521\n",
      "Epoch 14, Step 70, Training Loss: 10.1949\n",
      "Epoch 14, Step 71, Training Loss: 9.4442\n",
      "Epoch 14, Step 72, Training Loss: 17.0180\n",
      "Epoch 14, Step 73, Training Loss: 13.1474\n",
      "Epoch 14, Step 74, Training Loss: 14.7234\n",
      "Epoch 14, Step 75, Training Loss: 30.7870\n",
      "Epoch 14, Step 76, Training Loss: 26.6502\n",
      "Epoch 14, Step 77, Training Loss: 17.5096\n",
      "Epoch 14, Step 78, Training Loss: 8.0673\n",
      "Epoch 14, Step 79, Training Loss: 13.6194\n",
      "Epoch 14, Step 80, Training Loss: 20.7783\n",
      "Epoch 14, Step 81, Training Loss: 31.4036\n",
      "Epoch 14, Step 82, Training Loss: 10.3294\n",
      "Epoch 14, Step 83, Training Loss: 32.7482\n",
      "Epoch 14, Step 84, Training Loss: 32.6624\n",
      "Epoch 14, Step 85, Training Loss: 10.5669\n",
      "Epoch 14, Step 86, Training Loss: 11.8326\n",
      "Epoch 14, Step 87, Training Loss: 13.1713\n",
      "Epoch 14, Step 88, Training Loss: 19.1719\n",
      "Epoch 14, Step 89, Training Loss: 17.6971\n",
      "Epoch 14, Step 90, Training Loss: 12.4848\n",
      "Epoch 14, Step 91, Training Loss: 15.5518\n",
      "Epoch 14, Step 92, Training Loss: 20.0018\n",
      "Epoch 14, Step 93, Training Loss: 11.1440\n",
      "Epoch 14, Step 94, Training Loss: 29.3703\n",
      "Epoch 14, Step 95, Training Loss: 7.3464\n",
      "Epoch 14, Step 96, Training Loss: 11.3101\n",
      "Epoch 14, Step 97, Training Loss: 11.1717\n",
      "Epoch 14, Step 98, Training Loss: 20.8022\n",
      "Epoch 14, Step 99, Training Loss: 27.8945\n",
      "Epoch 14, Step 100, Training Loss: 8.8347\n",
      "Epoch 14, Step 101, Training Loss: 8.1832\n",
      "Epoch 14, Step 102, Training Loss: 11.1768\n",
      "Epoch 14, Step 103, Training Loss: 8.6639\n",
      "Epoch 14, Step 104, Training Loss: 15.6710\n",
      "Epoch 14, Step 105, Training Loss: 7.5500\n",
      "Epoch 14, Step 106, Training Loss: 16.5065\n",
      "Epoch 14, Step 107, Training Loss: 17.9915\n",
      "Epoch 14, Step 108, Training Loss: 9.9564\n",
      "Epoch 14, Step 109, Training Loss: 8.4077\n",
      "Epoch 14, Step 110, Training Loss: 14.2716\n",
      "Epoch 14, Step 111, Training Loss: 8.7534\n",
      "Epoch 14, Step 112, Training Loss: 9.2581\n",
      "Epoch 14, Step 113, Training Loss: 13.0789\n",
      "Epoch 14, Step 114, Training Loss: 7.4756\n",
      "Epoch 14, Step 115, Training Loss: 20.1322\n",
      "Epoch 14, Step 116, Training Loss: 8.5388\n",
      "Epoch 14, Step 117, Training Loss: 13.1062\n",
      "Epoch 14, Step 118, Training Loss: 8.1144\n",
      "Epoch 14, Step 119, Training Loss: 9.5861\n",
      "Epoch 14, Step 120, Training Loss: 12.2546\n",
      "Epoch 14, Step 121, Training Loss: 30.1974\n",
      "Epoch 14, Step 122, Training Loss: 32.5190\n",
      "Epoch 14, Step 123, Training Loss: 11.0323\n",
      "Epoch 14, Step 124, Training Loss: 13.0109\n",
      "Epoch 14, Step 125, Training Loss: 14.5642\n",
      "Epoch 14, Step 126, Training Loss: 11.3358\n",
      "Epoch 14, Step 127, Training Loss: 13.6826\n",
      "Epoch 14, Step 128, Training Loss: 10.3116\n",
      "Epoch 14, Step 129, Training Loss: 20.0687\n",
      "Epoch 14, Step 130, Training Loss: 9.5993\n",
      "Epoch 14, Step 131, Training Loss: 10.1862\n",
      "Epoch 14, Step 132, Training Loss: 20.7521\n",
      "Epoch 14, Step 133, Training Loss: 34.8034\n",
      "Epoch 14, Step 134, Training Loss: 18.1215\n",
      "Epoch 14, Step 135, Training Loss: 16.0485\n",
      "Epoch 14, Step 136, Training Loss: 48.0742\n",
      "Epoch 14, Step 137, Training Loss: 9.6510\n",
      "Epoch 14, Step 138, Training Loss: 8.2009\n",
      "Epoch 14, Step 139, Training Loss: 13.3831\n",
      "Epoch 14, Step 140, Training Loss: 10.0365\n",
      "Epoch 14, Step 141, Training Loss: 16.7246\n",
      "Epoch 14, Step 142, Training Loss: 8.8417\n",
      "Epoch 14, Step 143, Training Loss: 9.5653\n",
      "Epoch 14, Step 144, Training Loss: 8.6744\n",
      "Epoch 14, Step 145, Training Loss: 9.7633\n",
      "Epoch 14, Step 146, Training Loss: 11.3090\n",
      "Epoch 14, Step 147, Training Loss: 10.4993\n",
      "Epoch 14, Step 148, Training Loss: 55.4358\n",
      "Epoch 14, Step 149, Training Loss: 14.8501\n",
      "Epoch 14, Step 150, Training Loss: 17.1103\n",
      "Epoch 14, Step 151, Training Loss: 11.2525\n",
      "Epoch 14, Step 152, Training Loss: 6.5357\n",
      "Epoch 14, Step 153, Training Loss: 9.8140\n",
      "Epoch 14, Step 154, Training Loss: 11.0998\n",
      "Epoch 14, Step 155, Training Loss: 19.6294\n",
      "Epoch 14, Step 156, Training Loss: 10.9088\n",
      "Epoch 14, Step 157, Training Loss: 16.0339\n",
      "Epoch 14, Step 158, Training Loss: 10.1141\n",
      "Epoch 14, Step 159, Training Loss: 20.7489\n",
      "Epoch 14, Step 160, Training Loss: 39.3927\n",
      "Epoch 14, Step 161, Training Loss: 11.3313\n",
      "Epoch 14, Step 162, Training Loss: 6.5525\n",
      "Epoch 14, Step 163, Training Loss: 10.4097\n",
      "Epoch 14, Step 164, Training Loss: 9.5432\n",
      "Epoch 14, Step 165, Training Loss: 10.7224\n",
      "Epoch 14, Step 166, Training Loss: 10.0614\n",
      "Epoch 14, Step 167, Training Loss: 10.3865\n",
      "Epoch 14, Step 168, Training Loss: 17.9679\n",
      "Epoch 14, Step 169, Training Loss: 6.7217\n",
      "Epoch 14, Step 170, Training Loss: 9.2249\n",
      "Epoch 14, Step 171, Training Loss: 6.4636\n",
      "Epoch 14, Step 172, Training Loss: 15.9767\n",
      "Epoch 14, Step 173, Training Loss: 12.5881\n",
      "Epoch 14, Step 174, Training Loss: 9.9981\n",
      "Epoch 14, Step 175, Training Loss: 11.9524\n",
      "Epoch 14, Step 176, Training Loss: 8.9277\n",
      "Epoch 14, Step 177, Training Loss: 20.2694\n",
      "Epoch 14, Step 178, Training Loss: 12.5075\n",
      "Epoch 14, Step 179, Training Loss: 7.0570\n",
      "Epoch 14, Step 180, Training Loss: 13.5563\n",
      "Epoch 14, Step 181, Training Loss: 10.2140\n",
      "Epoch 14, Step 182, Training Loss: 13.8062\n",
      "Epoch 14, Step 183, Training Loss: 9.5260\n",
      "Epoch 14, Step 184, Training Loss: 7.7316\n",
      "Epoch 14, Step 185, Training Loss: 9.2084\n",
      "Epoch 14, Step 186, Training Loss: 20.7821\n",
      "Epoch 14, Step 187, Training Loss: 7.3331\n",
      "Epoch 14, Step 188, Training Loss: 104.8294\n",
      "Epoch 14, Step 189, Training Loss: 9.2337\n",
      "Epoch 14, Step 190, Training Loss: 94.1295\n",
      "Epoch 14, Step 191, Training Loss: 8.3559\n",
      "Epoch 14, Step 192, Training Loss: 11.8226\n",
      "Epoch 14, Step 193, Training Loss: 13.3106\n",
      "Epoch 14, Step 194, Training Loss: 11.4715\n",
      "Epoch 14, Step 195, Training Loss: 8.7916\n",
      "Epoch 14, Step 196, Training Loss: 15.5906\n",
      "Epoch 14, Step 197, Training Loss: 12.8005\n",
      "Epoch 14, Step 198, Training Loss: 8.2355\n",
      "Epoch 14, Step 199, Training Loss: 13.7241\n",
      "Epoch 14, Step 200, Training Loss: 8.0231\n",
      "Epoch 14, Step 201, Training Loss: 9.1665\n",
      "Epoch 14, Step 202, Training Loss: 10.7952\n",
      "Epoch 14, Step 203, Training Loss: 29.7452\n",
      "Epoch 14, Step 204, Training Loss: 16.1231\n",
      "Epoch 14, Step 205, Training Loss: 13.3066\n",
      "Epoch 14, Step 206, Training Loss: 9.5381\n",
      "--- Epoch 14, Validation Loss: 12.3316 ---\n",
      "Epoch 15, Step 0, Training Loss: 10.0823\n",
      "Epoch 15, Step 1, Training Loss: 7.9999\n",
      "Epoch 15, Step 2, Training Loss: 9.7212\n",
      "Epoch 15, Step 3, Training Loss: 27.1396\n",
      "Epoch 15, Step 4, Training Loss: 43.1801\n",
      "Epoch 15, Step 5, Training Loss: 7.5491\n",
      "Epoch 15, Step 6, Training Loss: 11.7458\n",
      "Epoch 15, Step 7, Training Loss: 12.9572\n",
      "Epoch 15, Step 8, Training Loss: 7.4177\n",
      "Epoch 15, Step 9, Training Loss: 11.3184\n",
      "Epoch 15, Step 10, Training Loss: 28.0825\n",
      "Epoch 15, Step 11, Training Loss: 13.7810\n",
      "Epoch 15, Step 12, Training Loss: 10.9438\n",
      "Epoch 15, Step 13, Training Loss: 37.4571\n",
      "Epoch 15, Step 14, Training Loss: 13.6726\n",
      "Epoch 15, Step 15, Training Loss: 10.1133\n",
      "Epoch 15, Step 16, Training Loss: 8.0701\n",
      "Epoch 15, Step 17, Training Loss: 9.5518\n",
      "Epoch 15, Step 18, Training Loss: 8.2502\n",
      "Epoch 15, Step 19, Training Loss: 29.1377\n",
      "Epoch 15, Step 20, Training Loss: 11.5168\n",
      "Epoch 15, Step 21, Training Loss: 18.0669\n",
      "Epoch 15, Step 22, Training Loss: 21.0440\n",
      "Epoch 15, Step 23, Training Loss: 11.5331\n",
      "Epoch 15, Step 24, Training Loss: 10.0924\n",
      "Epoch 15, Step 25, Training Loss: 11.5967\n",
      "Epoch 15, Step 26, Training Loss: 12.0743\n",
      "Epoch 15, Step 27, Training Loss: 12.8834\n",
      "Epoch 15, Step 28, Training Loss: 9.6108\n",
      "Epoch 15, Step 29, Training Loss: 7.5054\n",
      "Epoch 15, Step 30, Training Loss: 7.7693\n",
      "Epoch 15, Step 31, Training Loss: 9.5508\n",
      "Epoch 15, Step 32, Training Loss: 10.1201\n",
      "Epoch 15, Step 33, Training Loss: 11.7249\n",
      "Epoch 15, Step 34, Training Loss: 8.9808\n",
      "Epoch 15, Step 35, Training Loss: 7.8467\n",
      "Epoch 15, Step 36, Training Loss: 14.5054\n",
      "Epoch 15, Step 37, Training Loss: 28.0853\n",
      "Epoch 15, Step 38, Training Loss: 14.8639\n",
      "Epoch 15, Step 39, Training Loss: 10.7143\n",
      "Epoch 15, Step 40, Training Loss: 13.6486\n",
      "Epoch 15, Step 41, Training Loss: 19.0050\n",
      "Epoch 15, Step 42, Training Loss: 9.4238\n",
      "Epoch 15, Step 43, Training Loss: 11.2861\n",
      "Epoch 15, Step 44, Training Loss: 12.6666\n",
      "Epoch 15, Step 45, Training Loss: 11.2504\n",
      "Epoch 15, Step 46, Training Loss: 10.5671\n",
      "Epoch 15, Step 47, Training Loss: 10.4458\n",
      "Epoch 15, Step 48, Training Loss: 8.6435\n",
      "Epoch 15, Step 49, Training Loss: 10.6072\n",
      "Epoch 15, Step 50, Training Loss: 7.8731\n",
      "Epoch 15, Step 51, Training Loss: 9.8628\n",
      "Epoch 15, Step 52, Training Loss: 7.4737\n",
      "Epoch 15, Step 53, Training Loss: 6.1070\n",
      "Epoch 15, Step 54, Training Loss: 9.5073\n",
      "Epoch 15, Step 55, Training Loss: 14.2262\n",
      "Epoch 15, Step 56, Training Loss: 20.8851\n",
      "Epoch 15, Step 57, Training Loss: 8.2945\n",
      "Epoch 15, Step 58, Training Loss: 14.7821\n",
      "Epoch 15, Step 59, Training Loss: 11.3825\n",
      "Epoch 15, Step 60, Training Loss: 46.5012\n",
      "Epoch 15, Step 61, Training Loss: 8.8763\n",
      "Epoch 15, Step 62, Training Loss: 13.5002\n",
      "Epoch 15, Step 63, Training Loss: 29.4454\n",
      "Epoch 15, Step 64, Training Loss: 9.9719\n",
      "Epoch 15, Step 65, Training Loss: 13.0280\n",
      "Epoch 15, Step 66, Training Loss: 7.2318\n",
      "Epoch 15, Step 67, Training Loss: 13.1167\n",
      "Epoch 15, Step 68, Training Loss: 10.1382\n",
      "Epoch 15, Step 69, Training Loss: 23.6950\n",
      "Epoch 15, Step 70, Training Loss: 7.6295\n",
      "Epoch 15, Step 71, Training Loss: 9.3565\n",
      "Epoch 15, Step 72, Training Loss: 15.2765\n",
      "Epoch 15, Step 73, Training Loss: 11.9336\n",
      "Epoch 15, Step 74, Training Loss: 12.4373\n",
      "Epoch 15, Step 75, Training Loss: 27.5185\n",
      "Epoch 15, Step 76, Training Loss: 26.1141\n",
      "Epoch 15, Step 77, Training Loss: 15.3284\n",
      "Epoch 15, Step 78, Training Loss: 7.5853\n",
      "Epoch 15, Step 79, Training Loss: 12.4837\n",
      "Epoch 15, Step 80, Training Loss: 19.6751\n",
      "Epoch 15, Step 81, Training Loss: 32.9792\n",
      "Epoch 15, Step 82, Training Loss: 8.4840\n",
      "Epoch 15, Step 83, Training Loss: 33.8716\n",
      "Epoch 15, Step 84, Training Loss: 30.6217\n",
      "Epoch 15, Step 85, Training Loss: 12.0485\n",
      "Epoch 15, Step 86, Training Loss: 9.9922\n",
      "Epoch 15, Step 87, Training Loss: 11.2482\n",
      "Epoch 15, Step 88, Training Loss: 13.7800\n",
      "Epoch 15, Step 89, Training Loss: 12.5583\n",
      "Epoch 15, Step 90, Training Loss: 15.1833\n",
      "Epoch 15, Step 91, Training Loss: 7.5740\n",
      "Epoch 15, Step 92, Training Loss: 15.7583\n",
      "Epoch 15, Step 93, Training Loss: 9.0775\n",
      "Epoch 15, Step 94, Training Loss: 24.4114\n",
      "Epoch 15, Step 95, Training Loss: 10.4142\n",
      "Epoch 15, Step 96, Training Loss: 11.0133\n",
      "Epoch 15, Step 97, Training Loss: 9.4463\n",
      "Epoch 15, Step 98, Training Loss: 16.3831\n",
      "Epoch 15, Step 99, Training Loss: 27.7066\n",
      "Epoch 15, Step 100, Training Loss: 8.7666\n",
      "Epoch 15, Step 101, Training Loss: 7.5160\n",
      "Epoch 15, Step 102, Training Loss: 12.1453\n",
      "Epoch 15, Step 103, Training Loss: 9.0821\n",
      "Epoch 15, Step 104, Training Loss: 13.0503\n",
      "Epoch 15, Step 105, Training Loss: 9.1786\n",
      "Epoch 15, Step 106, Training Loss: 13.8447\n",
      "Epoch 15, Step 107, Training Loss: 15.5451\n",
      "Epoch 15, Step 108, Training Loss: 12.2992\n",
      "Epoch 15, Step 109, Training Loss: 9.0796\n",
      "Epoch 15, Step 110, Training Loss: 9.8365\n",
      "Epoch 15, Step 111, Training Loss: 10.0123\n",
      "Epoch 15, Step 112, Training Loss: 9.5155\n",
      "Epoch 15, Step 113, Training Loss: 13.0034\n",
      "Epoch 15, Step 114, Training Loss: 11.5322\n",
      "Epoch 15, Step 115, Training Loss: 17.3070\n",
      "Epoch 15, Step 116, Training Loss: 8.9133\n",
      "Epoch 15, Step 117, Training Loss: 9.9742\n",
      "Epoch 15, Step 118, Training Loss: 8.2002\n",
      "Epoch 15, Step 119, Training Loss: 9.9057\n",
      "Epoch 15, Step 120, Training Loss: 11.6353\n",
      "Epoch 15, Step 121, Training Loss: 26.7421\n",
      "Epoch 15, Step 122, Training Loss: 30.5769\n",
      "Epoch 15, Step 123, Training Loss: 10.9057\n",
      "Epoch 15, Step 124, Training Loss: 13.8904\n",
      "Epoch 15, Step 125, Training Loss: 12.7399\n",
      "Epoch 15, Step 126, Training Loss: 9.1456\n",
      "Epoch 15, Step 127, Training Loss: 12.5156\n",
      "Epoch 15, Step 128, Training Loss: 7.8069\n",
      "Epoch 15, Step 129, Training Loss: 15.7199\n",
      "Epoch 15, Step 130, Training Loss: 7.8204\n",
      "Epoch 15, Step 131, Training Loss: 10.1018\n",
      "Epoch 15, Step 132, Training Loss: 15.0662\n",
      "Epoch 15, Step 133, Training Loss: 34.1153\n",
      "Epoch 15, Step 134, Training Loss: 15.8181\n",
      "Epoch 15, Step 135, Training Loss: 14.9488\n",
      "Epoch 15, Step 136, Training Loss: 35.5570\n",
      "Epoch 15, Step 137, Training Loss: 8.9342\n",
      "Epoch 15, Step 138, Training Loss: 7.6278\n",
      "Epoch 15, Step 139, Training Loss: 12.7345\n",
      "Epoch 15, Step 140, Training Loss: 12.0791\n",
      "Epoch 15, Step 141, Training Loss: 15.0137\n",
      "Epoch 15, Step 142, Training Loss: 7.0292\n",
      "Epoch 15, Step 143, Training Loss: 11.0958\n",
      "Epoch 15, Step 144, Training Loss: 8.7222\n",
      "Epoch 15, Step 145, Training Loss: 9.3968\n",
      "Epoch 15, Step 146, Training Loss: 11.3477\n",
      "Epoch 15, Step 147, Training Loss: 8.7044\n",
      "Epoch 15, Step 148, Training Loss: 48.0657\n",
      "Epoch 15, Step 149, Training Loss: 13.7764\n",
      "Epoch 15, Step 150, Training Loss: 13.2852\n",
      "Epoch 15, Step 151, Training Loss: 9.7486\n",
      "Epoch 15, Step 152, Training Loss: 6.5260\n",
      "Epoch 15, Step 153, Training Loss: 7.4577\n",
      "Epoch 15, Step 154, Training Loss: 9.5245\n",
      "Epoch 15, Step 155, Training Loss: 16.7844\n",
      "Epoch 15, Step 156, Training Loss: 9.2589\n",
      "Epoch 15, Step 157, Training Loss: 16.2806\n",
      "Epoch 15, Step 158, Training Loss: 9.4096\n",
      "Epoch 15, Step 159, Training Loss: 15.5985\n",
      "Epoch 15, Step 160, Training Loss: 39.7234\n",
      "Epoch 15, Step 161, Training Loss: 9.4232\n",
      "Epoch 15, Step 162, Training Loss: 6.7659\n",
      "Epoch 15, Step 163, Training Loss: 10.0763\n",
      "Epoch 15, Step 164, Training Loss: 10.6664\n",
      "Epoch 15, Step 165, Training Loss: 9.7889\n",
      "Epoch 15, Step 166, Training Loss: 7.1938\n",
      "Epoch 15, Step 167, Training Loss: 9.5387\n",
      "Epoch 15, Step 168, Training Loss: 15.5091\n",
      "Epoch 15, Step 169, Training Loss: 8.3792\n",
      "Epoch 15, Step 170, Training Loss: 7.7779\n",
      "Epoch 15, Step 171, Training Loss: 10.0074\n",
      "Epoch 15, Step 172, Training Loss: 12.6802\n",
      "Epoch 15, Step 173, Training Loss: 12.5575\n",
      "Epoch 15, Step 174, Training Loss: 11.7273\n",
      "Epoch 15, Step 175, Training Loss: 12.0484\n",
      "Epoch 15, Step 176, Training Loss: 10.7496\n",
      "Epoch 15, Step 177, Training Loss: 17.8965\n",
      "Epoch 15, Step 178, Training Loss: 7.9522\n",
      "Epoch 15, Step 179, Training Loss: 7.2622\n",
      "Epoch 15, Step 180, Training Loss: 12.0747\n",
      "Epoch 15, Step 181, Training Loss: 8.7736\n",
      "Epoch 15, Step 182, Training Loss: 14.1411\n",
      "Epoch 15, Step 183, Training Loss: 9.8248\n",
      "Epoch 15, Step 184, Training Loss: 7.9919\n",
      "Epoch 15, Step 185, Training Loss: 8.7784\n",
      "Epoch 15, Step 186, Training Loss: 19.9033\n",
      "Epoch 15, Step 187, Training Loss: 7.7997\n",
      "Epoch 15, Step 188, Training Loss: 102.3796\n",
      "Epoch 15, Step 189, Training Loss: 8.4161\n",
      "Epoch 15, Step 190, Training Loss: 88.5639\n",
      "Epoch 15, Step 191, Training Loss: 9.3530\n",
      "Epoch 15, Step 192, Training Loss: 11.2553\n",
      "Epoch 15, Step 193, Training Loss: 11.9734\n",
      "Epoch 15, Step 194, Training Loss: 10.1528\n",
      "Epoch 15, Step 195, Training Loss: 9.1792\n",
      "Epoch 15, Step 196, Training Loss: 16.0693\n",
      "Epoch 15, Step 197, Training Loss: 13.4622\n",
      "Epoch 15, Step 198, Training Loss: 6.6515\n",
      "Epoch 15, Step 199, Training Loss: 9.8712\n",
      "Epoch 15, Step 200, Training Loss: 6.7518\n",
      "Epoch 15, Step 201, Training Loss: 9.1105\n",
      "Epoch 15, Step 202, Training Loss: 7.3767\n",
      "Epoch 15, Step 203, Training Loss: 29.1623\n",
      "Epoch 15, Step 204, Training Loss: 15.7900\n",
      "Epoch 15, Step 205, Training Loss: 11.4691\n",
      "Epoch 15, Step 206, Training Loss: 10.6044\n",
      "--- Epoch 15, Validation Loss: 10.7292 ---\n",
      "Epoch 16, Step 0, Training Loss: 9.9954\n",
      "Epoch 16, Step 1, Training Loss: 8.2331\n",
      "Epoch 16, Step 2, Training Loss: 7.1626\n",
      "Epoch 16, Step 3, Training Loss: 24.9442\n",
      "Epoch 16, Step 4, Training Loss: 34.0037\n",
      "Epoch 16, Step 5, Training Loss: 7.6052\n",
      "Epoch 16, Step 6, Training Loss: 8.6947\n",
      "Epoch 16, Step 7, Training Loss: 11.4643\n",
      "Epoch 16, Step 8, Training Loss: 7.6265\n",
      "Epoch 16, Step 9, Training Loss: 9.0455\n",
      "Epoch 16, Step 10, Training Loss: 25.1621\n",
      "Epoch 16, Step 11, Training Loss: 12.7798\n",
      "Epoch 16, Step 12, Training Loss: 14.0008\n",
      "Epoch 16, Step 13, Training Loss: 36.8418\n",
      "Epoch 16, Step 14, Training Loss: 13.1566\n",
      "Epoch 16, Step 15, Training Loss: 9.7640\n",
      "Epoch 16, Step 16, Training Loss: 8.5168\n",
      "Epoch 16, Step 17, Training Loss: 10.9433\n",
      "Epoch 16, Step 18, Training Loss: 6.8447\n",
      "Epoch 16, Step 19, Training Loss: 29.4074\n",
      "Epoch 16, Step 20, Training Loss: 10.4887\n",
      "Epoch 16, Step 21, Training Loss: 12.0227\n",
      "Epoch 16, Step 22, Training Loss: 20.0702\n",
      "Epoch 16, Step 23, Training Loss: 11.3958\n",
      "Epoch 16, Step 24, Training Loss: 10.9957\n",
      "Epoch 16, Step 25, Training Loss: 12.1431\n",
      "Epoch 16, Step 26, Training Loss: 11.3214\n",
      "Epoch 16, Step 27, Training Loss: 13.6290\n",
      "Epoch 16, Step 28, Training Loss: 9.9736\n",
      "Epoch 16, Step 29, Training Loss: 8.8169\n",
      "Epoch 16, Step 30, Training Loss: 8.4258\n",
      "Epoch 16, Step 31, Training Loss: 9.5795\n",
      "Epoch 16, Step 32, Training Loss: 11.1101\n",
      "Epoch 16, Step 33, Training Loss: 11.4390\n",
      "Epoch 16, Step 34, Training Loss: 10.2537\n",
      "Epoch 16, Step 35, Training Loss: 7.5348\n",
      "Epoch 16, Step 36, Training Loss: 13.1104\n",
      "Epoch 16, Step 37, Training Loss: 31.8381\n",
      "Epoch 16, Step 38, Training Loss: 14.3078\n",
      "Epoch 16, Step 39, Training Loss: 9.8641\n",
      "Epoch 16, Step 40, Training Loss: 12.2663\n",
      "Epoch 16, Step 41, Training Loss: 16.2663\n",
      "Epoch 16, Step 42, Training Loss: 11.2965\n",
      "Epoch 16, Step 43, Training Loss: 11.0537\n",
      "Epoch 16, Step 44, Training Loss: 11.5262\n",
      "Epoch 16, Step 45, Training Loss: 8.8830\n",
      "Epoch 16, Step 46, Training Loss: 11.3484\n",
      "Epoch 16, Step 47, Training Loss: 8.1844\n",
      "Epoch 16, Step 48, Training Loss: 9.6338\n",
      "Epoch 16, Step 49, Training Loss: 10.7001\n",
      "Epoch 16, Step 50, Training Loss: 5.4594\n",
      "Epoch 16, Step 51, Training Loss: 8.7712\n",
      "Epoch 16, Step 52, Training Loss: 8.8250\n",
      "Epoch 16, Step 53, Training Loss: 7.6206\n",
      "Epoch 16, Step 54, Training Loss: 9.6590\n",
      "Epoch 16, Step 55, Training Loss: 11.9887\n",
      "Epoch 16, Step 56, Training Loss: 25.9888\n",
      "Epoch 16, Step 57, Training Loss: 9.5228\n",
      "Epoch 16, Step 58, Training Loss: 14.4866\n",
      "Epoch 16, Step 59, Training Loss: 11.8144\n",
      "Epoch 16, Step 60, Training Loss: 42.4431\n",
      "Epoch 16, Step 61, Training Loss: 10.7010\n",
      "Epoch 16, Step 62, Training Loss: 14.1831\n",
      "Epoch 16, Step 63, Training Loss: 29.0206\n",
      "Epoch 16, Step 64, Training Loss: 10.9850\n",
      "Epoch 16, Step 65, Training Loss: 8.2262\n",
      "Epoch 16, Step 66, Training Loss: 7.5605\n",
      "Epoch 16, Step 67, Training Loss: 15.0969\n",
      "Epoch 16, Step 68, Training Loss: 8.9195\n",
      "Epoch 16, Step 69, Training Loss: 26.2763\n",
      "Epoch 16, Step 70, Training Loss: 9.0269\n",
      "Epoch 16, Step 71, Training Loss: 7.3443\n",
      "Epoch 16, Step 72, Training Loss: 14.9236\n",
      "Epoch 16, Step 73, Training Loss: 10.5937\n",
      "Epoch 16, Step 74, Training Loss: 11.8474\n",
      "Epoch 16, Step 75, Training Loss: 29.4096\n",
      "Epoch 16, Step 76, Training Loss: 25.3978\n",
      "Epoch 16, Step 77, Training Loss: 14.3092\n",
      "Epoch 16, Step 78, Training Loss: 8.8342\n",
      "Epoch 16, Step 79, Training Loss: 13.8092\n",
      "Epoch 16, Step 80, Training Loss: 17.4139\n",
      "Epoch 16, Step 81, Training Loss: 32.1179\n",
      "Epoch 16, Step 82, Training Loss: 9.7028\n",
      "Epoch 16, Step 83, Training Loss: 33.2038\n",
      "Epoch 16, Step 84, Training Loss: 34.8036\n",
      "Epoch 16, Step 85, Training Loss: 8.4285\n",
      "Epoch 16, Step 86, Training Loss: 10.1365\n",
      "Epoch 16, Step 87, Training Loss: 12.9300\n",
      "Epoch 16, Step 88, Training Loss: 15.2364\n",
      "Epoch 16, Step 89, Training Loss: 13.3726\n",
      "Epoch 16, Step 90, Training Loss: 13.4575\n",
      "Epoch 16, Step 91, Training Loss: 8.3548\n",
      "Epoch 16, Step 92, Training Loss: 19.1601\n",
      "Epoch 16, Step 93, Training Loss: 9.5467\n",
      "Epoch 16, Step 94, Training Loss: 23.8290\n",
      "Epoch 16, Step 95, Training Loss: 9.4379\n",
      "Epoch 16, Step 96, Training Loss: 11.1063\n",
      "Epoch 16, Step 97, Training Loss: 10.8616\n",
      "Epoch 16, Step 98, Training Loss: 17.9275\n",
      "Epoch 16, Step 99, Training Loss: 27.0336\n",
      "Epoch 16, Step 100, Training Loss: 12.6391\n",
      "Epoch 16, Step 101, Training Loss: 7.3433\n",
      "Epoch 16, Step 102, Training Loss: 11.6778\n",
      "Epoch 16, Step 103, Training Loss: 7.8454\n",
      "Epoch 16, Step 104, Training Loss: 14.9134\n",
      "Epoch 16, Step 105, Training Loss: 8.5893\n",
      "Epoch 16, Step 106, Training Loss: 15.9975\n",
      "Epoch 16, Step 107, Training Loss: 13.3326\n",
      "Epoch 16, Step 108, Training Loss: 9.8816\n",
      "Epoch 16, Step 109, Training Loss: 8.3575\n",
      "Epoch 16, Step 110, Training Loss: 12.4660\n",
      "Epoch 16, Step 111, Training Loss: 7.1675\n",
      "Epoch 16, Step 112, Training Loss: 7.9529\n",
      "Epoch 16, Step 113, Training Loss: 11.4009\n",
      "Epoch 16, Step 114, Training Loss: 6.0401\n",
      "Epoch 16, Step 115, Training Loss: 16.1548\n",
      "Epoch 16, Step 116, Training Loss: 8.2553\n",
      "Epoch 16, Step 117, Training Loss: 10.3370\n",
      "Epoch 16, Step 118, Training Loss: 7.4803\n",
      "Epoch 16, Step 119, Training Loss: 8.6007\n",
      "Epoch 16, Step 120, Training Loss: 11.4532\n",
      "Epoch 16, Step 121, Training Loss: 23.8089\n",
      "Epoch 16, Step 122, Training Loss: 31.9059\n",
      "Epoch 16, Step 123, Training Loss: 11.4734\n",
      "Epoch 16, Step 124, Training Loss: 12.3263\n",
      "Epoch 16, Step 125, Training Loss: 12.8072\n",
      "Epoch 16, Step 126, Training Loss: 10.1056\n",
      "Epoch 16, Step 127, Training Loss: 15.3203\n",
      "Epoch 16, Step 128, Training Loss: 9.5918\n",
      "Epoch 16, Step 129, Training Loss: 16.9374\n",
      "Epoch 16, Step 130, Training Loss: 9.6101\n",
      "Epoch 16, Step 131, Training Loss: 10.7085\n",
      "Epoch 16, Step 132, Training Loss: 18.0059\n",
      "Epoch 16, Step 133, Training Loss: 33.0983\n",
      "Epoch 16, Step 134, Training Loss: 15.2124\n",
      "Epoch 16, Step 135, Training Loss: 12.1384\n",
      "Epoch 16, Step 136, Training Loss: 36.8227\n",
      "Epoch 16, Step 137, Training Loss: 11.5149\n",
      "Epoch 16, Step 138, Training Loss: 9.0492\n",
      "Epoch 16, Step 139, Training Loss: 14.6479\n",
      "Epoch 16, Step 140, Training Loss: 9.6884\n",
      "Epoch 16, Step 141, Training Loss: 14.1345\n",
      "Epoch 16, Step 142, Training Loss: 11.9548\n",
      "Epoch 16, Step 143, Training Loss: 10.1849\n",
      "Epoch 16, Step 144, Training Loss: 6.8446\n",
      "Epoch 16, Step 145, Training Loss: 8.3237\n",
      "Epoch 16, Step 146, Training Loss: 10.7581\n",
      "Epoch 16, Step 147, Training Loss: 7.5706\n",
      "Epoch 16, Step 148, Training Loss: 50.5055\n",
      "Epoch 16, Step 149, Training Loss: 13.3605\n",
      "Epoch 16, Step 150, Training Loss: 16.7912\n",
      "Epoch 16, Step 151, Training Loss: 8.6579\n",
      "Epoch 16, Step 152, Training Loss: 9.0896\n",
      "Epoch 16, Step 153, Training Loss: 7.1627\n",
      "Epoch 16, Step 154, Training Loss: 8.1358\n",
      "Epoch 16, Step 155, Training Loss: 16.5757\n",
      "Epoch 16, Step 156, Training Loss: 10.0254\n",
      "Epoch 16, Step 157, Training Loss: 18.7680\n",
      "Epoch 16, Step 158, Training Loss: 8.8174\n",
      "Epoch 16, Step 159, Training Loss: 15.0007\n",
      "Epoch 16, Step 160, Training Loss: 39.6434\n",
      "Epoch 16, Step 161, Training Loss: 9.6089\n",
      "Epoch 16, Step 162, Training Loss: 6.6242\n",
      "Epoch 16, Step 163, Training Loss: 10.9468\n",
      "Epoch 16, Step 164, Training Loss: 6.7075\n",
      "Epoch 16, Step 165, Training Loss: 8.0129\n",
      "Epoch 16, Step 166, Training Loss: 8.6134\n",
      "Epoch 16, Step 167, Training Loss: 12.4151\n",
      "Epoch 16, Step 168, Training Loss: 13.9320\n",
      "Epoch 16, Step 169, Training Loss: 9.8702\n",
      "Epoch 16, Step 170, Training Loss: 8.4221\n",
      "Epoch 16, Step 171, Training Loss: 7.2789\n",
      "Epoch 16, Step 172, Training Loss: 11.8444\n",
      "Epoch 16, Step 173, Training Loss: 11.6376\n",
      "Epoch 16, Step 174, Training Loss: 9.4521\n",
      "Epoch 16, Step 175, Training Loss: 11.1172\n",
      "Epoch 16, Step 176, Training Loss: 8.3601\n",
      "Epoch 16, Step 177, Training Loss: 21.9461\n",
      "Epoch 16, Step 178, Training Loss: 10.8180\n",
      "Epoch 16, Step 179, Training Loss: 6.7304\n",
      "Epoch 16, Step 180, Training Loss: 10.9822\n",
      "Epoch 16, Step 181, Training Loss: 9.1640\n",
      "Epoch 16, Step 182, Training Loss: 9.4519\n",
      "Epoch 16, Step 183, Training Loss: 9.2482\n",
      "Epoch 16, Step 184, Training Loss: 6.6978\n",
      "Epoch 16, Step 185, Training Loss: 9.5898\n",
      "Epoch 16, Step 186, Training Loss: 17.2386\n",
      "Epoch 16, Step 187, Training Loss: 7.0290\n",
      "Epoch 16, Step 188, Training Loss: 98.1406\n",
      "Epoch 16, Step 189, Training Loss: 9.7989\n",
      "Epoch 16, Step 190, Training Loss: 90.5859\n",
      "Epoch 16, Step 191, Training Loss: 7.6849\n",
      "Epoch 16, Step 192, Training Loss: 11.0423\n",
      "Epoch 16, Step 193, Training Loss: 12.0293\n",
      "Epoch 16, Step 194, Training Loss: 7.9637\n",
      "Epoch 16, Step 195, Training Loss: 9.5778\n",
      "Epoch 16, Step 196, Training Loss: 11.2586\n",
      "Epoch 16, Step 197, Training Loss: 11.7083\n",
      "Epoch 16, Step 198, Training Loss: 9.0082\n",
      "Epoch 16, Step 199, Training Loss: 9.1571\n",
      "Epoch 16, Step 200, Training Loss: 9.3484\n",
      "Epoch 16, Step 201, Training Loss: 9.9976\n",
      "Epoch 16, Step 202, Training Loss: 11.2463\n",
      "Epoch 16, Step 203, Training Loss: 28.8820\n",
      "Epoch 16, Step 204, Training Loss: 15.1656\n",
      "Epoch 16, Step 205, Training Loss: 12.3041\n",
      "Epoch 16, Step 206, Training Loss: 10.0679\n",
      "--- Epoch 16, Validation Loss: 10.5551 ---\n",
      "Epoch 17, Step 0, Training Loss: 9.8590\n",
      "Epoch 17, Step 1, Training Loss: 8.4981\n",
      "Epoch 17, Step 2, Training Loss: 6.8932\n",
      "Epoch 17, Step 3, Training Loss: 26.2337\n",
      "Epoch 17, Step 4, Training Loss: 34.7531\n",
      "Epoch 17, Step 5, Training Loss: 7.4129\n",
      "Epoch 17, Step 6, Training Loss: 9.0529\n",
      "Epoch 17, Step 7, Training Loss: 16.1273\n",
      "Epoch 17, Step 8, Training Loss: 6.6829\n",
      "Epoch 17, Step 9, Training Loss: 11.7215\n",
      "Epoch 17, Step 10, Training Loss: 22.3505\n",
      "Epoch 17, Step 11, Training Loss: 8.7366\n",
      "Epoch 17, Step 12, Training Loss: 13.5424\n",
      "Epoch 17, Step 13, Training Loss: 35.1922\n",
      "Epoch 17, Step 14, Training Loss: 10.5172\n",
      "Epoch 17, Step 15, Training Loss: 10.3529\n",
      "Epoch 17, Step 16, Training Loss: 11.4321\n",
      "Epoch 17, Step 17, Training Loss: 9.8885\n",
      "Epoch 17, Step 18, Training Loss: 9.0887\n",
      "Epoch 17, Step 19, Training Loss: 29.8128\n",
      "Epoch 17, Step 20, Training Loss: 8.2855\n",
      "Epoch 17, Step 21, Training Loss: 13.5875\n",
      "Epoch 17, Step 22, Training Loss: 16.9161\n",
      "Epoch 17, Step 23, Training Loss: 10.4047\n",
      "Epoch 17, Step 24, Training Loss: 11.2383\n",
      "Epoch 17, Step 25, Training Loss: 13.2970\n",
      "Epoch 17, Step 26, Training Loss: 10.5870\n",
      "Epoch 17, Step 27, Training Loss: 12.4670\n",
      "Epoch 17, Step 28, Training Loss: 10.2703\n",
      "Epoch 17, Step 29, Training Loss: 8.7317\n",
      "Epoch 17, Step 30, Training Loss: 8.7764\n",
      "Epoch 17, Step 31, Training Loss: 8.7728\n",
      "Epoch 17, Step 32, Training Loss: 11.1823\n",
      "Epoch 17, Step 33, Training Loss: 8.4044\n",
      "Epoch 17, Step 34, Training Loss: 8.3783\n",
      "Epoch 17, Step 35, Training Loss: 7.2643\n",
      "Epoch 17, Step 36, Training Loss: 13.5860\n",
      "Epoch 17, Step 37, Training Loss: 26.8986\n",
      "Epoch 17, Step 38, Training Loss: 12.8158\n",
      "Epoch 17, Step 39, Training Loss: 9.6933\n",
      "Epoch 17, Step 40, Training Loss: 11.9857\n",
      "Epoch 17, Step 41, Training Loss: 14.4243\n",
      "Epoch 17, Step 42, Training Loss: 11.2472\n",
      "Epoch 17, Step 43, Training Loss: 7.9797\n",
      "Epoch 17, Step 44, Training Loss: 12.9940\n",
      "Epoch 17, Step 45, Training Loss: 9.2516\n",
      "Epoch 17, Step 46, Training Loss: 8.8579\n",
      "Epoch 17, Step 47, Training Loss: 8.1095\n",
      "Epoch 17, Step 48, Training Loss: 6.1045\n",
      "Epoch 17, Step 49, Training Loss: 11.0774\n",
      "Epoch 17, Step 50, Training Loss: 6.6431\n",
      "Epoch 17, Step 51, Training Loss: 7.1828\n",
      "Epoch 17, Step 52, Training Loss: 7.7519\n",
      "Epoch 17, Step 53, Training Loss: 6.9543\n",
      "Epoch 17, Step 54, Training Loss: 10.5511\n",
      "Epoch 17, Step 55, Training Loss: 10.6864\n",
      "Epoch 17, Step 56, Training Loss: 17.9265\n",
      "Epoch 17, Step 57, Training Loss: 7.3616\n",
      "Epoch 17, Step 58, Training Loss: 14.0871\n",
      "Epoch 17, Step 59, Training Loss: 8.8294\n",
      "Epoch 17, Step 60, Training Loss: 44.6543\n",
      "Epoch 17, Step 61, Training Loss: 10.3719\n",
      "Epoch 17, Step 62, Training Loss: 11.6718\n",
      "Epoch 17, Step 63, Training Loss: 30.8960\n",
      "Epoch 17, Step 64, Training Loss: 6.8783\n",
      "Epoch 17, Step 65, Training Loss: 11.0248\n",
      "Epoch 17, Step 66, Training Loss: 8.3164\n",
      "Epoch 17, Step 67, Training Loss: 10.2225\n",
      "Epoch 17, Step 68, Training Loss: 10.6479\n",
      "Epoch 17, Step 69, Training Loss: 22.0663\n",
      "Epoch 17, Step 70, Training Loss: 8.1875\n",
      "Epoch 17, Step 71, Training Loss: 9.8372\n",
      "Epoch 17, Step 72, Training Loss: 12.8281\n",
      "Epoch 17, Step 73, Training Loss: 9.8188\n",
      "Epoch 17, Step 74, Training Loss: 11.0797\n",
      "Epoch 17, Step 75, Training Loss: 28.8255\n",
      "Epoch 17, Step 76, Training Loss: 22.7835\n",
      "Epoch 17, Step 77, Training Loss: 15.4402\n",
      "Epoch 17, Step 78, Training Loss: 8.1422\n",
      "Epoch 17, Step 79, Training Loss: 14.5447\n",
      "Epoch 17, Step 80, Training Loss: 14.5725\n",
      "Epoch 17, Step 81, Training Loss: 26.6391\n",
      "Epoch 17, Step 82, Training Loss: 10.8361\n",
      "Epoch 17, Step 83, Training Loss: 34.4925\n",
      "Epoch 17, Step 84, Training Loss: 26.8092\n",
      "Epoch 17, Step 85, Training Loss: 6.7535\n",
      "Epoch 17, Step 86, Training Loss: 10.4707\n",
      "Epoch 17, Step 87, Training Loss: 11.2241\n",
      "Epoch 17, Step 88, Training Loss: 13.8899\n",
      "Epoch 17, Step 89, Training Loss: 13.2526\n",
      "Epoch 17, Step 90, Training Loss: 11.1347\n",
      "Epoch 17, Step 91, Training Loss: 7.3093\n",
      "Epoch 17, Step 92, Training Loss: 14.6580\n",
      "Epoch 17, Step 93, Training Loss: 9.2961\n",
      "Epoch 17, Step 94, Training Loss: 21.3998\n",
      "Epoch 17, Step 95, Training Loss: 5.8027\n",
      "Epoch 17, Step 96, Training Loss: 7.3934\n",
      "Epoch 17, Step 97, Training Loss: 8.5367\n",
      "Epoch 17, Step 98, Training Loss: 18.0434\n",
      "Epoch 17, Step 99, Training Loss: 26.7642\n",
      "Epoch 17, Step 100, Training Loss: 7.7748\n",
      "Epoch 17, Step 101, Training Loss: 5.7074\n",
      "Epoch 17, Step 102, Training Loss: 11.6291\n",
      "Epoch 17, Step 103, Training Loss: 7.8194\n",
      "Epoch 17, Step 104, Training Loss: 9.8547\n",
      "Epoch 17, Step 105, Training Loss: 11.7561\n",
      "Epoch 17, Step 106, Training Loss: 13.3440\n",
      "Epoch 17, Step 107, Training Loss: 14.0029\n",
      "Epoch 17, Step 108, Training Loss: 7.4366\n",
      "Epoch 17, Step 109, Training Loss: 7.2701\n",
      "Epoch 17, Step 110, Training Loss: 12.1713\n",
      "Epoch 17, Step 111, Training Loss: 6.6308\n",
      "Epoch 17, Step 112, Training Loss: 8.4914\n",
      "Epoch 17, Step 113, Training Loss: 10.7910\n",
      "Epoch 17, Step 114, Training Loss: 5.9666\n",
      "Epoch 17, Step 115, Training Loss: 16.0733\n",
      "Epoch 17, Step 116, Training Loss: 8.9384\n",
      "Epoch 17, Step 117, Training Loss: 10.2450\n",
      "Epoch 17, Step 118, Training Loss: 8.5114\n",
      "Epoch 17, Step 119, Training Loss: 7.5065\n",
      "Epoch 17, Step 120, Training Loss: 9.9395\n",
      "Epoch 17, Step 121, Training Loss: 25.9997\n",
      "Epoch 17, Step 122, Training Loss: 30.8592\n",
      "Epoch 17, Step 123, Training Loss: 11.8376\n",
      "Epoch 17, Step 124, Training Loss: 11.3072\n",
      "Epoch 17, Step 125, Training Loss: 15.1260\n",
      "Epoch 17, Step 126, Training Loss: 9.1408\n",
      "Epoch 17, Step 127, Training Loss: 12.4808\n",
      "Epoch 17, Step 128, Training Loss: 6.1918\n",
      "Epoch 17, Step 129, Training Loss: 13.8403\n",
      "Epoch 17, Step 130, Training Loss: 7.1074\n",
      "Epoch 17, Step 131, Training Loss: 11.6815\n",
      "Epoch 17, Step 132, Training Loss: 16.5138\n",
      "Epoch 17, Step 133, Training Loss: 33.9424\n",
      "Epoch 17, Step 134, Training Loss: 15.4395\n",
      "Epoch 17, Step 135, Training Loss: 11.8210\n",
      "Epoch 17, Step 136, Training Loss: 32.8215\n",
      "Epoch 17, Step 137, Training Loss: 9.4420\n",
      "Epoch 17, Step 138, Training Loss: 6.3461\n",
      "Epoch 17, Step 139, Training Loss: 10.8049\n",
      "Epoch 17, Step 140, Training Loss: 11.1839\n",
      "Epoch 17, Step 141, Training Loss: 14.3460\n",
      "Epoch 17, Step 142, Training Loss: 8.1457\n",
      "Epoch 17, Step 143, Training Loss: 8.4802\n",
      "Epoch 17, Step 144, Training Loss: 8.1344\n",
      "Epoch 17, Step 145, Training Loss: 8.8397\n",
      "Epoch 17, Step 146, Training Loss: 7.7253\n",
      "Epoch 17, Step 147, Training Loss: 12.9756\n",
      "Epoch 17, Step 148, Training Loss: 48.1413\n",
      "Epoch 17, Step 149, Training Loss: 16.7737\n",
      "Epoch 17, Step 150, Training Loss: 14.0082\n",
      "Epoch 17, Step 151, Training Loss: 10.0160\n",
      "Epoch 17, Step 152, Training Loss: 8.3974\n",
      "Epoch 17, Step 153, Training Loss: 6.4139\n",
      "Epoch 17, Step 154, Training Loss: 8.5456\n",
      "Epoch 17, Step 155, Training Loss: 14.3461\n",
      "Epoch 17, Step 156, Training Loss: 10.5821\n",
      "Epoch 17, Step 157, Training Loss: 15.6237\n",
      "Epoch 17, Step 158, Training Loss: 8.5880\n",
      "Epoch 17, Step 159, Training Loss: 16.4778\n",
      "Epoch 17, Step 160, Training Loss: 40.0532\n",
      "Epoch 17, Step 161, Training Loss: 10.6328\n",
      "Epoch 17, Step 162, Training Loss: 7.3994\n",
      "Epoch 17, Step 163, Training Loss: 10.2553\n",
      "Epoch 17, Step 164, Training Loss: 8.1042\n",
      "Epoch 17, Step 165, Training Loss: 11.1227\n",
      "Epoch 17, Step 166, Training Loss: 8.2908\n",
      "Epoch 17, Step 167, Training Loss: 9.3626\n",
      "Epoch 17, Step 168, Training Loss: 15.2515\n",
      "Epoch 17, Step 169, Training Loss: 8.6774\n",
      "Epoch 17, Step 170, Training Loss: 9.3755\n",
      "Epoch 17, Step 171, Training Loss: 9.3894\n",
      "Epoch 17, Step 172, Training Loss: 12.4319\n",
      "Epoch 17, Step 173, Training Loss: 14.4085\n",
      "Epoch 17, Step 174, Training Loss: 10.1909\n",
      "Epoch 17, Step 175, Training Loss: 14.1349\n",
      "Epoch 17, Step 176, Training Loss: 11.9120\n",
      "Epoch 17, Step 177, Training Loss: 16.8262\n",
      "Epoch 17, Step 178, Training Loss: 10.9671\n",
      "Epoch 17, Step 179, Training Loss: 8.8578\n",
      "Epoch 17, Step 180, Training Loss: 14.3045\n",
      "Epoch 17, Step 181, Training Loss: 9.3332\n",
      "Epoch 17, Step 182, Training Loss: 13.2348\n",
      "Epoch 17, Step 183, Training Loss: 8.7838\n",
      "Epoch 17, Step 184, Training Loss: 7.5660\n",
      "Epoch 17, Step 185, Training Loss: 9.5028\n",
      "Epoch 17, Step 186, Training Loss: 15.9018\n",
      "Epoch 17, Step 187, Training Loss: 7.8511\n",
      "Epoch 17, Step 188, Training Loss: 98.0441\n",
      "Epoch 17, Step 189, Training Loss: 9.2513\n",
      "Epoch 17, Step 190, Training Loss: 94.0275\n",
      "Epoch 17, Step 191, Training Loss: 7.8191\n",
      "Epoch 17, Step 192, Training Loss: 9.5246\n",
      "Epoch 17, Step 193, Training Loss: 12.0782\n",
      "Epoch 17, Step 194, Training Loss: 8.2694\n",
      "Epoch 17, Step 195, Training Loss: 9.6766\n",
      "Epoch 17, Step 196, Training Loss: 11.4345\n",
      "Epoch 17, Step 197, Training Loss: 15.6267\n",
      "Epoch 17, Step 198, Training Loss: 9.9460\n",
      "Epoch 17, Step 199, Training Loss: 6.8069\n",
      "Epoch 17, Step 200, Training Loss: 8.6458\n",
      "Epoch 17, Step 201, Training Loss: 10.2288\n",
      "Epoch 17, Step 202, Training Loss: 8.5391\n",
      "Epoch 17, Step 203, Training Loss: 28.3295\n",
      "Epoch 17, Step 204, Training Loss: 20.8328\n",
      "Epoch 17, Step 205, Training Loss: 10.4261\n",
      "Epoch 17, Step 206, Training Loss: 8.9379\n",
      "--- Epoch 17, Validation Loss: 10.9772 ---\n",
      "Epoch 18, Step 0, Training Loss: 9.3896\n",
      "Epoch 18, Step 1, Training Loss: 8.4884\n",
      "Epoch 18, Step 2, Training Loss: 8.6214\n",
      "Epoch 18, Step 3, Training Loss: 24.4293\n",
      "Epoch 18, Step 4, Training Loss: 23.3711\n",
      "Epoch 18, Step 5, Training Loss: 9.6908\n",
      "Epoch 18, Step 6, Training Loss: 7.9529\n",
      "Epoch 18, Step 7, Training Loss: 9.2424\n",
      "Epoch 18, Step 8, Training Loss: 5.1663\n",
      "Epoch 18, Step 9, Training Loss: 10.1505\n",
      "Epoch 18, Step 10, Training Loss: 19.8237\n",
      "Epoch 18, Step 11, Training Loss: 10.8999\n",
      "Epoch 18, Step 12, Training Loss: 13.0327\n",
      "Epoch 18, Step 13, Training Loss: 33.1369\n",
      "Epoch 18, Step 14, Training Loss: 11.7965\n",
      "Epoch 18, Step 15, Training Loss: 9.4830\n",
      "Epoch 18, Step 16, Training Loss: 6.9686\n",
      "Epoch 18, Step 17, Training Loss: 6.6824\n",
      "Epoch 18, Step 18, Training Loss: 10.6958\n",
      "Epoch 18, Step 19, Training Loss: 25.8475\n",
      "Epoch 18, Step 20, Training Loss: 7.0205\n",
      "Epoch 18, Step 21, Training Loss: 14.3611\n",
      "Epoch 18, Step 22, Training Loss: 19.7874\n",
      "Epoch 18, Step 23, Training Loss: 11.6455\n",
      "Epoch 18, Step 24, Training Loss: 10.4269\n",
      "Epoch 18, Step 25, Training Loss: 10.8443\n",
      "Epoch 18, Step 26, Training Loss: 8.4340\n",
      "Epoch 18, Step 27, Training Loss: 9.5073\n",
      "Epoch 18, Step 28, Training Loss: 9.6656\n",
      "Epoch 18, Step 29, Training Loss: 6.2580\n",
      "Epoch 18, Step 30, Training Loss: 6.9151\n",
      "Epoch 18, Step 31, Training Loss: 8.4916\n",
      "Epoch 18, Step 32, Training Loss: 10.6654\n",
      "Epoch 18, Step 33, Training Loss: 9.1805\n",
      "Epoch 18, Step 34, Training Loss: 12.9124\n",
      "Epoch 18, Step 35, Training Loss: 9.1805\n",
      "Epoch 18, Step 36, Training Loss: 11.6303\n",
      "Epoch 18, Step 37, Training Loss: 30.3964\n",
      "Epoch 18, Step 38, Training Loss: 12.6726\n",
      "Epoch 18, Step 39, Training Loss: 9.0581\n",
      "Epoch 18, Step 40, Training Loss: 11.9790\n",
      "Epoch 18, Step 41, Training Loss: 14.4811\n",
      "Epoch 18, Step 42, Training Loss: 7.8377\n",
      "Epoch 18, Step 43, Training Loss: 10.5573\n",
      "Epoch 18, Step 44, Training Loss: 10.7811\n",
      "Epoch 18, Step 45, Training Loss: 11.3649\n",
      "Epoch 18, Step 46, Training Loss: 6.6097\n",
      "Epoch 18, Step 47, Training Loss: 10.7242\n",
      "Epoch 18, Step 48, Training Loss: 11.8454\n",
      "Epoch 18, Step 49, Training Loss: 10.5666\n",
      "Epoch 18, Step 50, Training Loss: 6.4479\n",
      "Epoch 18, Step 51, Training Loss: 8.8853\n",
      "Epoch 18, Step 52, Training Loss: 9.8096\n",
      "Epoch 18, Step 53, Training Loss: 4.6111\n",
      "Epoch 18, Step 54, Training Loss: 8.2304\n",
      "Epoch 18, Step 55, Training Loss: 9.9016\n",
      "Epoch 18, Step 56, Training Loss: 16.3176\n",
      "Epoch 18, Step 57, Training Loss: 9.2841\n",
      "Epoch 18, Step 58, Training Loss: 11.2528\n",
      "Epoch 18, Step 59, Training Loss: 11.0074\n",
      "Epoch 18, Step 60, Training Loss: 41.7167\n",
      "Epoch 18, Step 61, Training Loss: 7.4934\n",
      "Epoch 18, Step 62, Training Loss: 12.8552\n",
      "Epoch 18, Step 63, Training Loss: 29.6460\n",
      "Epoch 18, Step 64, Training Loss: 7.4250\n",
      "Epoch 18, Step 65, Training Loss: 7.4256\n",
      "Epoch 18, Step 66, Training Loss: 7.1441\n",
      "Epoch 18, Step 67, Training Loss: 7.7402\n",
      "Epoch 18, Step 68, Training Loss: 7.8090\n",
      "Epoch 18, Step 69, Training Loss: 23.7556\n",
      "Epoch 18, Step 70, Training Loss: 6.5801\n",
      "Epoch 18, Step 71, Training Loss: 7.3857\n",
      "Epoch 18, Step 72, Training Loss: 11.3076\n",
      "Epoch 18, Step 73, Training Loss: 10.3425\n",
      "Epoch 18, Step 74, Training Loss: 11.2513\n",
      "Epoch 18, Step 75, Training Loss: 27.9387\n",
      "Epoch 18, Step 76, Training Loss: 20.2695\n",
      "Epoch 18, Step 77, Training Loss: 12.2544\n",
      "Epoch 18, Step 78, Training Loss: 7.3345\n",
      "Epoch 18, Step 79, Training Loss: 13.4874\n",
      "Epoch 18, Step 80, Training Loss: 16.5798\n",
      "Epoch 18, Step 81, Training Loss: 23.9527\n",
      "Epoch 18, Step 82, Training Loss: 9.7544\n",
      "Epoch 18, Step 83, Training Loss: 30.3301\n",
      "Epoch 18, Step 84, Training Loss: 25.0386\n",
      "Epoch 18, Step 85, Training Loss: 8.4389\n",
      "Epoch 18, Step 86, Training Loss: 12.2269\n",
      "Epoch 18, Step 87, Training Loss: 10.7774\n",
      "Epoch 18, Step 88, Training Loss: 14.3773\n",
      "Epoch 18, Step 89, Training Loss: 10.6022\n",
      "Epoch 18, Step 90, Training Loss: 10.9756\n",
      "Epoch 18, Step 91, Training Loss: 6.5912\n",
      "Epoch 18, Step 92, Training Loss: 14.6749\n",
      "Epoch 18, Step 93, Training Loss: 9.9884\n",
      "Epoch 18, Step 94, Training Loss: 20.3759\n",
      "Epoch 18, Step 95, Training Loss: 5.4619\n",
      "Epoch 18, Step 96, Training Loss: 9.1549\n",
      "Epoch 18, Step 97, Training Loss: 6.4674\n",
      "Epoch 18, Step 98, Training Loss: 14.6186\n",
      "Epoch 18, Step 99, Training Loss: 26.6221\n",
      "Epoch 18, Step 100, Training Loss: 10.4908\n",
      "Epoch 18, Step 101, Training Loss: 11.6277\n",
      "Epoch 18, Step 102, Training Loss: 10.6374\n",
      "Epoch 18, Step 103, Training Loss: 8.8957\n",
      "Epoch 18, Step 104, Training Loss: 12.0455\n",
      "Epoch 18, Step 105, Training Loss: 9.5430\n",
      "Epoch 18, Step 106, Training Loss: 15.7420\n",
      "Epoch 18, Step 107, Training Loss: 10.8399\n",
      "Epoch 18, Step 108, Training Loss: 8.5706\n",
      "Epoch 18, Step 109, Training Loss: 9.8992\n",
      "Epoch 18, Step 110, Training Loss: 9.6531\n",
      "Epoch 18, Step 111, Training Loss: 7.9556\n",
      "Epoch 18, Step 112, Training Loss: 9.3460\n",
      "Epoch 18, Step 113, Training Loss: 8.9976\n",
      "Epoch 18, Step 114, Training Loss: 5.4495\n",
      "Epoch 18, Step 115, Training Loss: 14.9868\n",
      "Epoch 18, Step 116, Training Loss: 9.0170\n",
      "Epoch 18, Step 117, Training Loss: 10.1768\n",
      "Epoch 18, Step 118, Training Loss: 10.3124\n",
      "Epoch 18, Step 119, Training Loss: 7.7820\n",
      "Epoch 18, Step 120, Training Loss: 9.9471\n",
      "Epoch 18, Step 121, Training Loss: 21.8007\n",
      "Epoch 18, Step 122, Training Loss: 27.8592\n",
      "Epoch 18, Step 123, Training Loss: 10.4446\n",
      "Epoch 18, Step 124, Training Loss: 11.5409\n",
      "Epoch 18, Step 125, Training Loss: 12.2565\n",
      "Epoch 18, Step 126, Training Loss: 8.4512\n",
      "Epoch 18, Step 127, Training Loss: 13.6082\n",
      "Epoch 18, Step 128, Training Loss: 6.8026\n",
      "Epoch 18, Step 129, Training Loss: 14.0339\n",
      "Epoch 18, Step 130, Training Loss: 7.3757\n",
      "Epoch 18, Step 131, Training Loss: 10.8416\n",
      "Epoch 18, Step 132, Training Loss: 13.1503\n",
      "Epoch 18, Step 133, Training Loss: 32.3382\n",
      "Epoch 18, Step 134, Training Loss: 16.8681\n",
      "Epoch 18, Step 135, Training Loss: 8.8260\n",
      "Epoch 18, Step 136, Training Loss: 35.2270\n",
      "Epoch 18, Step 137, Training Loss: 9.8151\n",
      "Epoch 18, Step 138, Training Loss: 8.7278\n",
      "Epoch 18, Step 139, Training Loss: 13.5577\n",
      "Epoch 18, Step 140, Training Loss: 7.7909\n",
      "Epoch 18, Step 141, Training Loss: 17.3196\n",
      "Epoch 18, Step 142, Training Loss: 6.6787\n",
      "Epoch 18, Step 143, Training Loss: 10.8754\n",
      "Epoch 18, Step 144, Training Loss: 7.3622\n",
      "Epoch 18, Step 145, Training Loss: 11.3284\n",
      "Epoch 18, Step 146, Training Loss: 9.6750\n",
      "Epoch 18, Step 147, Training Loss: 8.4943\n",
      "Epoch 18, Step 148, Training Loss: 42.5611\n",
      "Epoch 18, Step 149, Training Loss: 11.8671\n",
      "Epoch 18, Step 150, Training Loss: 13.2683\n",
      "Epoch 18, Step 151, Training Loss: 8.7386\n",
      "Epoch 18, Step 152, Training Loss: 7.4421\n",
      "Epoch 18, Step 153, Training Loss: 7.6324\n",
      "Epoch 18, Step 154, Training Loss: 8.0656\n",
      "Epoch 18, Step 155, Training Loss: 15.1222\n",
      "Epoch 18, Step 156, Training Loss: 9.3842\n",
      "Epoch 18, Step 157, Training Loss: 15.9277\n",
      "Epoch 18, Step 158, Training Loss: 11.4550\n",
      "Epoch 18, Step 159, Training Loss: 13.3488\n",
      "Epoch 18, Step 160, Training Loss: 36.1566\n",
      "Epoch 18, Step 161, Training Loss: 7.6163\n",
      "Epoch 18, Step 162, Training Loss: 4.7446\n",
      "Epoch 18, Step 163, Training Loss: 9.9579\n",
      "Epoch 18, Step 164, Training Loss: 12.2514\n",
      "Epoch 18, Step 165, Training Loss: 11.8601\n",
      "Epoch 18, Step 166, Training Loss: 8.5256\n",
      "Epoch 18, Step 167, Training Loss: 11.3491\n",
      "Epoch 18, Step 168, Training Loss: 11.3362\n",
      "Epoch 18, Step 169, Training Loss: 7.3747\n",
      "Epoch 18, Step 170, Training Loss: 6.3791\n",
      "Epoch 18, Step 171, Training Loss: 6.5890\n",
      "Epoch 18, Step 172, Training Loss: 14.3940\n",
      "Epoch 18, Step 173, Training Loss: 11.2909\n",
      "Epoch 18, Step 174, Training Loss: 10.3316\n",
      "Epoch 18, Step 175, Training Loss: 9.8367\n",
      "Epoch 18, Step 176, Training Loss: 8.9464\n",
      "Epoch 18, Step 177, Training Loss: 19.0322\n",
      "Epoch 18, Step 178, Training Loss: 11.2152\n",
      "Epoch 18, Step 179, Training Loss: 8.7702\n",
      "Epoch 18, Step 180, Training Loss: 14.7870\n",
      "Epoch 18, Step 181, Training Loss: 7.0583\n",
      "Epoch 18, Step 182, Training Loss: 10.7500\n",
      "Epoch 18, Step 183, Training Loss: 8.2631\n",
      "Epoch 18, Step 184, Training Loss: 11.3971\n",
      "Epoch 18, Step 185, Training Loss: 9.7823\n",
      "Epoch 18, Step 186, Training Loss: 19.6402\n",
      "Epoch 18, Step 187, Training Loss: 8.0706\n",
      "Epoch 18, Step 188, Training Loss: 98.7735\n",
      "Epoch 18, Step 189, Training Loss: 6.8859\n",
      "Epoch 18, Step 190, Training Loss: 83.4336\n",
      "Epoch 18, Step 191, Training Loss: 8.4741\n",
      "Epoch 18, Step 192, Training Loss: 9.9975\n",
      "Epoch 18, Step 193, Training Loss: 11.2185\n",
      "Epoch 18, Step 194, Training Loss: 9.0333\n",
      "Epoch 18, Step 195, Training Loss: 8.1644\n",
      "Epoch 18, Step 196, Training Loss: 16.0480\n",
      "Epoch 18, Step 197, Training Loss: 10.9554\n",
      "Epoch 18, Step 198, Training Loss: 6.1217\n",
      "Epoch 18, Step 199, Training Loss: 9.6563\n",
      "Epoch 18, Step 200, Training Loss: 7.6774\n",
      "Epoch 18, Step 201, Training Loss: 7.6091\n",
      "Epoch 18, Step 202, Training Loss: 7.4544\n",
      "Epoch 18, Step 203, Training Loss: 27.6181\n",
      "Epoch 18, Step 204, Training Loss: 15.6627\n",
      "Epoch 18, Step 205, Training Loss: 9.5027\n",
      "Epoch 18, Step 206, Training Loss: 7.8674\n",
      "--- Epoch 18, Validation Loss: 10.7058 ---\n",
      "Epoch 19, Step 0, Training Loss: 10.5913\n",
      "Epoch 19, Step 1, Training Loss: 9.7598\n",
      "Epoch 19, Step 2, Training Loss: 6.5592\n",
      "Epoch 19, Step 3, Training Loss: 23.1685\n",
      "Epoch 19, Step 4, Training Loss: 39.5145\n",
      "Epoch 19, Step 5, Training Loss: 6.6352\n",
      "Epoch 19, Step 6, Training Loss: 9.7003\n",
      "Epoch 19, Step 7, Training Loss: 10.2626\n",
      "Epoch 19, Step 8, Training Loss: 7.3779\n",
      "Epoch 19, Step 9, Training Loss: 10.1129\n",
      "Epoch 19, Step 10, Training Loss: 30.5188\n",
      "Epoch 19, Step 11, Training Loss: 8.3366\n",
      "Epoch 19, Step 12, Training Loss: 10.3206\n",
      "Epoch 19, Step 13, Training Loss: 35.8562\n",
      "Epoch 19, Step 14, Training Loss: 11.0212\n",
      "Epoch 19, Step 15, Training Loss: 9.4960\n",
      "Epoch 19, Step 16, Training Loss: 6.5641\n",
      "Epoch 19, Step 17, Training Loss: 7.4795\n",
      "Epoch 19, Step 18, Training Loss: 7.7760\n",
      "Epoch 19, Step 19, Training Loss: 26.6355\n",
      "Epoch 19, Step 20, Training Loss: 8.0535\n",
      "Epoch 19, Step 21, Training Loss: 16.0004\n",
      "Epoch 19, Step 22, Training Loss: 16.1534\n",
      "Epoch 19, Step 23, Training Loss: 9.3933\n",
      "Epoch 19, Step 24, Training Loss: 9.6290\n",
      "Epoch 19, Step 25, Training Loss: 10.7636\n",
      "Epoch 19, Step 26, Training Loss: 11.0414\n",
      "Epoch 19, Step 27, Training Loss: 12.0057\n",
      "Epoch 19, Step 28, Training Loss: 9.9977\n",
      "Epoch 19, Step 29, Training Loss: 6.8198\n",
      "Epoch 19, Step 30, Training Loss: 9.6184\n",
      "Epoch 19, Step 31, Training Loss: 7.2437\n",
      "Epoch 19, Step 32, Training Loss: 9.8602\n",
      "Epoch 19, Step 33, Training Loss: 9.7361\n",
      "Epoch 19, Step 34, Training Loss: 8.8434\n",
      "Epoch 19, Step 35, Training Loss: 7.1908\n",
      "Epoch 19, Step 36, Training Loss: 15.9539\n",
      "Epoch 19, Step 37, Training Loss: 23.4218\n",
      "Epoch 19, Step 38, Training Loss: 13.7297\n",
      "Epoch 19, Step 39, Training Loss: 6.2940\n",
      "Epoch 19, Step 40, Training Loss: 10.8357\n",
      "Epoch 19, Step 41, Training Loss: 16.2882\n",
      "Epoch 19, Step 42, Training Loss: 10.3024\n",
      "Epoch 19, Step 43, Training Loss: 10.9454\n",
      "Epoch 19, Step 44, Training Loss: 13.7659\n",
      "Epoch 19, Step 45, Training Loss: 9.9549\n",
      "Epoch 19, Step 46, Training Loss: 7.8711\n",
      "Epoch 19, Step 47, Training Loss: 10.3271\n",
      "Epoch 19, Step 48, Training Loss: 7.2819\n",
      "Epoch 19, Step 49, Training Loss: 10.5076\n",
      "Epoch 19, Step 50, Training Loss: 6.3123\n",
      "Epoch 19, Step 51, Training Loss: 7.8762\n",
      "Epoch 19, Step 52, Training Loss: 12.0488\n",
      "Epoch 19, Step 53, Training Loss: 6.2334\n",
      "Epoch 19, Step 54, Training Loss: 10.0055\n",
      "Epoch 19, Step 55, Training Loss: 9.5090\n",
      "Epoch 19, Step 56, Training Loss: 16.9009\n",
      "Epoch 19, Step 57, Training Loss: 7.8884\n",
      "Epoch 19, Step 58, Training Loss: 12.5289\n",
      "Epoch 19, Step 59, Training Loss: 9.5265\n",
      "Epoch 19, Step 60, Training Loss: 41.3378\n",
      "Epoch 19, Step 61, Training Loss: 12.2260\n",
      "Epoch 19, Step 62, Training Loss: 13.3014\n",
      "Epoch 19, Step 63, Training Loss: 28.2132\n",
      "Epoch 19, Step 64, Training Loss: 8.1680\n",
      "Epoch 19, Step 65, Training Loss: 10.1687\n",
      "Epoch 19, Step 66, Training Loss: 8.3111\n",
      "Epoch 19, Step 67, Training Loss: 8.5689\n",
      "Epoch 19, Step 68, Training Loss: 10.2049\n",
      "Epoch 19, Step 69, Training Loss: 22.3197\n",
      "Epoch 19, Step 70, Training Loss: 9.7588\n",
      "Epoch 19, Step 71, Training Loss: 9.8127\n",
      "Epoch 19, Step 72, Training Loss: 11.2251\n",
      "Epoch 19, Step 73, Training Loss: 9.9162\n",
      "Epoch 19, Step 74, Training Loss: 10.7381\n",
      "Epoch 19, Step 75, Training Loss: 28.3714\n",
      "Epoch 19, Step 76, Training Loss: 20.1974\n",
      "Epoch 19, Step 77, Training Loss: 10.5152\n",
      "Epoch 19, Step 78, Training Loss: 7.3223\n",
      "Epoch 19, Step 79, Training Loss: 13.9790\n",
      "Epoch 19, Step 80, Training Loss: 19.0844\n",
      "Epoch 19, Step 81, Training Loss: 22.2299\n",
      "Epoch 19, Step 82, Training Loss: 10.3467\n",
      "Epoch 19, Step 83, Training Loss: 32.4350\n",
      "Epoch 19, Step 84, Training Loss: 24.6599\n",
      "Epoch 19, Step 85, Training Loss: 8.3576\n",
      "Epoch 19, Step 86, Training Loss: 11.2723\n",
      "Epoch 19, Step 87, Training Loss: 9.9870\n",
      "Epoch 19, Step 88, Training Loss: 10.0290\n",
      "Epoch 19, Step 89, Training Loss: 12.7026\n",
      "Epoch 19, Step 90, Training Loss: 9.7138\n",
      "Epoch 19, Step 91, Training Loss: 7.8309\n",
      "Epoch 19, Step 92, Training Loss: 13.4804\n",
      "Epoch 19, Step 93, Training Loss: 8.7993\n",
      "Epoch 19, Step 94, Training Loss: 18.5576\n",
      "Epoch 19, Step 95, Training Loss: 5.9004\n",
      "Epoch 19, Step 96, Training Loss: 8.9528\n",
      "Epoch 19, Step 97, Training Loss: 8.6381\n",
      "Epoch 19, Step 98, Training Loss: 13.2122\n",
      "Epoch 19, Step 99, Training Loss: 26.8133\n",
      "Epoch 19, Step 100, Training Loss: 9.1143\n",
      "Epoch 19, Step 101, Training Loss: 4.7141\n",
      "Epoch 19, Step 102, Training Loss: 10.8804\n",
      "Epoch 19, Step 103, Training Loss: 8.5681\n",
      "Epoch 19, Step 104, Training Loss: 11.0891\n",
      "Epoch 19, Step 105, Training Loss: 9.4120\n",
      "Epoch 19, Step 106, Training Loss: 14.1559\n",
      "Epoch 19, Step 107, Training Loss: 13.0604\n",
      "Epoch 19, Step 108, Training Loss: 9.6926\n",
      "Epoch 19, Step 109, Training Loss: 7.8365\n",
      "Epoch 19, Step 110, Training Loss: 9.4255\n",
      "Epoch 19, Step 111, Training Loss: 6.0380\n",
      "Epoch 19, Step 112, Training Loss: 8.3428\n",
      "Epoch 19, Step 113, Training Loss: 9.7935\n",
      "Epoch 19, Step 114, Training Loss: 6.3969\n",
      "Epoch 19, Step 115, Training Loss: 15.9667\n",
      "Epoch 19, Step 116, Training Loss: 12.0803\n",
      "Epoch 19, Step 117, Training Loss: 11.6032\n",
      "Epoch 19, Step 118, Training Loss: 7.4013\n",
      "Epoch 19, Step 119, Training Loss: 6.3083\n",
      "Epoch 19, Step 120, Training Loss: 11.5641\n",
      "Epoch 19, Step 121, Training Loss: 19.8524\n",
      "Epoch 19, Step 122, Training Loss: 30.7908\n",
      "Epoch 19, Step 123, Training Loss: 11.3000\n",
      "Epoch 19, Step 124, Training Loss: 11.4734\n",
      "Epoch 19, Step 125, Training Loss: 11.8611\n",
      "Epoch 19, Step 126, Training Loss: 8.6858\n",
      "Epoch 19, Step 127, Training Loss: 14.2183\n",
      "Epoch 19, Step 128, Training Loss: 7.2455\n",
      "Epoch 19, Step 129, Training Loss: 13.9977\n",
      "Epoch 19, Step 130, Training Loss: 5.4265\n",
      "Epoch 19, Step 131, Training Loss: 10.4453\n",
      "Epoch 19, Step 132, Training Loss: 13.9891\n",
      "Epoch 19, Step 133, Training Loss: 31.8687\n",
      "Epoch 19, Step 134, Training Loss: 13.9463\n",
      "Epoch 19, Step 135, Training Loss: 10.2413\n",
      "Epoch 19, Step 136, Training Loss: 36.3982\n",
      "Epoch 19, Step 137, Training Loss: 9.2958\n",
      "Epoch 19, Step 138, Training Loss: 9.0267\n",
      "Epoch 19, Step 139, Training Loss: 10.9848\n",
      "Epoch 19, Step 140, Training Loss: 9.5138\n",
      "Epoch 19, Step 141, Training Loss: 14.3982\n",
      "Epoch 19, Step 142, Training Loss: 8.1258\n",
      "Epoch 19, Step 143, Training Loss: 8.2372\n",
      "Epoch 19, Step 144, Training Loss: 4.9432\n",
      "Epoch 19, Step 145, Training Loss: 9.3184\n",
      "Epoch 19, Step 146, Training Loss: 8.8972\n",
      "Epoch 19, Step 147, Training Loss: 10.8358\n",
      "Epoch 19, Step 148, Training Loss: 40.9146\n",
      "Epoch 19, Step 149, Training Loss: 14.3106\n",
      "Epoch 19, Step 150, Training Loss: 13.1142\n",
      "Epoch 19, Step 151, Training Loss: 6.9714\n",
      "Epoch 19, Step 152, Training Loss: 6.8877\n",
      "Epoch 19, Step 153, Training Loss: 8.2523\n",
      "Epoch 19, Step 154, Training Loss: 7.8358\n",
      "Epoch 19, Step 155, Training Loss: 14.0470\n",
      "Epoch 19, Step 156, Training Loss: 8.6078\n",
      "Epoch 19, Step 157, Training Loss: 17.3509\n",
      "Epoch 19, Step 158, Training Loss: 9.7741\n",
      "Epoch 19, Step 159, Training Loss: 16.6751\n",
      "Epoch 19, Step 160, Training Loss: 37.0427\n",
      "Epoch 19, Step 161, Training Loss: 8.2570\n",
      "Epoch 19, Step 162, Training Loss: 6.8461\n",
      "Epoch 19, Step 163, Training Loss: 6.0024\n",
      "Epoch 19, Step 164, Training Loss: 6.3680\n",
      "Epoch 19, Step 165, Training Loss: 12.6772\n",
      "Epoch 19, Step 166, Training Loss: 8.6098\n",
      "Epoch 19, Step 167, Training Loss: 9.5713\n",
      "Epoch 19, Step 168, Training Loss: 13.1420\n",
      "Epoch 19, Step 169, Training Loss: 6.0415\n",
      "Epoch 19, Step 170, Training Loss: 9.2558\n",
      "Epoch 19, Step 171, Training Loss: 7.4915\n",
      "Epoch 19, Step 172, Training Loss: 12.4686\n",
      "Epoch 19, Step 173, Training Loss: 11.4143\n",
      "Epoch 19, Step 174, Training Loss: 7.7877\n",
      "Epoch 19, Step 175, Training Loss: 12.0523\n",
      "Epoch 19, Step 176, Training Loss: 9.6685\n",
      "Epoch 19, Step 177, Training Loss: 16.4250\n",
      "Epoch 19, Step 178, Training Loss: 7.9233\n",
      "Epoch 19, Step 179, Training Loss: 5.7040\n",
      "Epoch 19, Step 180, Training Loss: 10.9077\n",
      "Epoch 19, Step 181, Training Loss: 7.4038\n",
      "Epoch 19, Step 182, Training Loss: 11.8279\n",
      "Epoch 19, Step 183, Training Loss: 8.7859\n",
      "Epoch 19, Step 184, Training Loss: 8.4480\n",
      "Epoch 19, Step 185, Training Loss: 12.0380\n",
      "Epoch 19, Step 186, Training Loss: 13.3011\n",
      "Epoch 19, Step 187, Training Loss: 6.9435\n",
      "Epoch 19, Step 188, Training Loss: 97.0017\n",
      "Epoch 19, Step 189, Training Loss: 9.2608\n",
      "Epoch 19, Step 190, Training Loss: 82.0361\n",
      "Epoch 19, Step 191, Training Loss: 8.2583\n",
      "Epoch 19, Step 192, Training Loss: 9.8619\n",
      "Epoch 19, Step 193, Training Loss: 10.5654\n",
      "Epoch 19, Step 194, Training Loss: 9.5603\n",
      "Epoch 19, Step 195, Training Loss: 11.5609\n",
      "Epoch 19, Step 196, Training Loss: 12.3610\n",
      "Epoch 19, Step 197, Training Loss: 11.6577\n",
      "Epoch 19, Step 198, Training Loss: 8.1653\n",
      "Epoch 19, Step 199, Training Loss: 7.5553\n",
      "Epoch 19, Step 200, Training Loss: 6.6484\n",
      "Epoch 19, Step 201, Training Loss: 8.6411\n",
      "Epoch 19, Step 202, Training Loss: 8.7418\n",
      "Epoch 19, Step 203, Training Loss: 27.8136\n",
      "Epoch 19, Step 204, Training Loss: 17.5793\n",
      "Epoch 19, Step 205, Training Loss: 10.9914\n",
      "Epoch 19, Step 206, Training Loss: 12.8951\n",
      "--- Epoch 19, Validation Loss: 12.2516 ---\n",
      "Epoch 20, Step 0, Training Loss: 10.5884\n",
      "Epoch 20, Step 1, Training Loss: 13.0467\n",
      "Epoch 20, Step 2, Training Loss: 8.3617\n",
      "Epoch 20, Step 3, Training Loss: 25.3106\n",
      "Epoch 20, Step 4, Training Loss: 30.0033\n",
      "Epoch 20, Step 5, Training Loss: 6.3277\n",
      "Epoch 20, Step 6, Training Loss: 10.1023\n",
      "Epoch 20, Step 7, Training Loss: 11.5816\n",
      "Epoch 20, Step 8, Training Loss: 6.4748\n",
      "Epoch 20, Step 9, Training Loss: 9.4538\n",
      "Epoch 20, Step 10, Training Loss: 19.5053\n",
      "Epoch 20, Step 11, Training Loss: 11.9270\n",
      "Epoch 20, Step 12, Training Loss: 10.7715\n",
      "Epoch 20, Step 13, Training Loss: 32.8756\n",
      "Epoch 20, Step 14, Training Loss: 9.6277\n",
      "Epoch 20, Step 15, Training Loss: 9.6519\n",
      "Epoch 20, Step 16, Training Loss: 10.1451\n",
      "Epoch 20, Step 17, Training Loss: 8.5469\n",
      "Epoch 20, Step 18, Training Loss: 10.6045\n",
      "Epoch 20, Step 19, Training Loss: 27.3651\n",
      "Epoch 20, Step 20, Training Loss: 7.4803\n",
      "Epoch 20, Step 21, Training Loss: 11.4968\n",
      "Epoch 20, Step 22, Training Loss: 17.6374\n",
      "Epoch 20, Step 23, Training Loss: 11.1123\n",
      "Epoch 20, Step 24, Training Loss: 10.0230\n",
      "Epoch 20, Step 25, Training Loss: 11.0643\n",
      "Epoch 20, Step 26, Training Loss: 13.0639\n",
      "Epoch 20, Step 27, Training Loss: 12.0675\n",
      "Epoch 20, Step 28, Training Loss: 8.9728\n",
      "Epoch 20, Step 29, Training Loss: 7.5839\n",
      "Epoch 20, Step 30, Training Loss: 8.3768\n",
      "Epoch 20, Step 31, Training Loss: 7.7819\n",
      "Epoch 20, Step 32, Training Loss: 8.6309\n",
      "Epoch 20, Step 33, Training Loss: 9.8100\n",
      "Epoch 20, Step 34, Training Loss: 10.0482\n",
      "Epoch 20, Step 35, Training Loss: 8.6419\n",
      "Epoch 20, Step 36, Training Loss: 13.5573\n",
      "Epoch 20, Step 37, Training Loss: 23.1587\n",
      "Epoch 20, Step 38, Training Loss: 11.7468\n",
      "Epoch 20, Step 39, Training Loss: 8.8975\n",
      "Epoch 20, Step 40, Training Loss: 11.1570\n",
      "Epoch 20, Step 41, Training Loss: 14.0743\n",
      "Epoch 20, Step 42, Training Loss: 9.8407\n",
      "Epoch 20, Step 43, Training Loss: 10.1901\n",
      "Epoch 20, Step 44, Training Loss: 12.9346\n",
      "Epoch 20, Step 45, Training Loss: 9.7624\n",
      "Epoch 20, Step 46, Training Loss: 7.8812\n",
      "Epoch 20, Step 47, Training Loss: 10.2936\n",
      "Epoch 20, Step 48, Training Loss: 8.0652\n",
      "Epoch 20, Step 49, Training Loss: 10.5751\n",
      "Epoch 20, Step 50, Training Loss: 5.5005\n",
      "Epoch 20, Step 51, Training Loss: 7.6809\n",
      "Epoch 20, Step 52, Training Loss: 9.5401\n",
      "Epoch 20, Step 53, Training Loss: 9.3091\n",
      "Epoch 20, Step 54, Training Loss: 9.0668\n",
      "Epoch 20, Step 55, Training Loss: 11.6830\n",
      "Epoch 20, Step 56, Training Loss: 16.7461\n",
      "Epoch 20, Step 57, Training Loss: 7.6696\n",
      "Epoch 20, Step 58, Training Loss: 13.2516\n",
      "Epoch 20, Step 59, Training Loss: 8.3578\n",
      "Epoch 20, Step 60, Training Loss: 41.2327\n",
      "Epoch 20, Step 61, Training Loss: 12.2898\n",
      "Epoch 20, Step 62, Training Loss: 12.1121\n",
      "Epoch 20, Step 63, Training Loss: 27.0287\n",
      "Epoch 20, Step 64, Training Loss: 8.8558\n",
      "Epoch 20, Step 65, Training Loss: 7.9295\n",
      "Epoch 20, Step 66, Training Loss: 9.5604\n",
      "Epoch 20, Step 67, Training Loss: 13.1672\n",
      "Epoch 20, Step 68, Training Loss: 6.6098\n",
      "Epoch 20, Step 69, Training Loss: 24.3863\n",
      "Epoch 20, Step 70, Training Loss: 9.7670\n",
      "Epoch 20, Step 71, Training Loss: 7.5541\n",
      "Epoch 20, Step 72, Training Loss: 13.2032\n",
      "Epoch 20, Step 73, Training Loss: 10.7224\n",
      "Epoch 20, Step 74, Training Loss: 12.7634\n",
      "Epoch 20, Step 75, Training Loss: 26.4312\n",
      "Epoch 20, Step 76, Training Loss: 21.9409\n",
      "Epoch 20, Step 77, Training Loss: 13.3521\n",
      "Epoch 20, Step 78, Training Loss: 8.4394\n",
      "Epoch 20, Step 79, Training Loss: 11.5354\n",
      "Epoch 20, Step 80, Training Loss: 14.9003\n",
      "Epoch 20, Step 81, Training Loss: 23.2851\n",
      "Epoch 20, Step 82, Training Loss: 11.0925\n",
      "Epoch 20, Step 83, Training Loss: 30.9291\n",
      "Epoch 20, Step 84, Training Loss: 25.6629\n",
      "Epoch 20, Step 85, Training Loss: 6.7464\n",
      "Epoch 20, Step 86, Training Loss: 10.4710\n",
      "Epoch 20, Step 87, Training Loss: 11.6214\n",
      "Epoch 20, Step 88, Training Loss: 11.0572\n",
      "Epoch 20, Step 89, Training Loss: 13.3907\n",
      "Epoch 20, Step 90, Training Loss: 12.7716\n",
      "Epoch 20, Step 91, Training Loss: 8.1278\n",
      "Epoch 20, Step 92, Training Loss: 13.2206\n",
      "Epoch 20, Step 93, Training Loss: 7.9946\n",
      "Epoch 20, Step 94, Training Loss: 21.9070\n",
      "Epoch 20, Step 95, Training Loss: 6.7146\n",
      "Epoch 20, Step 96, Training Loss: 7.7018\n",
      "Epoch 20, Step 97, Training Loss: 6.4645\n",
      "Epoch 20, Step 98, Training Loss: 14.7305\n",
      "Epoch 20, Step 99, Training Loss: 26.9847\n",
      "Epoch 20, Step 100, Training Loss: 9.8372\n",
      "Epoch 20, Step 101, Training Loss: 6.1416\n",
      "Epoch 20, Step 102, Training Loss: 9.8764\n",
      "Epoch 20, Step 103, Training Loss: 8.9030\n",
      "Epoch 20, Step 104, Training Loss: 10.2052\n",
      "Epoch 20, Step 105, Training Loss: 7.5915\n",
      "Epoch 20, Step 106, Training Loss: 11.3942\n",
      "Epoch 20, Step 107, Training Loss: 12.1735\n",
      "Epoch 20, Step 108, Training Loss: 7.0653\n",
      "Epoch 20, Step 109, Training Loss: 8.1795\n",
      "Epoch 20, Step 110, Training Loss: 8.8975\n",
      "Epoch 20, Step 111, Training Loss: 9.1907\n",
      "Epoch 20, Step 112, Training Loss: 7.4295\n",
      "Epoch 20, Step 113, Training Loss: 8.5325\n",
      "Epoch 20, Step 114, Training Loss: 7.7265\n",
      "Epoch 20, Step 115, Training Loss: 14.8354\n",
      "Epoch 20, Step 116, Training Loss: 8.8003\n",
      "Epoch 20, Step 117, Training Loss: 9.8811\n",
      "Epoch 20, Step 118, Training Loss: 5.8297\n",
      "Epoch 20, Step 119, Training Loss: 6.5703\n",
      "Epoch 20, Step 120, Training Loss: 11.7039\n",
      "Epoch 20, Step 121, Training Loss: 21.4269\n",
      "Epoch 20, Step 122, Training Loss: 31.6288\n",
      "Epoch 20, Step 123, Training Loss: 11.7144\n",
      "Epoch 20, Step 124, Training Loss: 11.8165\n",
      "Epoch 20, Step 125, Training Loss: 13.3849\n",
      "Epoch 20, Step 126, Training Loss: 9.3831\n",
      "Epoch 20, Step 127, Training Loss: 13.5980\n",
      "Epoch 20, Step 128, Training Loss: 8.4932\n",
      "Epoch 20, Step 129, Training Loss: 14.2465\n",
      "Epoch 20, Step 130, Training Loss: 6.1047\n",
      "Epoch 20, Step 131, Training Loss: 10.6254\n",
      "Epoch 20, Step 132, Training Loss: 16.0944\n",
      "Epoch 20, Step 133, Training Loss: 32.2477\n",
      "Epoch 20, Step 134, Training Loss: 17.4948\n",
      "Epoch 20, Step 135, Training Loss: 8.6317\n",
      "Epoch 20, Step 136, Training Loss: 31.7143\n",
      "Epoch 20, Step 137, Training Loss: 6.5980\n",
      "Epoch 20, Step 138, Training Loss: 8.1308\n",
      "Epoch 20, Step 139, Training Loss: 13.9820\n",
      "Epoch 20, Step 140, Training Loss: 7.8223\n",
      "Epoch 20, Step 141, Training Loss: 14.5907\n",
      "Epoch 20, Step 142, Training Loss: 8.4066\n",
      "Epoch 20, Step 143, Training Loss: 8.7262\n",
      "Epoch 20, Step 144, Training Loss: 7.1529\n",
      "Epoch 20, Step 145, Training Loss: 7.8832\n",
      "Epoch 20, Step 146, Training Loss: 11.1663\n",
      "Epoch 20, Step 147, Training Loss: 9.1877\n",
      "Epoch 20, Step 148, Training Loss: 40.8009\n",
      "Epoch 20, Step 149, Training Loss: 13.3271\n",
      "Epoch 20, Step 150, Training Loss: 12.0084\n",
      "Epoch 20, Step 151, Training Loss: 6.1426\n",
      "Epoch 20, Step 152, Training Loss: 7.9131\n",
      "Epoch 20, Step 153, Training Loss: 9.6484\n",
      "Epoch 20, Step 154, Training Loss: 14.1079\n",
      "Epoch 20, Step 155, Training Loss: 11.4588\n",
      "Epoch 20, Step 156, Training Loss: 9.5046\n",
      "Epoch 20, Step 157, Training Loss: 15.1085\n",
      "Epoch 20, Step 158, Training Loss: 8.4922\n",
      "Epoch 20, Step 159, Training Loss: 14.9433\n",
      "Epoch 20, Step 160, Training Loss: 35.4387\n",
      "Epoch 20, Step 161, Training Loss: 6.0754\n",
      "Epoch 20, Step 162, Training Loss: 9.2184\n",
      "Epoch 20, Step 163, Training Loss: 9.3986\n",
      "Epoch 20, Step 164, Training Loss: 9.7725\n",
      "Epoch 20, Step 165, Training Loss: 13.0737\n",
      "Epoch 20, Step 166, Training Loss: 10.8618\n",
      "Epoch 20, Step 167, Training Loss: 11.3786\n",
      "Epoch 20, Step 168, Training Loss: 14.9927\n",
      "Epoch 20, Step 169, Training Loss: 7.3813\n",
      "Epoch 20, Step 170, Training Loss: 7.7271\n",
      "Epoch 20, Step 171, Training Loss: 9.2950\n",
      "Epoch 20, Step 172, Training Loss: 10.1468\n",
      "Epoch 20, Step 173, Training Loss: 12.1435\n",
      "Epoch 20, Step 174, Training Loss: 8.2858\n",
      "Epoch 20, Step 175, Training Loss: 11.9180\n",
      "Epoch 20, Step 176, Training Loss: 9.9820\n",
      "Epoch 20, Step 177, Training Loss: 19.6056\n",
      "Epoch 20, Step 178, Training Loss: 9.6882\n",
      "Epoch 20, Step 179, Training Loss: 8.0339\n",
      "Epoch 20, Step 180, Training Loss: 11.7456\n",
      "Epoch 20, Step 181, Training Loss: 8.1147\n",
      "Epoch 20, Step 182, Training Loss: 11.2110\n",
      "Epoch 20, Step 183, Training Loss: 8.1848\n",
      "Epoch 20, Step 184, Training Loss: 6.8679\n",
      "Epoch 20, Step 185, Training Loss: 7.7154\n",
      "Epoch 20, Step 186, Training Loss: 16.5105\n",
      "Epoch 20, Step 187, Training Loss: 6.7913\n",
      "Epoch 20, Step 188, Training Loss: 96.3010\n",
      "Epoch 20, Step 189, Training Loss: 7.6554\n",
      "Epoch 20, Step 190, Training Loss: 82.5047\n",
      "Epoch 20, Step 191, Training Loss: 8.0262\n",
      "Epoch 20, Step 192, Training Loss: 8.5310\n",
      "Epoch 20, Step 193, Training Loss: 13.0411\n",
      "Epoch 20, Step 194, Training Loss: 8.5402\n",
      "Epoch 20, Step 195, Training Loss: 8.7693\n",
      "Epoch 20, Step 196, Training Loss: 20.2702\n",
      "Epoch 20, Step 197, Training Loss: 13.3541\n",
      "Epoch 20, Step 198, Training Loss: 9.7778\n",
      "Epoch 20, Step 199, Training Loss: 6.9164\n",
      "Epoch 20, Step 200, Training Loss: 7.1976\n",
      "Epoch 20, Step 201, Training Loss: 8.8083\n",
      "Epoch 20, Step 202, Training Loss: 10.5347\n",
      "Epoch 20, Step 203, Training Loss: 25.5093\n",
      "Epoch 20, Step 204, Training Loss: 16.3001\n",
      "Epoch 20, Step 205, Training Loss: 9.5803\n",
      "Epoch 20, Step 206, Training Loss: 10.6519\n",
      "--- Epoch 20, Validation Loss: 10.9661 ---\n",
      "Epoch 21, Step 0, Training Loss: 8.1101\n",
      "Epoch 21, Step 1, Training Loss: 11.8746\n",
      "Epoch 21, Step 2, Training Loss: 8.0350\n",
      "Epoch 21, Step 3, Training Loss: 26.4610\n",
      "Epoch 21, Step 4, Training Loss: 22.0115\n",
      "Epoch 21, Step 5, Training Loss: 6.8622\n",
      "Epoch 21, Step 6, Training Loss: 9.2754\n",
      "Epoch 21, Step 7, Training Loss: 8.4065\n",
      "Epoch 21, Step 8, Training Loss: 6.8851\n",
      "Epoch 21, Step 9, Training Loss: 10.4410\n",
      "Epoch 21, Step 10, Training Loss: 15.3649\n",
      "Epoch 21, Step 11, Training Loss: 8.9099\n",
      "Epoch 21, Step 12, Training Loss: 15.1084\n",
      "Epoch 21, Step 13, Training Loss: 37.2561\n",
      "Epoch 21, Step 14, Training Loss: 11.0456\n",
      "Epoch 21, Step 15, Training Loss: 9.8392\n",
      "Epoch 21, Step 16, Training Loss: 8.6789\n",
      "Epoch 21, Step 17, Training Loss: 9.8894\n",
      "Epoch 21, Step 18, Training Loss: 6.5641\n",
      "Epoch 21, Step 19, Training Loss: 25.1485\n",
      "Epoch 21, Step 20, Training Loss: 9.2873\n",
      "Epoch 21, Step 21, Training Loss: 10.9005\n",
      "Epoch 21, Step 22, Training Loss: 16.7964\n",
      "Epoch 21, Step 23, Training Loss: 9.5297\n",
      "Epoch 21, Step 24, Training Loss: 6.4862\n",
      "Epoch 21, Step 25, Training Loss: 9.8505\n",
      "Epoch 21, Step 26, Training Loss: 13.6343\n",
      "Epoch 21, Step 27, Training Loss: 10.4010\n",
      "Epoch 21, Step 28, Training Loss: 9.6240\n",
      "Epoch 21, Step 29, Training Loss: 8.5616\n",
      "Epoch 21, Step 30, Training Loss: 8.5369\n",
      "Epoch 21, Step 31, Training Loss: 6.6726\n",
      "Epoch 21, Step 32, Training Loss: 8.6476\n",
      "Epoch 21, Step 33, Training Loss: 8.4145\n",
      "Epoch 21, Step 34, Training Loss: 8.4219\n",
      "Epoch 21, Step 35, Training Loss: 6.6865\n",
      "Epoch 21, Step 36, Training Loss: 12.0097\n",
      "Epoch 21, Step 37, Training Loss: 22.3194\n",
      "Epoch 21, Step 38, Training Loss: 13.8952\n",
      "Epoch 21, Step 39, Training Loss: 7.3214\n",
      "Epoch 21, Step 40, Training Loss: 12.0315\n",
      "Epoch 21, Step 41, Training Loss: 13.1412\n",
      "Epoch 21, Step 42, Training Loss: 9.6657\n",
      "Epoch 21, Step 43, Training Loss: 9.8537\n",
      "Epoch 21, Step 44, Training Loss: 13.1227\n",
      "Epoch 21, Step 45, Training Loss: 8.5742\n",
      "Epoch 21, Step 46, Training Loss: 9.8232\n",
      "Epoch 21, Step 47, Training Loss: 8.9245\n",
      "Epoch 21, Step 48, Training Loss: 8.5176\n",
      "Epoch 21, Step 49, Training Loss: 8.9525\n",
      "Epoch 21, Step 50, Training Loss: 8.3772\n",
      "Epoch 21, Step 51, Training Loss: 8.8498\n",
      "Epoch 21, Step 52, Training Loss: 9.8868\n",
      "Epoch 21, Step 53, Training Loss: 5.1098\n",
      "Epoch 21, Step 54, Training Loss: 8.7518\n",
      "Epoch 21, Step 55, Training Loss: 9.0478\n",
      "Epoch 21, Step 56, Training Loss: 20.0271\n",
      "Epoch 21, Step 57, Training Loss: 6.4753\n",
      "Epoch 21, Step 58, Training Loss: 13.4348\n",
      "Epoch 21, Step 59, Training Loss: 9.0818\n",
      "Epoch 21, Step 60, Training Loss: 39.8489\n",
      "Epoch 21, Step 61, Training Loss: 10.5564\n",
      "Epoch 21, Step 62, Training Loss: 12.3384\n",
      "Epoch 21, Step 63, Training Loss: 29.5701\n",
      "Epoch 21, Step 64, Training Loss: 9.1170\n",
      "Epoch 21, Step 65, Training Loss: 7.4720\n",
      "Epoch 21, Step 66, Training Loss: 6.3735\n",
      "Epoch 21, Step 67, Training Loss: 8.6006\n",
      "Epoch 21, Step 68, Training Loss: 6.5177\n",
      "Epoch 21, Step 69, Training Loss: 22.3646\n",
      "Epoch 21, Step 70, Training Loss: 9.2881\n",
      "Epoch 21, Step 71, Training Loss: 7.2790\n",
      "Epoch 21, Step 72, Training Loss: 13.2662\n",
      "Epoch 21, Step 73, Training Loss: 10.2957\n",
      "Epoch 21, Step 74, Training Loss: 9.2037\n",
      "Epoch 21, Step 75, Training Loss: 28.9410\n",
      "Epoch 21, Step 76, Training Loss: 21.4742\n",
      "Epoch 21, Step 77, Training Loss: 12.4827\n",
      "Epoch 21, Step 78, Training Loss: 8.0609\n",
      "Epoch 21, Step 79, Training Loss: 11.7496\n",
      "Epoch 21, Step 80, Training Loss: 15.5557\n",
      "Epoch 21, Step 81, Training Loss: 26.5402\n",
      "Epoch 21, Step 82, Training Loss: 10.5960\n",
      "Epoch 21, Step 83, Training Loss: 32.1108\n",
      "Epoch 21, Step 84, Training Loss: 22.4837\n",
      "Epoch 21, Step 85, Training Loss: 6.6662\n",
      "Epoch 21, Step 86, Training Loss: 11.6994\n",
      "Epoch 21, Step 87, Training Loss: 13.0137\n",
      "Epoch 21, Step 88, Training Loss: 14.0674\n",
      "Epoch 21, Step 89, Training Loss: 12.7483\n",
      "Epoch 21, Step 90, Training Loss: 12.2345\n",
      "Epoch 21, Step 91, Training Loss: 8.3813\n",
      "Epoch 21, Step 92, Training Loss: 16.9920\n",
      "Epoch 21, Step 93, Training Loss: 10.0902\n",
      "Epoch 21, Step 94, Training Loss: 20.4738\n",
      "Epoch 21, Step 95, Training Loss: 7.1106\n",
      "Epoch 21, Step 96, Training Loss: 7.6918\n",
      "Epoch 21, Step 97, Training Loss: 6.9333\n",
      "Epoch 21, Step 98, Training Loss: 14.8173\n",
      "Epoch 21, Step 99, Training Loss: 27.0443\n",
      "Epoch 21, Step 100, Training Loss: 10.0265\n",
      "Epoch 21, Step 101, Training Loss: 7.3592\n",
      "Epoch 21, Step 102, Training Loss: 11.7075\n",
      "Epoch 21, Step 103, Training Loss: 8.3455\n",
      "Epoch 21, Step 104, Training Loss: 10.6161\n",
      "Epoch 21, Step 105, Training Loss: 6.8692\n",
      "Epoch 21, Step 106, Training Loss: 14.8976\n",
      "Epoch 21, Step 107, Training Loss: 10.9068\n",
      "Epoch 21, Step 108, Training Loss: 7.8700\n",
      "Epoch 21, Step 109, Training Loss: 9.4065\n",
      "Epoch 21, Step 110, Training Loss: 9.9090\n",
      "Epoch 21, Step 111, Training Loss: 8.7827\n",
      "Epoch 21, Step 112, Training Loss: 7.7888\n",
      "Epoch 21, Step 113, Training Loss: 10.1532\n",
      "Epoch 21, Step 114, Training Loss: 5.0996\n",
      "Epoch 21, Step 115, Training Loss: 13.0453\n",
      "Epoch 21, Step 116, Training Loss: 9.7430\n",
      "Epoch 21, Step 117, Training Loss: 8.7123\n",
      "Epoch 21, Step 118, Training Loss: 6.3727\n",
      "Epoch 21, Step 119, Training Loss: 5.7154\n",
      "Epoch 21, Step 120, Training Loss: 10.8599\n",
      "Epoch 21, Step 121, Training Loss: 21.5597\n",
      "Epoch 21, Step 122, Training Loss: 29.5701\n",
      "Epoch 21, Step 123, Training Loss: 10.1088\n",
      "Epoch 21, Step 124, Training Loss: 11.7691\n",
      "Epoch 21, Step 125, Training Loss: 10.3356\n",
      "Epoch 21, Step 126, Training Loss: 8.5878\n",
      "Epoch 21, Step 127, Training Loss: 16.3785\n",
      "Epoch 21, Step 128, Training Loss: 7.2307\n",
      "Epoch 21, Step 129, Training Loss: 14.5489\n",
      "Epoch 21, Step 130, Training Loss: 6.3504\n",
      "Epoch 21, Step 131, Training Loss: 9.0150\n",
      "Epoch 21, Step 132, Training Loss: 15.2269\n",
      "Epoch 21, Step 133, Training Loss: 34.0120\n",
      "Epoch 21, Step 134, Training Loss: 13.5395\n",
      "Epoch 21, Step 135, Training Loss: 11.7814\n",
      "Epoch 21, Step 136, Training Loss: 31.8117\n",
      "Epoch 21, Step 137, Training Loss: 7.8960\n",
      "Epoch 21, Step 138, Training Loss: 7.5592\n",
      "Epoch 21, Step 139, Training Loss: 17.7119\n",
      "Epoch 21, Step 140, Training Loss: 11.0451\n",
      "Epoch 21, Step 141, Training Loss: 11.5289\n",
      "Epoch 21, Step 142, Training Loss: 7.5602\n",
      "Epoch 21, Step 143, Training Loss: 8.1051\n",
      "Epoch 21, Step 144, Training Loss: 7.8377\n",
      "Epoch 21, Step 145, Training Loss: 8.9783\n",
      "Epoch 21, Step 146, Training Loss: 10.8999\n",
      "Epoch 21, Step 147, Training Loss: 7.7387\n",
      "Epoch 21, Step 148, Training Loss: 41.5693\n",
      "Epoch 21, Step 149, Training Loss: 9.4497\n",
      "Epoch 21, Step 150, Training Loss: 12.1615\n",
      "Epoch 21, Step 151, Training Loss: 8.2534\n",
      "Epoch 21, Step 152, Training Loss: 11.7670\n",
      "Epoch 21, Step 153, Training Loss: 6.4674\n",
      "Epoch 21, Step 154, Training Loss: 7.6165\n",
      "Epoch 21, Step 155, Training Loss: 14.7341\n",
      "Epoch 21, Step 156, Training Loss: 9.4982\n",
      "Epoch 21, Step 157, Training Loss: 14.5284\n",
      "Epoch 21, Step 158, Training Loss: 10.7147\n",
      "Epoch 21, Step 159, Training Loss: 12.2975\n",
      "Epoch 21, Step 160, Training Loss: 37.2210\n",
      "Epoch 21, Step 161, Training Loss: 11.5572\n",
      "Epoch 21, Step 162, Training Loss: 7.7217\n",
      "Epoch 21, Step 163, Training Loss: 8.4009\n",
      "Epoch 21, Step 164, Training Loss: 8.6385\n",
      "Epoch 21, Step 165, Training Loss: 10.6779\n",
      "Epoch 21, Step 166, Training Loss: 8.3076\n",
      "Epoch 21, Step 167, Training Loss: 10.2517\n",
      "Epoch 21, Step 168, Training Loss: 9.9701\n",
      "Epoch 21, Step 169, Training Loss: 5.8117\n",
      "Epoch 21, Step 170, Training Loss: 9.1606\n",
      "Epoch 21, Step 171, Training Loss: 6.8485\n",
      "Epoch 21, Step 172, Training Loss: 11.1945\n",
      "Epoch 21, Step 173, Training Loss: 11.7720\n",
      "Epoch 21, Step 174, Training Loss: 8.3563\n",
      "Epoch 21, Step 175, Training Loss: 10.1583\n",
      "Epoch 21, Step 176, Training Loss: 9.0915\n",
      "Epoch 21, Step 177, Training Loss: 18.5528\n",
      "Epoch 21, Step 178, Training Loss: 8.0479\n",
      "Epoch 21, Step 179, Training Loss: 7.6953\n",
      "Epoch 21, Step 180, Training Loss: 11.4908\n",
      "Epoch 21, Step 181, Training Loss: 6.9079\n",
      "Epoch 21, Step 182, Training Loss: 8.5814\n",
      "Epoch 21, Step 183, Training Loss: 8.0164\n",
      "Epoch 21, Step 184, Training Loss: 6.0817\n",
      "Epoch 21, Step 185, Training Loss: 8.4998\n",
      "Epoch 21, Step 186, Training Loss: 15.3222\n",
      "Epoch 21, Step 187, Training Loss: 6.9694\n",
      "Epoch 21, Step 188, Training Loss: 95.6917\n",
      "Epoch 21, Step 189, Training Loss: 7.7272\n",
      "Epoch 21, Step 190, Training Loss: 79.7437\n",
      "Epoch 21, Step 191, Training Loss: 7.3050\n",
      "Epoch 21, Step 192, Training Loss: 7.8314\n",
      "Epoch 21, Step 193, Training Loss: 11.7470\n",
      "Epoch 21, Step 194, Training Loss: 8.4961\n",
      "Epoch 21, Step 195, Training Loss: 7.3697\n",
      "Epoch 21, Step 196, Training Loss: 15.8796\n",
      "Epoch 21, Step 197, Training Loss: 11.4900\n",
      "Epoch 21, Step 198, Training Loss: 6.4891\n",
      "Epoch 21, Step 199, Training Loss: 8.8682\n",
      "Epoch 21, Step 200, Training Loss: 6.4476\n",
      "Epoch 21, Step 201, Training Loss: 8.0060\n",
      "Epoch 21, Step 202, Training Loss: 9.7224\n",
      "Epoch 21, Step 203, Training Loss: 25.5561\n",
      "Epoch 21, Step 204, Training Loss: 15.8610\n",
      "Epoch 21, Step 205, Training Loss: 11.9634\n",
      "Epoch 21, Step 206, Training Loss: 7.6334\n",
      "--- Epoch 21, Validation Loss: 9.7888 ---\n",
      "Epoch 22, Step 0, Training Loss: 8.5599\n",
      "Epoch 22, Step 1, Training Loss: 10.3470\n",
      "Epoch 22, Step 2, Training Loss: 7.1833\n",
      "Epoch 22, Step 3, Training Loss: 24.7538\n",
      "Epoch 22, Step 4, Training Loss: 22.0945\n",
      "Epoch 22, Step 5, Training Loss: 5.1464\n",
      "Epoch 22, Step 6, Training Loss: 9.0904\n",
      "Epoch 22, Step 7, Training Loss: 9.0147\n",
      "Epoch 22, Step 8, Training Loss: 8.3976\n",
      "Epoch 22, Step 9, Training Loss: 9.6944\n",
      "Epoch 22, Step 10, Training Loss: 29.1536\n",
      "Epoch 22, Step 11, Training Loss: 7.3261\n",
      "Epoch 22, Step 12, Training Loss: 9.6788\n",
      "Epoch 22, Step 13, Training Loss: 34.4288\n",
      "Epoch 22, Step 14, Training Loss: 11.2696\n",
      "Epoch 22, Step 15, Training Loss: 9.2149\n",
      "Epoch 22, Step 16, Training Loss: 6.6497\n",
      "Epoch 22, Step 17, Training Loss: 11.3376\n",
      "Epoch 22, Step 18, Training Loss: 9.8234\n",
      "Epoch 22, Step 19, Training Loss: 26.7088\n",
      "Epoch 22, Step 20, Training Loss: 9.2010\n",
      "Epoch 22, Step 21, Training Loss: 12.9967\n",
      "Epoch 22, Step 22, Training Loss: 15.1144\n",
      "Epoch 22, Step 23, Training Loss: 13.6239\n",
      "Epoch 22, Step 24, Training Loss: 10.8757\n",
      "Epoch 22, Step 25, Training Loss: 11.2764\n",
      "Epoch 22, Step 26, Training Loss: 10.1791\n",
      "Epoch 22, Step 27, Training Loss: 14.9006\n",
      "Epoch 22, Step 28, Training Loss: 10.5584\n",
      "Epoch 22, Step 29, Training Loss: 8.6647\n",
      "Epoch 22, Step 30, Training Loss: 8.3154\n",
      "Epoch 22, Step 31, Training Loss: 7.4731\n",
      "Epoch 22, Step 32, Training Loss: 8.4844\n",
      "Epoch 22, Step 33, Training Loss: 9.1615\n",
      "Epoch 22, Step 34, Training Loss: 10.3086\n",
      "Epoch 22, Step 35, Training Loss: 8.4289\n",
      "Epoch 22, Step 36, Training Loss: 12.9655\n",
      "Epoch 22, Step 37, Training Loss: 23.8179\n",
      "Epoch 22, Step 38, Training Loss: 21.3490\n",
      "Epoch 22, Step 39, Training Loss: 10.2445\n",
      "Epoch 22, Step 40, Training Loss: 11.1767\n",
      "Epoch 22, Step 41, Training Loss: 12.6735\n",
      "Epoch 22, Step 42, Training Loss: 8.7793\n",
      "Epoch 22, Step 43, Training Loss: 11.5947\n",
      "Epoch 22, Step 44, Training Loss: 13.0764\n",
      "Epoch 22, Step 45, Training Loss: 9.7036\n",
      "Epoch 22, Step 46, Training Loss: 13.7871\n",
      "Epoch 22, Step 47, Training Loss: 7.7088\n",
      "Epoch 22, Step 48, Training Loss: 9.5546\n",
      "Epoch 22, Step 49, Training Loss: 11.2649\n",
      "Epoch 22, Step 50, Training Loss: 6.4230\n",
      "Epoch 22, Step 51, Training Loss: 7.6608\n",
      "Epoch 22, Step 52, Training Loss: 9.4293\n",
      "Epoch 22, Step 53, Training Loss: 5.4580\n",
      "Epoch 22, Step 54, Training Loss: 9.3803\n",
      "Epoch 22, Step 55, Training Loss: 12.4384\n",
      "Epoch 22, Step 56, Training Loss: 17.5124\n",
      "Epoch 22, Step 57, Training Loss: 7.2435\n",
      "Epoch 22, Step 58, Training Loss: 13.7408\n",
      "Epoch 22, Step 59, Training Loss: 8.4362\n",
      "Epoch 22, Step 60, Training Loss: 38.5656\n",
      "Epoch 22, Step 61, Training Loss: 7.0144\n",
      "Epoch 22, Step 62, Training Loss: 12.7800\n",
      "Epoch 22, Step 63, Training Loss: 26.8909\n",
      "Epoch 22, Step 64, Training Loss: 8.6559\n",
      "Epoch 22, Step 65, Training Loss: 6.4387\n",
      "Epoch 22, Step 66, Training Loss: 7.5056\n",
      "Epoch 22, Step 67, Training Loss: 10.2268\n",
      "Epoch 22, Step 68, Training Loss: 10.5057\n",
      "Epoch 22, Step 69, Training Loss: 17.0293\n",
      "Epoch 22, Step 70, Training Loss: 5.5733\n",
      "Epoch 22, Step 71, Training Loss: 6.6287\n",
      "Epoch 22, Step 72, Training Loss: 11.6627\n",
      "Epoch 22, Step 73, Training Loss: 11.3888\n",
      "Epoch 22, Step 74, Training Loss: 11.9936\n",
      "Epoch 22, Step 75, Training Loss: 26.1179\n",
      "Epoch 22, Step 76, Training Loss: 18.8798\n",
      "Epoch 22, Step 77, Training Loss: 11.9496\n",
      "Epoch 22, Step 78, Training Loss: 6.8694\n",
      "Epoch 22, Step 79, Training Loss: 16.2156\n",
      "Epoch 22, Step 80, Training Loss: 13.4368\n",
      "Epoch 22, Step 81, Training Loss: 22.2649\n",
      "Epoch 22, Step 82, Training Loss: 9.6459\n",
      "Epoch 22, Step 83, Training Loss: 33.6834\n",
      "Epoch 22, Step 84, Training Loss: 21.1875\n",
      "Epoch 22, Step 85, Training Loss: 6.0689\n",
      "Epoch 22, Step 86, Training Loss: 11.1416\n",
      "Epoch 22, Step 87, Training Loss: 11.0201\n",
      "Epoch 22, Step 88, Training Loss: 10.4192\n",
      "Epoch 22, Step 89, Training Loss: 11.5012\n",
      "Epoch 22, Step 90, Training Loss: 9.7884\n",
      "Epoch 22, Step 91, Training Loss: 7.4591\n",
      "Epoch 22, Step 92, Training Loss: 14.1497\n",
      "Epoch 22, Step 93, Training Loss: 9.7066\n",
      "Epoch 22, Step 94, Training Loss: 19.2816\n",
      "Epoch 22, Step 95, Training Loss: 6.6484\n",
      "Epoch 22, Step 96, Training Loss: 8.5552\n",
      "Epoch 22, Step 97, Training Loss: 9.3218\n",
      "Epoch 22, Step 98, Training Loss: 13.6678\n",
      "Epoch 22, Step 99, Training Loss: 27.7078\n",
      "Epoch 22, Step 100, Training Loss: 10.4927\n",
      "Epoch 22, Step 101, Training Loss: 7.4365\n",
      "Epoch 22, Step 102, Training Loss: 8.9726\n",
      "Epoch 22, Step 103, Training Loss: 8.3094\n",
      "Epoch 22, Step 104, Training Loss: 10.1567\n",
      "Epoch 22, Step 105, Training Loss: 5.7322\n",
      "Epoch 22, Step 106, Training Loss: 13.0118\n",
      "Epoch 22, Step 107, Training Loss: 13.5278\n",
      "Epoch 22, Step 108, Training Loss: 6.5617\n",
      "Epoch 22, Step 109, Training Loss: 7.5016\n",
      "Epoch 22, Step 110, Training Loss: 10.5283\n",
      "Epoch 22, Step 111, Training Loss: 8.0521\n",
      "Epoch 22, Step 112, Training Loss: 7.6289\n",
      "Epoch 22, Step 113, Training Loss: 7.9124\n",
      "Epoch 22, Step 114, Training Loss: 6.7284\n",
      "Epoch 22, Step 115, Training Loss: 12.1299\n",
      "Epoch 22, Step 116, Training Loss: 6.5392\n",
      "Epoch 22, Step 117, Training Loss: 9.7359\n",
      "Epoch 22, Step 118, Training Loss: 5.2549\n",
      "Epoch 22, Step 119, Training Loss: 7.4412\n",
      "Epoch 22, Step 120, Training Loss: 10.9824\n",
      "Epoch 22, Step 121, Training Loss: 22.3660\n",
      "Epoch 22, Step 122, Training Loss: 28.9830\n",
      "Epoch 22, Step 123, Training Loss: 9.5310\n",
      "Epoch 22, Step 124, Training Loss: 10.9247\n",
      "Epoch 22, Step 125, Training Loss: 12.0201\n",
      "Epoch 22, Step 126, Training Loss: 10.1547\n",
      "Epoch 22, Step 127, Training Loss: 12.4926\n",
      "Epoch 22, Step 128, Training Loss: 6.3072\n",
      "Epoch 22, Step 129, Training Loss: 13.1831\n",
      "Epoch 22, Step 130, Training Loss: 5.7449\n",
      "Epoch 22, Step 131, Training Loss: 9.4916\n",
      "Epoch 22, Step 132, Training Loss: 14.5313\n",
      "Epoch 22, Step 133, Training Loss: 30.7488\n",
      "Epoch 22, Step 134, Training Loss: 14.4567\n",
      "Epoch 22, Step 135, Training Loss: 8.0193\n",
      "Epoch 22, Step 136, Training Loss: 33.6766\n",
      "Epoch 22, Step 137, Training Loss: 5.9985\n",
      "Epoch 22, Step 138, Training Loss: 6.0267\n",
      "Epoch 22, Step 139, Training Loss: 8.9638\n",
      "Epoch 22, Step 140, Training Loss: 8.5870\n",
      "Epoch 22, Step 141, Training Loss: 10.9874\n",
      "Epoch 22, Step 142, Training Loss: 7.6831\n",
      "Epoch 22, Step 143, Training Loss: 7.0637\n",
      "Epoch 22, Step 144, Training Loss: 6.5305\n",
      "Epoch 22, Step 145, Training Loss: 6.6410\n",
      "Epoch 22, Step 146, Training Loss: 9.6180\n",
      "Epoch 22, Step 147, Training Loss: 11.1362\n",
      "Epoch 22, Step 148, Training Loss: 57.9432\n",
      "Epoch 22, Step 149, Training Loss: 15.5552\n",
      "Epoch 22, Step 150, Training Loss: 11.1823\n",
      "Epoch 22, Step 151, Training Loss: 9.9942\n",
      "Epoch 22, Step 152, Training Loss: 8.7712\n",
      "Epoch 22, Step 153, Training Loss: 7.0719\n",
      "Epoch 22, Step 154, Training Loss: 9.2278\n",
      "Epoch 22, Step 155, Training Loss: 13.6204\n",
      "Epoch 22, Step 156, Training Loss: 11.6480\n",
      "Epoch 22, Step 157, Training Loss: 17.3419\n",
      "Epoch 22, Step 158, Training Loss: 7.7411\n",
      "Epoch 22, Step 159, Training Loss: 13.7562\n",
      "Epoch 22, Step 160, Training Loss: 38.2102\n",
      "Epoch 22, Step 161, Training Loss: 10.8971\n",
      "Epoch 22, Step 162, Training Loss: 6.7868\n",
      "Epoch 22, Step 163, Training Loss: 7.8951\n",
      "Epoch 22, Step 164, Training Loss: 7.2884\n",
      "Epoch 22, Step 165, Training Loss: 13.1839\n",
      "Epoch 22, Step 166, Training Loss: 6.7900\n",
      "Epoch 22, Step 167, Training Loss: 10.8475\n",
      "Epoch 22, Step 168, Training Loss: 10.9615\n",
      "Epoch 22, Step 169, Training Loss: 7.4968\n",
      "Epoch 22, Step 170, Training Loss: 6.2687\n",
      "Epoch 22, Step 171, Training Loss: 6.3436\n",
      "Epoch 22, Step 172, Training Loss: 10.4976\n",
      "Epoch 22, Step 173, Training Loss: 13.5123\n",
      "Epoch 22, Step 174, Training Loss: 8.9663\n",
      "Epoch 22, Step 175, Training Loss: 10.1960\n",
      "Epoch 22, Step 176, Training Loss: 9.6902\n",
      "Epoch 22, Step 177, Training Loss: 20.2289\n",
      "Epoch 22, Step 178, Training Loss: 9.3196\n",
      "Epoch 22, Step 179, Training Loss: 6.0151\n",
      "Epoch 22, Step 180, Training Loss: 9.7682\n",
      "Epoch 22, Step 181, Training Loss: 5.6940\n",
      "Epoch 22, Step 182, Training Loss: 8.1981\n",
      "Epoch 22, Step 183, Training Loss: 10.2992\n",
      "Epoch 22, Step 184, Training Loss: 7.8479\n",
      "Epoch 22, Step 185, Training Loss: 8.8269\n",
      "Epoch 22, Step 186, Training Loss: 14.6090\n",
      "Epoch 22, Step 187, Training Loss: 5.7953\n",
      "Epoch 22, Step 188, Training Loss: 94.8370\n",
      "Epoch 22, Step 189, Training Loss: 10.0407\n",
      "Epoch 22, Step 190, Training Loss: 80.6929\n",
      "Epoch 22, Step 191, Training Loss: 7.8878\n",
      "Epoch 22, Step 192, Training Loss: 10.3858\n",
      "Epoch 22, Step 193, Training Loss: 11.2220\n",
      "Epoch 22, Step 194, Training Loss: 10.0344\n",
      "Epoch 22, Step 195, Training Loss: 7.0291\n",
      "Epoch 22, Step 196, Training Loss: 7.4735\n",
      "Epoch 22, Step 197, Training Loss: 10.6429\n",
      "Epoch 22, Step 198, Training Loss: 6.7933\n",
      "Epoch 22, Step 199, Training Loss: 7.2742\n",
      "Epoch 22, Step 200, Training Loss: 8.2656\n",
      "Epoch 22, Step 201, Training Loss: 9.9517\n",
      "Epoch 22, Step 202, Training Loss: 7.7137\n",
      "Epoch 22, Step 203, Training Loss: 26.0739\n",
      "Epoch 22, Step 204, Training Loss: 14.2065\n",
      "Epoch 22, Step 205, Training Loss: 11.3544\n",
      "Epoch 22, Step 206, Training Loss: 7.0275\n",
      "--- Epoch 22, Validation Loss: 9.8054 ---\n",
      "Epoch 23, Step 0, Training Loss: 8.1782\n",
      "Epoch 23, Step 1, Training Loss: 7.4901\n",
      "Epoch 23, Step 2, Training Loss: 7.5087\n",
      "Epoch 23, Step 3, Training Loss: 23.3015\n",
      "Epoch 23, Step 4, Training Loss: 26.9677\n",
      "Epoch 23, Step 5, Training Loss: 7.8994\n",
      "Epoch 23, Step 6, Training Loss: 9.9129\n",
      "Epoch 23, Step 7, Training Loss: 8.5450\n",
      "Epoch 23, Step 8, Training Loss: 6.9986\n",
      "Epoch 23, Step 9, Training Loss: 9.6492\n",
      "Epoch 23, Step 10, Training Loss: 22.6353\n",
      "Epoch 23, Step 11, Training Loss: 10.2168\n",
      "Epoch 23, Step 12, Training Loss: 9.7520\n",
      "Epoch 23, Step 13, Training Loss: 33.7141\n",
      "Epoch 23, Step 14, Training Loss: 11.9671\n",
      "Epoch 23, Step 15, Training Loss: 10.5033\n",
      "Epoch 23, Step 16, Training Loss: 7.5584\n",
      "Epoch 23, Step 17, Training Loss: 7.3823\n",
      "Epoch 23, Step 18, Training Loss: 10.0960\n",
      "Epoch 23, Step 19, Training Loss: 26.2615\n",
      "Epoch 23, Step 20, Training Loss: 7.6215\n",
      "Epoch 23, Step 21, Training Loss: 10.1271\n",
      "Epoch 23, Step 22, Training Loss: 16.9941\n",
      "Epoch 23, Step 23, Training Loss: 9.6520\n",
      "Epoch 23, Step 24, Training Loss: 8.2633\n",
      "Epoch 23, Step 25, Training Loss: 10.1403\n",
      "Epoch 23, Step 26, Training Loss: 9.2449\n",
      "Epoch 23, Step 27, Training Loss: 9.8525\n",
      "Epoch 23, Step 28, Training Loss: 9.5984\n",
      "Epoch 23, Step 29, Training Loss: 8.0639\n",
      "Epoch 23, Step 30, Training Loss: 7.7334\n",
      "Epoch 23, Step 31, Training Loss: 7.2883\n",
      "Epoch 23, Step 32, Training Loss: 8.9776\n",
      "Epoch 23, Step 33, Training Loss: 8.6944\n",
      "Epoch 23, Step 34, Training Loss: 8.2924\n",
      "Epoch 23, Step 35, Training Loss: 6.2582\n",
      "Epoch 23, Step 36, Training Loss: 12.0634\n",
      "Epoch 23, Step 37, Training Loss: 26.7732\n",
      "Epoch 23, Step 38, Training Loss: 13.2839\n",
      "Epoch 23, Step 39, Training Loss: 7.1643\n",
      "Epoch 23, Step 40, Training Loss: 11.2942\n",
      "Epoch 23, Step 41, Training Loss: 12.3671\n",
      "Epoch 23, Step 42, Training Loss: 7.0779\n",
      "Epoch 23, Step 43, Training Loss: 10.7989\n",
      "Epoch 23, Step 44, Training Loss: 11.5008\n",
      "Epoch 23, Step 45, Training Loss: 8.0875\n",
      "Epoch 23, Step 46, Training Loss: 9.4489\n",
      "Epoch 23, Step 47, Training Loss: 8.5604\n",
      "Epoch 23, Step 48, Training Loss: 9.1336\n",
      "Epoch 23, Step 49, Training Loss: 11.6040\n",
      "Epoch 23, Step 50, Training Loss: 8.6457\n",
      "Epoch 23, Step 51, Training Loss: 6.6102\n",
      "Epoch 23, Step 52, Training Loss: 8.2265\n",
      "Epoch 23, Step 53, Training Loss: 6.1114\n",
      "Epoch 23, Step 54, Training Loss: 9.2104\n",
      "Epoch 23, Step 55, Training Loss: 11.0880\n",
      "Epoch 23, Step 56, Training Loss: 15.4468\n",
      "Epoch 23, Step 57, Training Loss: 5.4453\n",
      "Epoch 23, Step 58, Training Loss: 10.1660\n",
      "Epoch 23, Step 59, Training Loss: 7.4203\n",
      "Epoch 23, Step 60, Training Loss: 41.0898\n",
      "Epoch 23, Step 61, Training Loss: 8.5378\n",
      "Epoch 23, Step 62, Training Loss: 9.9084\n",
      "Epoch 23, Step 63, Training Loss: 27.6242\n",
      "Epoch 23, Step 64, Training Loss: 6.1483\n",
      "Epoch 23, Step 65, Training Loss: 7.6326\n",
      "Epoch 23, Step 66, Training Loss: 5.3893\n",
      "Epoch 23, Step 67, Training Loss: 9.4680\n",
      "Epoch 23, Step 68, Training Loss: 8.1889\n",
      "Epoch 23, Step 69, Training Loss: 17.4802\n",
      "Epoch 23, Step 70, Training Loss: 8.7671\n",
      "Epoch 23, Step 71, Training Loss: 8.6117\n",
      "Epoch 23, Step 72, Training Loss: 11.4263\n",
      "Epoch 23, Step 73, Training Loss: 8.3797\n",
      "Epoch 23, Step 74, Training Loss: 10.0941\n",
      "Epoch 23, Step 75, Training Loss: 29.3025\n",
      "Epoch 23, Step 76, Training Loss: 21.1077\n",
      "Epoch 23, Step 77, Training Loss: 13.4141\n",
      "Epoch 23, Step 78, Training Loss: 6.0181\n",
      "Epoch 23, Step 79, Training Loss: 12.2173\n",
      "Epoch 23, Step 80, Training Loss: 14.6249\n",
      "Epoch 23, Step 81, Training Loss: 21.4303\n",
      "Epoch 23, Step 82, Training Loss: 7.7297\n",
      "Epoch 23, Step 83, Training Loss: 32.4108\n",
      "Epoch 23, Step 84, Training Loss: 21.5940\n",
      "Epoch 23, Step 85, Training Loss: 9.8421\n",
      "Epoch 23, Step 86, Training Loss: 9.8516\n",
      "Epoch 23, Step 87, Training Loss: 9.1987\n",
      "Epoch 23, Step 88, Training Loss: 11.9242\n",
      "Epoch 23, Step 89, Training Loss: 12.2513\n",
      "Epoch 23, Step 90, Training Loss: 10.5661\n",
      "Epoch 23, Step 91, Training Loss: 8.1410\n",
      "Epoch 23, Step 92, Training Loss: 17.1541\n",
      "Epoch 23, Step 93, Training Loss: 10.5443\n",
      "Epoch 23, Step 94, Training Loss: 19.0955\n",
      "Epoch 23, Step 95, Training Loss: 8.3778\n",
      "Epoch 23, Step 96, Training Loss: 7.7291\n",
      "Epoch 23, Step 97, Training Loss: 8.2102\n",
      "Epoch 23, Step 98, Training Loss: 12.6268\n",
      "Epoch 23, Step 99, Training Loss: 28.0465\n",
      "Epoch 23, Step 100, Training Loss: 8.9030\n",
      "Epoch 23, Step 101, Training Loss: 7.2206\n",
      "Epoch 23, Step 102, Training Loss: 8.5668\n",
      "Epoch 23, Step 103, Training Loss: 7.5408\n",
      "Epoch 23, Step 104, Training Loss: 9.4018\n",
      "Epoch 23, Step 105, Training Loss: 8.0213\n",
      "Epoch 23, Step 106, Training Loss: 10.4940\n",
      "Epoch 23, Step 107, Training Loss: 13.9827\n",
      "Epoch 23, Step 108, Training Loss: 8.0233\n",
      "Epoch 23, Step 109, Training Loss: 7.6937\n",
      "Epoch 23, Step 110, Training Loss: 10.8464\n",
      "Epoch 23, Step 111, Training Loss: 7.2701\n",
      "Epoch 23, Step 112, Training Loss: 8.2043\n",
      "Epoch 23, Step 113, Training Loss: 8.9779\n",
      "Epoch 23, Step 114, Training Loss: 7.3616\n",
      "Epoch 23, Step 115, Training Loss: 9.8880\n",
      "Epoch 23, Step 116, Training Loss: 9.0837\n",
      "Epoch 23, Step 117, Training Loss: 6.3701\n",
      "Epoch 23, Step 118, Training Loss: 7.9916\n",
      "Epoch 23, Step 119, Training Loss: 8.5331\n",
      "Epoch 23, Step 120, Training Loss: 8.9412\n",
      "Epoch 23, Step 121, Training Loss: 18.8497\n",
      "Epoch 23, Step 122, Training Loss: 28.2759\n",
      "Epoch 23, Step 123, Training Loss: 9.4244\n",
      "Epoch 23, Step 124, Training Loss: 15.1701\n",
      "Epoch 23, Step 125, Training Loss: 9.7262\n",
      "Epoch 23, Step 126, Training Loss: 9.0822\n",
      "Epoch 23, Step 127, Training Loss: 12.0807\n",
      "Epoch 23, Step 128, Training Loss: 5.5434\n",
      "Epoch 23, Step 129, Training Loss: 12.9642\n",
      "Epoch 23, Step 130, Training Loss: 6.8912\n",
      "Epoch 23, Step 131, Training Loss: 10.4782\n",
      "Epoch 23, Step 132, Training Loss: 11.6151\n",
      "Epoch 23, Step 133, Training Loss: 32.9341\n",
      "Epoch 23, Step 134, Training Loss: 13.8546\n",
      "Epoch 23, Step 135, Training Loss: 11.7654\n",
      "Epoch 23, Step 136, Training Loss: 28.4883\n",
      "Epoch 23, Step 137, Training Loss: 7.1626\n",
      "Epoch 23, Step 138, Training Loss: 8.8740\n",
      "Epoch 23, Step 139, Training Loss: 13.1582\n",
      "Epoch 23, Step 140, Training Loss: 9.1871\n",
      "Epoch 23, Step 141, Training Loss: 11.0220\n",
      "Epoch 23, Step 142, Training Loss: 8.0326\n",
      "Epoch 23, Step 143, Training Loss: 8.5617\n",
      "Epoch 23, Step 144, Training Loss: 6.2900\n",
      "Epoch 23, Step 145, Training Loss: 8.8395\n",
      "Epoch 23, Step 146, Training Loss: 10.9183\n",
      "Epoch 23, Step 147, Training Loss: 7.3688\n",
      "Epoch 23, Step 148, Training Loss: 35.2566\n",
      "Epoch 23, Step 149, Training Loss: 8.2986\n",
      "Epoch 23, Step 150, Training Loss: 13.4698\n",
      "Epoch 23, Step 151, Training Loss: 9.1385\n",
      "Epoch 23, Step 152, Training Loss: 8.0935\n",
      "Epoch 23, Step 153, Training Loss: 6.8997\n",
      "Epoch 23, Step 154, Training Loss: 7.2482\n",
      "Epoch 23, Step 155, Training Loss: 14.8525\n",
      "Epoch 23, Step 156, Training Loss: 8.5463\n",
      "Epoch 23, Step 157, Training Loss: 13.6236\n",
      "Epoch 23, Step 158, Training Loss: 8.7630\n",
      "Epoch 23, Step 159, Training Loss: 11.3792\n",
      "Epoch 23, Step 160, Training Loss: 36.3996\n",
      "Epoch 23, Step 161, Training Loss: 9.5583\n",
      "Epoch 23, Step 162, Training Loss: 6.1546\n",
      "Epoch 23, Step 163, Training Loss: 8.2256\n",
      "Epoch 23, Step 164, Training Loss: 10.2164\n",
      "Epoch 23, Step 165, Training Loss: 10.0830\n",
      "Epoch 23, Step 166, Training Loss: 9.5316\n",
      "Epoch 23, Step 167, Training Loss: 10.3125\n",
      "Epoch 23, Step 168, Training Loss: 9.5377\n",
      "Epoch 23, Step 169, Training Loss: 7.5762\n",
      "Epoch 23, Step 170, Training Loss: 7.9414\n",
      "Epoch 23, Step 171, Training Loss: 7.2390\n",
      "Epoch 23, Step 172, Training Loss: 10.7162\n",
      "Epoch 23, Step 173, Training Loss: 10.5022\n",
      "Epoch 23, Step 174, Training Loss: 6.8894\n",
      "Epoch 23, Step 175, Training Loss: 10.9787\n",
      "Epoch 23, Step 176, Training Loss: 9.7143\n",
      "Epoch 23, Step 177, Training Loss: 17.4042\n",
      "Epoch 23, Step 178, Training Loss: 7.3700\n",
      "Epoch 23, Step 179, Training Loss: 4.8269\n",
      "Epoch 23, Step 180, Training Loss: 12.5318\n",
      "Epoch 23, Step 181, Training Loss: 5.7717\n",
      "Epoch 23, Step 182, Training Loss: 11.0792\n",
      "Epoch 23, Step 183, Training Loss: 9.7923\n",
      "Epoch 23, Step 184, Training Loss: 5.3604\n",
      "Epoch 23, Step 185, Training Loss: 9.0708\n",
      "Epoch 23, Step 186, Training Loss: 14.3323\n",
      "Epoch 23, Step 187, Training Loss: 7.4919\n",
      "Epoch 23, Step 188, Training Loss: 95.3647\n",
      "Epoch 23, Step 189, Training Loss: 8.3817\n",
      "Epoch 23, Step 190, Training Loss: 76.1110\n",
      "Epoch 23, Step 191, Training Loss: 8.9262\n",
      "Epoch 23, Step 192, Training Loss: 8.5984\n",
      "Epoch 23, Step 193, Training Loss: 10.9289\n",
      "Epoch 23, Step 194, Training Loss: 10.9630\n",
      "Epoch 23, Step 195, Training Loss: 8.7687\n",
      "Epoch 23, Step 196, Training Loss: 9.5203\n",
      "Epoch 23, Step 197, Training Loss: 12.4929\n",
      "Epoch 23, Step 198, Training Loss: 6.4553\n",
      "Epoch 23, Step 199, Training Loss: 7.2749\n",
      "Epoch 23, Step 200, Training Loss: 7.5678\n",
      "Epoch 23, Step 201, Training Loss: 8.7971\n",
      "Epoch 23, Step 202, Training Loss: 9.0314\n",
      "Epoch 23, Step 203, Training Loss: 27.0466\n",
      "Epoch 23, Step 204, Training Loss: 13.8901\n",
      "Epoch 23, Step 205, Training Loss: 7.6811\n",
      "Epoch 23, Step 206, Training Loss: 9.2677\n",
      "--- Epoch 23, Validation Loss: 10.3339 ---\n",
      "Epoch 24, Step 0, Training Loss: 7.8360\n",
      "Epoch 24, Step 1, Training Loss: 10.2830\n",
      "Epoch 24, Step 2, Training Loss: 6.4853\n",
      "Epoch 24, Step 3, Training Loss: 26.5116\n",
      "Epoch 24, Step 4, Training Loss: 18.7703\n",
      "Epoch 24, Step 5, Training Loss: 7.5484\n",
      "Epoch 24, Step 6, Training Loss: 8.7273\n",
      "Epoch 24, Step 7, Training Loss: 8.8988\n",
      "Epoch 24, Step 8, Training Loss: 5.4013\n",
      "Epoch 24, Step 9, Training Loss: 9.2917\n",
      "Epoch 24, Step 10, Training Loss: 17.4227\n",
      "Epoch 24, Step 11, Training Loss: 9.4215\n",
      "Epoch 24, Step 12, Training Loss: 10.6247\n",
      "Epoch 24, Step 13, Training Loss: 36.1341\n",
      "Epoch 24, Step 14, Training Loss: 11.4812\n",
      "Epoch 24, Step 15, Training Loss: 8.6037\n",
      "Epoch 24, Step 16, Training Loss: 9.4664\n",
      "Epoch 24, Step 17, Training Loss: 8.7960\n",
      "Epoch 24, Step 18, Training Loss: 8.3216\n",
      "Epoch 24, Step 19, Training Loss: 26.6713\n",
      "Epoch 24, Step 20, Training Loss: 6.6051\n",
      "Epoch 24, Step 21, Training Loss: 11.2829\n",
      "Epoch 24, Step 22, Training Loss: 13.3883\n",
      "Epoch 24, Step 23, Training Loss: 11.6398\n",
      "Epoch 24, Step 24, Training Loss: 9.5158\n",
      "Epoch 24, Step 25, Training Loss: 12.2457\n",
      "Epoch 24, Step 26, Training Loss: 11.2314\n",
      "Epoch 24, Step 27, Training Loss: 9.7712\n",
      "Epoch 24, Step 28, Training Loss: 8.0226\n",
      "Epoch 24, Step 29, Training Loss: 5.2085\n",
      "Epoch 24, Step 30, Training Loss: 8.4790\n",
      "Epoch 24, Step 31, Training Loss: 11.4790\n",
      "Epoch 24, Step 32, Training Loss: 11.2110\n",
      "Epoch 24, Step 33, Training Loss: 7.8996\n",
      "Epoch 24, Step 34, Training Loss: 8.7327\n",
      "Epoch 24, Step 35, Training Loss: 9.3027\n",
      "Epoch 24, Step 36, Training Loss: 14.8233\n",
      "Epoch 24, Step 37, Training Loss: 21.8393\n",
      "Epoch 24, Step 38, Training Loss: 14.7161\n",
      "Epoch 24, Step 39, Training Loss: 6.2303\n",
      "Epoch 24, Step 40, Training Loss: 9.5924\n",
      "Epoch 24, Step 41, Training Loss: 13.9372\n",
      "Epoch 24, Step 42, Training Loss: 9.7897\n",
      "Epoch 24, Step 43, Training Loss: 8.8049\n",
      "Epoch 24, Step 44, Training Loss: 11.0780\n",
      "Epoch 24, Step 45, Training Loss: 6.8198\n",
      "Epoch 24, Step 46, Training Loss: 10.8025\n",
      "Epoch 24, Step 47, Training Loss: 7.4881\n",
      "Epoch 24, Step 48, Training Loss: 7.0325\n",
      "Epoch 24, Step 49, Training Loss: 9.5021\n",
      "Epoch 24, Step 50, Training Loss: 5.7039\n",
      "Epoch 24, Step 51, Training Loss: 6.2455\n",
      "Epoch 24, Step 52, Training Loss: 10.0740\n",
      "Epoch 24, Step 53, Training Loss: 9.5933\n",
      "Epoch 24, Step 54, Training Loss: 8.5419\n",
      "Epoch 24, Step 55, Training Loss: 8.5510\n",
      "Epoch 24, Step 56, Training Loss: 14.6838\n",
      "Epoch 24, Step 57, Training Loss: 5.6185\n",
      "Epoch 24, Step 58, Training Loss: 10.2347\n",
      "Epoch 24, Step 59, Training Loss: 7.7985\n",
      "Epoch 24, Step 60, Training Loss: 38.4292\n",
      "Epoch 24, Step 61, Training Loss: 9.2258\n",
      "Epoch 24, Step 62, Training Loss: 12.3617\n",
      "Epoch 24, Step 63, Training Loss: 29.5379\n",
      "Epoch 24, Step 64, Training Loss: 6.1122\n",
      "Epoch 24, Step 65, Training Loss: 6.6889\n",
      "Epoch 24, Step 66, Training Loss: 8.3934\n",
      "Epoch 24, Step 67, Training Loss: 9.5838\n",
      "Epoch 24, Step 68, Training Loss: 6.6155\n",
      "Epoch 24, Step 69, Training Loss: 15.9853\n",
      "Epoch 24, Step 70, Training Loss: 7.9706\n",
      "Epoch 24, Step 71, Training Loss: 8.2150\n",
      "Epoch 24, Step 72, Training Loss: 10.5384\n",
      "Epoch 24, Step 73, Training Loss: 8.6109\n",
      "Epoch 24, Step 74, Training Loss: 10.5802\n",
      "Epoch 24, Step 75, Training Loss: 27.1573\n",
      "Epoch 24, Step 76, Training Loss: 19.0523\n",
      "Epoch 24, Step 77, Training Loss: 11.7108\n",
      "Epoch 24, Step 78, Training Loss: 7.2150\n",
      "Epoch 24, Step 79, Training Loss: 14.2913\n",
      "Epoch 24, Step 80, Training Loss: 15.2943\n",
      "Epoch 24, Step 81, Training Loss: 20.4652\n",
      "Epoch 24, Step 82, Training Loss: 8.1565\n",
      "Epoch 24, Step 83, Training Loss: 32.8532\n",
      "Epoch 24, Step 84, Training Loss: 18.8450\n",
      "Epoch 24, Step 85, Training Loss: 5.2582\n",
      "Epoch 24, Step 86, Training Loss: 11.2858\n",
      "Epoch 24, Step 87, Training Loss: 10.3718\n",
      "Epoch 24, Step 88, Training Loss: 9.8853\n",
      "Epoch 24, Step 89, Training Loss: 11.1999\n",
      "Epoch 24, Step 90, Training Loss: 10.8358\n",
      "Epoch 24, Step 91, Training Loss: 6.1491\n",
      "Epoch 24, Step 92, Training Loss: 12.8915\n",
      "Epoch 24, Step 93, Training Loss: 8.8473\n",
      "Epoch 24, Step 94, Training Loss: 20.3774\n",
      "Epoch 24, Step 95, Training Loss: 6.6768\n",
      "Epoch 24, Step 96, Training Loss: 9.4087\n",
      "Epoch 24, Step 97, Training Loss: 8.9933\n",
      "Epoch 24, Step 98, Training Loss: 12.4188\n",
      "Epoch 24, Step 99, Training Loss: 26.6293\n",
      "Epoch 24, Step 100, Training Loss: 10.6960\n",
      "Epoch 24, Step 101, Training Loss: 5.3679\n",
      "Epoch 24, Step 102, Training Loss: 9.6158\n",
      "Epoch 24, Step 103, Training Loss: 8.1073\n",
      "Epoch 24, Step 104, Training Loss: 12.4033\n",
      "Epoch 24, Step 105, Training Loss: 6.3302\n",
      "Epoch 24, Step 106, Training Loss: 13.9592\n",
      "Epoch 24, Step 107, Training Loss: 11.8886\n",
      "Epoch 24, Step 108, Training Loss: 8.3398\n",
      "Epoch 24, Step 109, Training Loss: 7.4181\n",
      "Epoch 24, Step 110, Training Loss: 8.0760\n",
      "Epoch 24, Step 111, Training Loss: 6.8150\n",
      "Epoch 24, Step 112, Training Loss: 7.2765\n",
      "Epoch 24, Step 113, Training Loss: 8.9557\n",
      "Epoch 24, Step 114, Training Loss: 5.5866\n",
      "Epoch 24, Step 115, Training Loss: 14.0717\n",
      "Epoch 24, Step 116, Training Loss: 8.3582\n",
      "Epoch 24, Step 117, Training Loss: 8.5941\n",
      "Epoch 24, Step 118, Training Loss: 5.9410\n",
      "Epoch 24, Step 119, Training Loss: 7.4653\n",
      "Epoch 24, Step 120, Training Loss: 10.1280\n",
      "Epoch 24, Step 121, Training Loss: 20.1817\n",
      "Epoch 24, Step 122, Training Loss: 26.6388\n",
      "Epoch 24, Step 123, Training Loss: 10.8442\n",
      "Epoch 24, Step 124, Training Loss: 12.7862\n",
      "Epoch 24, Step 125, Training Loss: 8.9709\n",
      "Epoch 24, Step 126, Training Loss: 7.9516\n",
      "Epoch 24, Step 127, Training Loss: 13.6506\n",
      "Epoch 24, Step 128, Training Loss: 7.9748\n",
      "Epoch 24, Step 129, Training Loss: 11.0531\n",
      "Epoch 24, Step 130, Training Loss: 7.0071\n",
      "Epoch 24, Step 131, Training Loss: 9.7532\n",
      "Epoch 24, Step 132, Training Loss: 14.4947\n",
      "Epoch 24, Step 133, Training Loss: 32.7175\n",
      "Epoch 24, Step 134, Training Loss: 13.7897\n",
      "Epoch 24, Step 135, Training Loss: 11.1699\n",
      "Epoch 24, Step 136, Training Loss: 27.9014\n",
      "Epoch 24, Step 137, Training Loss: 7.3394\n",
      "Epoch 24, Step 138, Training Loss: 9.2833\n",
      "Epoch 24, Step 139, Training Loss: 10.1081\n",
      "Epoch 24, Step 140, Training Loss: 6.7445\n",
      "Epoch 24, Step 141, Training Loss: 9.2015\n",
      "Epoch 24, Step 142, Training Loss: 10.0530\n",
      "Epoch 24, Step 143, Training Loss: 7.5833\n",
      "Epoch 24, Step 144, Training Loss: 5.1631\n",
      "Epoch 24, Step 145, Training Loss: 9.1117\n",
      "Epoch 24, Step 146, Training Loss: 8.4584\n",
      "Epoch 24, Step 147, Training Loss: 6.9394\n",
      "Epoch 24, Step 148, Training Loss: 38.1612\n",
      "Epoch 24, Step 149, Training Loss: 9.0722\n",
      "Epoch 24, Step 150, Training Loss: 12.4774\n",
      "Epoch 24, Step 151, Training Loss: 6.5780\n",
      "Epoch 24, Step 152, Training Loss: 4.2799\n",
      "Epoch 24, Step 153, Training Loss: 7.6713\n",
      "Epoch 24, Step 154, Training Loss: 6.2174\n",
      "Epoch 24, Step 155, Training Loss: 14.2598\n",
      "Epoch 24, Step 156, Training Loss: 8.9161\n",
      "Epoch 24, Step 157, Training Loss: 13.3857\n",
      "Epoch 24, Step 158, Training Loss: 9.0047\n",
      "Epoch 24, Step 159, Training Loss: 14.7088\n",
      "Epoch 24, Step 160, Training Loss: 35.6016\n",
      "Epoch 24, Step 161, Training Loss: 10.8820\n",
      "Epoch 24, Step 162, Training Loss: 6.2229\n",
      "Epoch 24, Step 163, Training Loss: 9.5575\n",
      "Epoch 24, Step 164, Training Loss: 7.8688\n",
      "Epoch 24, Step 165, Training Loss: 9.5991\n",
      "Epoch 24, Step 166, Training Loss: 7.2000\n",
      "Epoch 24, Step 167, Training Loss: 9.8951\n",
      "Epoch 24, Step 168, Training Loss: 14.8915\n",
      "Epoch 24, Step 169, Training Loss: 6.1882\n",
      "Epoch 24, Step 170, Training Loss: 9.3690\n",
      "Epoch 24, Step 171, Training Loss: 7.0020\n",
      "Epoch 24, Step 172, Training Loss: 9.6149\n",
      "Epoch 24, Step 173, Training Loss: 13.2065\n",
      "Epoch 24, Step 174, Training Loss: 8.1019\n",
      "Epoch 24, Step 175, Training Loss: 10.5930\n",
      "Epoch 24, Step 176, Training Loss: 8.2261\n",
      "Epoch 24, Step 177, Training Loss: 15.1635\n",
      "Epoch 24, Step 178, Training Loss: 8.3561\n",
      "Epoch 24, Step 179, Training Loss: 5.6988\n",
      "Epoch 24, Step 180, Training Loss: 9.8891\n",
      "Epoch 24, Step 181, Training Loss: 5.9665\n",
      "Epoch 24, Step 182, Training Loss: 9.3725\n",
      "Epoch 24, Step 183, Training Loss: 9.1503\n",
      "Epoch 24, Step 184, Training Loss: 4.9717\n",
      "Epoch 24, Step 185, Training Loss: 8.4793\n",
      "Epoch 24, Step 186, Training Loss: 13.6927\n",
      "Epoch 24, Step 187, Training Loss: 7.3310\n",
      "Epoch 24, Step 188, Training Loss: 98.6411\n",
      "Epoch 24, Step 189, Training Loss: 8.2061\n",
      "Epoch 24, Step 190, Training Loss: 81.7960\n",
      "Epoch 24, Step 191, Training Loss: 6.6006\n",
      "Epoch 24, Step 192, Training Loss: 9.7809\n",
      "Epoch 24, Step 193, Training Loss: 13.4283\n",
      "Epoch 24, Step 194, Training Loss: 7.8025\n",
      "Epoch 24, Step 195, Training Loss: 12.9310\n",
      "Epoch 24, Step 196, Training Loss: 10.7471\n",
      "Epoch 24, Step 197, Training Loss: 10.8939\n",
      "Epoch 24, Step 198, Training Loss: 5.9125\n",
      "Epoch 24, Step 199, Training Loss: 6.6664\n",
      "Epoch 24, Step 200, Training Loss: 8.0554\n",
      "Epoch 24, Step 201, Training Loss: 8.0686\n",
      "Epoch 24, Step 202, Training Loss: 7.4565\n",
      "Epoch 24, Step 203, Training Loss: 27.5978\n",
      "Epoch 24, Step 204, Training Loss: 14.8640\n",
      "Epoch 24, Step 205, Training Loss: 7.9100\n",
      "Epoch 24, Step 206, Training Loss: 8.2303\n",
      "--- Epoch 24, Validation Loss: 9.9737 ---\n"
     ]
    }
   ],
   "source": [
    "#### CONTINUE TRAINING + 25 epoch\n",
    "\n",
    "for epoch in range(25):\n",
    "\n",
    "    efficientnetb0.train()\n",
    "    for step, (images, keypoints) in enumerate(cour_keypoints_train_dataloader):\n",
    "\n",
    "        images = images.to(device)\n",
    "        keypoints = keypoints.to(device) # Moving to GPU\n",
    "\n",
    "        optimizer.zero_grad() # Flush gradients\n",
    "        outputs = efficientnetb0(images) # Get output of a model\n",
    "        loss = mse_loss( outputs, keypoints ) # Coompute loss \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        print(f'Epoch {epoch}, Step {step}, Training Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "    efficientnetb0.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, keypoints in cour_keypoints_val_dataloader:\n",
    "\n",
    "            images = images.to(device)\n",
    "            keypoints = keypoints.to(device)\n",
    "            outputs = efficientnetb0(images)\n",
    "  \n",
    "            val_loss_computed = mse_loss( outputs, keypoints )\n",
    "            val_loss += val_loss_computed.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(cour_keypoints_val_dataloader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        print(f'--- Epoch {epoch}, Validation Loss: {avg_val_loss:.4f} ---')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "235ce02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "000833f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert step-wise training losses to per-epoch average\n",
    "steps_per_epoch = len(cour_keypoints_train_dataloader)\n",
    "train_losses_per_epoch = [\n",
    "    np.mean(train_losses[i * steps_per_epoch: (i + 1) * steps_per_epoch])\n",
    "    for i in range(25)\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_losses_per_epoch, label='Avg Training Loss (per epoch)', marker='o')\n",
    "plt.plot(val_losses, label='Validation Loss (per epoch)', marker='s')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40a37d0",
   "metadata": {},
   "source": [
    "#### TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "27d43a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = r\"C:\\Users\\User\\Downloads\\test_image.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "358ac45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(test_image_path)\n",
    "images = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "h, w = image.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ebc898b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7cdfe67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = transform(image).unsqueeze(0).to(device)  # Add batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7bae7e55-7bf3-4055-b8a7-8453e0e76e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnetb0.eval()\n",
    "with torch.no_grad():\n",
    "    pred = efficientnetb0(input_tensor).cpu().numpy().reshape(-1, 2)  # shape: (14, 2)\n",
    "\n",
    "\n",
    "pred[:, 0] *= w / 224.0  # x coordinates\n",
    "pred[:, 1] *= h / 224.0  # y coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "43085e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(image)\n",
    "plt.scatter(pred[:, 0], pred[:, 1], c='red', s=30)\n",
    "plt.title('Predicted Keypoints')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6b2b45f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 699 frames, saved to C:\\Users\\User\\Desktop\\tennis assistant\\efficientnet_keypoint_detection\\annotated_output.mp4\n"
     ]
    }
   ],
   "source": [
    "# Video path\n",
    "video_path = r\"C:\\Users\\User\\Downloads\\tennis_game_sample2.mp4\"\n",
    "\n",
    "# Output video (optional)\n",
    "output_path = r\"C:\\Users\\User\\Desktop\\tennis assistant\\efficientnet_keypoint_detection\\annotated_output.mp4\"\n",
    "\n",
    "# Transformation (same as training)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# OpenCV video reader/writer\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get video info\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# (Optional) Setup video writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "# Model in eval mode\n",
    "efficientnetb0.eval()\n",
    "\n",
    "frame_count = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    original = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    h, w = original.shape[:2]\n",
    "\n",
    "    # Preprocess\n",
    "    img_tensor = transform(original).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = efficientnetb0(img_tensor).cpu().numpy().reshape(-1, 2)\n",
    "\n",
    "    # Scale keypoints to original image\n",
    "    pred[:, 0] *= w / 224.0\n",
    "    pred[:, 1] *= h / 224.0\n",
    "\n",
    "    # Draw keypoints\n",
    "    for (x, y) in pred.astype(np.int32):\n",
    "        cv2.circle(frame, (x, y), 4, (0, 0, 255), -1)\n",
    "\n",
    "    # Write or show\n",
    "    out.write(frame)  # write to output file\n",
    "    frame_count += 1\n",
    "\n",
    "    # Optional: preview in real time (press q to quit)\n",
    "    cv2.imshow(\"Keypoints\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Processed {frame_count} frames, saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dc68acec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = next(efficientnetb0.parameters()).device\n",
    "print(f\"Model is on: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "21f94400",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnetb0 = efficientnetb0.to('cpu')\n",
    "torch.save(efficientnetb0.state_dict(), r\"C:\\Users\\User\\Desktop\\tennis assistant\\models\\efficientnetb0_tennis_court_keypoints.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00025c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e41725f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e003e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
